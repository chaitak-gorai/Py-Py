<Paper ID = 10> <Table 0> <Abstractive Summary> =ComparedtotheMF
models,GBSrunsonetotwoordersofmagnitude
Table 3: Evaluation Results for nocaps. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 10>


<Paper ID = 10> <Table 1> <Abstractive Summary> =T5-Base+G 438m 16.9 645m 23.4 93m 4.4
T5-Base+MF 19m 1 10m 1 18m 1
T5-Base 17m 1 8m 1 16m 1
Results Mention Flags achieve optimal con-
Table 4: Efﬁciency of the MF and GBS model. </Abstractive Summary> <Extractive Summary> elssharethesameimplementationoftheT5-Base
models,exceptthatitisnotinitializedwiththepre-
trainedparametersanditonlyuses3layers,rather Results Table 1 shows that the MF model im-
than 12 layers, for both encoder and decoder.  </Extractive Summary>  </Table 1>  </Paper ID = 10>


<Paper ID = 10> <Table 2> <Abstractive Summary> =MF 25.6 79.9 11.9 98.3
Here,theMFmodelscansatisfynovelconstraints,
Table 5: Ablation Study For MF Status. </Abstractive Summary> <Extractive Summary> Followingthis,wepropose
to ﬁrst select salient objects and incorporate the
Results Table 2 shows that the MF models con-
selectedobjectsintothedescriptionusingMention
sistentlyachievehigheroutputtextqualityandcon- Flags.  </Extractive Summary>  </Table 2>  </Paper ID = 10>


<Paper ID = 10> <Table 3> <Abstractive Summary> =We thank anonymous reviewers for their insight-
Table 7: Representative examples illustrate successful
ful suggestions to improve this paper. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 10>


<Paper ID = 1000> <Table 0> <Abstractive Summary> =Table 1: Example post-statement and post-question pairs from our manually annotated dataset (Section 3.1) ad-
dressingissuedrelatedto(a,b)academicanxiety;(c)testanxiety;and(d)loneliness
tal results (Section 5) and conclude (Section 6). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1000>


<Paper ID = 1000> <Table 1> <Abstractive Summary> =4Model ROUGE-1 ROUGE-2 ROUGE-L BLEU METEOR BertScore
DialoGPT 0.5587 0.4369 0.5525 0.5010 0.5135 0.4954
DialoGPT+ 0.5740 0.4656 0.5681 0.5038 0.5303 0.5127
GlobalEncoding 0.4114 0.2588 0.4031 0.3200 0.3347 0.3511
GlobalEncoding+ 0.6136 0.5079 0.6073 0.5449 0.5738 0.5508
mT5 0.5004 0.4133 0.4960 0.4102 0.4332 0.4276
mT5+ 0.5550 0.4787 0.5520 0.4751 0.5051 0.4712
BertSum 0.5013 0.3171 0.4938 0.4315 0.3986 0.3618
BertSum+ 0.7184 0.6362 0.7142 0.6518 0.6881 0.6647
OracleRetrieval 0.6902 0.6011 0.6932 0.6709 0.6878 0.6604
Table 4: Model performance on restatement generation (the + superscript means the training set includes the
automaticallygenerateddata)
Model ROUGE-1 ROUGE-2 ROUGE-L BLEU METEOR BertScore
DialoGPT 0.4252 0.2601 0.4160 0.4157 0.3605 0.4273
DialoGPT+ 0.3952 0.2360 0.3848 0.3803 0.3251 0.3905
GlobalEncoding 0.3845 0.2085 0.3766 0.3658 0.3082 0.3820
GlobalEncoding+ 0.4073 0.2516 0.3990 0.3887 0.3372 0.4004
mT5 0.3807 0.2415 0.3699 0.3669 0.3184 0.4152
mT5+ 0.3564 0.2293 0.3472 0.3338 0.2975 0.3932
BertSum 0.3676 0.1718 0.3602 0.3568 0.2591 0.2992
BertSum+ 0.4752 0.3171 0.4665 0.4390 0.4002 0.4658
OracleRetrieval 0.6597 0.5612 0.6538 0.6401 0.6111 0.6626
Table5: Modelperformanceonquestiongeneration(the+superscriptmeansthetrainingsetincludestheautomat-
icallygenerateddata)
Whenaugmentedwiththeautomaticallymined likewiseconﬁguredtheBertSum+ (random)model
dataset,BertSum+ againshowedsigniﬁcantgains to randomly choose 27.1% of the posts to reply
inperformance. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1000>


<Paper ID = 1002> <Table 0> <Abstractive Summary> =Withthisinmind,
3.65 2.97
perpaper andforthesakeofabroaderanalysisofresearch
impact, we include into our consideration other
Table 3: Explicit vs. Non-explicit NLP4SG papers
NLP4SG dimensions such as ethics, social good
statistics. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1002>


<Paper ID = 1004> <Table 0> <Abstractive Summary> =Incomparison,
Waysofprotection (cid:51) (cid:51) (cid:51)
Vaccineinformation (cid:51)∗ (cid:51) (cid:55) Theanotriestoovercomethefallback,bysuggest-
Chitchat (cid:51) (cid:51) (cid:55) ingthetopicsthatsheisawareof,withoutexplain-
ingwhyshecouldnotrespondtothespeciﬁcques-
Table 2: Comparison of supported features of Clara,
tion. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1004>


<Paper ID = 1010> <Table 0> <Abstractive Summary> =Because scholarly understanding of the
Encouragereﬂections Criticalthinking
detailed language in curricular versus job docu-
ments is still limited, we assume that the overall
Table 1: Example rubric of course design features
semantictextsimilaritybetweenthemmightreﬂect
mappedtogeneralcompetencies
latentaspectsofeducation-occupationalignment
such as culture or values. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1010>


<Paper ID = 1011> <Table 0> <Abstractive Summary> =Thiswouldprovide
deeperinsightintowhethertheindividualcanvo- Table 1: Counts of dialogue act tags in the ALS
calize a particular communicative function or if Dataset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1011>


<Paper ID = 1011> <Table 1> <Abstractive Summary> =However,
SWBD AAC 0.341 2.787 thelow38.6%accuracyofthismodelreﬂectsthe
factthatourcurrentAACdatasetisnotadequate
Table 2: We evaluated all three versions of our Dia-
fortrainingastatisticalDialogueActclassiﬁcation
logue Act Classiﬁcation models with a subset of the
model. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1011>


<Paper ID = 1013> <Table 0> <Abstractive Summary> =Thedataset
Table 2: Example tweets exhibiting empathy, distress,
isgroundedinpriorpsychologyliteratureonem-
andsolidarity. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1013>


<Paper ID = 1013> <Table 1> <Abstractive Summary> =supportivePak 85.30% 6.64±270.6 505.61±1378.1
not-supportivePak 14.70% 1.26±24.8 276.28±300.9 Let S = {(cid:104)x,y(cid:105)} such that x ∼ Tsupportive and
y ∼ T , i.e., S consists of tweet pairs
not-supportive
Table 6: Like and retweet behavior and count of sup-
(cid:104)x,y(cid:105)wherexandy arerandomlydrawnfromthe
portiveandnot-supportivetweetsfromPakistan. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1013>


<Paper ID = 1013> <Table 2> <Abstractive Summary> =Weranthis
Table 7: Test performance comparison. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 1013>


<Paper ID = 1013> <Table 3> <Abstractive Summary> =Table 8: Randomly sampled YouTube comments pre-
dictedassupportivebyMBERT inthewild. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 1013>


<Paper ID = 1015> <Table 0> <Abstractive Summary> =The
Table 2: Interaction Mode Prediction Evaluation Re-
datasizeandsplitinformationispresentedinTa-
sults
ble3. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1015>


<Paper ID = 1015> <Table 1> <Abstractive Summary> =The topic classiﬁer, Table 6: Language Model Evaluation. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1015>


<Paper ID = 1015> <Table 2> <Abstractive Summary> =150ankle arm breast
cheeks chin collarbone
earlobe ear elbow
eyebrows eyelashes eyelids
SubReddit QuestionNum eyes ﬁnger foot
AskPhotography 996 forehead groin hair
NoStupidQuestions 912 hand heart hip
AskHistorians 985 intestines jaw knee
askscience 998 lips liver lungs
AskWomen 525 mouth neck nipple
AskReddit 925 nose nostril pancreas
AskUK 781 pelvis rectum ribs
AskMen 200 shin shoulderblade shoulder
AskCulinary 998 spinalcord spine stomach
AskEconomics 560 teeth thigh throat
AskAnAmerican 850 thumb toes tongue
AskALiberal 830 waist wrist
askaconservative 775
Table8: HumanAvatarFrontBodyParts
AskElectronics 842
Ask_Politics 999
AskEngineers 912
askmath 999
AskScienceFiction 652
AskNYC 994
AskTrumpSupporters 357
AskDocs 684
AskAcademia 987
askcarsales 995
ankle anus arm
askphilosophy 981
back brain buttocks
AskSocialScience 487
calf earlobe ear
AskEurope 844
elbow ﬁnger foot
AskLosAngeles 400
heart intestines kidney
AskNetsec 995
knee liver lungs
AskFeminists 978
neck palm pancreas
AskWomenOver30 838
pelvis rectum ribs
scalp shoulderblade shoulder
Table7: Numberofquestionsweextractedfromeach
SubReddit spinalcord spine stomach
thigh thumb wrist
Table 9: Human Avatar Back Body Keywords. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 1015>


<Paper ID = 102> <Table 0> <Abstractive Summary> =Europarl Germanic 11.8 24.8 25.5(+0.7) In the very challenging case of PMIndia (Row
w/ooverlap Romance 13.5 31.0 32.3(+1.3) 5),whileremovingresidualdoesimprovethezero-
shotperformance,thescoreof2.3indicatesthatthe
Table 4: Zero-shot BLEU scores between languages
outputsarestillfarfrombeinguseful. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 102>


<Paper ID = 102> <Table 1> <Abstractive Summary> =Incontrast,ourmodelislesssuscep-
Table 5: Zero-shot BLEU scores by variational
dropout (“+vardrop”) on IWSLT, Europarl non- tibletothisissueandconsistentlystrongerunder
overlap, and PMIndia. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 102>


<Paper ID = 102> <Table 2> <Abstractive Summary> =Table 6: Zero-shot BLEU scores of on a subset of
IWSLT artiﬁcially constructed with little training data
and no shared lexicon. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 102>


<Paper ID = 102> <Table 3> <Abstractive Summary> =Afterresidualremoval,thesimilarityis
Table 8: Accuracy of classiﬁers trained to recover in-
much higher within the Germanic and Romance
put positional information (token ID or position ID)
family. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 102>


<Paper ID = 102> <Table 4> <Abstractive Summary> =Residual 0.650 62.0%
Input ...geveninditverbandhetverkeerde
Table 9: Average pairwise similarity of encoder out-
(nl) voorbeeld,maaranderenhelaasook. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 4>  </Paper ID = 102>


<Paper ID = 102> <Table 5> <Abstractive Summary> =Conﬁrm-
ing our hypotheses, the model outputs are much Table 10: An example of pivoting (nl→en→de) vs
zero-shot (nl→de). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 5>  </Paper ID = 102>


<Paper ID = 1022> <Table 0> <Abstractive Summary> =Weobtained
the ratio of the number of overlapping n-grams allDIREresultsbyre-runningtheauthors’codeon
53Model Accuracy(%)↑ Top-5Accuracy(%)↑ CER↓ JaccardDist↓
DIRE 35.8 41.5 .664 .537
DIRECT 42.8 49.3 .663 .501
Improvement 20% 19% .2% 6.5%
Table 1: Test Accuracy, Top-5 Accuracy (computed by takingthe top 5predictions for each sequence and using
thepredictionsofvariablescontainedinthesesequences),CharacterErrorRateandJaccarddistanceofDIREvs
DIRECT.DIRECToutperformsDIREonallfourmetrics. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1022>


<Paper ID = 1022> <Table 1> <Abstractive Summary> =54Model Accuracy(%)↑ CER↓
Uniformtokenweighting 30.0 .80
Weightingidentiﬁersonly 33.7 .76
ITCweightingscheme 34.4 .75
Table 2: Validation accuracy and Character Error Rate for various token weighting schemes. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1022>


<Paper ID = 1023> <Table 0> <Abstractive Summary> =com/dessertlab/Shellcode_IA32 withourdataset,inordertoassesstheapplicability
60Number Layer BLEU-1 BLEU-2 BLEU-3 BLEU-4
ACC(%)
Layers Dimension (%) (%) (%) (%)
64 75.75 69.76 65.14 60.8 34.69
128 80.80 76.29 73.10 69.69 42.5
1
256 75.50 70.50 66.65 62.86 43.75
512 83.55 80.08 78.06 76.12 51.25
64 63.25 53.24 46.12 39.46 15.62
128 71.79 64.24 58.25 51.65 26.25
2
256 75.13 68.63 63.94 58.93 25.62
512 80.22 75.00 71.11 67.24 43.44
64 61.98 50.68 43.02 36.15 9.38
128 69.75 61.08 55.09 49.18 19.06
3
256 76.93 71.32 67.41 63.50 31.87
512 74.99 68.58 64.23 60.36 29.38
64 61.41 50.68 43.58 37.33 10.00
128 63.26 51.98 44.62 37.57 10.94
4
256 66.94 57.85 51.97 46.87 15.31
512 70.51 62.44 56.27 50.15 18.75
Table 3: Performance results obtained by varying the model hyper-parameters. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1023>


<Paper ID = 1024> <Table 0> <Abstractive Summary> =Whileitisanimprovement, 11https://www.python.org/doc/sunset-python-2/
it is still a 3.76% drop from when the body was 12https://docs.python.org/3/library/2to3.html
70Input BLEU Unigram∗ Bigram∗ Trigram∗ Valid(cid:172)
Baseline 26.24±0.31 67.53±0.46 44.10±0.60 29.80±0.69 84.08±1.27
+Mined 30.55±0.38 67.81±0.23 45.55±0.27 31.69±0.37 93.08±1.28
Body 34.35±1.01 69.97±0.89 49.74±0.99 36.62±0.97 81.44±2.25
-NL 34.06±0.48 68.29±0.48 47.91±0.45 35.33±0.40 81.92±0.75
-Code 27.67±0.40 68.29±0.53 44.93±0.57 30.12±0.69 84.92±1.00
-Blocks 29.53±0.47 68.14±0.26 45.69±0.10 31.36±0.15 80.84±1.37
-Inline 33.57±0.94 70.50±0.27 49.56±0.40 36.54±0.46 82.16±1.53
Body+Mined 35.32±0.42 67.62±0.76 47.69±0.82 35.00±0.87 89.32±1.49
-NL 34.53±0.88 66.24±0.90 46.11±1.15 33.54±1.02 90.08±0.48
-Code 31.39±0.75 67.00±0.75 45.65±0.97 31.60±0.88 92.00±1.31
-Blocks 32.14±0.14 66.96±1.03 45.32±0.97 31.49±0.74 89.24±1.30
-Inline 35.06±0.49 67.04±1.54 46.99±1.29 34.31±1.04 89.20±0.42
Table 4: Ablation Experiments all with BART ran on 5 different random initializations. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1024>


<Paper ID = 1024> <Table 1> <Abstractive Summary> =-Blocks -3.48 -4.16 -0.84 -1.19
4.4 Cheating -Inline 7.93 9.73 1.11 0.25
Insubsection3.3wedeﬁnethe"cheating"equation
Table 6: Cheating Measurements calculated by Equa-
tomeasureifthegeneratedsnippetismoresimilar
tion 2 using a single run but same seed and environ-
tothequestionbodythanthegroundtruthis. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1024>


<Paper ID = 1024> <Table 2> <Abstractive Summary> =Intent:concatenateelementsoflist‘b‘byacolon":"
(cid:51)
""":""".join(str(x) for x in b) 5 Conclusion
(cid:172)
[‘ ‘.join(x) for x in b]
(cid:173) WeexpandtheCoNaLadatasetbyaddingthetex-
b = [int(i) for i in b]
(cid:174) tualquestionbodiesfromtheStackExchangeAPI
print(’:’.join(map(str, b))
and achieve state-of-the-art performance with a
Table 7: Example intents and generated snippets. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 1024>


<Paper ID = 1025> <Table 0> <Abstractive Summary> =We show that these ) as ContQ
JOIN posts p on ContQ.ParentId = p.Id
pairscontainavarietyofreal-worldchallenges WHERE ContQ.ContACnt > (p.AnswerCount / 2) and
whichwererarelyreﬂectedsofarinanyother p.AnswerCount > 1
ORDER BY Score desc
semantic parsing dataset, propose an evalu-
ation metric based on comparison of partial
Table 1: Example from SEDE for a title and descrip-
query clauses that is more suitable for real-
tiongivenbytheuser,togetherwiththeSQLquerythat
world queries, and conduct experiments with
theuserhaswritten. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1025>


<Paper ID = 1025> <Table 1> <Abstractive Summary> =Consider the
andshowthatevenmodelsthatgetstrongresults
example in Table 1: the deﬁnition of “bad an-
onSpider’sdevelopmentset(63.2%Exact-Match,
swers” is not well-deﬁned, and in fact could be
86.3% PCM-F1), perform poorly on our dataset,
subjective. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1025>


<Paper ID = 1025> <Table 2> <Abstractive Summary> =DENSE_RANK() OVER (ORDER BY Reputation DESC)
Quickestnewcontributoranswers
Datesmanipulation 15 0 0 DATEDIFF(s, Q.CreationDate, A.CreationDate)
tonewcontributorquestions
Numerical computations
35 0 0 AverageNumberofViewsperTag sum(p.ViewCount)/count(*)
andtextmanipulation
DECLARE/WITH 11 0 0 Rollbacksbyacertainuser DECLARE @UserId AS int = ##UserId:int##
CASE 10 0 0 Questionsandanswersperyear CASE WHEN Score < 0 THEN 1 ELSE 0 END
Table 2: Dataset characteristics comparison of randomly selected 100 samples among SEDE and other popular
Text-to-SQLdatasets. </Abstractive Summary> <Extractive Summary> awareoftheschema,whicharenotSQL-savy,and
that the person asking the question would be dif-
Comparison In Table 2 we see that a vast ma-
ferentthanthepersonansweringit.  </Extractive Summary>  </Table 2>  </Paper ID = 1025>


<Paper ID = 1025> <Table 3> <Abstractive Summary> =See
example,theymightﬁlteroutaspecial“Commu- the example category query in Table 2: this ex-
nity”userinStackExchange,whichshouldnotbe pressioncalculatesthedifferenceinsecondsfrom
accountedforincomputationofvotes. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 1025>


<Paper ID = 1025> <Table 4> <Abstractive Summary> =80Unique Unique Averageunique Utterance SQL Avg.nesting Unique Averageunique
Dataset Utterances Queries Tables/uttr 3-gram 3-gram Level Templates Queries/template
Spider 8,034 4491 1.71 41.7K 25.2K 1.15 1,059 7.6
WikiSQL 80,654† 77,840† 1† 375K 209K 1† 488† 165.3†
Academic 196† 185† 3.0† <1K <1K 1.04† 92† 2.1†
Advising 4,570† 211† 3.0† 20K 11.2K 1.18† 174† 20.3†
ATIS 5,280† 947† 3.8† 13.2K 5.8K 1.39† 751† 7.0†
GeoQuery 877† 246† 1.1† 1.5K 1.4K 2.03† 98† 8.9†
IMDB 131† 89† 1.9† <1K <1K 1.01† 52† 2.5†
Restaurants 378† 23† 2.3† <1K <1K 1.17† 17† 22.2†
Scholar 817† 193† 3.2† 2.6K 2.2K 1.02† 146† 5.6†
Yelp 128† 110† 1.0† <1K <1K 1.0† 89† 1.4†
SEDE 12,023 11,767 2.14 42.6K 173K 1.28 10,664 1.1
Table 3: Comparison of different semantic parsing datasets (for Spider, analysis is performed on training and
validation sets only). </Abstractive Summary> <Extractive Summary> Table 4 shows that EM and PCM-EM-
Acknowledgments We thank Kevin Montrose
NOVALUES areonlydifferentbyupto0.7points
andtherestoftheStackExchangeteamforprovid-
forallmodels,showingthat PCM-F1 iswellcali-
ingtherawquerylog.  </Extractive Summary>  </Table 4>  </Paper ID = 1025>


<Paper ID = 1025> <Table 5> <Abstractive Summary> =Wedothis PCM-F1(qp,qg) = F1(sc(qp),sc(qg))
| C |
by parsing both the predicted query and the gold c∈C
query,comparingdifferentpartsofthetwoparsed
5https://github.com/JSQLParser/
treesandaggregatingthescoresintoasinglemet- JSqlParser
82Model Spider-Dev
PCM-F1 PCM-EM PCM-F1-NOVALUES PCM-EM-NOVALUES EM
RAT(Wangetal.,2020b) 88.1 37.3 91.3 69.0 69.7†
RAT+GAP(Shietal.,2020) 89.3 39.0 92.6 71.8 71.8†
T5-Basewithschema 85.7 56.7 85.9 57.2 57.6
T5-Largewithschema 86.3 61.2 86.6 62.6 63.2
Table 4: Results on Spider with various metrics. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 5>  </Paper ID = 1025>


<Paper ID = 1028> <Table 0> <Abstractive Summary> =XLMR 0.690 0.700 0.664 0.674
t
XLMR+IW 0.704 0.714 0.706 0.682
Fori ∈ D :
s
(cid:88) Table 1: F1 scores on SemEval for Opinion Tar-
w = score(i,D ) = score(i,j). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1028>


<Paper ID = 1028> <Table 1> <Abstractive Summary> =language-translator/,version2018-05-01
3Method en de es fr it ja ru zh
SchwenkandLi(2018)(cid:72) 0.9220 0.8120 0.7250 0.7238 0.6938 0.6763 0.6080 0.7473
WuandDredze(2019) 0.9420 0.8020 0.7260 0.7260 0.6890 0.5650 0.7370 0.7690
ArtetxeandSchwenk(2019) 0.8993 0.8478 0.7733 0.7795 0.6943 0.6030 0.6778 0.7193
mBERT 0.8981 0.8680 0.7519 0.7492 0.6952 0.7222 0.6797 0.7937
mBERT+IW - 0.8766 0.7532 0.7527 0.7122 0.7264 0.6949 0.8277
XLMR 0.9295 0.9245 0.8462 0.8710 0.7322 0.7824 0.6892 0.8580
XLMR+IW - 0.9265 0.8612 0.8797 0.7464 0.7942 0.7024 0.8712
Table 2: F1 scores on MLDoc for Cross-lingual Document Classiﬁcation. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1028>


<Paper ID = 1028> <Table 2> <Abstractive Summary> =MAN-MoE(Chenetal.,2019) 0.7543 0.7738 0.7688
While our approach is model-agnostic, when the
mBERT 0.7497 0.7378 0.7575
basemodelortheembeddingimproves, instance
mBERT+IW 0.7573 0.7565 0.7553
XLMR 0.8248 0.8268 0.8425 weighting will still help, as we can see the im-
XLMR+IW 0.8452 0.8362 0.8400 provedresultsobtainedbyswitchingfrommBERT
toXLMR.Again,theframeworkissimplebutef-
Table 3: F1 scores on Amazon Review for Sentiment
fectivegiventheseobservations. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 1028>


<Paper ID = 1029> <Table 0> <Abstractive Summary> =Such low
14Model PDTB RST X-stance XQuAD MNLI Average±std
mBERT 74.49 64.18 84.75 74.22 80.28 75.58±6.92
distilmBERT 66.13 54.37 71.34 57.35 75.9 65.02±8.15
XLM-mlm 60.32 52.93 76.4 69.68 83.47 68.56±10.93
XLM-tlm 63.49 50.36 85.57 78.76 84.26 72.49±13.56
XLM-100 73.76 57.54 87.62 74.89 81.01 74.96±10.02
XLM-R 78.96 70.75 94.29 82.44 88.1 82.91±8.00
base
XLM-R 79.91 73.33 100.4 86.81 89 85.89±9.11
large
Table 3: Relative zero-shot performance of each encoder to the source language performance (metrics differ be-
tweentasksbuthigherisbetterinallcases).Theﬁguresshowswhatpercentageofthesourcelanguageperformance
isretainedthroughzero-shottransferineachtask. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1029>


<Paper ID = 1029> <Table 1> <Abstractive Summary> =Model en de lt pl pt ru tr zh AVG
mBERT 53.6 42.7 39.2 33.9 46.7 33.1 40.3 43.5 39.9
distilmBERT 53.1 42.7 30.0 34.7 41.1 32.6 29.4 35.4 35.1
XLM-mlm 54.9 44.9 19.5* 20.6* 28.9* 33.8 43.5 40.5 33.1
XLM-tlm 53.3 45.9 20.1* 21.3* 26.8* 37.1 41.9 43.6 33.8
XLM-100 54.6 41.9 41.6 32.5 44.5 34.2 35.9 40.4 38.7
XLMR-b 61.8 49.5 49.6 40.4 53.5 42.7 54.4 51.4 48.8
XLMR-l 65.4 53.4 49.4 42.8 59.5 48.9 53.8 58.1 52.3
Table 5: PDTB zero-shot results (F ) for each language. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1029>


<Paper ID = 1030> <Table 0> <Abstractive Summary> =Table 1: This table shows some of the question preﬁxes we used for different datasets in our experiments. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1030>


<Paper ID = 1030> <Table 1> <Abstractive Summary> =Notethattheannotationofquestions Table 2: Question answering accuracy and std. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1030>


<Paper ID = 1030> <Table 2> <Abstractive Summary> =What[NAME]didwas 1
Winogrande
Whatisthedeﬁnitionof Thedeﬁnitionof is 1
Whatisthemainpurposeof Thepurposeof isto 2
Whatisthemainfunctionofa Themainfunctionofa is 2
Whatarethepropertiesofa Thepropertiesofa arethat 1
Whatis is 1
Whatdoesitmeanto means 2
27Table 4: Example contexts, questions, choices, clariﬁcation questions and clariﬁcation answers for each dataset. </Abstractive Summary> <Extractive Summary> Distil-GPT2clariﬁcation
questionsandanswersoftendonothavemeaning-
Table 2 reports the performance of our Bloom’s
ful semantics, are not correct, or are not relevant.  </Extractive Summary>  </Table 2>  </Paper ID = 1030>


<Paper ID = 1034> <Table 0> <Abstractive Summary> =SBERT 70.97 76.53 73.19 79.09 74.30 76.98 72.91 74.85
Ours 72.51 77.05 74.06 80.90 76.20 78.50 73.58 76.11
4 Experiments
Table 1: Results on STS12-16, STSb and SICK-R.
WecompareourmodelwithSBERT2,InferSent3, Spearman rank correlation ρ between the cosine simi-
USE4,averageGloVevectors,andalsotwostrate- larityofsentencerepresentationsandthegoldlabelsis
calculated. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1034>


<Paper ID = 1034> <Table 1> <Abstractive Summary> =CR 78.9±0.1 87.12±0.31 87.33±0.23 86.34±0.52 86.03±0.23 88.99±0.16 89.02±0.13
AVG 76.57 81.04 81.42 80.40 80.36 81.63 81.88
4.3 Evaluation-TransferTasks
Table 2: Results on SentEval evaluation with logistic
While the best results for BERT-like models is
regression. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1034>


<Paper ID = 1034> <Table 2> <Abstractive Summary> =Table 3: Results on SentEval evaluation with MLP. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 1034>


<Paper ID = 1035> <Table 0> <Abstractive Summary> =outperform the baselines by an around or more
66POS NER
Model
en es fr el ru avg† en es de nl avg†
NaiveFine-tune 96.23 82.95 89.12 84.21 85.45 85.43 91.97 74.96 69.56 77.57 74.03
w/frozenlayers 96.07 83.41 89.41 85.54 85.17 85.88 91.90 75.27 70.23 77.89 74.46
Multi-TaskLearning
MTFw/MLM 94.47 83.01 88.08 84.48 80.46 84.01 91.82 71.47 67.90 74.91 71.43
MTFw/XSR 96.39 82.41 87.05 72.51 86.09 82.01 91.85 74.02 68.55 75.67 72.75
MTFw/Both 95.63 83.52 89.07 85.21 83.10 85.28 91.74 71.87 68.12 74.86 71.62
ContinualLearning
GEMw/MLM 97.39 84.65 89.74 86.04 86.93 86.84‡ 91.93 76.45 70.48 78.61 75.18‡
GEMw/XSR 96.97 84.53 89.83 86.53 86.36 86.81‡ 91.89 76.29 70.74 78.77 75.27‡
GEMw/Both 97.04 84.91 90.32 86.44 86.13 86.95‡ 91.45 76.20 70.98 79.19 75.46‡
Table 2: Zero-shot results on POS and NER tasks based on mBERT. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1035>


<Paper ID = 1035> <Table 1> <Abstractive Summary> =#samples en es de nl
Train 14,040 8,319 12,152 15,802
Validation 3,249 1,914 2,867 2,895
Test 3,452 1,516 3,005 5,194
Table 4: Number of samples for each language in the
CoNLL2002andCoNLL2003NERdatasets. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1035>


<Paper ID = 1035> <Table 2> <Abstractive Summary> =#samples en es fr el ru
Train 12,543 14,187 14,450 1,662 3,850
Validation 2,002 1,400 1,476 403 579
Test 2,007 426 416 456 601
Table 5: Number of samples for each language in the
UniversalDependencies2.0datasetforthePOStask. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 1035>


<Paper ID = 1035> <Table 3> <Abstractive Summary> =XSR(FrenchtoEnglish) XSR(GreektoEnglish) XSR(GermantoEnglish) XSR(DutchtoEnglish)
Model
P@1 P@5 P@10 P@1 P@5 P@10 P@1 P@5 P@10 P@1 P@5 P@10
mBERT 53.92 65.44 72.12 35.68 59.40 65.31 52.10 64.71 69.43 54.56 66.69 72.54
NaiveFine-tune 34.12 50.03 57.90 15.12 33.35 42.69 33.68 49.23 56.45 34.79 51.13 58.01
w/frozenlayers 35.50 52.23 59.87 16.98 35.63 44.74 34.20 50.97 58.11 35.29 53.24 59.77
Multi-TaskLearning
MTFw/MLM 32.49 48.67 56.23 14.67 32.29 40.64 32.37 47.45 55.48 32.86 50.35 56.55
MTFw/XSR 74.20 78.65 83.69 73.94 77.59 83.47 75.48 80.67 85.44 75.83 85.28 88.35
MTFw/Both 75.30 79.34 84.86 74.25 78.39 84.63 77.93 82.67 87.86 74.42 83.57 86.68
ContinualLearning
GEMw/MLM 39.79 55.62 63.34 21.33 39.60 47.36 37.70 53.44 60.53 38.35 54.89 63.06
GEMw/XSR 63.11 67.81 71.92 61.79 65.37 70.43 63.14 75.52 80.85 63.90 78.33 83.46
GEMw/Both 63.84 68.50 72.05 61.54 64.38 69.50 64.41 76.39 81.70 64.36 79.65 84.72
Table 7: Experiments on XSR tasks based on mBERT. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 1035>


<Paper ID = 1036> <Table 0> <Abstractive Summary> =The
hyperparameter k of vector arithmetic method is
chosenbasedontheperformanceinthevalidation
Table 1: Evaluation of the smoothness of the latent
space via k-nearest-neighbours. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1036>


<Paper ID = 1036> <Table 1> <Abstractive Summary> =Table 3: Evaluation results of style transfer based on
TAE+classiﬁerguidance Ourmethod
the vector arithmetic based update on Yelp and Ama-
servicewasterrible. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1036>


<Paper ID = 1036> <Table 2> <Abstractive Summary> =ARAE 3.388 2.671 3.439
Table 6: Results of multiple attributes (sentiment and
Ourmethod 3.468 3.018 3.612
tense)transferonYelp. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 1036>


<Paper ID = 1038> <Table 0> <Abstractive Summary> =formﬁne-tuningpre-trainedparametersofthelan-
In TAPT, the second phase of pretraining is per- guageadaptermodulesforevaluationtoalignwith
91Domain Task Labeltype Numberofinst(Train/Dev/Test) Classes
Biomedical CHEMPROT Relationshipclassiﬁcation 4169/2427/3469 13
Biomedical RCT Abstractsentenceroles 18040/30212/30135 5
ComputerScience ACL-ARC Citationintent 1688/114/139 6
ComputerScience SCIERC Relationclassiﬁcation 3219/455/974 7
News HYPERPARTISAN Partisanship 515/65/65 2
News AGNEWS Topic 115000/5000/7600 4
Reviews HELPFULNESS Reviewhelpfulness 115251/5000/25000 2
Reviews IMDB Reviewsentiment 20000/5000/25000 2
Table 1: Datasets used for experimentation. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1038>


<Paper ID = 1038> <Table 1> <Abstractive Summary> =92Dataset BaselineRoBERTa TAPT Adapterw/oPT Adapterw/PT
CHEMPROT 81.9 82.6 82.69 82.71
1.0 0.4 0.4 0.4
RCT 87.2 87.7 87.35 87.4
0.1 0.1 0.04 0.1
ACL-ARC 63.0 67.4 69.47 69.25
5.8 1.8 2.4 2.5
SCIERC 77.3 79.3 81.5 82.37
1.9 1.5 0.9 1.0
HYPERPARTISAN 86.6 90.4 93.01 84.97
0.9 5.2 4.7 6.4
AGNEWS 93.9 94.5 94.00 93.94
0.2 0.1 0.1 0.1
HELPFULNESS 65.1 68.5 70.96 70.83
3.4 1.9 0.6 0.8
IMDB 95.0 95.5 95.51 95.57
0.2 0.1 0.1 0.1
AverageF 81.3 83.24 84.31 83.38
1
Trainableparamspertask(PT/FT) -/124.64M 163.35M/124.64M -/1.78M 2.18M/2.08M
Ratiotototalparams(PT/FT) -/100% 100%/100% -/1.42% 1.32%/1.65%
Relativetrainingspeed(PT/FT) -/1.0 1.0/1.0 -/1.29 1.14/1.24
Relativeinferencespeed(PT/FT) -/1.0 1.0/1.0 -/0.98 0.88/0.98
Table 2: Average F score with standard deviation on test set. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1038>


<Paper ID = 1038> <Table 2> <Abstractive Summary> =AGNEWS 93.9 94.05
0.2 0.1
HELPFUL 69.63 71.28
0.6 0.8
IMDB 94.93 95.33 4 Conclusion
0.1 0.1
AverageF 84.06 83.52
1
Our work demonstrates that adapters provide a
Table 3: Best performance of baseline RoBERTa and competitivealternativetolarge-scaletask-adaptive
TAPT (Gururangan et al., 2020) on our implementa- pretrainingforNLPclassiﬁcationtasks. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 1038>


<Paper ID = 1038> <Table 3> <Abstractive Summary> =96Hyper-parameter Value
Optimizer Adam
Adamepsilon 1e-8,0.999
Learningrate 1e-4
Batchsize 8
Gradientaccumulationstep 32
Epochs 40or100
Adapterreductionfactor 12
Maximumsequencelength 512
Table 4: Details of hyperparameters used in pretraining experiments. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 1038>


<Paper ID = 104> <Table 0> <Abstractive Summary> =Ours Anneal 28.1∗
Gate 27.75
4.1 Dataset
Table 2: The comparison of our model, Transformer
We tokenize the corpora using a script from
baselinesandrelatedworkontheWMT14En⇒Deus-
Moses (Koehn et al., 2007). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 104>


<Paper ID = 104> <Table 1> <Abstractive Summary> =Model En⇒Lv Lv⇒En En⇒Fi Fi⇒En En⇒Ro Ro⇒En
Baseline 16.26 17.76 22.01 26.07 22.56 27.53
Fixed 16.54 18.45∗ 22.42 26.2 23.1 28.02
Ours Anneal 16.35 18.12 22.4 26.39 23.27∗ 28.2∗
Gate 16.83∗ 18.71∗ 22.55∗ 26.67∗ 24.00∗ 28.48∗
Table 4: Evaluation of translation quality for WMT17 En⇔Fi, WMT17 En⇔Lv and WMT16 En⇔Ro using
case-insensitiveBLEUscore. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 104>


<Paper ID = 1041> <Table 0> <Abstractive Summary> =(2018) No Yes Yes 4.68 3.98
and-slab prior (Mitchell and Beauchamp, 1988),
whichaimsfordisentanglementviaclusteringand Table 1: The disentanglement (Dis. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1041>


<Paper ID = 1041> <Table 1> <Abstractive Summary> =ingofVAEsandthetypeofinformationcaptured
134START z1 [z1,1,z1,2,z1,3]
i=1 z(cid:48) z ,z ,z → z ,z ,z
1,1 1,1 1,2 1,3 2,1 1,2 1,3
i=2 z(cid:48) z ,z ,z → z ,z ,z
1,2 2,1 1,2 1,3 2,1 2,2 1,3
i=3 z(cid:48) z ,z ,z → z ,z ,z
1,3 2,1 2,2 1,3 2,1 2,2 2,3
END z2 [z2,1,z2,2,z2,3]
Table 6: An example of a 3D latent code transforma-
tion in the dimension-wise homotopy. </Abstractive Summary> <Extractive Summary> Table 1 (Ex.1 and Ex.2
n.[dogscatsfoxeshorsestigers]
columns)summarisestheresults,illustratingthat
v.[wantneedhavegetrequire]
outofthe6metrics,Higginsetal.  </Extractive Summary>  </Table 1>  </Paper ID = 1041>


<Paper ID = 1041> <Table 2> <Abstractive Summary> =A15B2C8D20 A4B14C14D12 A12B19C10D15
z2 A15B2C8D10 A4B14C14D12 A12B19C10D15
References
Table 7: The homotopy experiments, comparing an
idealgeneratorandthebestdisentangledVAEsaccord- Alexander Alemi, Ben Poole, Ian Fischer, Joshua Dil-
ingtoHigginsetal.(2017)(VAE-Higg)andChenetal. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 1041>


<Paper ID = 1042> <Table 0> <Abstractive Summary> =Weusethreeclusteringevaluationmetrics,
RAND index (RI), Adjusted RAND index (ARI)
Table 4: Clustering performance on NG20 dataset in
andNormalizedMutualInformation(NMI). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1042>


<Paper ID = 1043> <Table 0> <Abstractive Summary> =encoder decoder weight baseline lambda
dropout dropout decay decay entropy
0.8 0.8 5e-5 0.99 0.01
Table 5: Best parameters for N2NMN model, found
withagridsearch. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1043>


<Paper ID = 1044> <Table 0> <Abstractive Summary> =exp(φ (q,p)/τ) Although effective, due to BERT’s quadratic
≈ θˆ
(cid:80) exp(φ (q,p(cid:48))/τ) complexitywithrespecttoinputsequencelength,
p(cid:48)∈D(cid:48) θˆ
this design makes exhaustive combinations be-
= Pq (p,D(cid:48)), (2)
θˆ;teacher tweenaqueryandpossiblecandidatesimpractical,
165sincethisrequiresevaluatingcross-encoders|B|2 Table 1: Training cost comparison. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1044>


<Paper ID = 1044> <Table 1> <Abstractive Summary> =166Table 2: Passage retrieval results with BM25 negative training. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1044>


<Paper ID = 1044> <Table 2> <Abstractive Summary> =168Table 3: Passage retrieval results with hard negative training. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 1044>


<Paper ID = 1044> <Table 3> <Abstractive Summary> =Thesettingsforﬁne-tuningourwarmed-upencoder
169Table 4: Document retrieval results using the FirstP approach. </Abstractive Summary> <Extractive Summary> This dataset contains
Table 3 reports the results of our experiments 3.2MwebpagesgatheredfrompassagesintheMS
withhardnegativetraining.  </Extractive Summary>  </Table 3>  </Paper ID = 1044>


<Paper ID = 1047> <Table 0> <Abstractive Summary> =MAPistheMeanAveragePrecisionatthetoken-
Table 5: Sentence-level results: P, R and F refer to
1 level. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1047>


<Paper ID = 1047> <Table 1> <Abstractive Summary> =BEA2019
P R F MAP
1
BEA2019 Randombaseline 10.05 50.00 16.73 27.01
SentF1 SentP SentR RoBERTa - - - -
Randombaseline - - - ReiandSøgaard(2018) 10.93 61.63 18.53 31.69
RoBERTa 83.66 82.29 85.15 LIME 13.49 1.13 2.09 31.41
ReiandSøgaard(2018) 81.27 - - Attentionheads 18.48 21.07 19.69 40.55
LIME 83.66 82.29 85.15 Softattention 13.20 87.19 22.92 35.79
Attentionheads 83.66 82.29 85.15 Weightedsoftattention 14.20 85.49 24.35 41.07
Softattention 83.41 81.47 85.54
Weightedsoftattention 83.68 79.95 87.91 Table9: Token-levelresults: P,RandF refertoPreci-
1
sion,RecallandF-measurerespectivelyonthepositive
Table 6: Sentence-level results: P, R and F refer to
1 class. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1047>


<Paper ID = 1047> <Table 2> <Abstractive Summary> =CoNLL2010
CoNLL2010
P R F MAP
1
SentF SentP SentR
1 Randombaseline 0.83 49.70 1.63 14.15
Randombaseline - - -
RoBERTa - - - -
RoBERTa 86.66 84.90 88.63
ReiandSøgaard(2018) 78.99 67.06 72.42 87.82
ReiandSøgaard(2018) 84.16 - -
LIME 63.25 52.11 57.14 78.44
LIME 86.66 84.90 88.63
Attentionheads 22.33 30.11 25.64 79.82
Attentionheads 86.66 84.90 88.63
Softattention 4.48 86.14 8.45 20.04
Softattention 86.25 85.75 86.89
Weightedsoftattention 58.80 78.89 67.28 91.18
Weightedsoftattention 87.20 89.17 85.37
Table10: Token-levelresults: P,RandF refertoPre-
Table 7: Sentence-level results: P, R and F refer to 1
1 cision, Recall and F-measure respectively on the posi-
Precision, Recall and F-measure respectively on the
tive class. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 1047>


<Paper ID = 1048> <Table 0> <Abstractive Summary> =208
 
     DT  SDA  mSDAR 
  Target  F1     A  cc  CRP  Top1  Top3  Top5  F1     Acc  CRP  Top1  Top3  Top5  F1     Acc  CRP  Top1  Top3  Top5 
Apple  1  1  0.4  1  0.67  1  0.89  0.9  0.3  0  0.67  1  0.89  0.9  0.4  1  1  1 
AskUbuntu  1  1  0.3  0  0.67  1  0.86  0.9  0  0  0.67  0.8  1  1  0.2  0  0.67  0.8 
MRPC  0.71  0.6  0.2  0  0.67  0.6  0.93  0.9  0.2  0  0.33  0.6  0.93  0.9  0.3  0  0.67  0.8 
r 
o Math  0.67  0.6  0.2  0  0.67  0.6  0.6  0.6  0  0  0.33  0.8  0.86  0.8  0.1  0  0.33  0.6 
ct
di PAWS  0  0  0.3  0  0.33  0.8  0.18  0.1  0.3  0  0.33  0.6  0.18  0.1  0  0  0.33  0.6 
re Quora  0  0  0.3  0  0.67  1  0  0  0.3  1  0.67  0.8  0  0.1  0.3  1  0.33  0.8 
P
s  SICK  0.89  0.8  0.5  0  0.67  0.8  0.88  0.8  0.2  0  0  0.4  0.93  0.9  0.3  0  0.33  0.8 
s
e StackOverflow  0.67  0.8  0.1  0  0.67  0.6  0  0.8  0.3  0  1  0.6  0.75  0.8  0.1  0  1  0.6 
c
uc Stats  0.67  0.8  0.2  1  0.33  0.8  0.67  0.9  0.5  1  0.67  0.6  0.4  0.7  0.4  1  0.67  0.8 
S
SuperUser  0.89  0.9  0.2  0  0.67  1  1  1  0.1  0  0.67  0.8  0.86  0.9  0.3  1  1  0.8 
Unix  1  1  0.3  1  0.67  1  1  1  0.7  1  1  1  0.86  0.9  0.5  1  1  1 
AVERAGE  0.68  0.68  0.27  0.27  0.61  0.84  0.64  0.72  0.26  0.27  0.58  0.73  0.70  0.73  0.26  0.45  0.67  0.78 
Apple  0.86  0.89  0.8  1  1  1  0.97  0.98  0.8  1  1  1  0.89  0.91  0.5  1  0.67  1 
AskUbuntu  0.85  0.89  0.7  0  0.67  1  0.86  0.91  0.4  0  0.67  1  0.77  0.84  0.5  0  0.67  0.8 
MRPC  0.77  0.78  0.2  1  0.67  0.8  0.65  0.76  0.2  0  0.67  0.8  0.72  0.84  0.3  1  0.67  1 
er  Math  0.73  0.76  0.1  0  0.67  0.6  0.67  0.71  0.1  0  0.33  0.6  0.65  0.76  0.2  0  0.33  0.8 
k
n PAWS  0.44  0.56  0.2  0  0.33  0.6  0.69  0.76  0.2  0  0.67  1  0.59  0.76  0.1  0  0.33  0.8 
a
R Quora  0.86  0.84  0.4  0  0.67  1  0.87  0.87  0.3  0  0.67  1  0.76  0.82  0.2  0  0.67  0.8 
n  SICK  0.87  0.87  0.2  0  0.33  1  0.54  0.62  0.2  0  0.33  0.6  0.76  0.84  0.4  0  0.67  1 
ai
m StackOverflow  0.88  0.89  0.5  0  0.67  1  0.78  0.8  0.5  0  0.33  0.8  0.86  0.87  0.5  1  0.67  1 
Do Stats  0.91  0.91  0.7  1  0.67  0.8  0.86  0.87  0.4  1  0.67  0.8  0.83  0.87  0.4  1  0.67  0.8 
SuperUser  0.94  0.93  0.5  0  1  1  0.94  0.93  0.5  0  1  0.8  0.9  0.91  0.6  1  1  0.8 
Unix  0.92  0.91  0.4  0  0.67  1  0.89  0.89  0.3  1  0.67  0.8  0.93  0.93  0.5  0  1  0.8 
AVERAGE  0.82  0.84  0.43  0.27  0.67  0.89  0.79  0.83  0.35  0.27  0.64  0.84  0.79  0.85  0.38  0.45  0.67  0.87 
Table 1: Performance of Success Predictor and Domain Ranker in identifying the most suitable target domains under 
domain transfer (DT) and two domain adaptation approaches (SDA and mSDAR). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1048>


<Paper ID = 105> <Table 0> <Abstractive Summary> =Table 1: We breakdown the type, quantity, and rel- Table 2 compares our Multi-source and Multi-
evance of parallel sentences used when training mod- contextmodelstobaselinesofrelatedpriorwork,
elsforeachdataset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 105>


<Paper ID = 105> <Table 1> <Abstractive Summary> =Wetestthis Table 4: We remove one of the references from the
inthelimitbyprovidingoraclecontext,whichusesone validation dataset and use it to provide target context
ofthereferencesascontext.WereportBLEUscoreson only. </Abstractive Summary> <Extractive Summary> Tothis
3 ExperimentSetup
effect,weintroducetwonewmodelsthatleverage
theoutputfrombothBERTandPEGASUS: 3.1 Datasets
Weevaluate our modelon three translationtasks,
Multi-source := B (c) ⇒ P (c)
s s the NIST Open MT Chinese–English task,1 the
Multi-context := Bs(p,c) ⇒ Bs(c,n) ⇒ Ps(3p,c,3n) IWSLT’14English-Germantranslationtask,2 and
the WMT’14 English-German news translation
Thereareafewwaystointegratetheoutputof task.3 Table 1 provides a breakdown of the type,
externalmodelsintoatransformerlayer.  </Extractive Summary>  </Table 1>  </Paper ID = 105>


<Paper ID = 105> <Table 2> <Abstractive Summary> =Inthisway,
s
BERT-fused 29.44 31.50 boththenewbaselinesandtreatmentsstartedfrom
Doc
Multi-context 29.97 31.86 thesamepretrainedMulti-sourcemodel,wereex-
posedtothesamedata,andhadonlytheparameters
Table 6: Model performance before and after docu-
underinvestigationupdated. </Abstractive Summary> <Extractive Summary> Table 1: We breakdown the type, quantity, and rel- Table 2 compares our Multi-source and Multi-
evance of parallel sentences used when training mod- contextmodelstobaselinesofrelatedpriorwork,
elsforeachdataset.  </Extractive Summary>  </Table 2>  </Paper ID = 105>


<Paper ID = 105> <Table 3> <Abstractive Summary> =They have also
Multi-source
sent-WMT++ 29.62 been used to improve text generation tasks, such
3 doc-WMT 29.60 assentence-levelmachinetranslation(Songetal.,
Multi-source
doc-WMT+ 29.78 2019; Edunov et al., 2019; Zhu et al., 2020) and
⇒ P (3p,3n)
s doc-WMT++ 29.89 summarization (Zhang et al., 2019, 2020; Dong
et al., 2019), and repurposing unconditional lan-
Table 7: Results from using a three staged training
guagegeneration(Ziegleretal.,2019;deOliveira
approach. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 105>


<Paper ID = 1050> <Table 0> <Abstractive Summary> =229A AdditionalExperimentalDetails
Hyper-parameter Value
Learningrate 3e-5
Mini-batchsize 16
Max.sequencelength 100
Table 3: Hyper-parameter values for all compared ap-
proaches
All compared approaches have a run time of
abouttwohoursonaverage. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1050>


<Paper ID = 1051> <Table 0> <Abstractive Summary> =Table 1: CSQA w/ Large Models. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1051>


<Paper ID = 1051> <Table 1> <Abstractive Summary> =76.27 78.33 77.99
knowledgegraphimprovesthelogicalformskele-
Simple(Direct) 85.39 86.57 85.49
tonupto2.3points.AsshowninExample3and4
Simple(Ellipsis) 83.04 85.57 83.60
oftheAppendix,thecount,filter actionswithin
Overall 38.56 44.73 42.55
thelogicalformarebetterpredictedbyKISP.KIL
c. Comparative(Count) 22.66 28.71 23.65
Ac Quantitative(Count) 42.73 50.07 45.65 providesentity-embeddingfortheentityofinterest
Veriﬁcation 60.54 65.00 71.63 at current timestep this helps the model pick the
rightpredicatesinthefollowingstepsinambigu-
Table 2: Comparison of KISP(cid:51)=KISP(KIL+AKW)-
ouscases.Casesrequiringreasoningbeneﬁtfrom
Smallwithdifferentsizedbaselinemodels. </Abstractive Summary> <Extractive Summary> KISP shows
Methods MaSP CTN KISP KISP signiﬁcant improvements in Table 1 compared
w\BERT (cid:7) (cid:51)
to MaSP. Table 1 compares with MaSP (Shen
Simple(Coref.)  </Extractive Summary>  </Table 1>  </Paper ID = 1051>


<Paper ID = 1051> <Table 2> <Abstractive Summary> =arisenfromthisinverseindex.Recentwork,(Kacu-
MaSP++(S) 72.99 35.61 79.31 40.27
KISP(cid:7)(S) 75.45 37.70 80.93 42.53 paj et al., 2021) also points this and uses a better
entitylinker.Improvingthismoduleshouldsigniﬁ-
Table 3: Comparison of small KISP(KIL+AKW) and cantlyaddtoﬁnalperformanceandhenceisavery
MaSPmodels.KISP(cid:7)=KISP(KIL+AKW) interestingdirectionforfuturework. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 1051>


<Paper ID = 1051> <Table 3> <Abstractive Summary> =Ourmethodcanhelpimproveoverstrongbaseline
Table 4: Fine grained metrics. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 1051>


<Paper ID = 1052> <Table 0> <Abstractive Summary> =We create a men-
i
Table 1: Accuracy on predicting random tokens and
tionrepresentationm˜ byconcatenatingx˜ and
entitymentiontokens. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1052>


<Paper ID = 1052> <Table 1> <Abstractive Summary> =(2018) 93.00
OpenEntity Precision Recall F1
LeandTitov(2018) 93.07
RoBERTa 76.91 73.84 75.34
GaneaandHofmann(2017) 92.22
RoBERTa+MM 74.67 74.63 74.65
KNIT 92.87
Ernie 78.40 72.90 75.56
KnowBert 78.60 73.70 76.10
Table 4: Entity linking accuracy under various ﬁne-
KNIT 76.48 75.76 76.10
tuningscenarios. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1052>


<Paper ID = 1052> <Table 2> <Abstractive Summary> =Table 3: F1 score on entity typing when using only a
fractionofthetask-speciﬁctrainingdata(0.05%−4%). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 1052>


<Paper ID = 1053> <Table 0> <Abstractive Summary> =253FEATURE PROPERTY-MEAN CONTEXTUALISED
BERT XL-Net RoBERTa BERT XL-Net RoBERTa
Visual 0.532 0.448 0.456 0.652 0.583 0.633
Auditory 0.722 0.668 0.680 0.793 0.733 0.772
Haptic 0.556 0.512 0.505 0.660 0.616 0.634
Gustatory 0.611 0.531 0.591 0.800 0.704 0.813
Olfactory 0.610 0.587 0.597 0.740 0.736 0.731
MEAN 0.607 0.549 0.556 0.729 0.674 0.717
Table 4: Mean R-squared scores for the ﬁve features for mean and contextualised embeddings from the three
differentmodels,comparedtoaNumberbatchbaseline. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1053>


<Paper ID = 1055> <Table 0> <Abstractive Summary> =TC(X)-TC(X1)
Hierarchy TC(X) TC(X1) X-X1
-(X-X1)
IsA 61,667 51,195 3,991 6,481
HasPart 30,335 26,388 503 3,444
Table 7: Dataset statistics for different composition
edgesinJointHierarchy. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1055>


<Paper ID = 1056> <Table 0> <Abstractive Summary> =294WithoutScaling-BinningCalibrator WithScaling-BinningCalibrator
MCE ECE BrierScore SCE(d) SCE(b) MCE ECE SCE(d) SCE(b)
InDomain
Baseline 24.51 5.80 12.20 6.28 12.18 9.11 3.78 1.71 5.95
Ensemble 23.96 6.10 11.83 7.81 12.03 11.81 2.94 4.36 7.46
TempScale 23.49 4.39 11.87 7.31 10.75 8.81 3.91 0.93 5.41
Ours 17.19 5.66 12.19 8.18 12.28 12.94 3.24 4.39 7.51
Ours(Tˆ) 16.21 4.93 12.09 8.58 11.91 10.78 3.43 4.66 8.11
OutofDomain
Baseline 29.66 19.30 29.00 20.06 23.92 30.16 17.83 19.44 21.40
Ensemble 30.71 16.61 27.60 18.95 22.95 23.77 14.39 13.45 17.17
TempScale 26.45 16.35 27.53 18.71 22.35 33.60 17.55 18.61 20.65
Ours 28.26 17.17 28.08 17.63 22.15 25.11 14.50 15.55 17.92
Ours(Tˆ) 29.79 15.52 27.21 17.20 21.28 28.95 14.62 15.97 18.82
Table 1: In-domain and out-of-domain experiment results averaged across tasks. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1056>


<Paper ID = 1056> <Table 1> <Abstractive Summary> =in out-of-domain settings (1/9 similar), but out-
ResultsinTable1showthatperformancesimprove performsthemoreexpensiveensemblesinjust3/9
295WithoutScaling-BinningCalibrator WithScaling-BinningCalibrator
MCE ECE BrierScore SCE(d) SCE(b) MCE ECE SCE(d) SCE(b)
InDomain
Ours 17.19 5.66 12.19 8.18 12.28 12.94 3.24 4.39 7.51
−Ensemble 18.10 5.90 12.20 10.11 13.19 17.09 5.48 6.40 9.33
−TempScale 21.70 6.13 12.28 8.33 12.58 10.49 3.79 4.45 8.26
−Distillation 13.04 4.51 11.58 4.40 10.09 6.14 2.61 4.30 7.38
OutofDomain
Ours 28.26 17.17 28.08 17.63 22.15 25.11 14.50 15.55 17.92
−Ensemble 27.25 17.40 27.96 18.75 22.89 32.20 16.70 19.86 21.81
−TempScale 29.18 19.89 29.50 21.28 24.89 30.68 17.40 20.76 22.63
−Distillation 21.74 15.39 26.71 15.85 20.58 19.89 14.82 13.05 16.85
Table 2: In-domain/out-of-domain ablation results averaged across tasks. </Abstractive Summary> <Extractive Summary> formancebetweenthe3-labelMultiNLIandother We compute ρ based on both Table 1 and
AB
2-label NLI tasks, we follow the approach used Table 2 of the main paper.  </Extractive Summary>  </Table 1>  </Paper ID = 1056>


<Paper ID = 1057> <Table 0> <Abstractive Summary> =600 Models Multi-Mention Multi-Evidence 650
601 R P F1 R P F1 651
602 RelationExtraction 652
603 BERTBASE-JointTraining 52.42 43.88 47.77 51.20 37.55 43.33 653
E2GRE-BERTBASE 55.84 47.75 51.47 53.04 40.78 46.11
604 EvidencePredictions 654
605 BERTBASE-JointTraining 42.59 31.21 36.02 40.44 34.68 37.34 655
E2GRE-BERTBASE 42.04 37.78 39.79 38.34 40.83 39.54
606 656
Table 2: Analysis of how Evidence Prediction (EP)
607 657
impact on Relation Extraction (RE) in the joint train-
608 658
ingframework.Resultsonrecall,precisionandF1are
609 shownonthedevsetwithBERTbasemodel. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1057>


<Paper ID = 1057> <Table 1> <Abstractive Summary> =In
709 Table 4: Analysis on the number of BERT layers for ACL,2019. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1057>


<Paper ID = 1059> <Table 0> <Abstractive Summary> =originallinearAutoEncoderarchitecturebyaddingCR(#Params) Architecture Objective RMSE CosineDistance MAE Perplexity
2.5(~9.38M) SVD l2 0.02233 0.10300 0.01734 1130
LinearAE(+ELU) Φ 0.02427(0.02431) 0.1024(0.1028) 0.01896(0.01902) 669.8(664.0)
[2.0,0.6],75
5.0(~4.69M) SVD l2 0.02848 0.17490 0.02216 5035
LinearAE(+ELU) Ψ 0.03101(0.03061) 0.17390(0.17410) 0.02433(0.02401) 1776(1730)
400
10.0(~2.34M) SVD l2 0.03215 0.23050 0.02506 13501
LinearAE(+ELU) Φ 0.03680(0.03707) 0.22900(0.22910) 0.02909(0.02934) 4478(4387)
1,400
Table 1: Additional metrics for comparing the performance of SVD baseline and the best performing linear
AutoEncodermodel(weselecttheconﬁgurationthatminimizesPerplexity,aspresentedinFigure3)fordifferent
compression ratios (CR). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1059>


<Paper ID = 1059> <Table 1> <Abstractive Summary> =STS-B
SST-2 MRPC QQP MNLI QNLI RTE SQuADv1.1
CR Architecture (Pearson/Spearman
(Acc) (F1/Acc) (Acc/F1) (Acc) (Acc) (Acc) (F1/EM)
correlation)
- OriginalBERT 91.74 88.12/83.58 88.71/88.55 90.67/87.43 84.04 90.96 65.34 81.97/73.42
SVD 89.22 82.37/75.25 86.27/85.72 89.88/86.39 82.83 89.46 62.92 80.75/72.34
2.5
LinearAE 90.83 86.64/80.88 87.35/86.88 90.04/86.72 83.13 89.16 62.58 81.29/72.85
SVD 87.04 83.95/77.70 84.88/84.2 89.79/86.45 81.39 87.33 59.21 80.37/71.67
5.0
LinearAE 88.07 86.67/81.37 85.9/85.43 89.2/85.66 81.11 87.53 64.26 80.53/72.00
SVD 82.0 83.95/72.55 80.93/80.67 87.6/83.57 76.59 83.51 54.51 74.15/65.0
10.0
LinearAE 84.29 84.06/77.7 84.7/84.16 88.32/84.38 79.26 86.09 58.48 75.70/66.75
Table 2: Performance comparison of the best SVD and the best linear AutoEncoder objective conﬁguration on
several NLU tasks from GLUE benchmark (Wang et al., 2018) and for SQuAD v1.1 in different compression
ratios(CR). </Abstractive Summary> <Extractive Summary> as we observed more signiﬁcant gain for higher Table 1 presents the effect of modifying the
compressionratios.  </Extractive Summary>  </Table 1>  </Paper ID = 1059>


<Paper ID = 106> <Table 0> <Abstractive Summary> =(2020)addresstheissueofgeneratingﬂuent
1314PercentageOverlapofWords BLEUScores
LRL RelatedProminent DistantProminent LRL RelatedProminent DistantProminent
(Hindi) (English) (Target) (Hindi)(Source) (English)(Source)
Punjabi 25.5 7.5 Punjabi 24.6 16.5
Gujarati 23.3 4.5 Gujarati 20.3 12.9
Bengali 10.9 5.5 Bengali 19.3 12.4
Table 1: Motivation for transliteration: % over- Table 2: Motivation for pseudo translation: BLEU
lapping words between transliterated LRL (in Promi- scores between pseudo translated prominent language
nent Language’s script) and prominent language text. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 106>


<Paper ID = 106> <Table 1> <Abstractive Summary> =(Section4.2) TestDataLRL bn 1.0 9.7 5.8
• Wethenmovetothebilingualsettingwhere as - 14.0 8.0
weuseRelateLMtoadaptamodeltrainedon or 0.2 4.0 7.6
asingleRPLtoaLRL.Thissettingallowedus
Table 3: Statistics of Task-speciﬁc Datasets. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 106>


<Paper ID = 106> <Table 2> <Abstractive Summary> =Table 5 shows MSE weighted 57.3 71.7 78.7
theresultsofdifferentmethodsofadaptingMto cstv weighted 56.6 67.6 76.5
a LRL with Hi-BERT and BERT as two choices
Table 7: Usefulness of Bilingual Dictionaries with
of M. We obtain much higher gains when the
MSE(Mean Squared Error Loss) and cstv(Contrastive
LRL is transliterated to Hindi than to English or
Loss)evaluatedonNER,POStaggingandTextClassi-
keepingthescriptas-is. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 106>


<Paper ID = 106> <Table 3> <Abstractive Summary> =In Findings of the Associ- cstv weighted 56.6 67.6 76.5
ationforComputationalLinguistics: EMNLP2020,
pages2649–2656,Online.AssociationforComputa-
Table 8: Evaluations on NER, POS tagging and Text
tionalLinguistics. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 106>


<Paper ID = 106> <Table 4> <Abstractive Summary> =PennTagset BISTagset PennTagset BISTagset
CC CC CD QT
EX RD FW RD
IN PSP JJ JJ
JJR JJ JJS JJ
LS QT MD V
NN N NNS N
NNP N NNPS N
POS PSP PRP PR
PRP$ PR RB RB
RBR RB RBS RB
RP RP SYM RD
TO RP UH RP
VB V VBD V
VBG V VBN V
VBP V VBZ V
WP PR WP$ PR
AFX RD -LRB- RD
#.,$“(
-RRB- RD RD
):-‘’‘
all,half:QT which,that:PR
PDT such:DM WDT whatever:RP
”default”:QT ”default”:PR
some,every,
both,all,
how,wherever,
another,a,
when,where:PR
an:QT
DT WRB whenever:RB
this,these,
why:RB
the:DM
”default”:PR
those,that:PR
”default”:QT
Table 9: Tagset mapping between Penn Treebank and
BIS. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 4>  </Paper ID = 106>


<Paper ID = 1063> <Table 0> <Abstractive Summary> =Table 6: Multilingual section: ﬁve best-scoring Optionally, data augmentation was performed by
systemsbylanguagecombination. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1063>


<Paper ID = 1064> <Table 0> <Abstractive Summary> =train 2,148 0.934 p < 10−5
test 1,877 0.854 p < 10−5 Filtering by Synonyms and Antonyms For a
word in a summary, if a synonym or antonym of
Table 2: Fitting performance of neural regression the word appears in the corresponding passage,
modelontheMRCdatabase. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1064>


<Paper ID = 1064> <Table 1> <Abstractive Summary> =Table 3: Three baseline models are used to generate
Theﬁrstissueismainlyrelatedtotheproperty
candidate multiple choices for Subtask 1. </Abstractive Summary> <Extractive Summary> Table 1 shows an is a three-layer network that consists of two non-
example.  </Extractive Summary>  </Table 1>  </Paper ID = 1064>


<Paper ID = 1064> <Table 2> <Abstractive Summary> =AttReader 0.348 0.273 0.424 0.490
Tofurtherensurethequalityofourdataset,we
+gloss 0.228 0.166 0.286 0.345
inviteworkersinAmazonMechanicalTurktoper-
Table 4: Three baseline models are used to generate formfurtherdataselection. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 1064>


<Paper ID = 1064> <Table 3> <Abstractive Summary> =Table 6: Ofﬁcial results of Subtask 1 and Subtask
3. </Abstractive Summary> <Extractive Summary> The
performanceofthethreebaselinemodelsarelisted
3.7 ReCAMDataStatistics
in Table 3 for Subtask 1 and Table 4 for Subtask
2,usingseveraltypicalretrieval-basedevaluation Table5liststhesizeofourReCAMdatasets,i.e.,
metrics.  </Extractive Summary>  </Table 3>  </Paper ID = 1064>


<Paper ID = 1064> <Table 4> <Abstractive Summary> =owlmx
Table 7: Ofﬁcial results of Subtask 2 and Subtask 3.
usedtheMRCPsycholinguisticDatabasetoobtain Acc is the accuracy (%) of the models trained on the
ameasurementofimperceptibilityabstractness. </Abstractive Summary> <Extractive Summary> The
performanceofthethreebaselinemodelsarelisted
3.7 ReCAMDataStatistics
in Table 3 for Subtask 1 and Table 4 for Subtask
2,usingseveraltypicalretrieval-basedevaluation Table5liststhesizeofourReCAMdatasets,i.e.,
metrics.  </Extractive Summary>  </Table 4>  </Paper ID = 1064>


<Paper ID = 1065> <Table 0> <Abstractive Summary> =Seetheappendixforhyperparam-
Table 3: Dev accuracy for different transfer learning
eter details. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1065>


<Paper ID = 1065> <Table 1> <Abstractive Summary> =Table 4: Dev accuracy on different transfer learning
Besides the task-adaptive pretraining and ﬁne-
settings
tuning, we also tried multitask learning with
54Generalization
subtask1 subtask2
Procedures
93.72 93.65
datarepar. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1065>


<Paper ID = 1066> <Table 0> <Abstractive Summary> =posts as toxic or not, and detect toxic spans only
Table 6: The types and descriptions of the annotation when posts are classiﬁed as toxic, instead of pro-
mistakesthatweredetectedbysomeoftheparticipants. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1066>


<Paper ID = 1067> <Table 0> <Abstractive Summary> =Table 8: Inter-annotator agreement in terms of Krip-
Figure5: Examplesofmemesweﬁlteredout. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1067>


<Paper ID = 1069> <Table 0> <Abstractive Summary> =Inthefollowingtwoexamples,allofthe
Humor Offense -0.156 -0.03 -0.42
top-10 systems classed this as humorous, and ar-
Rating Rating p=0.0001 p=0.51 p=0.0011
guably, they are intended to be humorous, even
Table 9: Correlations between tasks, Pearson’s r and thoughthemajorityofannotatorstechnicallydid
p-value notclassthemassuch. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1069>


<Paper ID = 1069> <Table 1> <Abstractive Summary> =How-
ever, the teams that took part did not obtain the
Table 10: Percentage of texts with highest MAE from
perfecthumorratingscoresrequiredforthissimple
thedifferentsources
rule to work so effectively, yet were still able to
achieve similar scores on the task. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1069>


<Paper ID = 1069> <Table 2> <Abstractive Summary> =80%ofthetexts
Username Count Username Count
humurous1liners 924 BlkMentalHealth 37
joeljeffrey 692 mikewickett 35
UberFacts 632 BlackLoveAdvice 35
Dadsaysjokes 541 JNFUSA 35
GreysAnatomyMsg 402 JokesMemesFacts 34
ConanOBrien 340 MissyDuckWife 32
boonaamohammed 337 blackbodyhealth 32
Demented Jokes 325 RobBenedict 31
thenatewolf 284 Boyfriend Tips 30
DailyHealthFact 284 TheJimMichaels 29
Kasandd 219 realGpad 29
songs Iyrics 203 EverBestFilms 27
Shen the Bird 187 NicoleB MD 23
BadJokeCat 130 iGirlfriendTip 23
OURSELVES BLACK 129 Grindr 23
SupereeeGO 124 MNateShyamalan 23
Mr Truth Hurts 112 kecia ali 20
GayAdvicer 112 RobbyActually 19
Wizdomstweets 103 hardwick 19
TrippAdvice 102 RabbiHarvey 19
JensenAckles 97 taylorswift13 18
BunAndLeggings 93 PGATOURWives 17
MovieQuotesPage 90 tomhanks 15
annehelen 87 BlackGirlsSmile 15
YaGayAunties 83 curtisisbooger 11
mindykaling 74 evanmarckatz 11
RyanSeacrest 70 bosshogswife 11
murrman5 59 PenguinBooks 10
TheOkraProject 59 GuyStuffAdvice 10
benyahr 57 gaystarnews 10
thatonequeen 55 DrakeGatsby 9
ZaraRahim 52 offensivefcker 9
Oprah 52 outmagazine 9
michaelstrahan 43 therapy4bgirls 8
youknowwhenshe 42 ProBonoASL 4
Blackkidsswim 40 TheAdvocateMag 3
andreavsmoak 40
Table 11: Twitter sources of data and number of texts
sourcedfromeachaccount
117Table12showstheresultsofthetopsystemforeachteamandforeachtask. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 1069>


<Paper ID = 107> <Table 0> <Abstractive Summary> =6.95 14.04 35.11
3: yieldG(1)
kbest 4.89 10.10 25.63
4: Q ← priority queue([(cid:104)w,e,G(cid:105)])
5: fork = 2,...,K : Speed-up 1.42× 1.39× 1.37×
6: ifQ.empty(): return
Table 1: Runtime experiment for parsing the K-best
7: (cid:104)w,e,G(cid:48)(cid:105) ← Q.pop() spanningtreesintheEnglishUDtestset(Nivreetal.,
8: (cid:104)G(k),(cid:104)w(cid:48),e(cid:48)(cid:105)(cid:105) ← next(G(cid:48)−e) 2018).Timesaregivenin10−2secondsfortheaverage
9: yieldG(k) parseoftheK-bestspanningtrees. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 107>


<Paper ID = 1071> <Table 0> <Abstractive Summary> =Table 1: Total number of sentences in each training
corpus. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1071>


<Paper ID = 1073> <Table 0> <Abstractive Summary> =Most
Table 1: The performances of the different ML algo-
of the classiﬁcation errors (18.54%) were due to
rithmsonthetrialset
incorrectclassiﬁcationofveryeasywordsaseasy. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1073>


<Paper ID = 1073> <Table 1> <Abstractive Summary> =MAE MSE R2
LR 0.629 0.622 0.079 0.01 0.384
SVM 0.669 0.645 0.074 0.009 0.439
XGB 0.666 0.646 0.074 0.009 0.44
KNN 0.618 0.598 0.074 0.01 0.358
Stack 0.658 0.633 0.079 0.009 0.433
Figure 2: A confusion matrix for the XGBoost com-
plexitypredictions
Table 2: The performances of the different ML algo-
rithmsonthetestset
1415 ConclusionsandFutureWork 10th International Workshop on Semantic Evalua-
tion(SemEval-2016),pages1042–1046. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1073>


<Paper ID = 1074> <Table 0> <Abstractive Summary> =Biomed 0.8571 0.8367 0.066 0.0075
7 Conclusion
Overall 0.8228 0.7643 0.062 0.0062
Inthispaper,wepresentedoursystemforthesin-
Table 3: Results in validation set grouped by corpus glewordcomplexitypredictionsub-taskintheLCP
domain. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1074>


<Paper ID = 1075> <Table 0> <Abstractive Summary> =T
pre-trained multilingual language models, (‘Themouseeatsthecheese’)
XLM-RoBERTa(XLMR),MultilingualBERT
(mBERT) and multilingual distilled BERT Table 1: Examples for multilingual (top) and cross-
(mDistilBERT).Wecomparethesethreemod- lingual(bottom)word-in-contextdisambiguation. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1075>


<Paper ID = 1075> <Table 1> <Abstractive Summary> =5ThepackageforSuperGLUEtasksisavailableathttps: 8https://spacy.io/usage/
//github.com/nyu-mll/jiant linguistic-features#dependency-parse
152Train Dev Test
en-en 8000 500 1000
ar-ar – 500 1000
fr-fr – 500 1000
ru-ru – 500 1000
zh-zh – 500 1000
en-ar – – 1000
en-fr – – 1000
en-ru – – 1000
en-zh – – 1000
Table 2: SemEval-2021 Task 2 Datasets. </Abstractive Summary> <Extractive Summary> Table 1 shows two example
givessimilarresultstotheothermodelswhen
sentencepairswherethetargetword(mouse)has
used as a feature extractor.  </Extractive Summary>  </Table 1>  </Paper ID = 1075>


<Paper ID = 1076> <Table 0> <Abstractive Summary> =Elementwiseproduct S 81.8±1.4
Absolutedifference S 81.5±1.8
4.1 ResultsonVariousEmbedding
Concatofsymmetric S 82.1±1.4
AggregationMethods
Allembeddingaggregationmethodsweretestedon
Table 1: Symmetric (S) vs asymmetric (A) ways
theFrenchlanguagedevelopmentset,beentrained
of merging XLMR-large contextualized embeddings. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1076>


<Paper ID = 1076> <Table 1> <Abstractive Summary> =Thatiswhywealsopresentresultsforthe
ﬁxedsizesofsyntheticdatasetsforeachlanguage The results are presented in Table 2: substan-
intheTable2. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1076>


<Paper ID = 1077> <Table 0> <Abstractive Summary> =BERT-l 3 0.598 0.583
BERT-b 2.5 0.601 0.592
embeddings activation threshold
xlm-roberta-large sigmoid 0.680 Table 2: Accuracy of models with Multilayer Percep-
xlm-roberta-base 0.632 tron Architecture. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1077>


<Paper ID = 1077> <Table 1> <Abstractive Summary> =bert-base-cased 0.509
Table 1: Probability thresholds for Cosine Similarity ferentembeddingsandthresholdsforsigmoidand
Architecture. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1077>


<Paper ID = 1077> <Table 2> <Abstractive Summary> =BERT-b 0.69 0.77 0.690 0.780
The results in the Table 2 show that the usage of
[CLS]tokensgiveamoderateimprovementtoall
Table 3: Accuracy of models with Cosine Similar-
modelsexceptforonewithxlm-roberta-largeem-
ity Architecture without ﬁne-tuning. </Abstractive Summary> <Extractive Summary> BERT-b 0.69 0.77 0.690 0.780
The results in the Table 2 show that the usage of
[CLS]tokensgiveamoderateimprovementtoall
Table 3: Accuracy of models with Cosine Similar-
modelsexceptforonewithxlm-roberta-largeem-
ity Architecture without ﬁne-tuning.  </Extractive Summary>  </Table 2>  </Paper ID = 1077>


<Paper ID = 1077> <Table 3> <Abstractive Summary> =Duetothedescribed
XLMR-b 2 0.730 0.769 peculiarity of the data, we can not speculate that
BERT-l 4.5 0.808 0.927 certainlemmaisastumblingblockforthemodel
BERT-b 4 0.790 0.889 oritisjustacontextoftheﬁrstsentence,thatfor
examplediffersbygenreorthematicallyfromsec-
Table 4: Accuracy of models with Cosine Similarity
ondsentenceandcomplicatestheprediction. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 1077>


<Paper ID = 1081> <Table 0> <Abstractive Summary> =BERTFitBLF large 75.75% 75.06% BERTFitBHypo large 75.09% 72.83%
DistilBERTFitBLF base 68.10% 65.73% BERTFitBHyprAug large 62.26% 60.78%
BERTFitBHyprAugHypo large 64.51% 55.52%
BERTFitBENS large 75.15% 77.28%
BERTFitBEM large 72.86% 77.83%
BERTFitBENSLF large 75.87% 75.26%
BERTFitBEMHypo large 75.79% 78.98%
BERTFitBEM large 76.58% 76.35%
BERTFitBVS large 73.09% 77.59%
BERTFitBEMLF large 76.82% 76.10% BERTFitBVSHypo large 75.56% 78.63%
BERTFitBVS large 76.58% 76.54% BERTMC large 71.33% 71.21%
BERTFitBVSLF large 76.82% 76.20%
Table 3: Results and Ablation Study of the Improve-
BERTMC large 74.07% 73.76%
mentMethodsonSubtask-II0
Table 2: Results and Ablation Study of the Improve-
mentMethodsonSubtask-I0
BERTFitBVotingperformsbetterthanvanilla
BERTFitBonbothsubtasks. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1081>


<Paper ID = 1082> <Table 0> <Abstractive Summary> =OurApproach 87.81 87.69
Table 3: The results of our system on subtask-1. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1082>


<Paper ID = 1082> <Table 1> <Abstractive Summary> =N/A 86.23 83.12
ROBERTALARGE(Liuetal.,2019) 88.51 85.93
(1)w/specialtokens 87.47 88.98
Table 6: The results of models with different special
(2)w/sentenceranking 87.29 86.84
tokensonsubtask-1. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1082>


<Paper ID = 1082> <Table 2> <Abstractive Summary> =(3)w/labelsmoothing 87.67 87.08
(4)w/siameseencoders 87.34 86.18
(5)w/backtranslation 88.41 87.54
4 AnalysisandDiscussion
OurApproach 87.10 89.54
4.1 AblationStudy
Table 4: The results of our system on subtask-2. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 1082>


<Paper ID = 1084> <Table 0> <Abstractive Summary> =* 0.6773 0.6822 Val:753Test:1606)
5 XLNet-Base* 0.6852 0.6757 All
0.6927 0.6895
6 SSlIteration-4 0.6932 0.672 Val:794Test:2000
Ensemble(1,2,3,4,5,6) 0.6927 0.6895
Table 5: System performance over empty span (E.S)
Table3: F1Scoreondevandcompetitiontestset andnon-emptyspan(N.E.S)examplesoverDiv-Bsplit
*-ModelstrainedwithmodiﬁedDiceLoss
oneofthepreprocessingtechniquesmissing. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1084>


<Paper ID = 1084> <Table 1> <Abstractive Summary> =Table5depicts
the drastic difference in the performance of the
Table 4: F1 Score for different preprocessing tech-
systemoveremptyspanexamples(E.S)andnon-
niquesondevset
emptyspanexamples(N.E.S).Uponcloselyfollow-
ingE.Sexamples,wediscoveredthatannotations
Theresultsshowthatremovingnumbersandex-
ofsuchexamplescarrymoresubjectivitythanthe
pandingcontractionsbothhadcontrastingeffects
others. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1084>


<Paper ID = 1084> <Table 2> <Abstractive Summary> =ofexamplesintrain,valandtest
Table 8: Hyperparameter Values for Distil-Base-Unc. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 1084>


<Paper ID = 1084> <Table 3> <Abstractive Summary> =andXLNet-Base
Div-A Div-B
C Results
Train 6351 7835
Dev 794 794
C.1 DiceLossResults
Test 794 2000
Inthissection,wereporttheresultsofourhyper-
Total 7939 10629
parametertuningfortrainingwithSelfAdjusting
Table 6: Distribution of examples across Div-A and DiceLoss. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 1084>


<Paper ID = 1084> <Table 4> <Abstractive Summary> =ForAdamWoptimizer,weusedweightdecayrate
Table 10: Irregularity in annotation for similar text-
of 0.01 for all model parameters apart from the samples. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 4>  </Paper ID = 1084>


<Paper ID = 1085> <Table 0> <Abstractive Summary> =Figure 2
222Model F1
CharacterBERT 65.13
BoW(v1) 51.75
BoWwithbestparameters(v2) 62.79
CharacterBERT+BoW(v2) 65.87
CharacterBERT+BoW(v1) 66.72
Table 3: Comparing results of the proposed models. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1085>


<Paper ID = 1085> <Table 1> <Abstractive Summary> =Word Frequency ToxicityRatio
stupid 973 0.78
idiot 557 0.84 Figure3:Heatmapoftheresults(F1scores)withdiffer-
idiots 353 0.81 ent values of term frequency and toxicity ratio before
stupidity 223 0.77 combiningwithCharacterBERT
moron 147 0.71
idiotic 98 0.74
hypocrite 75 0.88
shit 56 0.72
scum 52 0.70
hypocrites 44 0.76
Table 4: Words selected as the toxic words with min-
imum frequency of 40 and minimum toxicity ratio of
0.7(BoW(v1))
showsthismodel’sperformanceforitstwoparame-
tersonthevalidationset. </Abstractive Summary> <Extractive Summary> Table 1 shows three examples of the
trainingdata.  </Extractive Summary>  </Table 1>  </Paper ID = 1085>


<Paper ID = 1086> <Table 0> <Abstractive Summary> =Table 2: Examples of model predictions with character embeddings (BERT-news-CRF-VAT+chars) and without
(BERT-toxic-CRF-VAT),comparedtotheofﬁcialannotations. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1086>


<Paper ID = 1086> <Table 1> <Abstractive Summary> =Table 3: Examples from the competition test dataset of differences between the annotations and the predictions
fromBERT-toxic-CRF-VATmodel. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1086>


<Paper ID = 1087> <Table 0> <Abstractive Summary> =RNNSLmodelisacombinationofasingleBi- Table 1: Conversion of Toxic Spans example to sam-
LSTMlayerwitharandomlyinitializedembedding plesforsingle-spanSpanPrediction. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1087>


<Paper ID = 1088> <Table 0> <Abstractive Summary> =Table 2: F1 score achieved by each model, tested
These vectors were then pushed through a fully againstthetestdataset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1088>


<Paper ID = 1088> <Table 1> <Abstractive Summary> =Tr Toxic 682 1829
5 DiscussionandAnalysis Table 4: Confusion matrix of the DistilBERT model
on a subset of the test dataset from which the to-
Itisdifﬁculttoconcludewithanycertaintywhether
kens correctly predicted by both the DistilBERT and
the addition of our proposed features improved DistilBERT+TF-IDFmodelstobenon-toxichavebeen
modelperformance,asthescoresachievedarevery removed. </Abstractive Summary> <Extractive Summary> therandomseedusedinﬁne-tuningBERTmodels
canyieldsubstantiallydifferentresults,evenifthe 4 Results
modelsarethesameandidenticalhyperparameters
Table 1 shows how the best performing version
areused(Dodgeetal.,2020).  </Extractive Summary>  </Table 1>  </Paper ID = 1088>


<Paper ID = 1089> <Table 0> <Abstractive Summary> =For our sequence tagging
approach, we divide our results according to the
Table 3: Major hyperparameters of Sequence Tagger
model transformerarchitectureandtaggingschemeused
forthatexperiment. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1089>


<Paper ID = 1089> <Table 1> <Abstractive Summary> =Parameter Value Model Scheme Test Dev
BiLSTMsize 200 XLNet IO 0.6922 0.6945
BiLSTMlayer 3 XLNet BIO 0.6653 0.6683
BiLSTMdropout 0.4 spanBERT IO 0.6777 0.6744
FFNNsize 150 spanBERT BIO 0.6887 0.6730
FFNNdropout 0.2 RoBERTa IO 0.6647 0.6967
BERTsize 1024 RoBERTa BIO 0.6849 0.6789
BERTencoderlayers last4 BERT IO 0.6830 0.6814
fastTextembeddingsize 300 BERT BIO 0.6852 0.6815
CharCNNsize 50 ALBERT IO 0.6621 0.6702
CharCNNﬁlterwidth [3,4,5] ALBERT BIO 0.6679 0.6431
Embeddingsdropout 0.5 Biafﬁne - 0.6731 0.6627
Optimiser Adam
Learningrate 1e-3 Table 5: Test and Dev Results of different models on
varioustaggingscheme
Table 4: Major hyperparameters of Dependancy Pars-
ingmodel Our best performing architecture proved to be
the sequence tagging system with XLnet trans-
Wetrainalloursequencetaggingmodelswith
3https://github.com/Sreyan88/SemEval-2021-Toxic-
2http://huggingface.co/ Spans-Detection
253former trained with IO tagging scheme. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1089>


<Paper ID = 109> <Table 0> <Abstractive Summary> =Quality  mAP  mAP gain  max P  max R 
0_ALL  .058  4.61  .38  .36 
0_EXEMP  .039  3.10  .34  .30  3  .086  6.86  .54  .41 
BEST_ALL  .042  3.35  .32  .33  2  .048  3.77  .34  .34 
BEST_EXEMP  .032  2.52  .27  .28  1  .045  3.57  .26  .33 
BASELINE  .013   1.00  .08   .20   0  .028  2.21  .14  .29 
BASELINE  .013  1.00  .08   .20  
Table 1: Performance under different confgurations. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 109>


<Paper ID = 109> <Table 1> <Abstractive Summary> =Table 3:  Mean performance metrics according to the 
input photos’ description quality. </Abstractive Summary> <Extractive Summary> 3 presents the P-R curves, while 
among all VIST-VAL) with the Selection  Method  
Table 1 shows the mAP  and maximum P  and R  
all_phrases and exemplars, resulting in four con-
mean values for the pairs of parameters values un-
fgurations: 0_ALL, 0_EXEMPLARS, BEST_ALL, 
der investigation, in comparison to the baseline.  </Extractive Summary>  </Table 1>  </Paper ID = 109>


<Paper ID = 109> <Table 2> <Abstractive Summary> =1 8.9 16 18 14
D D
1  .058  4.57  .38  .36  xt 2 1.2 12 12 5 xt 2 15 23 41 61
e e
0  .045  3.54  .29  .23  nt nt
Co3 1.9 25 9.3 1.5 Co3 24 46 31 19
BASELINE  .013   1.00  .08   .20  
(a)Percentages relative to all  (b) Percentages relative to
Table 2:  Mean performance according to the level of  photos (1946)  photos with same context 
contextual information in the input photos. </Abstractive Summary> <Extractive Summary> Table 2 
shows the mean performance metrics according to 
level of contextual information.  </Extractive Summary>  </Table 2>  </Paper ID = 109>


<Paper ID = 1090> <Table 0> <Abstractive Summary> =Table 3: Performance of Different Encoder
As shown in Table 3, we can ﬁnd that the over- References
all score’s difference is slight. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1090>


<Paper ID = 1091> <Table 0> <Abstractive Summary> =12.5
annotationbyground-truth 1374.Thatisabunchof horsesh*t.
Table 3: An error analysis of 200 predictions of our PTFT model relative to the ground-truth span. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1091>


<Paper ID = 1093> <Table 0> <Abstractive Summary> =Our
Table 1: Statistics of the provided datasets. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1093>


<Paper ID = 1098> <Table 0> <Abstractive Summary> =Base-
avoid crediting correct MeasuredEntities if asso-
8https://github.com/harperco/MeasEval/
7https://github.com/harperco/MeasEval tree/main/eval
309TeamName Overall Quantity Unit Modiﬁer MeasuredEntity MeasuredProperty Qualiﬁer
LIORI* 0.519 0.861 0.722 0.642 0.437 0.467 0.163
jarvis@tencent* 0.473 0.855 0.719 0.523 0.398 0.437 0.000
zyy 77 0.448 0.842 0.697 0.507 0.383 0.385 0.000
zz362 0.433 0.821 0.720 0.498 0.344 0.365 0.000
Counts@IITK* 0.432 0.861 0.406 0.245 0.077 0.804 0.614
yorkey 0.399 0.745 0.661 0.314 0.344 0.365 0.000
XMSHI 0.392 0.736 0.624 0.313 0.348 0.353 0.000
CLaC-BP* 0.389 0.855 0.677 0.546 0.251 0.318 0.107
clockwise9* 0.369 0.850 0.618 0.000 0.327 0.350 0.000
UPB* 0.369 0.742 0.533 0.277 0.331 0.374 0.040
Baseline 0.239 0.827 0.561 0.000 0.053 0.064 0.005
KGP* 0.278 0.787 0.748 0.309 0.113 0.012 0.005
StanfordMLab* 0.272 0.818 0.760 0.408 0.000 0.000 0.000
BuckschJ 0.263 0.825 0.695 0.375 0.000 0.000 0.000
CLaC-np* 0.241 0.756 0.495 0.408 0.056 0.006 0.000
FabianW 0.238 0.826 0.624 0.438 0.060 0.045 0.006
ugeijtsv 0.229 0.759 0.582 0.210 0.000 0.000 0.000
Jo 0.212 0.754 0.377 0.291 0.000 0.000 0.000
joe o123 0.185 0.376 0.383 0.242 0.000 0.000 0.000
SU-NLP 0.001 0.007 0.002 0.000 0.000 0.000 0.000
Table 2: Top result for each team/user, ordered by Overall F1 along with micro-averages for each annotation
span, for units, and for modiﬁers. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1098>


<Paper ID = 1098> <Table 1> <Abstractive Summary> =Table 3: Top result for each team/user for the Rela-
This was done to allow submissions to get credit
tionExtractioncomponentsofthescore. </Abstractive Summary> <Extractive Summary> Future work could be done to further analyze ar-
easoferroranddisagreementintheseannotations,
Finally, not shown in Table 1 is Veyseh et al.  </Extractive Summary>  </Table 1>  </Paper ID = 1098>


<Paper ID = 1098> <Table 2> <Abstractive Summary> =Count F1w/out
F1w/out
TeamName F1 Exact/ Any
Exact
Overlap Duplicates
LIORI 0.519 125/32 0.499 0.487
jarvis@tencent 0.473 0/11 0.473 0.470
Counts@IITK 0.432 0/0 0.432 0.432
CLaC-BP 0.389 0/0 0.389 0.389
UPB 0.369 0/1 0.369 0.369
KGP 0.278 0/0 0.278 0.278
StanfordMLab 0.272 0/0 0.272 0.272
CLaC-np 0.241 55/0 0.231 0.231
Table 4: Ablation analysis of duplicates and Overall
F1 (Overlap) score for each of the eight Teams with
SystemPapers. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 1098>


<Paper ID = 1099> <Table 0> <Abstractive Summary> =Table 7: Descriptions of systems from participants for Task A. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1099>


<Paper ID = 11> <Table 0> <Abstractive Summary> =InadditiontoLAD,where LAD 0.62 0.66 0.32 0.37 0.42 0.21
thesecomponentsareincrementallyremoved,we
Table 1: BLEU on WebNLG20* for delexicalisation
explorehowtheiradditionwouldinﬂuenceexact
modelsaugmentedwithgenericplaceholders+ordering,
andn-gramdelexicalisation(Trisedyaetal.,2018). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 11>


<Paper ID = 11> <Table 1> <Abstractive Summary> =Ontheotherhand,Copycan mB-LAD-SL 0.44 0.61 0.63 0.48
potentiallygeneratemorerelevantoutputsinceit
Table 6: Ofﬁcial WebNLG20 testset results for Pre-
cancopywordsfromattributesaswellasvalues. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 11>


<Paper ID = 11> <Table 2> <Abstractive Summary> =Table 9: Output text from three different systems in
Figure6: ExamplesofLAD’svaluemappingtotarget
English. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 11>


<Paper ID = 11> <Table 3> <Abstractive Summary> =Table 10: Output text from three different systems in
Russian. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 11>


<Paper ID = 110> <Table 0> <Abstractive Summary> =Thisbinaryfram-
Conditional 0 3 10
ImpEeBrativeE/B2ndEpBersonEB 3 EB 4Segment e4m1beddinignsgisstilluseful,assurfacingthesentencesfora
readeristheprimaryobjectivethatwillsavetime
#OOV 0.91 2.15 2.10
andeffort,withclassiﬁcationofthesentencebeing
Table 3: Comparing sentences in existing summariza- asecondarybeneﬁt. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 110>


<Paper ID = 1100> <Table 0> <Abstractive Summary> =Lovelyisanagoraphobicsituation Refuted
2.2 ProblemDeﬁntion
Table 2: Statements and Labels corresponding to Sub-
The problem statement is articulated around the taskA
followingtworelatedsubtasks. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1100>


<Paper ID = 1100> <Table 1> <Abstractive Summary> =(SeeAppendix
Table 1: 2 A sample table and statement with correct Aforpreprocessingdetails). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1100>


<Paper ID = 1101> <Table 0> <Abstractive Summary> =(Withpdis, trainedusingmajorityvotingaggregatedlabelsand
343Task Model Hardscore(F ) Softscore(cross-entropy)
1
pos basemodel+majorityvoting 0.753 2.263
pos basemodel+softloss 0.767 1.084
pos uor(bert+CrowdLayer) 0.125 2.331
pdis basemodel+majorityvoting 0.906 0.397
pdis basemodel+softloss 0.928 0.273
pdis uor(bert+CrowdLayer) 0.474 0.830
humour basemodel(gppl) 0.557 0.728
humour uor 0.513 3.697
ic-labelme basemodel+majorityvoting 0.806 2.833
ic-labelme basemodel+softloss 0.833 1.691
ic-labelme uor(basemodel+CrowdLayer) 0.784 1.769
ic-cifar10h basemodel+majorityvoting 0.646 2.610
ic-cifar10h basemodel+softloss 0.698 1.052
ic-cifar10h uor(WideResNet+sam) 0.769 0.827
Table 2: Results on the benchmarks and participant submissions on all the tasks using F (higher is better) and
1
cross-entropy(lowerisbetter)
Foret et al.’s (2020) sam optimization technique. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1101>


<Paper ID = 1102> <Table 0> <Abstractive Summary> =350source dev test
Sub-task System P R F P R F P R F
1 1 1
Negation Src-Trained - - 0.820 0.851 0.818 0.834 0.917 0.516 0.660
Negation Dev-Tuned - - - - - - 0.908 0.611 0.730
TimeExpression Src-Trained 0.967 0.968 0.968 0.775 0.768 0.771 0.849 0.746 0.794
TimeExpression Dev-Tuned - - - - - - 0.827 0.782 0.804
Table 3: Performance of the baselines on the source domain, where Source-Trained (Src-Trained) was trained,
andthetwotargetdomains(devandtest). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1102>


<Paper ID = 1102> <Table 1> <Abstractive Summary> =Table 4: Some details on the tasks submissions. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1102>


<Paper ID = 1103> <Table 0> <Abstractive Summary> =360Model F1 Precision Recall
Baseline 0.660 0.917 0.516
Baseline(ﬁne-tuned) 0.730 0.908 0.611
SFDAw/oL 0.674 0.874 0.548
source
SFDAw/oAPM 0.686 0.927 0.545
SFDA 0.717 0.936 0.581
SFDA+ensemble 0.736 0.913 0.616
Table 2: Resultsof differentablation experiments for
subtaskA.Allthemodelsaretrainedontrainingdata,
developmentdataandtestdata. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1103>


<Paper ID = 1103> <Table 1> <Abstractive Summary> =Model F1(dev) F1(test)
SFDA(t)w/oL 0.838 0.661
source
SFDA(t)w/oAPM 0.814 0.717
SFDA(t) 0.859 0.707
SFDA(t)+ensemble 0.873 0.720
SFDA(t+d)w/oL 0.864 0.689
source
SFDA(t+d)w/oAPM 0.851 0.668
SFDA(t+d) 0.868 0.718 Figure4: Theconfusionmatrixofourmodel
SFDA(t+d)+ensemble 0.870 0.725
Table 3: Results of models trained on different data Table4showstheresultsofseveralablationex-
sets. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1103>


<Paper ID = 1103> <Table 2> <Abstractive Summary> =Table 4: Resultsof differentablation experiments for Infuture,wewouldliketointroduceadversarial
subtaskB.Ourmodelsaretrainedontrainingset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 1103>


<Paper ID = 1104> <Table 0> <Abstractive Summary> =In this phase, systems were tested only for their
Table 2: Annotated MODEL Information Unit contri-
capacity to extract phrases and organize them as
bution data as triples. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1104>


<Paper ID = 1104> <Table 1> <Abstractive Summary> =375Team RESEARCHPROBLEM APPROACH MODEL CODE
UIUC BioNLP 26.17/53.19/89.41 11.54/20.2/28.87 38.14/55.31/76.9 57.14/80.0/100.0
ITNLP 35.79/43.18/78.35 0.0/0.0/0.0 16.03/22.65/51.42 83.33/100.0/100.0
KnowGraph@IITK 24.62/25.81/97.56 4.94/5.93/0.0 8.2/19.18/34.48 83.33/100.0/100.0
ECNUICA 6.45/65.12/89.89 1.75/17.83/28.93 0.0/29.73/56.67 0.0/80.0/80.0
INNOVATORS 9.88/9.88/3.25 0.0/0.0/3.8 0.0/0.0/7.55 50.0/50.0/0.0
DULUTH 0.0/4.71/58.73 0.0/2.06/21.78 7.23/7.14/35.36 0.0/40.0/88.89
YNU-HPCC -/2.9/5.07 -/2.53/7.22 -/3.52/18.29 -/0.93/0.56
Team EXPERIMENTALSETUP HYPERPARAMETERS BASELINES
UIUC BioNLP 28.37/52.42/67.27 5.6/35.71/39.44 20.69/50.85/74.34
ITNLP 18.78/29.87/42.16 4.0/6.06/12.63 0.0/16.67/27.69
KnowGraph@IITK 12.14/13.53/12.7 4.37/7.88/8.48 3.47/6.78/33.33
ECNUICA 14.79/25.88/42.34 3.36/13.4/3.36 9.11/34.62/51.06
INNOVATORS 0.0/0.0/0.0 0.0/0.0/0.0 0.0/0.0/0.0
DULUTH 1.54/6.33/30.47 4.04/7.89/21.43 5.56/3.23/17.5
YNU-HPCC -/4.24/16.7 -/0.88/2.58 -/0.87/3.5
Team RESULTS EXPERIMENTS ABLATIONANALYSIS
UIUC BioNLP 20.62/37.77/56.4 7.19/8.96/10.61 23.01/31.78/61.36
ITNLP 8.85/17.47/42.5 1.48/1.42/0.0 8.6/6.35/11.63
KnowGraph@IITK 10.86/17.55/28.94 3.33/1.96/0.0 4.23/3.74/35.16
ECNUICA 15.37/26.25/49.0 7.86/6.06/13.86 3.94/4.6/8.82
INNOVATORS 0.0/0.0/7.36 0.0/0.0/0.0 0.0/0.0/0.0
DULUTH 7.2/8.04/30.96 0.0/1.72/5.97 0.0/0.0/12.29
YNU-HPCC -/3.56/16.63 -/0.68/2.73 -/1.05/2.79
Table 7: Per Information Unit F1 scores per evaluation phase of the seven participating teams. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1104>


<Paper ID = 1104> <Table 2> <Abstractive Summary> =InformationUnits Triples
Model
F1 P R F1 P R
UIUC BioNLP 72.93/83.98 66.67/76.77 80.49/92.68 22.28/25.01 22.3/25.08 22.26/24.94
ITNLP 72.93/82.49 66.67/76.84 80.49/89.02 13.79/14.26 13.39/13.98 14.23/14.56
KnowGraph@IITK 60.54/72.32 44.13/57.04 96.34/98.78 8.57/10.0 6.53/7.87 12.45/13.72
ECNUICA 54.05/56.76 42.86/45.0 73.17/76.83 6.78/6.72 4.28/4.24 16.29/16.12
INNOVATORS 71.72/80.0 82.54/92.06 63.41/70.73 0.97/0.97 14.29/14.29 0.5/0.5
DULUTH 64.41/77.11 60.0/76.19 69.51/78.05 3.94/4.05 9.2/10.42 2.51/2.51
Table 8: Evaluation Phase 1: End-to-end Pipeline Results with (APPROACH, MODEL) IUs normalized to AP-
PROACH and (EXPERIMENTALSETUP, HYPERPARAMETERS) IUs normalized to EXPERIMENTALSETUP. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 1104>


<Paper ID = 1105> <Table 0> <Abstractive Summary> =unitsRESEARCH PROBLEM translation)
andCODE
(PositionalEncoding, Structurethe
TypeF Cross-sentencetriples inject,some information 3%
information) acrosssentences
Table 1: Triple types, their roles, and frequency. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1105>


<Paper ID = 1105> <Table 1> <Abstractive Summary> =382InformationUnits Phrases Triples
F P R F P R F P R
1 1 1
Part1 82.49 76.84 89.02 78.57 76.86 80.35 43.44 45.06 41.94
Part2 82.49 76.84 89.02 - - - 61.29 65.19 57.82
Table 3: Performance in phrase and triple extraction (Evaluation Phase 2). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1105>


<Paper ID = 1105> <Table 2> <Abstractive Summary> =Settings F P R
1
Sentence+title+position 65.11 63.96 66.30
Sentence+title 63.87 61.00 67.03
Sentence+position 52.28 46.38 59.89
Sentenceonly 51.39 49.00 54.03
Table 5: Results of ablation experiments on contribu-
tionsentenceclassiﬁcationtask. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 1105>


<Paper ID = 1105> <Table 3> <Abstractive Summary> =Weget12bootstrap
Class Pair 91.30 88.93 93.79
samplesfromthetrainingdata,andoneachsample,
weight Triple 80.37 81.35 79.42
wetrainthemodelandsaveitssnapshotaftereach
epoch from the 3th epoch to the 10th epoch, to Table 7: Performance of the pairwise classiﬁcation
get a total of 96 submodels. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 1105>


<Paper ID = 1105> <Table 4> <Abstractive Summary> =Downsampling 75.59 62.32 96.04
Classweight 83.35 74.94 93.89 (3) The MoE consists of a number of experts,
eachasimplefeed-forwardneuralnetwork,
Table 8: Performance of the triple classiﬁcation andatrainablegatingnetworkwhichselects
scheme. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 4>  </Paper ID = 1105>


<Paper ID = 1106> <Table 0> <Abstractive Summary> =Table 2: Multi-Task Results. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1106>


<Paper ID = 1108> <Table 0> <Abstractive Summary> =Therequiredmappingto
competitionoutputrequiresseveralpostprocessing Table 1: Development results. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1108>


<Paper ID = 1109> <Table 0> <Abstractive Summary> =Weanalyzeabla-
Qualiﬁer(QL) 276 .33
tionexperimentsanddemonstratehowthesys-
tem components, namely tokenizer, unit iden- Table 1: Frequency of training data annotations and
tiﬁer, modiﬁer classiﬁer, and language model, theirKrippendorff’sAlpha
affect the overall score. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1109>


<Paper ID = 1109> <Table 1> <Abstractive Summary> =Table 6: Validation SciBERT (S) and BERT base (B)
validationsetperformanceafter4epochsofﬁne-tuning CoreyHarper,JessicaCox,CurtKohler,AntonyScerri,
RonDanielJr.,andPaulGroth.2021. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1109>


<Paper ID = 111> <Table 0> <Abstractive Summary> =usingamorefine-grainedinventoryofclasses.Task-Parts-of-Speech(POS)Tagging
Noun Adjective Verb Adverb Punctuation Average Modified
Tools
26% 22% ~17.3% ~17.3% ~17.3% 100% Tokenizer
NLTK 100.0 0 0 0 0 26.1 26.1
NLTK-TT 83.3 100 100 0 0 60.9 60.9
SpaCy 66.7 0 100 0 0 34.8 34.8
SpaCyMoji 66.7 0 100 0 0 34.8 34.8
Stanza 83.3 20 100 25 0 47.8 ↑52.2
TextBlob 83.3 20 100 0 0 43.5 ↑60.9
Table 3: The percentage of success of tools at labeling emojis with different parts-of-speech. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 111>


<Paper ID = 111> <Table 1> <Abstractive Summary> =(NNP)
IMADEAPICTURE
TextBlob Punctuation (NNS) (NNP)
Whatdoyouthink
(NN)
TextBlob Yes,sheis andIlikeit Adjective is and(Verb) (Adj)
Table 4: Examples of tweets in which an emoji assumes the role of different parts-of-speech. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 111>


<Paper ID = 111> <Table 2> <Abstractive Summary> =ZWJFamily
(Man,Woman,Girl,Boy) Overall,NLTK-TT andTextBlobachievedthehigh-
estsuccessrateforPOStagging,althoughbothstill
Table 8: Nearest neighbour emojis for the Clapping
strugglewithadverbsandpunctuation,whichcan
Hands and Family emojis. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 111>


<Paper ID = 1110> <Table 0> <Abstractive Summary> =Amodelmayperformbetteronshorterstate- Superlative ()hashighestvalue(s)of()
mentswhileBmodelmayperformbetteronlonger
Table 2: Examples of the statement slots used in the
statements). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1110>


<Paper ID = 1110> <Table 1> <Abstractive Summary> =Models in the second stage are
pre-trainedontheTABFACTdatasetbeforefurther
Table 4: Ablation experiment regarding the symbolic-
trained on the competition dataset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1110>


<Paper ID = 1111> <Table 0> <Abstractive Summary> =Bothstagesareimplementusingabinary TAPAS
424Dataset Statements Tables Entailed Refuted Neutral
CrowdsourcedTrain 4,506 981 2,818(62.54%) 1,688(37.46%)
Auto-generatedTrain 179,345 1,980 92,136(51.37%) 87,209(48.63%)
Stage1train 9,012 1,915 4506(50%) 4506(50%)
Dev 556 52 250(44.96%) 213(38.31%) 93(16.73%)
Test 653 52 274(41.96%) 248(37.98%) 131(20.06%)
Table 1: SEMTABFACT (Wang et al., 2021) statistics. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1111>


<Paper ID = 1111> <Table 1> <Abstractive Summary> =Table 3: Confusion matrix for Stage 1 and Stage 2 on
thedevelopmentset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1111>


<Paper ID = 1112> <Table 0> <Abstractive Summary> =Statement
works have also focused on pretraining language
Length(Words) 11.5±7.1 13.2±4.5
models for tabular data by introducing new em-
beddinglayersandobjectivefunctions,aswellas
Table 1: Comparative statistics of SemTabFacts and
large-scaleaugmenteddatatobetterrepresentnu-
TabFact. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1112>


<Paper ID = 1112> <Table 1> <Abstractive Summary> =433TrainingSet Dev Test TrainingSet SemTabFacts TabFact
Dev Test Dev Test
SemTabFacts 0.7661 0.7044
SemTabFacts+WN 0.7791 0.7294 SemTabFacts 0.7661 0.7044 0.7435 0.7471
SemTabFacts+W2V 0.7486 0.7201 TabFact 0.7284 0.7019 0.8200 0.8178
SemTabFacts+BT 0.7725 0.6941 SemTabFacts
0.7992 0.7335 0.8167 0.8255
SemTabFacts+WN+W2V 0.7648 0.7147 +TabFact
SemTabFacts+WN+BT 0.7869 0.7217
SemTabFacts+W2V+BT 0.7614 0.7202 Table 3: F1 scores of domain adaptation and joint
learningcapabilitiesofSemTabFactsandTabFact. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1112>


<Paper ID = 1112> <Table 2> <Abstractive Summary> =SemTabFacts+W2V+WN+BT 0.7484 0.7101
Table 2: F1 scores of different augmentation tech-
4 ExperimentationandResults
niques on SemTabFacts. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 1112>


<Paper ID = 1113> <Table 0> <Abstractive Summary> =Table 2: Results obtained on test data of evaluation
phase
Analysis: To ascertain the relationship between
self-entropyandaprediction’sreliability,weanal-
yse the baseline performance scores for the data
points within the varying self-entropy percentile
threshold as shown in ﬁgure 1. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1113>


<Paper ID = 1114> <Table 0> <Abstractive Summary> =F P R
1
SRC 77.1 77.5 76.8
Nofreezing 77.8±0.5 81.2±0.2 74.7±1.0
Freezeemb 77.7±0.2 81.0±0.4 74.7±0.6
Freezeemb+6layers 78.2±0.2 80.3±0.3 76.2±0.0
Freezeemb+12(all)layers 77.2±0.0 77.7±0.0 76.7±0.0
Table 3: Model performance on the development data when the RoBERTa embedding and encoder layers are
frozenduringtraining. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1114>


<Paper ID = 1115> <Table 0> <Abstractive Summary> =t
454Method F Precision Recall Method F Precision Recall
1 1
SCT 0.784 0.814 0.756 SA 0.81 0.874 0.754
SA 0.808 0.819 0.797 SA+Sloughing* 0.811 0.873 0.757
SA+Sloughing* 0.812 0.822 0.801 Source-Trained 0.794 0.849 0.746
SA-ﬁltering 0.771 0.774 0.768 Dev-Tuned 0.804 0.827 0.782
Source-Trained 0.771 0.768 0.775
Table 2: F , Precision, Recall on the test data. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1115>


<Paper ID = 1115> <Table 1> <Abstractive Summary> =The
1
Table 1: F , Precision, Recall on development data. </Abstractive Summary> <Extractive Summary> How-
3.2 Experimentalresultsandanalysis
ever,thisisonlywhenthemodelisﬁne-tunedwith
Table 1 and Table 2 shows the performance of data from the domain same as the target domain.  </Extractive Summary>  </Table 1>  </Paper ID = 1115>


<Paper ID = 1116> <Table 0> <Abstractive Summary> =464A.2 Hyperparameters
Hyperparameter Value
number of examples from the test set used for 3000
self-training
maximumnumberofself-trainingiterations 30
actualnumberofself-trainingiterations 2
self-trainingthreshold(τ) 0.95
maximumsequencelength 128
batchsize 32
epochs 10
learningrate 5e-5
learningratescheduletype linear
learningratewarmupsteps 0
weightdecay 0.0
maximumgradientnorm 1.0
Table 4: Hyperparameters for negation detection sys-
tem
Hyperparameter Value
numberofactivelearningiterations(i) 5
number of sentences to annotate at each active 32
learningiteration(k)
number of new sequence to augment for each 5
annotatedtimeentity(n)
maximumsequencelength 271
batchsize 32
epochs 8
learningrate 3e-5
learningratescheduletype linear
learningratewarmupsteps 0
weightdecay 0.0
maximumgradientnorm 1.0
Table5: Hyperparametersfortimeexpressionrecogni-
tionsystem. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1116>


<Paper ID = 1117> <Table 0> <Abstractive Summary> =Firstisthe
Table 3: Number of triplets in each Information Unit Information Units prediction of a document (re-
ontrainanddevset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1117>


<Paper ID = 1118> <Table 0> <Abstractive Summary> =Subtask3 0.4385 0.4109 0.6151
• EvaluationPhase2,Part2: Triplesextrac-
Table 4: Score of the pre-trained BERT model for the
tion testing. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1118>


<Paper ID = 1119> <Table 0> <Abstractive Summary> =SC1 0.3636 0.5417 0.7391 0.7826
SC 0.5600 0.5714 0.5926 0.6667
2
TG 0.4681 0.5424 0.5385 0.5763
4 ExperimentalSetup
Table 2: F1 scores while adding different features. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1119>


<Paper ID = 1119> <Table 1> <Abstractive Summary> =Our system has achieved
goodresultsontasksSEandPE,buttaskTEcan
Table 1: F1 scores of Natural training (no adversarial still be improved. </Abstractive Summary> <Extractive Summary> Table 1 shows that FAT
ods on papers in various domains.  </Extractive Summary>  </Table 1>  </Paper ID = 1119>


<Paper ID = 112> <Table 0> <Abstractive Summary> =#Kp
KP20k 20,000 1,438/179.8 108/7.8 29.2 23/2.04 5.28 62.9 37.1
Inspec 500 386/128.7 23/5.5 16.5 10/2.48 9.83 73.6 26.4
Krapivin 400 554/182.6 28/8.2 28.3 6/2.21 5.84 55.7 44.3
Nus 211 973/219.1 42/11.8 32.6 70/2.22 11.65 54.4 45.6
SemEval 100 473/234.8 22/11.9 27.0 11/2.38 14.66 42.6 57.4
KPTimes 20,000 7,569/777.9 631/28.9 35.4 18/1.84 5.27 58.8 41.2
In-house 26,000 9,745/969.1 538/35.6 44.0 16/2.69 4.08 37.5 62.5
Table 1: Summary of the test portion of the keyphrase benchmarks used in experiments. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 112>


<Paper ID = 112> <Table 1> <Abstractive Summary> =Hence, predicting them is
more challenging and requires a comprehensive
Table 3: Keyphrase prediction results on the two web
understandingoftheunderlyingdocumentseman-
domain benchmarks. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 112>


<Paper ID = 112> <Table 2> <Abstractive Summary> =Overall,theabsentphrase
predictionresultsindicatethatSEG-Netiscapable
Table 4: Evaluation on predicting the correct number
ofunderstandingtheunderlyingdocumentseman-
of keyphrases on the KP20k dataset. </Abstractive Summary> <Extractive Summary> From Table 2 and 3, we see that SEG-Net
dicate the best and statistically signiﬁcantly better (by
pairedbootstraptest,p<0.05)performances.  </Extractive Summary>  </Table 2>  </Paper ID = 112>


<Paper ID = 112> <Table 3> <Abstractive Summary> =In Proceedings of Human
Language Technology Conference and Conference
1400Supplementary Material: Appendices
Present Absent Present Absent
Model Model
F1@M F1@5 F1@M F1@5 F1@M F1@5 F1@M F1@5
KP20k
catSeq 0.376 0.298 0.034 0.016
catSeqTG 0.386 0.321 0.050 0.027
catSeqD 0.372 0.293 0.033 0.016
SEG-Net 0.380 0.311 0.052 0.030
catSeqCorr 0.375 0.300 0.034 0.016
KPTimes
catSeqTG 0.374 0.302 0.033 0.016
catSeqTG 0.481 0.318 0.238 0.174
SEG-Net 0.390 0.326 0.042 0.021
SEG-Net 0.475 0.358 0.245 0.181
Table 7: Test set results on the KP20k dataset with
Table9:Testsetresultsafterﬁne-tuningthemodelsvia
“namevariations”asproposedinChanetal.(2019). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 112>


<Paper ID = 112> <Table 4> <Abstractive Summary> =Oracle
Table 8: Impact of different embeddings at the input isamodelthatgeneratestheground-truthkeyphrases. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 4>  </Paper ID = 112>


<Paper ID = 112> <Table 5> <Abstractive Summary> =WealsocomputeF1@10andF1@O,
In-house 0.094 0.282 0.014 0.035
where O represents the number of ground truth
keyphrases,andtheresultsarepresentedinTable
Table 12: Present and absent keyphrase prediction re-
12. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 5>  </Paper ID = 112>


<Paper ID = 1120> <Table 0> <Abstractive Summary> =rate of 0.5, is employed on the word embedding
Thiswouldbeaccomplishedbyﬁndingthenoun layer” is classiﬁed by the sentence extractor as
493belongingtotheinformationunit EXPERIMENTAL InformationUnit F1
SETUP,andthephrases“Dropout”,“isemployed”, None .9494
and “word embedding layer” were selected as a AblationAnalysis .1516
subject-predicate-objectpattern,thentripleswould Approach .0000
beformattedintheexperimental-setup.txttriples Baselines .2559
ﬁlelikeso: Code .7857
Dataset .0000
(Contribution||has||ExperimentalSetup) ExperimentalSetup .2466
(ExperimentalSetup||has||Dropout) Experiments .0000
(Dropout||isemployed||wordembeddinglayer) Hyperparameters .2358
Model .1778
ResearchProblem .4192
Results .3165
5.1 TriplesFormatting
Tasks N/A
Whilemostoftheinformationunits’tripleswere
formatted in the training data following the pat-
Table 1: F1 scores for each information unit based
tern in section 5, the information units Code and on evaluation on test data. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1120>


<Paper ID = 1120> <Table 1> <Abstractive Summary> =noprevioussubject-predicatepair,thenthesecond 30.19% (109 of 361) of sentences describing
494Predicted GoldClass
Class N AA A B C D ES E H M RP R T
None 27,922 113 123 55 7 10 178 223 59 446 230 405 0
AblationAnalysis 72 21 0 0 0 0 0 8 0 0 0 14 0
Approach 0 0 0 0 0 0 0 0 0 0 0 0 0
Baselines 146 0 0 38 1 0 1 5 2 5 2 2 0
Code 10 0 0 0 33 0 0 0 0 0 0 0 0
Dataset 0 0 0 0 0 0 0 0 0 0 0 0 0
ExperimentalSetup 125 0 0 0 0 0 73 5 27 1 0 0 0
Experiments 0 0 0 0 0 0 0 0 0 0 0 0 0
Hyperparameters 136 0 0 0 0 0 109 4 52 0 0 0 0
Model 222 0 7 2 0 0 0 2 0 75 2 3 0
ResearchProblem 88 0 0 0 0 0 0 1 0 3 118 0 0
Results 327 28 0 0 0 0 0 87 0 1 1 201 0
Tasks 0 0 0 0 0 0 0 0 0 0 0 0 0
Table 2: Confusion matrix for thirteen-class sentence classiﬁcation. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1120>


<Paper ID = 1120> <Table 2> <Abstractive Summary> =Sixoftheeightarticlesinthe
Tasks .0012
trialdatathatcontainedtheinformationunitTASKS
weremovedtothetrainingdatasetsothatitwould Table 8: Distribution of classes in the 59,755 training
containenoughexamplestolearnthepatternsas- sentencesprovidedbythetrainingdata. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 1120>


<Paper ID = 1121> <Table 0> <Abstractive Summary> =(’<s>’,’The’) 0.267
ScientiﬁcTermandPredicatePhrases: (’of’,’the’) 0.262
used (’on’,’the’) 0.174
BERTBASEmodel (’in’,’the’) 0.148
pre-trainedon (’<s>’,’In’) 0.147
EnglishWikipedia (’to’,’the’) 0.11
BooksCorpus (’with’,’the’) 0.101
for (’and’,’the’) 0.098
1Msteps (’state’,’of’) 0.088
Triples: (’the’,’art’) 0.088
(C,has,ES) (’with’,’a’) 0.081
(ES,used,BERTBASEmodel) (’the’,’model’) 0.08
(BERTBASEmodel,pre-trainedon,EnglishWikipedia) (’our’,’model’) 0.079
(BERTBASEmodel,pre-trainedon,BooksCorpus) (’learning’,’rate’) 0.073
(BERTBASEmodel,for,1Msteps) (’<s>’,’Our’) 0.071
(’for’,’the’) 0.068
(’We’,’use’) 0.068
Table 2: Example of a Contributing Sentence, corre- (’set’,’to’) 0.064
(’<s>’,’For’) 0.063
spondingScientiﬁcTermandPredicatePhrase,andex- (’In’,’this’) 0.058
tractedTriples (’that’,’the’) 0.058
(’of’,’%’) 0.053
(’word’,’embeddings’) 0.053
(’rate’,’of’) 0.051
(’natural’,’language’) 0.05
theseinformationunitsisshowninTable1. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1121>


<Paper ID = 1121> <Table 1> <Abstractive Summary> =The pre-training task of
2https://www.scholarcy.com/ BERT (Devlin et al., 2019a) depends on two un-
3seeourGithublinkmentionedintheabstractfordetails supervisedsub-tasks: maskedlanguagemodeling
505Model F1(withﬁltering) F1(w/oﬁltering)
CNN+Glove 0.3123 0.1347
Bertbase 0.3578 0.1681
Ourmodel 0.3987 0.1872
Table 4: Result of classiﬁction to contributing sen-
tences,allareF1scores
Figure 2: Classiﬁcation of Contributing and Non-
Contributingusingapre-trainedSciBERTmodel
Figure3:Architectureofclassiﬁcationofsentenceinto
correspondinginformationunits
(MLM)andnextsentenceprediction(NSP).These
twosub-tasksusethesamemodelarchitecturebut
with different input patterns and different output the[SEP]tokentocapturecontextualinformation
layer. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1121>


<Paper ID = 1122> <Table 0> <Abstractive Summary> =Therefore, Data
splittingtheMultilingualtask,weproposesystems
for three components - (i) EN-EN (train and dev Table 1: Available data for this task. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1122>


<Paper ID = 1122> <Table 1> <Abstractive Summary> =Model Accuracy
ELECTRA+Signal2 86.4
ELECTRABack-T+Signal2 86.1
ELECTRABack-T 85.6
rev
Table 4: Translate Test Models evaluated on Back Translated EN-EN dev set. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1122>


<Paper ID = 1122> <Table 2> <Abstractive Summary> =with respect to sentence 1 and 2, and ideally, we should train the model to lose its sense of order
516Submission EnsembleDetails Dev Cross-LingualTest
AR FR RU ZH
- OOV - 86.9 87.5 87.6 87.6
rev
- OOV2 - 85.6 86.8 87.1 87.5
rev
- RAND - 83.9 85.4 86.0 86.1
rev
- RAND2 - 85.4 86.7 86.9 84.5
rev
- ProbSum - 85.9 86.6 88.0 86.2
1 TTEnsemble1 87.1 83.7 85.3 86.0 86.1
- TTEnsemble2 87.3 83.9 84.8 85.1 86.5
- AdjustedThresholdRAND - 87.1 88.5 89 90.6
rev
Table 6: Final Ensembles Non-English Cross-Lingual Test. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 1122>


<Paper ID = 1122> <Table 3> <Abstractive Summary> =517Predicted Predicted
True False True False
Actual Actual
True 478 22 True 1627 373
False 45 455 False 131 1869
Table 8: Confusion Matrix of English (EN-EN) Sub- Table 10: Confusion Matrix of Zero-Shot model in
Task Cross-LingualSub-Task(ModelRAND ). </Abstractive Summary> <Extractive Summary> Fordevelopment, summarized in Table 5 for the development sets,
weuseaback-translatedEN-ENdevset(ENtoFR and Table 3 for test set performance (where we
to EN) for the second sentence to simulate inac- showscoresofvariousensembles).  </Extractive Summary>  </Table 3>  </Paper ID = 1122>


<Paper ID = 1122> <Table 4> <Abstractive Summary> =rev
Predicted
True False Predicted
Actual True False
Actual
True 1773 227
True 1700 300
False 344 1656
False 289 1711
Table 9: Confusion Matrix of Multi-Lingual (Non-
Table11: ConfusionMatrixofTranslate-Testmodelin
English)Sub-Task(ModelOOV ). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 4>  </Paper ID = 1122>


<Paper ID = 1123> <Table 0> <Abstractive Summary> =BERT+Span 76.29 86.77 69.34
Ensemble 75.01 89.66 70.83
Given the contextual representation x =
Table 2: Performance of three benchmark models and
{x ,x ,··· ,x } ∈ Rn×h, for the location i, we
1 2 n ensembleapproach. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1123>


<Paper ID = 1123> <Table 1> <Abstractive Summary> =Thelearning #w in whole corpusisthecountofappearances
523#ofwords P(%) R(%) F1(%)
Ensemble - 75.01 89.66 70.83
Lexicon1(Wiegandetal.,2018) 551 75.13 44.47 33.07
Lexicon2(Wiegandetal.,2018) 2989 66.22 72.01 50.98
Lexiconoriginal(Our) 119 76.71 82.22 64.98
Lexiconwordnet(Our) 231 72.56 84.05 64.09
Lexiconglove(Our) 186 73.98 83.34 64.19
Table 3: Results of Lexicon-based approaches and ensemble model on Precision, Recall and F1. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1123>


<Paper ID = 1124> <Table 0> <Abstractive Summary> =AlBERT- 3,5 16 1e-5 17
large
6 Experiments
Table 5: Hyperparameter was used in all experi-
ments for two phases(development and evaluation) of
We have experimented with several pre-trained
alltasks. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1124>


<Paper ID = 1124> <Table 1> <Abstractive Summary> =base
(3) RoBERTa-1e-5 32 0.9661 0.9580 # model LR Batch RMSE
large Size
(4) RoBERTa-1e-5 16 0.9663 0.9580 (1) RoBERTa- 1e-5 8 0.4828
large base
(5) RoBERTa-1e-5 8 0.9669 0.9590 (2) RoBERTa- 1e-5 32 0.4741
large large
(6) * * * 0.9675 0.9600 (3) RoBERTa- 1e-5 16 0.4609
large
Table 6: Top best experiments used for task 1a (4) RoBERTa- 1e-5 8 0.4559
in the evalution phase by RoBERTta(large/base)
large
model. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1124>


<Paper ID = 1124> <Table 2> <Abstractive Summary> =*Ensemblefor1,2,3,4,5
(5) * * * 0.4469
Table 8: Top best experiments used for task 2 in the
with the same method of ensemble and hyperpa-
evaluation phase by RoBERTta(large/base) model. </Abstractive Summary> <Extractive Summary> Thedatasetprovidedby(Meaneyetal.,2021)Se-
Table 2 shows an example of the training dataset mEval2021organizersfortask7contains10,000
fortask1b.  </Extractive Summary>  </Table 2>  </Paper ID = 1124>


<Paper ID = 1124> <Table 3> <Abstractive Summary> =(3) BERT- 1e-5 16 0.5468
large
(4) BERT- 1e-5 8 0.5498
large
(5) * * * 0.5446
Table 7: Top best experiments used for task 2 in the
evaluationphasebyBERT(large/base). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 1124>


<Paper ID = 1126> <Table 0> <Abstractive Summary> =2
3.4 Ensemble Table 2: Results on validation set (Mean Absolute Er-
rors)
Inordertohaveabetterbiasvariancetradeoffand
alsotoexploitthe“expertise”ofdifferentpipelines,
theﬁnalapproachincorporatesboththeregression
Task MAE Pearson MSE
and classiﬁcation pipelines to form an ensemble. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1126>


<Paper ID = 1129> <Table 0> <Abstractive Summary> =Thefeatureimportance
Table 2: Importance of the top 15 single features for
reﬂects the number of times a feature is selected
themodel(onsinglewords). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1129>


<Paper ID = 113> <Table 0> <Abstractive Summary> =tionfromaparaphrasewiththesamemeaning
and an exemplar with the same surface form, Table 1: Examples of question paraphrase clusters,
leadingtoseparatedencodingspaces. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 113>


<Paper ID = 113> <Table 1> <Abstractive Summary> =determining question templates, including using
Table 2: Examples of the exemplar retrieval process part-of-speech tags and (truncated) constituency
fortraining. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 113>


<Paper ID = 113> <Table 2> <Abstractive Summary> =(b)SEPARATOR
ModelConﬁguration Followingpreviouswork Table 3: Retrieval accuracies for each encoding for
eachclustertype. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 113>


<Paper ID = 113> <Table 3> <Abstractive Summary> =paraphrase reﬂected the meaning of the original,
Table 5: Examples of output generated by various ap- andtheﬂuencyoftheparaphrase(seeAppendixC). </Abstractive Summary> <Extractive Summary> Table 4 shows that the Copy, VAE and AE
Table 3 shows that our approach yields encod-
models display relatively high BLEU scores, but
ingsthatsuccessfullyfactorisemeaningandform,
achievethisby‘parroting’theinput;theyaregood
withnegligibleperformancelosscomparedtothe
atreconstructingtheinput,butintroducelittlevari-
VAEbaseline;paraphraseretrievalperformanceus-
ation in surface form, reﬂected in the high Self-
ingz fortheseparatedmodeliscomparableto
sem BLEU scores.  </Extractive Summary>  </Table 3>  </Paper ID = 113>


<Paper ID = 113> <Table 4> <Abstractive Summary> =Youshouldchoose
Table 6: Hyperparameter values used for our experi-
thesystemthatusesthemostdifferentwords
ments. </Abstractive Summary> <Extractive Summary> Table 4 shows that the Copy, VAE and AE
Table 3 shows that our approach yields encod-
models display relatively high BLEU scores, but
ingsthatsuccessfullyfactorisemeaningandform,
achievethisby‘parroting’theinput;theyaregood
withnegligibleperformancelosscomparedtothe
atreconstructingtheinput,butintroducelittlevari-
VAEbaseline;paraphraseretrievalperformanceus-
ation in surface form, reﬂected in the high Self-
ingz fortheseparatedmodeliscomparableto
sem BLEU scores. 4.3 Analysis
The last row in Table 4 (ORACLE) reports re-
sults when our model is given a valid exemplar When predicting latent codes at test time, we as-
to use directly for generation, thus bypassing the sumethatthecodeforeachheadmaybepredicted
codepredictionproblem.  </Extractive Summary>  </Table 4>  </Paper ID = 113>


<Paper ID = 1130> <Table 0> <Abstractive Summary> =Table 1: Examples of the instances from the different
Aseconditerationofthesharedtaskwasorga-
corpora,togetherwiththemeancomplexityscoresfor
nizedin2018(Yimametal.,2018),thistimefea-
thetargetwordsinbold. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1130>


<Paper ID = 1133> <Table 0> <Abstractive Summary> =Sub-Task1(Wordcomplexity) Sub-Task2(MWEcomplexity)
Pearson Spearman MAE MSE R2 Pearson Spearman MAE MSE R2
w/oattention 0.7584 0.7316 0.1089 0.0171 0.485 0.8323 0.8335 0.0941 0.094 0.6632
w/oauxiliaryloss(Laux) 0.7597 0.7198 0.0695 0.0082 0.3176 0.8382 0.8352 0.0692 0.0074 0.6167
w/ouncertaintylossweighing 0.7694 0.7321 0.0728 0.0088 0.4623 0.8472 0.8401 0.0797 0.0103 0.6071
Model 0.7779 0.7366 0.0803 0.01 0.3813 0.8489 0.8406 0.076 0.0087 0.638
Table 2: Ablation study of our model’s component using joint training and RoBERTa-large as encoder (symbol
w/o denotes without the corresponding component). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1133>


<Paper ID = 1134> <Table 0> <Abstractive Summary> =MTL 0.8000 0.7528 0.0662 0.0075 0.6052
POS
MTL 0.7936 0.7208 0.0654 0.0070 0.6290
GR
MTL 0.7982 0.7272 0.0656 0.0070 0.6300
genre
Camb-2018 0.7079 0.6885 0.0746 0.0095 0.4957
Table 4: Performance of individual systems on the trial set (sub-task 1). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1134>


<Paper ID = 1135> <Table 0> <Abstractive Summary> =legislativeefﬁcacy 0.3833
Table 1: The training set sample data we use in the task. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1135>


<Paper ID = 1135> <Table 1> <Abstractive Summary> =For the stop word list, we 2https://github.com/RaRe-Technologies/gensim
600Team subtask Pearson Spearman MAE MSE R2
Top1 1 0.7886 0.7369 0.0609 0.0062 0.6172
Top2 1 0.7882 0.7425 0.0610 0.0061 0.6210
Top3 1 0.7790 0.7355 0.0619 0.0064 0.6062
Our 1 0.7434 0.6995 0.0658 0.0073 0.5486
Top1 2 0.8612 0.8526 0.0616 0.0063 0.7389
Top2 2 0.8575 0.8529 0.0672 0.0072 0.7035
Top3 2 0.8571 0.8548 0.0675 0.0072 0.7012
Our 2 0.8000 0.7797 0.0754 0.0089 0.6323
Table 2: The scores of the top three teams and our team on the test set announced by the task organizer. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1135>


<Paper ID = 1135> <Table 2> <Abstractive Summary> =RoBERTa 0.7327 0.7846
BERT 0.7255 0.7644
5 ResultsandAnalysis
Table 3: The scores of the Pearson correlation coefﬁ-
According to the Pearson correlation coefﬁcient,
cient results obtained by our different systems on the
the results submitted by the teams participating
validation set. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 1135>


<Paper ID = 1138> <Table 0> <Abstractive Summary> =618Split Size (0,0) (0,1) (1,0) (1,1) (0,2) (2,0) (1,2) (2,1) (2,2)
Chi-M 1.5M 0.569 0.302 0.288 0.229 0.254 0.211 0.205 0.183 0.171
Chi-S 1.5M 0.547 0.297 0.287 0.225 0.246 0.215 0.200 0.183 0.170
Chi-MS 3M 0.578 0.316 0.312 0.245 0.261 0.233 0.217 0.200 0.184
Fam-M 2.9M 0.609 0.334 0.318 0.255 0.284 0.232 0.232 0.201 0.191
Fam-S 3.1M 0.578 0.338 0.305 0.253 0.277 0.226 0.225 0.202 0.187
Fam-MS 6M 0.607 0.346 0.327 0.263 0.291 0.241 0.239 0.211 0.198
Com-M 19.3M 0.591 0.333 0.323 0.258 0.280 0.241 0.233 0.210 0.196
Com-S 15.7M 0.578 0.351 0.319 0.268 0.279 0.234 0.229 0.211 0.189
Com-MS 35M 0.571 0.339 0.323 0.264 0.277 0.243 0.233 0.216 0.197
Movies 21M 0.592 0.335 0.327 0.262 0.281 0.244 0.236 0.213 0.198
Series 17M 0.576 0.352 0.321 0.269 0.281 0.238 0.233 0.214 0.193
All 38M 0.570 0.341 0.326 0.267 0.279 0.247 0.236 0.219 0.201
Table 1: Trial set Pearson correlations between complexity scores and frequencies for all SubIMDB splits and
n-gramconﬁgurationsonthesinglewordssub-track. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1138>


<Paper ID = 1138> <Table 1> <Abstractive Summary> =Cambat
cwisharedtask2018: Complexwordidentiﬁcation
Table 4: Pearson correlation obtained by the UTFPR with ensemble-based voting. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1138>


<Paper ID = 114> <Table 0> <Abstractive Summary> =The AGGGEN 58.74 0.40 0.43
AGGGEN−OD 55.30 0.44 0.43
model can predict the most likely plan based on AGGGEN−AG 52.17 0.50 0.44
theinputtriplesandthehyperparameterandgener-
Table 1: Generation Evaluation Results on the
ateacorrespondingtextdescription;(2)themodel
WebNLG(seen). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 114>


<Paper ID = 114> <Table 1> <Abstractive Summary> =Crucially,thisalso
Table 5: Alignment Evaluation Results. </Abstractive Summary> <Extractive Summary> We Table 1 shows the generation results on the
evaluatedontheE2Etestsetusingautomaticslot WebNLG seen category (Gardent et al., 2017b).  </Extractive Summary>  </Table 1>  </Paper ID = 114>


<Paper ID = 1141> <Table 0> <Abstractive Summary> =634FrequencySources Pearson FeatureCombination #Features Pearson
All-EMEA 0.713 36Linguistic+
112 0.7942
All 0.7128 76Embedding
All-EMEA-Bible 0.7041 Linguistic 36 0.7925
OpenSubs+BNC BERTEmbeddings 1536 0.6999
0.6882
+EnWiki+SimpleWiki
OpenSubs 0.6536
Table 4: Best systems trained on linguistic, word em-
SubIMDB 0.6479
beddingandthecombinedfeatures
Table2: FrequencySources
tures is statistically insigniﬁcant. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1141>


<Paper ID = 1142> <Table 0> <Abstractive Summary> =BERT minmax 0.7260 0.0088
BERT both 0.7178 0.0134
4.4 Model
Table 2: Results of all feature sets reporting Pearson
RS GV’sstructureisamoresimpleversionofthe correlation r (average of 10 runs) on the trial data set. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1142>


<Paper ID = 1142> <Table 1> <Abstractive Summary> =(2018),
Table 3: Results using the trial (3rd) and test dataset
RS GVperformsonaveragebetterusingthecross-
(4thcolumn)usingPearsoncorrelationrforevaluation. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1142>


<Paper ID = 1143> <Table 0> <Abstractive Summary> =652Model R Rho MAE MSE R2 Model R Rho MAE MSE R2
Baseline 0.618 0.633 0.080 0.011 0.378 Baseline 0.584 0.597 0.080 0.108 0.334
MLM 0.622 0.635 0.080 0.011 0.383 System 1 0.691 0.656 0.073 0.0094 0.418
System 0.698 0.673 0.074 0.009 0.476 System 2 0.695 0.654 0.072 0.0089 0.450
1
System 0.712 0.680 0.072 0.009 0.499 System 3 0.689 0.653 0.069 0.0086 0.471
2
System 0.705 0.678 0.073 0.009 0.482
3
Table3: ResultsonSINGLEforeachsystemandeach
Table 1: Results for each model for each evaluation evaluation metric. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1143>


<Paper ID = 1143> <Table 1> <Abstractive Summary> =System 0.741 0.735 0.0843 0.0116 0.519
1
Model R Rho MAE MSE R2 System2 0.752 0.742 0.0802 0.0106 0.562
Baseline 0.665 0.683 0.094 0.015 0.412 System3 0.736 0.730 0.0851 0.0116 0.521
MLM 0.665 0.684 0.094 0.015 0.411
Table 4: Results on MULTI for each system and each
System 0.675 0.686 0.092 0.014 0.440
1
evaluation metric. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1143>


<Paper ID = 1143> <Table 2> <Abstractive Summary> =System 0.673 0.684 0.091 0.014 0.432
3
Table 2: Results for each model for each evaluation
workstructure,andtrainingsettings,asforSystem . </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 1143>


<Paper ID = 1149> <Table 0> <Abstractive Summary> =• NUMDIGITS: thenumberofdigitsintheto-
Model Pearson ken
Flesch-KincaidGrade 0.07
• ISFIRSTCAPITAL: whether or not the ﬁrst
AutomatedReadabilityIndex 0.07
letteriscapitalized(implyingitisasubjector
SMOGIndex 0.03
technicalterm)
Table 1: Pearson correlation between complexity met-
• NUMSENTWORDS: thenumberofwordsin
ricsandtruecomplexityvalues(single-word)
thecontextsentence
• CORPUSTYPE: the type of corpus the sen-
1https://github.com/shivam5992/textstat tenceistakenfrom
689• POS:thepartofspeechofthetoken previoustreesdidnotﬁtwellto. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1149>


<Paper ID = 115> <Table 0> <Abstractive Summary> =REFLECTIVE DECODING
RD (Us) 36.4 56.9 45.3
45 achievesthebestunsupervisedscoresonnovelty-
awaremetrics(Table2),withthebestoverallSARI,
Table 2: Model performance on the Twitter URL test
evenoutperformingreferenceonthehumanmetric,
split. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 115>


<Paper ID = 115> <Table 1> <Abstractive Summary> =Table 3: Model performance on αNLG. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 115>


<Paper ID = 115> <Table 2> <Abstractive Summary> =0.9 6
Input: LefttorightlanguagemodelLM
←−
RighttoleftlanguagemodelLM
Table 4: Most parameters are explained in §2.4. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 115>


<Paper ID = 1150> <Table 0> <Abstractive Summary> =bible 0.296 0.132
In past evaluation campaigns, there have been europarl 0.287 0.109
occasionalattemptsatincorporatingwordembed- biomed 0.325 0.152
dingsmodelsintheautomaticevaluationprocess,
Table 1: Meancomplexity andstandard deviation for
withtheassumptionthatlexicalcomplexityshould
eachdomainintheLCP-2021trainingdataset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1150>


<Paper ID = 1150> <Table 1> <Abstractive Summary> =Weused
Table 3: Average random forest regression results on
pre-trained models made available by Hug-
ﬁvetraining-trialsplits. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1150>


<Paper ID = 1150> <Table 2> <Abstractive Summary> =Table 4: Average random forest regression results on
SianGoodingandEkaterinaKochmar.2018. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 1150>


<Paper ID = 1154> <Table 0> <Abstractive Summary> =Table 3: In the result list released by the task orga-
nizer team, the top 3 submitted test set prediction re-
sultsscoresandoursubmittedtestsetpredictionresults
ofRoBERTacombinedwithTf-Idf. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1154>


<Paper ID = 1156> <Table 0> <Abstractive Summary> =Table 2: Sample sentence-pair instances selected for data augmentation. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1156>


<Paper ID = 1156> <Table 1> <Abstractive Summary> =n Label F
• Ifoneofthemispositive(‘T’)andtheother
Table 3: A sentence-pair example extracted from
isnegative(‘F’,i.e. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1156>


<Paper ID = 1156> <Table 2> <Abstractive Summary> =1 WiC +XL-WiC(FR&ZH) 89.90 78.10 80.10 83.60 78.20 81.98
aug. aug.
2 WiC +XL-WiC 89.60 79.20 82.90 85.40 79.30 83.28
aug. aug.
3 WiC +XL-WiC +CALD+SeCoDa 90.30 80.20 83.30 86.30 76.90 83.40
aug. aug.
4 Ensemble(MV) 90.80 79.70 83.00 85.40 79.30 83.64
Table 5: Performance of individual systems and the ensemble on MCL-WiC-dev (multilingual track). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 1156>


<Paper ID = 1157> <Table 0> <Abstractive Summary> =Alltheexperimentsareperformed Python3.7.4
740EN-AR EN-FR EN-RU EN-ZH
XLM-RoBERTaBase+MLP,Zero-Shot 74.30(46) 80.00(39) 81.60(35) 76.30(43)
XLM-RoBERTaLarge+MLP,Zero-Shot 76.70(41) 84.00(19) 82.90(28) 81.00(37)
XLM-RoBERTaBase+MLP,Few-shot 73.00(49) 76.50(50) 80.10(40) 75.50(44)
XLM-RoBERTaLarge+MLP,Few-shot 80.40(34) 81.40(34) 80.70(38) 81.80(33)
XLM-RoBERTaLarge+KNN,Few-shot 81.90(30) 83.90(20) 83.30(24) 83.60(29)
Table 1: Accuracy on the ﬁnal cross-lingual test set with the rank achieved by that submission in brackets. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1157>


<Paper ID = 1157> <Table 1> <Abstractive Summary> =EN-EN AR-AR FR-FR RU-RU ZH-ZH
XLM-RoBERTaBase+MLP,Zero-Shot 84.50(50) 78.20(40) 78.60(44) 78.10(34) 81.40(32)
XLM-RoBERTaLarge+MLP,Zero-Shot 87.30(37) 77.30(43) 84.20(18) 82.30(23) 80.80(35)
XLM-RoBERTaBase+MLP,Few-shot 84.40(51) 78.90(36) 79.20(41) 78.10(34) 80.60(36)
XLM-RoBERTaLarge+MLP,Few-shot 87.10(38) 81.00(27) 83.40(22) 82.00(24) 82.00(28)
XLM-RoBERTaLarge+KNN,Few-shot 88.50(33) 78.40(38) 83.60(21) 81.90(25) 82.10(27)
Table 2: Accuracy on the ﬁnal multi-lingual test set with the rank achieved by that submission in brackets. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1157>


<Paper ID = 116> <Table 0> <Abstractive Summary> =Towards Table-to-Text Generation with Numerical Reasoning
LyaHulliyyatusSuadaa1,HidetakaKamigaito1,KotaroFunakoshi1,
ManabuOkumura1 andHiroyaTakamura1,2
1TokyoInstituteofTechnology
2NationalInstituteofAdvancedIndustrialScienceandTechnology(AIST)
lya@stis.ac.id
{kamigaito,funakoshi,oku}@lr.pi.titech.ac.jp
takamura@pi.titech.ac.jp
Abstract
Table 2: The overall mention detection results on the test set 
of OntoNotes. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 116>


<Paper ID = 116> <Table 1> <Abstractive Summary> =DescriptiveFacts InferredFacts
Model Relevance
#Supp #Cont %Cont #Supp #Cont %Cont
Template-based 1.00 0.01 0.01 0.93 0.11 10.64 3.89
Pointer-generator 0.00 0.00 0.00 0.00 0.00 0.00 1.50
Fine-tunedGPT2 0.03 1.28 97.46 0.43 1.94 81.78 2.36
Fine-tunedT5 0.05 0.07 54.55 0.50 1.10 68.75 3.51
Fine-tunedT5+Copy 0.04 0.04 50.00 0.78 0.57 42.62 3.78
Table 4: Average number of supporting and contradicting facts in generated table descriptions, percentage of
contradictingtototalfacts,andlevelsofrelevancetotablecaptions. </Abstractive Summary> <Extractive Summary> 3.2 DatasetComparison
Table 1 provides a comparison of numericNLG
3 NumericalTable-to-TextDataset
with other related table-to-text datasets.  </Extractive Summary>  </Table 1>  </Paper ID = 116>


<Paper ID = 116> <Table 2> <Abstractive Summary> =Wealsomeasuredthelevelofrel-
Table 5: Grammaticality, coherence, and conciseness evance of the generated text to the table captions
levelsoftabledescriptiongenerators. </Abstractive Summary> <Extractive Summary> One of the remaining impor-
tant challenges is generating more analytical Target Header
descriptionsthatcanbeinferredfromfactsin Our full model
adatasource.Theuseofatemplate-basedgen- Description
eratorandapointer-generatorisamongthepo-
Table 2 shows the mention detection results on the test set. Whileourfocusis
from T are injected in this representation primarily on pre-trained models since they have
OP
tocoverthenumericalreasoningofdatainthe been most widely used for limited data settings,
1454Fine-tuning phase
TOPof Table 2 TD of Table 2
Y:Table 2 shows that our full model achieves 
op … m h result valresult h th val m target
higher precisionand f1-score.  </Extractive Summary>  </Table 2>  </Paper ID = 116>


<Paper ID = 1160> <Table 0> <Abstractive Summary> =93.3 87.4 87.5 84.8 91
Table 2: Best test score for each of the proposed systems. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1160>


<Paper ID = 1160> <Table 1> <Abstractive Summary> =For
both submissions, due to a mistake, we used the Table 3: Post-evaluation test scores for the cross-
GLMmodeltrainedforonlyoneepochonSemCor lingual subtask. </Abstractive Summary> <Extractive Summary> In Table 1 we show some examples from the de-
Wealsosuspectedthatduringpre-trainingonthe
velopmentsetwithtop3senses(glosses)predicted
English WSD data, GLM models can overﬁt to
byoursystemforeachoccurrence.  </Extractive Summary>  </Table 1>  </Paper ID = 1160>


<Paper ID = 1163> <Table 0> <Abstractive Summary> =Word-
in-Context Disambiguation is a new declination Table 1: Statistics of the data provided by organizers. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1163>


<Paper ID = 1163> <Table 1> <Abstractive Summary> =(2020),inour
preliminary experiments we tried to solve MCL- Table 2: Training hyperparameters of MTL-EN and
WIC in Question Answering (QA) task manner, MTL-XXsystems,submittedtothecompetition
where we predict the start and end positions (the
span)oftheanswerinagiventext. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1163>


<Paper ID = 1164> <Table 0> <Abstractive Summary> =Most approaches are supervised methods which 
can be classified into different methods:  
Language  Total  Training  Testing 
(1) regression, based on the embeddings in one 
words  words  words 
language using a leastsquares objective (Dinu et al., 
Arabic  20000  15000  5000 
2015; Artexe et al., 2018);  
Chinese  16000  12000  4000 
(2) orthogonal, based on the embeddings in one 
English  24500  16500  8000 
or  both  languages  under  the  constraint  of  the  French  22000  15500  6500 
transformation (Zhang et al., 2016; Smith et al.,  Russian  20000  14500  5500 
2017);  
(3) canonical, based on the embeddings in both  Table 1: Corpus statistics 
languages to a shared space, using canonical link 
extension of it (Lu et al., 2015). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1164>


<Paper ID = 1165> <Table 0> <Abstractive Summary> =questionlength 24.6 27.1
2017), we ﬁrst take EOD as Query, EP as Key Vocabularysize 16,318 17,006
andValuetocalculateoneoftheco-attentionrepre- Answervocabularysize 4,333 4,775
sentations,whichsimulatestheprocessofhuman
re-reading the passage with impression of option Table 1: Basic statistics of subtask 1 and subtask 2
anddeﬁnition. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1165>


<Paper ID = 1166> <Table 0> <Abstractive Summary> =Themodel
Table 2: Evaluation results of the proposed approach was trained by RMSprop optimizer for 100
using different similarity metrics on the development
epochswiththelearningrate0.01. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1166>


<Paper ID = 1168> <Table 0> <Abstractive Summary> =3)Spanprediction: Thiskind
Table 1: Examples of the SemEval 2021 Task 4.
oftaskisalsocalled(Extractivequestionanswer-
Given a passage and a question, the model needs to
ing),whichrequiresthesystemtoextractasuitable pick the best one from the ﬁve candidates to replace
rangeoftextfragmentsfromagivenoriginaltext @placeholder. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1168>


<Paper ID = 117> <Table 0> <Abstractive Summary> =ingeneral.”
Table 1: Deﬁnitions and examples of our proposed citation functions. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 117>


<Paper ID = 117> <Table 1> <Abstractive Summary> =Weconcludethatfora
PTGEN-Cross∗ 27.08 7.14 20.61
citingsentencegeneration,consideringandtrain-
BACO 32.54 9.71 24.90
ingamodelonbackgroundknowledge, sentence
salience,andcitationfunctionimprovestheperfor-
Table 2: Experimental results for our framework and
mance. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 117>


<Paper ID = 117> <Table 2> <Abstractive Summary> =The output from BACO
-w/oCF 30.84 8.67 23.31
showed a higher overlap with the ground truth,
speciﬁcally because it included background that
Table 3: Ablation study for different components of
is not explicitly covered in the cited paper. </Abstractive Summary> <Extractive Summary> Cross-entropylosswas
5.2 ExperimentalResults
set as the objective function for training the clas-
siﬁerwiththegroundtruthlabely ,whichisa As the results in Table 2 show, our proposed
func
one-hotvector: framework (BACO) outperformed all of the con-
sidered baselines.  </Extractive Summary>  </Table 2>  </Paper ID = 117>


<Paper ID = 117> <Table 3> <Abstractive Summary> =1476A Appendices Precision Recall F1-score
cross 95.43 95.43 95.43
A.1 ExperimentsforCitationFunction
test 91.59 91.59 91.59
LabelingModel
To test our citation function labeling model, we Table 5: The results of the citation function labeling
model for cross-validation (denoted as cross) and on
applied 10-fold cross-validation to our training
theexternaltestdata(denotedastest)
datasetwith800citingsentences. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 117>


<Paper ID = 1170> <Table 0> <Abstractive Summary> =TounderstandComSR’sability
todisambiguate,wespeciﬁcallyselectedsamples
Table 3: Comparison among different implementation that contained polysemous words in answers. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1170>


<Paper ID = 1173> <Table 0> <Abstractive Summary> =.... 
Model Result(%)
BiLSTM-CRF 61.32
BiLSTM - CRF  BiLSTM-CRF+ToxicBERT 62.23
Top1rank 70.83
Output spans  Table 3: Experimental results obtained by our system
[0, 0, 0, 1, 1, ...] 
incomparisonwithTop1rankresult. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1173>


<Paper ID = 1174> <Table 0> <Abstractive Summary> =SqueezeBERT 0.657
ELECTRA 0.646
3.3.1 Dealingwithlonginputs
Table 2: The comparison of BERT and BERT-based
Thedatasetforthetaskcontainedmanycomments
modelsonthevalidationdataset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1174>


<Paper ID = 1174> <Table 1> <Abstractive Summary> =Table 3: The span-level F1 score on validation set for
BERTmodelwithaugmentationwithagivenalpha. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1174>


<Paper ID = 1174> <Table 2> <Abstractive Summary> =Thistechnique
Table 5: The comparison of selected models’ per-
slightlyimprovedtheperformanceasnotedinTa-
formance on the test dataset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 1174>


<Paper ID = 1174> <Table 3> <Abstractive Summary> =0 0.6720
1 0.6735
2 0.6730 5 Discussion
Table 4: The results of marking the given number of Aspresentedintheprevioussection,thesupervised
charactersinbetweentoxicspansastoxicbyBERTon solutiontotokenclassiﬁcationoutperformedboth
validationset. </Abstractive Summary> <Extractive Summary> Thelengthofthepreprocessedsamplesdid
Theresultsobtainedwhileusingaugmentationpre-
nothavetobebasedonlyonBERTlimitationsand
sented in Table 3 are ambiguous and do not give
canbeadjustedforbettertrainingcomplexity.  </Extractive Summary>  </Table 3>  </Paper ID = 1174>


<Paper ID = 1177> <Table 0> <Abstractive Summary> =Thenei isfedinto |St |
A
872Method F1
BERT-CRF 0.6933
ELECTRA-CRF 0.6944
ERNIE-CRF 0.6985
ERNIE-CRFw/o-adv 0.6964
ERNIE-CRFnltk-preprocessing 0.6557
Table 2: Results on the ofﬁcial evaluation testing data. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1177>


<Paper ID = 1179> <Table 0> <Abstractive Summary> =ond dimension we explore is methodology,
including leveraging attention, employing a Table 1: Examples of toxic spans in toxic texts. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1179>


<Paper ID = 1179> <Table 1> <Abstractive Summary> =toxicor
wasusedinbothOffensEval2019(Zampierietal.,
non-toxic),D representsthetextswithattributea,
a
2019b)andOffensEval2020(Zampierietal.,2020)
3https://www.kaggle.com/c/jigsaw-toxic-comment-
1Code:https://github.com/JonRusert/semeval-2021-task-5 classiﬁcation-challenge
2https://nlp.stanford.edu/projects/glove/ 4https://gab.com/
882ToxicDatasets
Train OLID Kaggle-Toxic Founta Gab Davidson Average
Attention 50.1 50.1* 39.4 35.2 17.4 22.8 35.8
GreedyRemove 38.3 44.7 43.3 41.9 20.8 18.6 34.6
s
d FrequencyRatio 41.5 45.5 22.5 44.3 19.7 8.0 30.3
o
h
t SimpleHybrid 38.4 45.5 41.7 39.6 17.7 21.7 34.1
e
M
RecallHybrid 37.9 45.2 38.4 34.6 17.8 22.7 32.8
PrecisionHybrid 50.7 49.8 44.6 42.6 20.8 19.0 37.9
Average 42.8 46.8 38.3 39.7 19.0 18.8
TopSystem 70.8
Table 2: Full Results on the provided Toxic Span Test Set. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1179>


<Paper ID = 1179> <Table 2> <Abstractive Summary> =Table 5: F1 scores of ensemble models. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 1179>


<Paper ID = 118> <Table 0> <Abstractive Summary> =Bothmodelsinheritatypi- A Avg.Tokens 4859.52 5056.25 5257.80
Avg.Sum 323.74 321.25 328.20
calsequence-to-sequenceframework, whichﬁrst
encodesthesourcedialogueD todistributedrepre-
Table 1: Statistics for SAMSum and AMI datasets. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 118>


<Paper ID = 118> <Table 1> <Abstractive Summary> =Training Objective Model parameters θ are 8https://github.com/pytorch/fairseq
trainedtomaximizetheconditionallikelihoodof 9https://github.com/OpenNMT/OpenNMT-py
1483Model R-1 R-2 R-L Model R-1 R-2 R-L
Extractive Extractive
LONGEST-3 32.46 10.27 29.92 TextRank 35.19 6.13 15.70
TextRank 29.27 8.02 28.78 SummaRunner 30.98 5.54 13.91
Abstractive Abstractive
Transformer 36.62 11.18 33.06 UNS 37.86 7.84 13.72
D-HGN 42.03 18.07 39.56 TopicSeg 51.53†† 12.23 25.47†
TGDGA 43.11 19.15 40.49 HMNet 52.36† 18.63† 24.00
DialoGPT 39.77 16.58 38.42
Ours
MV-BART 53.42 27.98 49.97††
PGN 48.34 16.02 23.49
Ours PGN(D ) 50.22 17.74 24.11
KE
BART 52.98 27.67 49.06 PGN(D ) 50.62 16.86 24.27
RD
BART(D ) 53.43†† 28.03†† 49.93 PGN(D ) 48.59 16.07 24.05
KE TS
BART(D ) 53.39 28.01 49.49 PGN(D ) 50.91 17.75†† 24.59††
RD ALL
BART(D ) 53.34 27.85 49.64
TS
BART(D ) 53.70† 28.79† 50.81† Table 3: Test set results on the AMI dataset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 118>


<Paper ID = 118> <Table 2> <Abstractive Summary> =ALL PGN(D ),PGN(D )andPGN(D )representtrain-
KE RD TS
ing PGN on the AMI with keywords, redundancy and
Table 2: Test set results on the SAMSum dataset,
topicannotationrespectively. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 118>


<Paper ID = 118> <Table 3> <Abstractive Summary> =BART(D ) 90.04 PGN(D ) 82.76
ALL ALL
Table 4: Test set results on the SAMSum and AMI. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 118>


<Paper ID = 118> <Table 4> <Abstractive Summary> =Method R-1 R-2 R-L
Golden 4.37 4.26 4.27 Rule-BasedMethods
BART 3.66 3.65 3.66 Entities 53.36 27.71 49.69
m
u MV-BART 3.85 3.76 3.88 NounsandVerbs 52.75 27.48 48.82
S
M BART(DKE) 3.88 3.77 3.79 TraditionalMethods
A BART(D ) 3.74 3.98† 3.89
S RD TextRank 53.29 27.66 49.33
BART(D ) 3.95†† 3.76 4.01††
TS Topicwords 53.28 27.76 49.59
BART(D ) 4.05† 3.78†† 4.08†
ALL Pre-trainedLanguageModel-BasedMethods
Golden 4.70 3.85 4.35
KeyBERT
PGN 2.92 3.08 2.70
w/BERTemb 52.39 27.14 48.52
HMNet 3.52† 2.40 3.40†
I w/DialoGPTemb 53.14 27.25 49.42
M
PGN(D ) 3.20 3.08 3.00
A KE Ours
PGN(D ) 3.15 3.25† 3.00
RD DialoGPT 53.43 28.03 49.93
PGN(D ) 3.05 3.10†† 3.17†† KE
TS
PGN(D ) 3.33†† 3.25† 3.10
ALL Table 6: Test set results of ﬁne-tuning BART on the
SAMSum that is annotated with keywords using vari-
Table5: Humanevaluationresults. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 4>  </Paper ID = 118>


<Paper ID = 118> <Table 5> <Abstractive Summary> =1485Model R-1 R-2 R-L Model R-1 R-2 R-L
SAMSum SAMSum
Rule-based 53.00 27.71 49.68 C99
DialoGPT 53.39 28.01 49.49 w/BERTemb 52.80 27.78 49.50
RD
w/DialoGPTemb 53.33 28.04 49.39
AMI
DialoGPT 53.34 27.85 49.64
Rule-based 50.19 16.45 23.95 TS
DialoGPT 50.62 16.86 24.27 AMI
RD
Golden 50.28 19.73 24.45
Table 8: Test set results on the SAMSum and AMI
C99
datasets that are annotated with redundant utterances. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 5>  </Paper ID = 118>


<Paper ID = 118> <Table 6> <Abstractive Summary> =BART(D ) 53.70 28.79 50.81
ALL
YizheZhang,SiqiSun,MichelGalley,Yen-ChunChen,
Table 10: Test set results on the SAMSum dataset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 6>  </Paper ID = 118>


<Paper ID = 118> <Table 7> <Abstractive Summary> =PGN(D ) 50.91 17.75 24.59
ALL
A EvaluationDetails Table 11: Test set results on the AMI dataset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 7>  </Paper ID = 118>


<Paper ID = 118> <Table 8> <Abstractive Summary> =PGN(DRD) 0.97 50.18 16.12 24.56
PGN(D ) 0.98 48.63 15.17 23.50
Model r R-1 R-2 R-L RD
KE PGN(D ) 0.99 47.15 13.94 22.53
RD
BART(D ) 10 52.17 26.64 48.34
KE
BART(DKE) 15 53.43 28.03 49.93 Table 15: Test set results on the AMI dataset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 8>  </Paper ID = 118>


<Paper ID = 118> <Table 9> <Abstractive Summary> =Table 12: Test set results on the SAMSum dataset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 9>  </Paper ID = 118>


<Paper ID = 118> <Table 10> <Abstractive Summary> =Model r R-1 R-2 R-L
KE
PGN(D ) 3 49.76 16.03 23.64
KE
PGN(D ) 4 50.22 17.74 24.11
KE Model r R-1 R-2 R-L
PGN(D ) 5 49.63 16.71 23.88 TS
KE BART(D ) 10 53.21 27.38 49.32
PGN(D ) 6 49.70 16.92 24.42 TS
KE BART(D ) 15 53.34 27.85 49.64
TS
Table 13: Test set results on the AMI dataset. </Abstractive Summary> <Extractive Summary> (3) Compared with summarizers
RD
The results are shown in Table 10 and Table 11.
thataretrainedonD andD , summa-
RD+TS KE+RD
We can ﬁnd that: (1) For both datasets, train-
rizers that are trained on D get relatively
KE+TS
ing summarizers based on datasets with two of
small improvements on both datasets.  </Extractive Summary>  </Table 10>  </Paper ID = 118>


<Paper ID = 118> <Table 11> <Abstractive Summary> =Table 16: Test set results on the SAMSum dataset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 11>  </Paper ID = 118>


<Paper ID = 118> <Table 12> <Abstractive Summary> =RD
BART(D ) 0.95 52.29 26.71 48.53
RD
BART(D ) 0.96 53.20 27.98 49.68
RD
BART(D ) 0.97 52.17 27.10 48.34
RD
BART(D ) 0.98 53.29 27.89 49.71
RD
BART(D ) 0.99 53.39 28.01 49.49
RD
Table 14: Test set results on the SAMSum dataset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 12>  </Paper ID = 118>


<Paper ID = 118> <Table 13> <Abstractive Summary> =TS
PGN(D ) 4 49.39 16.02 23.89
TS
PGN(D ) 5 48.59 16.07 24.05
TS
PGN(D ) 6 49.89 16.04 23.01
TS
PGN(D ) 7 49.37 16.07 23.46
TS
Table 17: Test set results on the AMI dataset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 13>  </Paper ID = 118>


<Paper ID = 1180> <Table 0> <Abstractive Summary> =ifSGt = {φ} ⇒ F1t(Ai,G) = (cid:26) 10iofthSeAtrwi =ise{φ} WordEmbeddings Pscroivreatetest
ToxicRoBERTa 69.89
n
1 (cid:88)
FT (A ,G) = Ft(A ,G)
1 i n 1 i FastTextw/BPE 67.89
t=1
Flair 67.92
With:
ToxicRoBERTa+Flair 69.99
• St : characteroffsetsoftoxicpostt,output
A
i ToxicRoBERTa
ofsystemAi 69.95
+FastTextw/BPE
• Gt : ground truth character offsets of toxic
ToxicRoBERTa
postt 70.26
+Flair+FastTextw/BPE
• Ft1(Ai,G) : F1 score of system Ai , with ToxicRoBERTa(ﬁne-tuned)
respecttogroundtruthGt ofpostt +Flair+FastTextw/BPE 67.37
• FT(A ,G) : F score of system A on
1 i 1 i Table 2: Results of different embedding combinations
datasetT
formethodone
• |.|: setcardinality
Table2showsthefeature-basedmodel’sperfor-
4.5 Results mancewithdifferentwordembeddingsandthegap
4.5.1 Baselineresult inF1-scorebetweenfeature-basedandﬁne-tuning
models. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1180>


<Paper ID = 1180> <Table 1> <Abstractive Summary> =Table 3: Performances of the teacher model with and • Truepositivespan: allwordsinthespanare
withoutpost-processingandstudentmodel. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1180>


<Paper ID = 1180> <Table 2> <Abstractive Summary> =Table 4: Performance of ensemble models with differ- 5.2 Falsenegativesduetopost-processing
entensemblemethods. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 1180>


<Paper ID = 1180> <Table 3> <Abstractive Summary> =Table 7: Common target identities in Civil Comment
dataset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 1180>


<Paper ID = 1181> <Table 0> <Abstractive Summary> =BASE 0.5523 0.6247 0.5630 0.6305 0.5969 0.6548
Table 3: Scores on development and test data. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1181>


<Paper ID = 1182> <Table 0> <Abstractive Summary> =S-NLP 0.7077035474 2
hitmi&t 0.6984762534 3
4.3 Resultsevaluationmethod
hub(ourmethod) 0.6640226029 37
Theevaluationindexannouncedbythetaskorga-
Table 3: In the result list released by the task orga-
nizer team is the F1 score. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1182>


<Paper ID = 1185> <Table 0> <Abstractive Summary> =5 Experiments
Table 2: The results of our systems compared with
Afterbuildingtwosuchsystems,westarttoexper- otherteamsbyF1-score(%). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1185>


<Paper ID = 1186> <Table 0> <Abstractive Summary> =The Attention-basedLogreg 0.524
pseudo-labelmodelisﬁrstﬁne-tunedontheorigi- CRF 0.523
naltoxicspansdataset,andthenontheself-labeled LSTMGloveembeddings 0.497
Jigsaw dataset, whereas the RoBERTa classiﬁer
+taggerandtaggingclassiﬁerareﬁrstﬁne-tuned Table 1: Performance of our models (baselines and
ontheJigsawdataset(asclassiﬁers),andthenon RoBERTa-based models) and their comparison with
the5best-performingparticipants. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1186>


<Paper ID = 1186> <Table 1> <Abstractive Summary> =maxtokenscore 0.673
mintokenscore 0.641
0.65
averagetokenscores 0.670 t
e
s
naiveBayes 0.653 t 
s0.60
e
t
e 
Table 2: Scores of the tagging classiﬁer model with h
differenttokenaggregationmethods(computedonthe n t0.55
o
developmentset). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1186>


<Paper ID = 1189> <Table 0> <Abstractive Summary> =950Method GloVe GPT-2 RoBERTa RG GoR GoG Ensemble
Resultsondevset
BiLSTM 0.619 0.580 0.634 0.647 0.627 0.621 0.655
BiGRU 0.597 0.641 0.621 0.664 0.637 0.668 0.643
BiLSTM+Attention 0.581 0.615 0.620 0.638 0.607 0.445 0.663
BiGRU+Attention 0.572 0.649 0.562 0.521 0.664 0.601 0.668
ResultsonTestset
BiLSTM 0.627 0.666 0.663 0.669 0.665 0.680 0.673
BiGRU 0.633 0.623 0.660 0.662 0.648 0.670 0.680
BiLSTM+Attention 0.653 0.676 0.657 0.600 0.668 0.559 0.633
BiGRU+Attention 0.639 0.659 0.644 0.627 0.640 0.678 0.677
Table 1: Experimental Results on Trial (dev) and Test sets. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1189>


<Paper ID = 119> <Table 0> <Abstractive Summary> =IntheGoldTypesetting,amodeloutputs Table 3: Oracle analysis on the dev set of TyDi QA. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 119>


<Paper ID = 119> <Table 1> <Abstractive Summary> =Thesere-
Table 4: Answer type classiﬁcation accuracy:
sultssuggestthatourmodelsperformedwellwhen
long,short,none for three-way classiﬁcation and
selectingplausibleanswersandwouldbeneﬁtfrom
answerable,unanswerablefortwo-wayclassiﬁcation. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 119>


<Paper ID = 119> <Table 2> <Abstractive Summary> =thecaronsocieties) 2017 Private Car
MarketSurvey)
Table 8: Examples of retrieval miss (factoid) questions in TyDi Japanese, Korean and Russian subsets. </Abstractive Summary> <Extractive Summary> ETCandmBERTjointly Table 2 presents oracle analysis on NQ.  </Extractive Summary>  </Table 2>  </Paper ID = 119>


<Paper ID = 119> <Table 3> <Abstractive Summary> =Table 10: Per-category answerablity prediction error Invalid or ambiguous queries are common in
rates. </Abstractive Summary> <Extractive Summary> Majority 50.9 58.9 58.2 58.2 50.0
QOnly 65.5 72.7 69.8 70.2 63.0
Table 3 shows that a similar pattern holds in
QAModel 72.0 82.5 74.2 79.4 94.1
TyDiQA:answerabilitypredictionisaremaining
Human
challenge for TyDi QA model.5 Given the gold
-binary 71.0 78.9 88.1 86.9 -
typeinformation,thelonganswerF1scoreisonly -aggregate 79.6 85.6 93.3 94.0 -
1.4pointsbelowthehumanperformance.  </Extractive Summary>  </Table 3>  </Paper ID = 119>


<Paper ID = 1191> <Table 0> <Abstractive Summary> =(ours)–DataCleaning 66.44%
(ours)–Postprocessing 69.38%
LastNlayers F1-score(trial)
1 69.04% Table 3: Ablation study on the system’s components. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1191>


<Paper ID = 1191> <Table 1> <Abstractive Summary> =4 69.11%
5 68.94%
6 69.48%
4.4 Ensemble
Table 2: Performance comparison for multi-depth
Giventheresultsweobtainedwithsinglemodels,
DistilBERT in the trial set using the concatenation of
we found it interesting to mix some of them to
thelastNlayer’soutputsfortheﬁnalclassiﬁcation. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1191>


<Paper ID = 1192> <Table 0> <Abstractive Summary> =970Model Dev Test
Precision Recall F1 Precision Recall F1
Random 0.143 0.463 0.175 0.089 0.413 0.122
SpaCy 0.692 0.588 0.595 0.664 0.686 0.656
BERToxic 0.781 0.678 0.681 0.683 0.732 0.683
+EDA 0.787 0.683 0.684 0.681 0.725 0.678
+HateXplain 0.792 0.674 0.681 0.683 0.721 0.678
BERTlatefusion 0.733 0.636 0.639 0.675 0.709 0.669
BERTmulti-task 0.744 0.629 0.634 0.665 0.694 0.656
Table 2: A summary of the performance of all our models, reporting the precision and recall scores along with
theF1evaluationmetricusedforthecompetition. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1192>


<Paper ID = 1192> <Table 1> <Abstractive Summary> =Table 3: Selected examples obtained from the test set. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1192>


<Paper ID = 1193> <Table 0> <Abstractive Summary> =dataaugumentation predictionthreshold F1mean F1std.deviation
F1-optimized 0.6700 0.0115
resampled,generated
0.5 0.6643 0.0128
F1-optimized 0.6670 0.0093
resampled
0.5 0.6644 0.0148
F1-optimized 0.6643 0.0110
generated
0.5 0.6666 0.0105
F1-optimized 0.6664 0.0121
none
0.5 0.6688 0.0107
Table 4: The results obtained using cross validation split and voting ensemble for different datasets. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1193>


<Paper ID = 1193> <Table 1> <Abstractive Summary> =Table 6: Examples of inconsistency in regard to span length. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1193>


<Paper ID = 1194> <Table 0> <Abstractive Summary> =Besides,weﬁndthatthisarchitecturewith
4 BERT+XLM+GloVe 0.6727 ourproposedcombinationofembeddingsforword
representationprovidesusefulinsightsforthelearn-
Table 2: Systems test results achieved by SINAI in ing phase of the neural network achieving better
SemEvalTask5: ToxicSpansDetection. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1194>


<Paper ID = 1199> <Table 0> <Abstractive Summary> =Tofurtheraddressthedataspar- Table 1: Labels of persuasion techniques with associ-
sity,weuseanotherinductivebiasattheclassiﬁer- atedcountsinthetrainingset
level with a chained classiﬁer (Read et al., 2009)
usingscikit-learnimplementation(Pedregosaetal.,
2011). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1199>


<Paper ID = 1199> <Table 1> <Abstractive Summary> =Bestsystem 0.27315 0.58109
For each input image/text, we generated a
Table 2: The results obtained by LIIR compared to
promptforeachlabels,andusedCLIPtoestimate
the baselines on the Test set for Subtask 3. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1199>


<Paper ID = 1199> <Table 2> <Abstractive Summary> =Give me more feedback: Anno-
tatingargumentpersuasivenessandrelatedattributes
Table 4: Ablation analysis for the effect of augmenta- in student essays. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 1199>


<Paper ID = 12> <Table 0> <Abstractive Summary> =NIST is a variant of BLEU that
medium, and DialoFlow-large, which are trained
weightsn-grammatchesbytheirinformationgain,
2https://github.com/microsoft/DialoGPT i.e.,itindirectlypenalizesuninformativen-grams
132Method NIST-2 NIST-4 BLEU-2 BLEU-4 METEOR Entropy AvgLen
Multi-referenceRedditDataset
DialoGPT(B,greedy) 2.39 2.41 10.54% 1.55% 7.53% 10.77 12.82
DialoFlow(B,greedy) 2.88 2.93 15.34% 3.97% 9.52% 9.27 15.43
DialoGPT(M,beam) 3.40 3.50 21.76% 7.92% 10.74% 10.48 11.34
DialoFlow(M,beam) 3.89 3.99 20.98% 7.36% 11.46% 10.42 13.37
DialoGPT(L,beam) 2.90 2.98 21.08% 7.57% 10.11% 10.06 10.68
DialoFlow(L,beam) 3.90 4.01 21.20% 7.42% 11.48% 10.42 13.38
Human 3.41 3.50 17.90% 7.48% 10.64% 10.99 13.10
Multi-referenceDailyDialogDataset
DialoGPT(B,beam) 2.28 2.78 18.83% 6.63% 15.5% 9.80 18.82
DialoFlow(B,beam) 3.65 3.84 26.47% 10.12% 16.1% 9.62 12.00
DialoGPT(M,beam) 3.47 3.65 25.39% 9.99% 15.9% 9.64 12.88
DialoFlow(M,beam) 3.80 4.02 27.63% 11.33% 16.7% 9.83 12.06
DialoGPT(L,beam) 3.30 3.46 23.69% 9.20% 15.7% 9.78 13.24
DialoFlow(L,beam) 3.86 4.08 28.02% 11.57% 17.0% 9.87 12.08
AblationStudyonMulti-referenceRedditDataset
DialoFlow(M,beam) 3.89 3.99 20.98% 7.36% 11.46% 10.42 13.37
w/oSIM 3.85 3.96 21.36% 7.71% 11.26% 10.43 12.70
w/oSIM&CFM 3.79 3.89 21.33% 7.65% 11.25% 10.33 12.55
Table 1: The evaluation on 6K Reddit multi-reference dataset and on DailyDialog dataset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 12>


<Paper ID = 12> <Table 1> <Abstractive Summary> =Metric DialoFlow DialoGPT Tie
Relevance 43.7% 28.8% 27.5%
Informativeness 45.3% 29.2% 25.5%
Human-likeness 46.2% 29.3% 24.5%
Table 2: Human evaluation for DialoFlow and Di-
aloGPTontheDailyDialogtestDataset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 12>


<Paper ID = 12> <Table 2> <Abstractive Summary> =Table 4: Chatbot-level correlations on the DSTC9 In- The human evaluation demonstrates that model-
teractiveConversationdataset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 12>


<Paper ID = 120> <Table 0> <Abstractive Summary> =DATASETS Fluency Coherence Informative Correct
MeQSum +11.25% +2.50% +7.50% 0%
HealthCareMagic +6.25% -2.50% +12.50% +1.25%
iCliniq +2.50% 0% +3.75% +5.00%
Table 4: Human Evaluation results on 120 samples
fromthequestionsummarizationdatasets.Thepercent-
agesindicatetheaddedvalueofourmethod. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 120>


<Paper ID = 1201> <Table 0> <Abstractive Summary> =1029Dev Test
Approach F1 Precision Recall F1 Precision Recall
SINGLES21 0.5412 0.5798 0.5075 0.4571 0.4752 0.4403
MULTI-SS20-S21 0.5084 0.5181 0.4990 0.4444 0.4500 0.4390
MULTI-SFN-S21 0.4581 0.4836 0.4351 0.4185 0.4778 0.3723
MULTI-MS20-S21 0.5455 0.5747 0.5191 0.4074 0.4121 0.4028
MULTI-MFN-S21 0.5291 0.6429 0.4496 0.4381 0.5307 0.3730
Table 1: Propaganda detection performance on the development and test set for different evaluated approaches. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1201>


<Paper ID = 1201> <Table 1> <Abstractive Summary> =Hence,
Whtb 0.3830 0.0000 0.2222
this model was used to generate the predictions
onthetestsetsubmittedtothesharedtask(under- Table 2: Per-technique F1 score on test set for dif-
lined). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1201>


<Paper ID = 121> <Table 0> <Abstractive Summary> =Table 4: Macro-averaged F of NERC on
1
BinaryEntailmentModel(BEM)isanNERC OntoNotes-ZS and MedMentions-ZS, re-
adjusted model of the state-of-the-art approach porting token-based and span-based scores for all
baselinesandSMXMwithclass-awareencoding. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 121>


<Paper ID = 121> <Table 1> <Abstractive Summary> =Table 5: Class-based token-level macro-F scores of
1
Scores decrease on both datasets when using the SMXM on the test set of OntoNotes-ZS (top) and
smaller model, with a substantial decrease on MedMentions-ZS(bottom). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 121>


<Paper ID = 121> <Table 2> <Abstractive Summary> =forthreeconsecutivesteps,ii)aschedulerthatre-
duces the learning rate linearly over the number
Table 9: Rule-based approach on non-challenging of trained steps until it reaches zero with the last
classesofOntoNotes-ZS. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 121>


<Paper ID = 121> <Table 3> <Abstractive Summary> =Table 10: Snippet of OntoNotes NERC annotation
guidelines. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 121>


<Paper ID = 1212> <Table 0> <Abstractive Summary> =1098Subtask1a
ACC architecture features shape #layers 1stneuron dropout PWE
83.926 MLP lf+we triangle 7 48 - none
83.828 MLP lf+we long funnel 7 16 - fastText
83.809 CNN lf+we diamond 7 256 0.2 fastText
83.633 MLP lf+we brick 4 256 - none
83.613 MLP lf+we rhombus 5 48 - fastText
Subtask1b
RMSE architecture features shape #layers 1stneuron dropout PWE
0.79820 CNN lf+we funnel 2 256 - gloVe
0.81080 BIGRU lf+we brick 5 64 0.5 fastText
0.81272 BILSTM lf+we brick 2 128 0.2 glove
0.81958 BILSTM we brick 3 48 0.2 glove
0.82004 LSTM we triangle 4 128 0.5 fastText
Subtask1c
ACC architecture features shape #layers 1stneuron dropout PWE
61.125 BILSTM lf+we triangle 1 48 0.5 gloVe
60.688 CNN we brick 2 48 - gloVe
59.625 BILSTM lf+we triangle 4 48 0.2 gloVe
59.125 LSTM we triangle 3 256 0.5 fastText
59.000 LSTM we brick 5 8 0.5 none
Subtask2a
RMSE architecture features shape #layers 1stneuron dropout PWE
0.68037 CNN we triangle 4 128 0.5 fastText
0.68085 BIGRU we triangle 7 48 - fastText
0.68399 LSTM we triangle 4 128 0.5 fastText
0.70100 CNN lf+we diamond 8 48 - gloVe
0.70353 CNN lf+we funnel 2 256 - gloVe
Table 1: Results of the best ﬁve hyperparameter combination for each subtask trained and evaluated with the
trainingdatasetwitharatioof80-20. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1212>


<Paper ID = 1212> <Table 1> <Abstractive Summary> =ThebestresultwasforDeepBlueAI with Table 2: Comparison of our results with other partici-
pantsandthebaselineforeachsubtask
anRMSEof0.412. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1212>


<Paper ID = 1213> <Table 0> <Abstractive Summary> =1-C
XLM-Roberta-Large 8 8e-5
BERT-Large-Cased 8 8e-5
BERTembedding+BiLSTM ES 2e-5
Roberta-Large 8 1e-5
Roberta-Large 8 3e-5
Roberta-Large 4 1e-5
2-A
Roberta-Large 12 1e-5
BERT-Large-Cased 8 1e-5
BERTembedding+BiLSTM ES 2e-5
Table 3: The models applied and hyper-parameters
used. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1213>


<Paper ID = 1216> <Table 0> <Abstractive Summary> =More-
RoBERTa 5000 16 2e-5 10 over,becausetask1chasadependencyontask1a,
onlyﬁllinginmissingvalueswith0mayaffectthe
Table 3: The parameters, where the lr stands for
judgmentofthesystem. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1216>


<Paper ID = 1216> <Table 1> <Abstractive Summary> =Table 4: The comparative results of task 1c, and the
modelisthebaseversion. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1216>


<Paper ID = 1219> <Table 0> <Abstractive Summary> =Task1a Task1c Task1b Task2
Accuracy F-score Accuracy F-score RMSE RMSE
w/otask-attention 0.9335 0.9472 0.4456 0.6122 0.5636 0.4891
w/ouncertaintylossweighting 0.9498 0.9582 0.4516 0.6198 0.5516 0.4722
MTLRoBERTa-large 0.951 0.9606 0.4537 0.6242 0.5401 0.4696
Table 2: Ablation study of our MTL model using MTL RoBERTa-large encoder (w/o denotes without the corre-
spondingcomponent). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1219>


<Paper ID = 122> <Table 0> <Abstractive Summary> =However, these meth-
ods tend to ignore the information of the Chi-
Table 1: Structure decomposition of Chinese charac-
nese character structure after integrating the
ters: ‘CR’ denotes the Chinese radical, ‘HT’ denotes
lexical information. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 122>


<Paper ID = 122> <Table 1> <Abstractive Summary> =ForZhang BERT+MECT - - 82.57
andYang(2018),Arepresentsword-basedLSTM’,B
indicates‘word-based+char+bicharLSTM’,C repre- Table 6: Results on Ontonotes 4.0 (%), where ‘§’ de-
sentsthe‘char-basedLSTM’model,andDisthe‘char- notes gold segmentation and ‘¶’ denotes auto segmen-
based+bichar+softwordLSTM’model. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 122>


<Paper ID = 122> <Table 2> <Abstractive Summary> =-RA 61.53 95.31 76.64 94.25
Table 8: The F1 scores (%) of the four experimental
single-streammodelwithamodiﬁedself-attention, methods on different datasets. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 122>


<Paper ID = 1221> <Table 0> <Abstractive Summary> =For
3https://keras.io SubTask 1-c, our model performed well in iden-
4https://huggingface.co/transformers tifying the controversial text but did not perform
1149Model Precision Recall F1 Accuracy
Subtask 1-a 1-c 1-a 1-c 1-a 1-c 1-a 1-c
BERT-base .9254 .4630 .9691 .9426 .9467 .6210 .9330 .4780
ELECTRA-base .9269 .4747 .9073 .7419 .9170 .5790 .8990 .5105
RoBERTa-base .9518 .4708 .8991 .8960 .9247 .6172 .9100 .4959
MPNet-base .9658 .4879 .9203 .7275 .9425 .5841 .9310 .5300
XLNet-base .9489 .4812 .9365 .6881 .9427 .5663 .9300 .5219
ALBERT-large .9632 .4666 .8943 .8530 .9274 .6032 .9140 .4910
Table3: TestsetresultsforSubTask1-aandSubTask1-c.
Model RMSE
SubTask Task1-b Task2
BERT-base .5380 .5066
ELECTRA-base .5418 .6071
RoBERTa-base .5428 .5046
MPNet-base .5401 .5142
XLNet-base .5380 .5298
ALBERT-large .5307 .5004
PLMAverage .5257 .4499
Table 4: Test set results for SubTask 1-b and SubTask
2.
pre-trainedlanguagemodelswithnewandbetter
models coming up. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1221>


<Paper ID = 1222> <Table 0> <Abstractive Summary> =1b 4935 * 19 1000 * 19 1000 * 23
Motivating by (Kendall et al., 2017) that model- 1c 4935 1:1 19 1000 1:1 19 1000 * 23
ingisbasedontask-dependentandhomoscedastic 2 8000 * 20 1000 * 19 1000 * 23
aleatoricuncertainty,i.e.,foracertainsample,the
modelnotonlypredictingitslabelbutalsoestimat- Table 1: Data Statistics. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1222>


<Paper ID = 1222> <Table 1> <Abstractive Summary> =For the classiﬁcation in task 1a,
nte 5 10 10 15
theSoftmaxlikelihoodcanbedeﬁnedby:
bs 64 32 32 32
msl 128 100 80 80
p(y1|fW(x)) = Softmax(fW(x),σ1), (3) wp 0.05 0.1 0.05 0.05
Table 2: Parameters for different pre-trained language
whereσ istheobservednoisescalarfortheclassi-
1
models. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1222>


<Paper ID = 1222> <Table 2> <Abstractive Summary> =More
XLNet 0.9462 0.9487 0.9470 speciﬁcally, the perturbation is ﬁrst added to the
ERNIE 0.9491 0.9499 0.9512 inputembeddinglayerandthepredictedlabelsare
also added with the real labels to reduce the loss
Table 3: The performance (accuracy) of task 1a with ofthenoisepointdata. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 1222>


<Paper ID = 1223> <Table 0> <Abstractive Summary> =(%) RMSE RMSE
MTL-Large∗ 94.80 93.40 0.6434 0.7390 95.05 93.90 0.6359 0.5891
MTL-Small 93.08 90.90 0.6747 0.6649 95.07 93.80 0.6699 0.5796
AMTL-LSTM 94.12 92.50 0.6939 0.6738 95.39 94.30 0.6569 0.5552
AMTL-Adv∗ 93.52 92.10 0.6979 0.7053 93.61 92.40 0.6882 0.5631
AMTL-Humor-1∗ 93.27 91.40 0.7294 0.7294 94.93 93.80 0.7116 0.5616
AMTL-Humor-2 93.75 92.10 0.7426 0.6759 95.32 94.30 0.7151 0.5680
AMTL-T1a-Twice 95.88 92.09 0.6977 0.6881 96.29 92.85 0.6774 0.5772
Ensemble-1∗ 94.05 92.50 0.6361 0.6656 95.66 94.70 0.6200 0.5318
Ensemble-2 94.54 93.10 0.6383 0.6497 95.82 94.90 0.6164 0.5270
Table 2: The results obtained on both development set (left) and test set (right). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1223>


<Paper ID = 1224> <Table 0> <Abstractive Summary> =Results show that our sys-
Table 5: RMSE for the models trained on the humor
tem using BERT with Linear layers outperforms
ratingtask
thebaselinemodelbyasigniﬁcantmarginforthe
ﬁrst and the third subtasks. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1224>


<Paper ID = 1224> <Table 1> <Abstractive Summary> =Bi-LSTMlayerapproach 0.5800
SVR 0.6415
References
Table 6: RMSE for the models trained on the offense A.Augello,G.Saccone,S.Gaglio,andG.Pilato.2008. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1224>


<Paper ID = 1226> <Table 0> <Abstractive Summary> =Also,we
Table 2: Confusion matrix of DistilBERT+MultiScale
foundthatpre-trainedembeddings,weightsorrep-
CNN’sresult
resentationsarecrucialforourmodelperformance. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1226>


<Paper ID = 1227> <Table 0> <Abstractive Summary> =Hu-
Table 3: Confusion matrixof ColBERTfor humor de-
mordetectionviaaninternalandexternalneuralnet-
tection
work. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1227>


<Paper ID = 1229> <Table 0> <Abstractive Summary> =Task2a Regression RMSE 8000 Intheﬁrststep,wemanuallyselectfromarange
of tunable hyperparameters, with batch sizes ∈
Table 1: A Summary of Subtasks and dataset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1229>


<Paper ID = 1229> <Table 1> <Abstractive Summary> =1198Metric Scores
Tasks
post-evaluation
F1-Score 0.957
Task1a
Accuracy 0.947
Task1b RMSE 0.5802
Task2a RMSE 0.469
Table 3: Post-evaluation scores. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1229>


<Paper ID = 1229> <Table 2> <Abstractive Summary> =Whilst the grid search is 8https://sigopt.com
1202hyperparams Task1a
layer 1.556e−5
0−5
layer 4.38e−6
lr 6−11
layer 4.62e−5
12−15
layer 3.24e−5
16−23
epochs 9
lr 4.5e−5
(a)Task1a
hyperparams Task1b
layer 3.55e−5
0−5
layer 9.38e−6
lr 6−11
layer 2.76e−5
12−15
layer 2.79e−5
16−23
epochs 6
lr 2.1e−5
(b)Task1b
hyperparams Task2a
layer 7.86e−6
0−5
layer 1.02e−5
lr 6−11
layer 1.38e−5
12−15
layer 2.08e−5
16−23
epochs 18
lr 3.74e−5
Table 5: Hyperparameter Sweep Results for learn-
ing rates for the 24 layers of RoBERTa model,
LARGE
learningrate,epochandbatchsizesofthemodel. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 1229>


<Paper ID = 123> <Table 0> <Abstractive Summary> =Tosimplifythingsforcrowd
Table 1: Modal strength values in the modal depen-
workers,wemadethedecisionnottointroduceab-
dencystructureandFactBank. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 123>


<Paper ID = 123> <Table 1> <Abstractive Summary> =Table 3: Agreements between crowd-workers and the
First, we compute the agreement among crowd- expertannotator. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 123>


<Paper ID = 1230> <Table 0> <Abstractive Summary> =MLXG(47th) 0.9587
Team(Rank) Accuracy F1-Score
Table 3: Comparative results with other participants’
ComparativePerformanceonSubtask-1a systemsinregressiontasks. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1230>


<Paper ID = 1230> <Table 1> <Abstractive Summary> =Achievinghighperformance
Table 2: Comparative results with other participants’
systemsinbinaryclassiﬁcationtasks. </Abstractive Summary> <Extractive Summary> Table 1 describes the summa-
rized parameters settings used in this work.  </Extractive Summary>  </Table 1>  </Paper ID = 1230>


<Paper ID = 1231> <Table 0> <Abstractive Summary> =Partofthechallenge
Table 1: Annotations/subtasks with their descriptions. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1231>


<Paper ID = 1231> <Table 1> <Abstractive Summary> =Hypothesizing
Ensemble — 0.957 0.946
thatpretrainedlanguagemodelscouldeffectively
model the presence of humor in statements, we
Table 2: Performance of our candidate models on the
investigatethefollowingmodels:
ofﬁcial evaluation set for Task 1a (humor prediction). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1231>


<Paper ID = 1233> <Table 0> <Abstractive Summary> =Forperform- Task2(RMSE) 0.579 0.522 0.057
ingthetaskadaptivepretraining(TAPT)ondown-
Table 2: Results on the Validation split for each task
stream tasks, we have used AllenAI’s implemen-
with and without Task Adaptive Pretraining(without
tationofTaskAdaptivePretraining7. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1233>


<Paper ID = 1235> <Table 0> <Abstractive Summary> =eval 0.0 0.193 0.114 0.0 0.330
Table2.B
Table 2: Table 2.A represents the F1-overlap score for subtask 1, 2, 3, and Table 2.B represents the F1-overlap
scoreforsubtask4,5andoverallF1-overlap
Metric SciBERT+CRF Baseline secondinMeasuredEntity,ModiﬁerandQualiﬁes
Precision 0.703 - subtasks,andthirdinQualiﬁersubtask. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1235>


<Paper ID = 1236> <Table 0> <Abstractive Summary> =Table 4: Experimental results of different model en-
coders
3.4 AxuiliaryExperiments
Settingsofn-gram. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1236>


<Paper ID = 1236> <Table 1> <Abstractive Summary> =Aswecan
window word 1 44.63
noticeinTable3,ROBERTA-basealloutperforms window word 3 44.08
BERT-basesothatitisselectedasourﬁnalmodel
Table 5: Experimental results of different model en-
encoder. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1236>


<Paper ID = 1236> <Table 2> <Abstractive Summary> =(%) F1(%)
Entities 4 Conclusion
BERT-large 58.85 56.02 57.40
ROBERTA-large 60.37 57.68 58.99
WeproposedCONNER,acascadecountandmea-
Relations
BERT-large 49.52 45.67 47.39 surementextractiontooltojointlyidentifythequan-
ROBERTA-large 49.52 52.94 51.17 titiesandtheirattacheditems,aswellasthecorre-
spondingrelationsforSemEval2021Task8: Mea-
Table 3: Experimental results of different model en-
sEval. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 1236>


<Paper ID = 1237> <Table 0> <Abstractive Summary> =In Proceedings of the 2019 Conference
Table 1: Trial set results with and without post-
of the North American Chapter of the Association
processing
for Computational Linguistics: Human Language
Technologies, Volume 1 (Long and Short Papers),
Category F1score Ranking
pages4171–4186,Minneapolis,Minnesota.Associ-
ationforComputationalLinguistics. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1237>


<Paper ID = 1238> <Table 0> <Abstractive Summary> =ForthesubtaskEweused XLM-Rwiththebesthyperparametersfrombase
1252Model Aug WSch PQ O Q ME MP Qlfr UoM M HQ HP Qlfs
post-evaluationphaseresults:roberta.base
QA-v1 F equal F 45.2 98.9 32.5 36.2 15.2 73.9 66.1 42.4 21.2 9.3
QA-v2 F equal T 45.6 98.9 33.2 36.1 15.7 74.3 73.0 42.9 22.6 11.3
QA-v3 F rsqr+log F 45.3 98.9 32.3 35.4 15.2 74.7 70.1 41.8 22.0 12.9
QA-v4 F rsqr+log T 45.8 98.9 33.6 37.8 13.4 73.0 67.9 46.1 22.5 9.7
QA-v5 F softmax F 45.8 98.9 33.4 36.6 13.5 74.0 72.6 42.3 20.5 11.8
QA-v6 F softmax T 45.6 98.9 32.5 37.3 16.2 75.3 75.5 45.6 21.8 11.3
QA-v7 T equal F 47.7 98.9 33.1 35.6 16.1 74.3 77.7 40.3 22.7 9.6
QA-v8 T equal T 46.1 98.9 32.8 35.5 11.1 73.7 76.4 38.9 21.2 9.3
QA-v9 T rsqr+log F 47.6 98.9 32.4 36.8 18.7 73.9 78.3 40.0 21.9 12.6
QA-v10 T rsqr+log T 46.1 98.9 33.1 36.3 14.3 73.9 78.2 42.0 22.3 10.2
QA-v11 T softmax F 47.3 98.9 32.9 37.2 16.6 73.6 78.1 41.8 23.0 10.7
QA-v12 T softmax T 46.9 98.9 34.5 35.2 13.6 73.6 76.3 39.9 24.2 10.0
post-evaluationphaseresults:roberta.large
QA-v1 T equal F 49.3 98.6 37.8 38.3 17.7 75.6 78.1 43.7 27.0 10.3
QA-v2 T rsqr+log F 48.8 98.5 35.0 41.3 10.7 75.3 77.7 46.0 24.5 6.9
QA-v3 T softmax F 48.9 98.5 37.9 38.1 17.8 73.7 78.4 44.4 27.2 10.3
Table 2: Best Overlap F1 scores for the dev set. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1238>


<Paper ID = 124> <Table 0> <Abstractive Summary> =155768 Emotionalshift w/oEmotionalshift
Dataset
#Samples Accuracy #Samples Accuracy
67 IEMOCAP 576 57.98% 1002 74.25%
MELD 1003 59.02% 861 69.45%
ore66 RGAT-RoBERTa DailyDialog 670 57.26% 454 59.25%
1 sc DDAAGGN-ENRC EmoryNLP 673 37.29% 361 42.10%
F65
Table 5: Test accuracy of DAG-ERC on samples with
64 emotionalshiftandwithoutit. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 124>


<Paper ID = 1240> <Table 0> <Abstractive Summary> =We
co/transformers/
label multi-row/multi-column cells as relevant if 3PyTorch,v1.7.1,https://pytorch.org/
1266ValidationSet TestSet
F1Score
TAPAS-stf TAPAS-tf TAPAS-tf-stf TAPAS-stf TAPAS-tf TAPAS-tf-stf
Withoutheaderstandardization
2-waymicro 72.1 69.42 71.01 68.01 70.97 72.97
±0.43 ±0.99 ±0.28 ±1.37
3-waymicro 66.41 58.97 65.76 61.59 57 65.15
±0.48 ±0.37 ±0.02 ±0.81
Refuted 67.95 64.31 70.32 62.04 64.05 69.13
±0.98 ±0.91 ±0.45 ±0.74
Entailed 67.8 58.94 68.09 64.89 61.9 67.23
±0.36 ±1.24 ±0.49 ±1.18
Unknown 49.76 0 47.52 47.58 0 46.43
±0.73 ±3.52 ±0.8 ±1.88
Withheaderstandardization
2-waymicro 71.34 72.78 74.35 68.67 73.79 73.87
±0.96 ±1.14 ±0.9 ±0.87
3-waymicro 66.16 61.11 69.16 61.99 59.32 66.95
±0.64 ±0.58 ±0.8 ±0.27
Refuted 68.22 65.98 73.2 61.42 65.7 70.39
±0.29 ±0.83 ±1.9 ±0.44
Entailed 67.98 63.67 70 65.67 65.38 68.9
±0.43 ±1.69 ±0.21 ±0.48
Unknown 49.9 0 50.91 48.27 0 50.89
±3.07 ±3.99 ±1.55 ±3.93
Table 3: Performance on subtask A: Mean and standard deviation of the metrics from 3 independent runs. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1240>


<Paper ID = 1241> <Table 0> <Abstractive Summary> =truth predicted
entailed refuted unknown
6 Conclusion
entailed 863 472 1483
refuted 49 861 778 Ihavedescribedthesystemusedforsubmissionto
the Statement Veriﬁcation and Evidence Finding
Table 5: Confusion Matrix for Task A on train data. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1241>


<Paper ID = 1242> <Table 0> <Abstractive Summary> =IncludedMetadata ValidationAccuracy
Yes 0.92
Orders Week1 Week2 Week3
No 0.93
Order1 Peat Straw Silage
Order2 Straw Silage Control Table3: Impactofinclusionofmetadataonvalidation
Order3 Silage Control Combo accuracy
Table 2: A table containing data about a few weekly
Weobservethatincludingthemetadataworsens
orders
theaccuracy. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1242>


<Paper ID = 1245> <Table 0> <Abstractive Summary> =Discriminationoftypesoftermsallows
Table 3: Hyperparameters for models. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1245>


<Paper ID = 1249> <Table 0> <Abstractive Summary> =work in prosodic phonology weakened the SLH:
prosodicrecursionatthephraseorsentencelevelis Table 1: Prosody of three items with non-identical
nowacceptedasempiricallyrobust(Ladd1986,2008, operators
ch8;Selkirk2011;ItoandMester2012,2013). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1249>


<Paper ID = 1251> <Table 0> <Abstractive Summary> =yue T|# 4.37 (0.05)
TrigrammodelswerebuiltusingtheSRILM
Table 1: Orders which produced the lowest per-
toolkit (Stolcke, 2002), with maximum likeli-
plexities averaged over 10 runs (means and stan-
hood estimates smoothed using interpolated
dard deviations). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1251>


<Paper ID = 1251> <Table 1> <Abstractive Summary> =34cmn tha vie yue
3-gram 5.15 (0.17) 7.76 (0.4) 7.49 (0.27) 5.98 (0.18)
RNN 4.01 (0.07) 5.28 (0.05) 5.18 (0.03) 4.42 (0.07)
Table 2: Mean and standard deviation of perplexity across all permutations by lexicon and language
model. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1251>


<Paper ID = 1252> <Table 0> <Abstractive Summary> =For example, for the Hungarian múltjá- tion is useful, for example, to NLP applications
val (with his/her/its past), Wiktionary provides that rely on subword information for understand-
4http://github.com/kbatsuren/CogNet 5http://github.com/kbatsuren/WiktConv
42Table3: MorphyNetdatasetstatistics
Inflectionalmorphology Derivationalmorphology
# Languages words entries morphemes words entries morphemes Total
1 Finnish 65,402 1,617,751 1,139 18,142 37,199 446 1,654,950
2 Serbo-Croatian 68,757 1,760,095 263 8,553 20,008 429 1,780,103
3 Italian 75,089 748,321 104 22,650 42,149 749 790,470
4 Hungarian 38,067 1,034,317 428 14,566 37,940 832 1,072,257
5 Russian 67,695 1,343,760 252 21,922 36,922 575 1,380,682
6 Spanish 67,796 677,423 145 16,268 27,633 490 705,056
7 French 44,729 453,229 98 15,473 37,203 636 490,432
8 Portuguese 30,969 329,861 161 10,504 15,974 387 345,835
9 Polish 36,940 663,545 251 9,518 18,404 405 681,949
10 German 35,086 214,401 243 13,070 23,867 465 238,268
11 Czech 9,781 298,888 112 4,875 9,660 318 307,935
12 English 149,265 652,487 8 67,412 200,365 2,445 852,852
13 Catalan 16,404 168,462 91 3,244 4,083 220 172,545
14 Swedish 14,485 131,693 32 3,190 5,810 217 137,503
15 Mongolian 2,085 14,592 35 1,410 1,940 229 16,532
Total 722,550 10,108,825 3,362 230,797 519,157 8,843 10,627,369
Table 4: UniMorph and MorphyNet data sizes com- Comparison to ground truth. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1252>


<Paper ID = 1253> <Table 0> <Abstractive Summary> =WerunMORPHEUS-MULTILINGUALtogener-
Table 2: Baseline & Adversarial results on new-
ateadversarialsentencesforthevalidationsplitsof
stest2018 using fairseq’s pre-trained models. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1253>


<Paper ID = 1253> <Table 1> <Abstractive Summary> =To this end, we utilize two grammatical er-
Table 3: List of language chosen from multilingual ror correction (GEC) datasets, German Falko-
TEDcorpus. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1253>


<Paper ID = 1253> <Table 2> <Abstractive Summary> =Theadversarialsentencesonlycapturethe
Table 5: Translation results on Russian and German
worstcasedropinchrF.Therefore,toanalyzethe
GECcorpora. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 1253>


<Paper ID = 1253> <Table 3> <Abstractive Summary> =Grammarerror Table 7: Example inﬂections for German verb abspie-
correction in morphologically rich languages: The len(‘play’)fromtheUniMorphdictionary. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 1253>


<Paper ID = 1254> <Table 0> <Abstractive Summary> =We ﬁllinM(cid:48) byapplyingf toeachtokenofM and
is is
65All Morphophonology Multilingual Transliteration Stress
Model
EXACT CHRF EXACT CHRF EXACT CHRF EXACT CHRF EXACT
NOFEATURE 26.8% 0.64 30.1% 0.72 42.1% 0.59 12.0% 0.51 15.4%
TOKEN 32.7% 0.63 37.5% 0.68 45.3% 0.60 16.4% 0.52 22.2%
FEATURE 30.9% 0.51 38.6% 0.56 39.9% 0.42 9.5% 0.49 23.0%
LSTM 8.2% 0.44 9.2% 0.49 5.7% 0.45 2.1% 0.31 15.0%
Transformer 5.4% 0.42 2.3% 0.39 9.2% 0.50 1.7% 0.42 12.6%
WFST 20.9% 0.56 16.3% 0.47 38.7% 0.63 29.7% 0.71 2.8%
Table 5: Metrics for all problems, and for problems of each type. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1254>


<Paper ID = 1254> <Table 1> <Abstractive Summary> =Table 6: Number of problems where the model
#{correctlypredictedtestsamples} achievesdifferentthresholdsoftheEXACTscore. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1254>


<Paper ID = 1255> <Table 0> <Abstractive Summary> =splitintohighlyconnectedsubgraphs(HCS)con-
taining n nodes, where the number of edges that The Edinburgh team (McCurdy et al., 2021)
needtobecutinordertosplitthegraphintotwo submitsasystembasedonadaptorgrammars(John-
75English Navajo Spanish Finnish Bulgarian Basque Kannada German Turkish Average
Rec 28.93 32.71 23.90 18.43 20.55 28.57 25.19 25.50 15.70 24.39
Boulder-PDP-1 Prec 29.27 34.15 24.68 18.81 20.75 29.51 35.18 25.64 15.90 25.99
F1 29.10 33.41 24.29 18.62 20.65 29.03 29.36 25.57 15.80 25.09
Rec 36.57 36.92 28.52 23.38 26.37 30.16 25.83 33.21 19.53 28.94
Boulder-PDP-2 Prec 37.00 38.54 29.45 23.86 26.63 31.15 36.08 33.40 19.79 30.65
F1 36.78 37.71 28.98 23.62 26.50 30.65 30.11 33.31 19.66 29.70
Rec 42.79 37.85 29.41 26.01 28.73 26.98 25.94 38.18 21.38 30.81
Boulder-PDP-3 Prec 43.30 39.51 30.37 26.55 29.01 27.87 36.23 38.39 21.66 32.54
F1 43.04 38.66 29.88 26.27 28.87 27.42 30.23 38.28 21.52 31.58
Rec 45.45 40.19 30.64 26.60 29.79 28.57 24.54 39.86 21.65 31.92
Boulder-PDP-4 Prec 45.99 41.95 31.63 27.15 30.08 29.51 34.28 40.08 21.93 33.62
F1 45.72 41.05 31.13 26.87 29.93 29.03 28.61 39.97 21.79 32.68
Rec 28.81 10.75 19.27 22.02 30.02 19.05 18.54 31.92 20.63 22.33
Boulder-GWK-2 Prec 66.33 65.71 69.93 67.36 71.69 35.29 62.45 78.56 64.09 64.60
F1 40.17 18.47 30.21 33.19 42.32 24.74 28.60 45.39 31.22 32.70
Rec 24.53 11.21 18.30 22.69 31.18 25.40 16.93 30.98 21.16 22.49
Boulder-GWK-1 Prec 56.47 68.57 66.41 69.41 74.46 47.06 57.04 76.26 65.74 64.60
F1 34.20 19.28 28.69 34.20 43.96 32.99 26.12 44.06 32.02 32.83
Rec 76.69 59.81 72.18 76.73 73.02 25.40 38.48 77.62 65.82 62.86
Baseline Prec 38.76 23.02 26.56 17.86 26.50 18.60 17.22 25.35 15.60 23.28
F1 51.49 33.25 38.83 28.97 38.89 21.48 23.79 38.22 25.23 33.35
Rec 66.95 50.93 60.52 45.96 65.08 17.46 30.33 66.57 43.25 49.67
CU–UBC-5 Prec 90.40 68.55 72.70 56.47 76.85 52.38 61.26 74.40 54.05 67.45
F1 76.93 58.45 66.05 50.68 70.48 26.19 40.57 70.26 48.05 56.41
Rec 63.76 51.867 63.62 48.75 63.84 17.46 33.12 65.05 45.81 50.36
CU–UBC-6 Prec 85.99 69.375 76.49 59.67 75.99 52.38 64.24 72.39 57.52 68.23
F1 73.23 59.36 69.46 53.66 69.39 26.19 43.71 68.52 51.00 57.17
Rec 60.36 53.74 64.05 51.51 58.18 22.22 35.37 59.32 47.74 50.28
CU–UBC-7 Prec 81.42 72.33 76.98 62.58 69.23 66.67 69.77 66.13 60.17 69.47
F1 69.33 61.66 69.92 56.51 63.23 33.33 46.94 62.54 53.24 57.41
Rec 83.39 47.66 76.48 52.06 73.14 25.40 36.33 74.28 46.50 57.25
CU–UBC-3 Prec 84.38 49.76 78.97 53.14 73.87 26.23 50.75 74.70 47.10 59.88
F1 83.89 48.69 77.71 52.60 73.50 25.81 42.35 74.49 46.80 58.42
Rec 80.69 47.66 78.35 57.29 73.77 28.57 40.73 74.06 50.93 59.12
CU–UBC-4 Rec 81.64 49.76 80.89 58.48 74.50 29.51 56.89 74.47 51.59 61.97
F1 81.16 48.69 79.60 57.88 74.14 29.03 47.47 74.27 51.26 60.39
Rec 75.96 47.66 75.73 65.35 69.07 28.57 49.52 65.08 60.58 59.73
CU–UBC-1 Prec 76.86 49.76 78.19 66.71 69.92 29.51 69.16 65.44 61.36 62.99
F1 76.41 48.69 76.94 66.03 69.50 29.03 57.71 65.26 60.97 61.17
Rec 88.16 41.59 81.90 72.68 76.58 28.57 50.91 73.98 67.37 64.64
CU–UBC-2 Prec 89.21 43.41 84.56 74.18 77.34 29.51 71.11 74.39 68.24 67.99
F1 88.68 42.48 83.21 73.42 76.96 29.03 59.34 74.18 67.80 66.12
Rec 89.54 41.59 82.38 59.58 80.22 31.75 58.95 78.97 72.82 66.20
Edinburgh Prec 90.75 43.41 85.06 60.84 83.30 32.79 82.34 79.41 73.75 70.18
F1 90.14 42.48 83.70 60.20 81.73 32.26 68.71 79.19 73.28 67.96
Rec 95.31 - 85.49 86.21 84.74 65.08 - 79.19 86.80 83.26
stanza Prec 93.87 - 85.84 85.91 82.79 50.62 - 71.57 86.87 79.64
F1 94.59 - 85.66 86.06 83.75 56.94 - 75.19 86.84 81.29
Table 3: Results on all test languages for all systems in %; the ofﬁcial shared task metric is best-match F1. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1255>


<Paper ID = 1257> <Table 0> <Abstractive Summary> =The goal of this
task is to correctly cluster words in a given Table 1: Morphological paradigms for the English
language by their inﬂectional paradigm, with- verbswalkandbring. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1257>


<Paper ID = 1257> <Table 1> <Abstractive Summary> =TheKMeansclusteringsforthedevel-
Russian 0.36 0.11 0.34
opmentlanguagesweregeneratedbasedonoptimal
Swedish 0.44 0.18 0.45
cluster values starting with size 100 and increas-
Table 2: F1 Scores for each of the model types on all ingtoaclustersizeof6000,oruntiltheaccuracy
developmentlanguages. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1257>


<Paper ID = 1257> <Table 2> <Abstractive Summary> =Turkish 0.25 0.16 0.20 0.22 0.22
Fortestlanguages,werunclusteringonlywith
Table 3: F1 Scores for the baseline (BL) and the thebetter-performingcharacter-basedrepresenta-
KMCE models on the test languages. </Abstractive Summary> <Extractive Summary> This
clusterthataparticularwordisassignedtoshould approachwouldincorporatelinguisticinformation
93Language BL KMW2V KMCE 5 Results
Maltese 0.29 0.19 0.25
Table 2 shows results to date.  </Extractive Summary>  </Table 2>  </Paper ID = 1257>


<Paper ID = 1258> <Table 0> <Abstractive Summary> =102Maltese Persian Portuguese Russian Swedish Mean
Baseline 29.07 30.04 34.15 36.30 43.62 34.64
PS-2000 35.41 50.17 65.53 81.20 81.14 62.69
PS-5000 36.81 50.40 71.33 81.96 79.82 64.06
PS-all 40.67 53.15 76.63 75.39 72.46 63.66
S-all 30.32 52.69 82.67 80.65 80.74 65.41
D-200 42.99 54.65 66.86 70.38 68.76 60.73
D-300 42.99 53.64 69.38 72.33 67.14 61.10
D-500 45.05 51.82 66.37 75.26 62.30 60.16
Table 1: F1 Scores for each of the model types on all development languages. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1258>


<Paper ID = 1258> <Table 1> <Abstractive Summary> =Although the tendency is similar for derivational features, or even circumstantial
103English Navajo Spanish Finnish Bulgarian Basque Kannada German Turkish Mean
Baseline 51.49 33.25 38.83 28.97 38.89 21.48 23.79 38.22 25.23 33.35
PS-2000 83.89 48.69 77.71 52.60 73.50 25.81 42.35 74.49 46.80 58.42
PS-5000 81.16 48.69 79.60 57.88 74.14 29.03 47.47 74.27 51.26 60.39
PS-all 76.41 48.69 76.94 66.03 69.50 29.03 57.71 65.26 60.97 61.17
S-all 88.68 42.48 83.21 73.42 76.96 29.03 59.34 74.18 67.80 66.12
D-200 76.93 58.45 66.05 50.68 70.48 26.19 40.57 70.26 48.05 56.41
D-300 73.23 59.36 69.46 53.66 69.39 26.19 43.71 68.52 51.00 57.17
D-500 69.33 61.66 69.92 56.51 63.23 33.33 46.94 62.54 53.24 57.41
Table 3: F1 Scores for each of the model types on all test languages. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1258>


<Paper ID = 1259> <Table 0> <Abstractive Summary> =F1
English 0.388 0.767 0.515 0.565 0.245 0.3420 0.663 0.288 0.402
Navajo 0.230 0.598 0.333 0.686 0.112 0.1928 0.657 0.108 0.185
Spanish 0.266 0.722 0.388 0.664 0.183 0.2869 0.699 0.193 0.302
Finnish 0.179 0.767 0.290 0.694 0.227 0.342 0.674 0.220 0.332
Bulgarian 0.265 0.730 0.390 0.745 0.312 0.440 0.717 0.300 0.423
Basque 0.186 0.254 0.215 0.471 0.254 0.330 0.353 0.191 0.247
Kannada 0.172 0.385 0.238 0.570 0.169 0.261 0.625 0.185 0.286
German 0.254 0.776 0.382 0.7626 0.310 0.441 0.787 0.319 0.454
Turkish 0.156 0.658 0.252 0.6574 0.212 0.320 0.641 0.206 0.312
Average 0.233 0.629 0.334 0.646 0.225 0.328 0.646 0.223 0.327
Table 3: Precision, recall, and F1 for all test languages. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1259>


<Paper ID = 126> <Table 0> <Abstractive Summary> =Mad(cid:55)
etal.,2019),thereareotherrelationtypesinclud-
ing{sNeed,sWant,oWant,sEffect,oEffect},which
Table 4: Illustration of the attention mechanism in
identiﬁestheprerequisitesandpostconditionsof
Eq.9thathelpsdistinguishtheretrievedknowledge. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 126>


<Paper ID = 1260> <Table 0> <Abstractive Summary> =… To facilitate ensemble construction and further
ю ju erroranalysis,wereleaseallsubmissions’testset
ю u predictionstotheresearchcommunity.7
…
9 Discussion
Table 8: Fragment of a covering grammar for Bul-
We once again see an enormous difference in lan-
garian; the leftcolumn containsgraphemes and corre-
spondingphonesaregivenintherightcolumn. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1260>


<Paper ID = 1261> <Table 0> <Abstractive Summary> =Mean 94.58 74.5
The system was subject to certain amount of
randomnessbecauseofrandomizationoftraining
Table 3: Development accuracy for 10 runs of the re-
dataandrandominitialweightsinthenetwork. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1261>


<Paper ID = 1261> <Table 1> <Abstractive Summary> =127Code Itemsadded Character Word
ady 4 95.15 76.9
gre 223 94.40 73.7
ice 58 95.15 76.8
ita 194 94.59 74.5
khm 39 94.65 74.8
lav 100 95.27 77.4
mlt latn 62 94.53 74.2
rum 119 94.78 75.2
slv 127 95.09 76.6
wel sw 7 94.59 74.5
Mean 94.82 75.46
Table4:Numberofsubstringsaddedforeachlanguage
Table 5: 10 runs with all languages grouped together
withoutsubstringsaddedforeachlanguage
5 Usingsubstrings
Thismethodinvolvesﬁndingperipherallettersthat
resultinayinanon-ﬁnalsyllableendingupina
mapunambiguouslytosomesymbolandthenﬁnd-
ﬁnalsyllableinasubstringgeneratedasabove. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1261>


<Paper ID = 1262> <Table 0> <Abstractive Summary> =Furthermore, the
macroWERaveragenotonlyoutperformsthebase-
Table 1: Typical errors in the development set that in-
line,butallothersubmittedsystems. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1262>


<Paper ID = 1262> <Table 1> <Abstractive Summary> =The ﬁnal values used to Table 3: Comparison of test-set results based on the
generate predictions for the test data are listed in worderrorrates(WERs)
Table 2. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1262>


<Paper ID = 1262> <Table 2> <Abstractive Summary> =We leave
lav 0.5 0.5 thesespeculationsasresearchquestionsforfuture
mlt_latn 0.2 0.2 endeavorsandrestrictthesubsequenterroranaly-
rum 0.5 0.2 ses and discussion to the results from our vowel-
slv 0.4 0.4 penaltysystem.5
wel_sw 0.4 0.5
5One reviewer raised a question of why only syllable
boundaries,asopposedtosmallerconstituents,suchasonsets
Table 2: Vowel penalty and diacritic penalty values in orcodas,aremarked.Ourhunchisthatmanyphonologicalal-
theﬁnalmodels ternationshappenatsyllableboundaries,andthatvowellength
insomelanguagesdependsonwhetherthenucleusvowelis
inaclosedoropensyllable.Also,giventhataddingsyllable
135ady gre ice ita khm lav mlt_latn rum slv wel_sw
80
60
nt
u
o40
C
20
0
baseSyl VP baseSyl VP baseSyl VP baseSyl VP baseSyl VP baseSyl VP baseSyl VP baseSyl VP baseSyl VP baseSyl VP
Systems
Error types C-V, V-C C-C, C-ϵ, ϵ-C V-V, V-ϵ, ϵ-V
Figure2: Distributionsoferrortypesintest-setpredictionsacrosslanguages. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 1262>


<Paper ID = 1263> <Table 0> <Abstractive Summary> =These
counts are the weights of each sub-word se-
Table 1: Results for components of ensembles,
quence. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1263>


<Paper ID = 1264> <Table 0> <Abstractive Summary> =Technically, the same input is fed
thoughseveralsmallerLSTMs,eachwithitsown
Table 1: Statistics on Unicode normalization for low
parameterset,andthentheiroutputisconcatenated
(L), medium (M), and high (H) settings (column S). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1264>


<Paper ID = 1264> <Table 1> <Abstractive Summary> =setting,C-4(CHAR)andC-6(SEG)canbedirectly
151CLUZH-1(CHAR) CLUZH-2(SEG) C-3 OURBASELINE BSL Other
AVERAGE E AVERAGE E E AVERAGE E E
LNG dev test sd test dev test sd test test dev test sd test test test
ady 25.0 27.8 3.3 24 25.6 26.2 1.8 22 22 26 25.2 2.8 21 22 22
gre 6.5 22.2 2.3 20 5.1 22.8 2.8 22 20 5 26.0 3.3 25 21 21
ice 14.8 12.4 2.4 10 16.1 14.5 2.2 12 10 21 15.8 2.1 12 12 11
ita 24.5 27.0 2.2 23 24.4 26.3 3.2 24 21 25 22.7 3.5 19 19 20
khm 39.8 38.2 3.4 32 40.3 36.9 2.2 33 32 39 40.4 2.5 34 34 28
lav 47.2 53.7 2.8 53 46.9 55.3 3.7 49 49 44 56.5 2.2 54 55 49
mlt 17.0 18.0 2.4 12 19.7 21.2 2.9 16 14 23 21.8 5.1 17 19 18
rum 11.1 13.7 1.8 13 10.3 14.1 1.0 13 12 11 12.5 2.1 10 10 10
slv 46.4 56.4 2.7 50 48 60.2 3.4 59 55 44 54.2 2.1 51 49 47
wel 18.0 14.9 3.5 10 15.6 15.7 1.8 13 12 19 14.8 2.0 12 10 12
AVG 25.0 28.4 2.7 24.7 25.2 29.3 2.5 26.3 24.7 25.7 29.0 2.8 25.5 25.1 23.8
Table 2: Overview of the dev and test results in the low setting. </Abstractive Summary> <Extractive Summary> Table 1 shows statistics
equipped with an LSTM decoder and a bidirec-
ontheresultingvocabularysizesif CHAR or SEG
tional LSTM encoder (Graves and Schmidhuber,
actions are used.  </Extractive Summary>  </Table 1>  </Paper ID = 1264>


<Paper ID = 1265> <Table 0> <Abstractive Summary> =Table 2: One-shot accuracy scores for models trained
The system trained with random exemplars withrandomandsimilarity-basedselection, compared
achievesitsbestresultsonTajik(Iranian: tgk,score to the baseline. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1265>


<Paper ID = 1269> <Table 0> <Abstractive Summary> =The model consists of an
202Arabic Russian Kannada
CER WER BLEU CER WER BLEU CER WER BLEU
WFST .405 .86 2.3 .202 .58 14.8 .359 .71 12.5
Seq2Seq .571 .85 4.0 .229 .38 48.3 .559 .79 11.3
RerankedWFST .398 .85 2.8 .195 .57 16.1 .358 .71 12.5
RerankedSeq2Seq .538 .82 4.6 .216 .39 45.6 .545 .78 12.6
Productofexperts .470 .88 2.5 .178 .50 22.9 .543 .93 7.0
Table 2: Character and word error rates (lower is better) and BLEU scores (higher is better) for the
romanizationdeciphermenttask. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1269>


<Paper ID = 1269> <Table 1> <Abstractive Summary> =Productofexperts kongress ne odobril bidet dl(cid:31) a kongressneodobrilbidetdlja a osušcˇestvleniye
osuwestvleniye "bor(cid:126)by s "bor’byskommunizmom"v uuznnik ameri
kommunizmom"v uuznnik ameri
Table 5: Different model outputs for a Russian transliteration example (left column—Cyrillic, right—
scientiﬁctransliteration). </Abstractive Summary> <Extractive Summary> However,
although both sides were scraped from the same
3 Data
onlineplatform,therelevantTaigadataiscollected
Table 1 details the statistics of the splits used for primarilyfrompoliticaldiscussiongroups,sothere
all languages and tasks.  </Extractive Summary>  </Table 1>  </Paper ID = 1269>


<Paper ID = 1269> <Table 2> <Abstractive Summary> =Input anah3dyy3(cid:16)lekbokra3la8(cid:13)kda(cid:9)
Groundtruth (cid:232)(cid:89)(cid:187)8(cid:250)(cid:206)(cid:171) (cid:232)(cid:81)(cid:186)(cid:75)(cid:46) (cid:189)(cid:74)(cid:10)(cid:202)(cid:171) (cid:248)(cid:10)(cid:89)(cid:171)(cid:65)(cid:103) (cid:65)(cid:75)(cid:64) AnAH>EdyElykbkrpElY8kdh
(cid:13)
(cid:9)
(cid:232)(cid:89)(cid:187) (cid:66) (cid:81)(cid:186)(cid:75)(cid:46) (cid:189)(cid:203) (cid:249)(cid:75)(cid:10) (cid:89)(cid:103) (cid:65)(cid:75)(cid:64)
WFST 8 (cid:13) (cid:10) AnAHd yy lkbkr l> 8kdh
(cid:9)
(cid:232)(cid:89)(cid:187) (cid:66) (cid:81)(cid:186)(cid:75)(cid:46) (cid:189)(cid:203) (cid:249)(cid:75)(cid:10) (cid:89)(cid:103) (cid:65)(cid:75)(cid:64)
RerankedWFST 8 (cid:13) (cid:10)(cid:13) (cid:13) AnAHd yy lkbkr l> 8kdh
(cid:9) (cid:9)
Seq2Seq (cid:232)(cid:89)(cid:187)1(cid:200)(cid:240)(cid:13)(cid:64) (cid:81)(cid:107) (cid:189)(cid:202)(cid:103)(cid:13)(cid:64) (cid:248)(cid:10)(cid:88)(cid:65)(cid:13)(cid:75)(cid:46) (cid:65)(cid:75)(cid:64) AnA b>dy >xlk Hr >wl 1 kdh
(cid:9) (cid:9)
RerankedSeq2Seq (cid:232)(cid:89)(cid:187)1(cid:200)(cid:240)(cid:13)(cid:64) (cid:81)(cid:107) (cid:189)(cid:202)(cid:103)(cid:64) (cid:248)(cid:10)(cid:88)(cid:65)(cid:75)(cid:46) (cid:65)(cid:75)(cid:64) AnA b>dy >xlk Hr >wl 1 kdh
(cid:9)
Productofexperts (cid:232)(cid:89)(cid:187)8(cid:66)(cid:64) (cid:64)(cid:81)(cid:187) (cid:72)(cid:46) (cid:189)(cid:203) (cid:248)(cid:10)(cid:88) (cid:65)(cid:75)(cid:64) AnA dy lkb krA > lA 8kdh
Table 6: Different model outputs for an Arabizi transliteration example (left column—Arabic, right—
Buckwaltertransliterಮatiೂonಲ) .+P,-re$.diನct/io$0 DnDerRro3ಯrsaನrುe2 hಬiಳghಸlಲigುhtedin red intheromanizedversions. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 1269>


<Paper ID = 127> <Table 0> <Abstractive Summary> =1588IBMCS ArgMin
Model macroF Acc macroF Acc
1 1
MajorityBaseline 34.06 51.66 33.83 51.14
RoBERTaLargeNLI 52.34 52.69 60.56 60.93
BertGCN(Linetal.,2021) 66.16 66.26 58.51 58.73
MT-DNN,1Dataset(Schilleretal.,2020)* 70.66 71.16 61.65 62.40
MT-DNN,10Datasets(Schilleretal.,2020)* 77.72 77.87 61.38 62.11
SyntopicalGraph(R-GCN,StructureOnly) 44.32 47.82 42.59 52.71
SyntopicalGraph(R-GCN,NoDocuments) 83.03 83.10 67.52 68.34
SyntopicalGraph(R-GCN) 83.40 83.54 67.77 68.01
Table 1: Results on the two stance detection datasets. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 127>


<Paper ID = 127> <Table 1> <Abstractive Summary> =Model b-cubedF b-cubedP b-cubedR
1
LDA 47.01 47.19 49.82
Clustering(RoBERTaLargeMNLI) 45.69 44.76 50.15
SyntopicalGraph(Modularity) 55.42 66.11 53.82
Table 2: Aspect detection results on the argument frames dataset (Ajjour et al., 2019). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 127>


<Paper ID = 127> <Table 2> <Abstractive Summary> =1589Edge Model StanceDetection(macroF ) AspectDetection
1
Alone Without Alone Without
RelativeStance RoBERTaBase 80.72 79.39 52.22 53.52
RelativeSpeciﬁcity RoBERTaBase 70.22 79.35 43.59 55.73
Paraphrase RoBERTaLarge 75.57 83.42 56.31 53.77
NLI RoBERTaBase 80.29 78.95 53.16 53.52
TermSimilarity TF-IDF+cosine 73.62 81.83 52.40 54.74
TopicSimilarity LDA+cosine 72.67 82.54 51.11 54.92
AllEdges 83.40 55.42
Table 3: Importance of each edge type for both evaluated tasks. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 127>


<Paper ID = 1270> <Table 0> <Abstractive Summary> =Table 1: Nominal and verbal reduplication in Shu-
pamem
Wethenprovideaformaldescriptionofthe2-way
(Section3)andMTFSTs(Section4). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1270>


<Paper ID = 1270> <Table 1> <Abstractive Summary> =LHŤH HLLH
Table 2: Tonal alternations: interaction of tones for
2 Shupamemnominalandverbal
reduplicatedforms(“Red. </Abstractive Summary> <Extractive Summary> OppositeToneInsertionexplainsthetonalalterna- The data in both Table 1 and 2 show that 1)
tioninthebaseofreduplicatednouns,andDefault verbs and nouns in Shupamem reduplicate fully
L-Insertion accounts for the L tone on the sufﬁx.  </Extractive Summary>  </Table 1>  </Paper ID = 1270>


<Paper ID = 1271> <Table 0> <Abstractive Summary> =LS LP withattention(BiLSTM+Attn)
masseuses(fr) n-f-pl /ma.søz/ masseur /ma.sœK/
Attention-based models (Vaswani et al., 2017;
fagylaltozom(hu)v-fp-s-in-pr-id/"f6Íl6ltozom/fagylaltozik/"f6Íl6ltozik/
Chan et al., 2016; Luong et al., 2015; Xu et al.,
Table 1: Example annotated entries. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1271>


<Paper ID = 1271> <Table 1> <Abstractive Summary> =We
224Model Inputs en fr ru es hu
BiLSTM (b/+c/+l) (39.7/39.4/37.1) (8.69/8.94/7.94) (5.26/4.87/5.60) (1.13/1.44/1.30) (6.96/5.85/7.21)
BiLSTM+Attn(b/+c/+l) (36.9/36.1/31.0) (4.45/4.20/4.12) (5.06/3.80/4.04) (0.32/0.32/0.29) (1.78/1.31/1.12)
Transformer (b/+c/+l) (40.2/39.3/37.7) (8.19/7.11/10.6) (6.57/6.38/5.36) (2.29/1.62/2.20) (8.20/4.93/8.11)
Table 2: Models and their Word Error Rates (WERs). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1271>


<Paper ID = 1271> <Table 2> <Abstractive Summary> =Also
Model ﬁ ﬁ+hu pt pt+es
morphologicalcategoryseemstohelpforexample
BiLSTM+Attn(base) 18.53 9.81 62.65 58.87
in Russian where it can contain a lot of informa-
BiLSTM+Attn(+lem) 9.27 8.45 59.63 55.48
tionduetotheinherentmorphologicalcomplexity
Table 3: Transfer learning for vanilla G2P (base) and (about25%relativeerrorreduction). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 1271>


<Paper ID = 1271> <Table 3> <Abstractive Summary> =hu 77.7K 31486
pt 0.39M 2647
ru 0.47M 20558
Table 5: Number of total Wiktionary entries, and in-
ﬂectedentrieswithpronunciationandmorphologyan-
notations,forthelanguagesconsidered. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 1271>


<Paper ID = 1272> <Table 0> <Abstractive Summary> =Theperformanceonthepreviouslyunseen - - - - - -
lemmas,ontheotherhand,ismostlydrivenbydata
Table 4: Accuracy comparison for the lemmas known
augmentation. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1272>


<Paper ID = 1272> <Table 1> <Abstractive Summary> =UniMorph does not vro 33.33 0
provide dependency information, however,
Table 5: Test accuracy for each language for the sam-
the information can be inferred from simi- ples where none of baseline systems succeeds to pro-
larsamplesorotherpartsofthesamelemma ducecorrectprediction. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1272>


<Paper ID = 1272> <Table 2> <Abstractive Summary> =90.26 75.22 97.34 97.34 97.34 95.57
Otherwise, the prediction accuracy signiﬁcantly
Table 6: Accuracy comparison for fragment substitu-
degraded. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 1272>


<Paper ID = 1272> <Table 3> <Abstractive Summary> =ThismappingaloneisnotsufﬁcienttoreconstructtheUniMorphannotation,
sincesomeconditionalrulesareappliedontopofthisconversion(see§3.8.1)
Level-1 Level-2 Level-3
MorphInd UniMorph MorphInd UniMorph MorphInd UniMorph
N N P PL F FEM
S SG M MASC
D NEUT
P PROPN P PL 1 1
S SG 2 2
3 3
V V P - A ACT
S - P PASS
C NUM C - - -
O - - -
D - - -
A ADJ P PL P -
S SG S -
Table 9: A simpliﬁed mapping from MorphInd tags to the UniMorph schema for Indonesian data. </Abstractive Summary> <Extractive Summary> (2016), with three-step training where the model
8 Results
is ﬁrst trained on all languages, then ﬁne-tuned
oneachlanguagefamily,andﬁnallyﬁne-tunedon As Table 3 demonstrates, most systems achieve
individuallanguages.  </Extractive Summary>  </Table 3>  </Paper ID = 1272>


<Paper ID = 1273> <Table 0> <Abstractive Summary> =To
Table 1: Hyperparameters used. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1273>


<Paper ID = 1274> <Table 0> <Abstractive Summary> =AnastasopoulosandNeubig
(2019) used a two step training method that ﬁrst
Table 1: List of language families and the number of
trainsonthelanguagefamilyandthenontheindi- languages from each family. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1274>


<Paper ID = 1274> <Table 1> <Abstractive Summary> =We use a bidirec- fusionalorlowresourcebecauseearlyexperiments
tionalLSTM(HochreiterandSchmidhuber,1997) showedthatthesearetheharderonestolearnforLang excludedfeature basemodels
Family Result
code Copy Stem-mod Step1 Step2 Step3 IIT+DA OL
Turkic tur 99.90 99.90 99.94 99.92 97.38 99.90 99.35 97.10
vep 99.72 54.10 99.55 99.80 99.05 99.67 99.70 91.13
Uralic lud 59.46 56.76 70.27 56.76 67.57 62.16 45.95 0.00
olo 99.72 91.15 99.84 99.78 98.26 99.72 99.66 99.48
rus 98.07 94.84 98.00 97.86 95.56 97.34 97.58 70.72
Indo-
kmr 98.21 86.02 98.74 98.41 97.50 98.21 98.01 5.14
European
deu 97.98 91.19 98.23 97.91 89.91 97.98 97.46 91.86
Table 2: The different results we achieved on the test dataset with different models, with different aug-
mentationtechniquesexcludedandwithdifferenttrainingstepsexcluded. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1274>


<Paper ID = 1275> <Table 0> <Abstractive Summary> =Table 3: Pearson correlations (r) of participant re-
2015. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1275>


<Paper ID = 1279> <Table 0> <Abstractive Summary> =Table 1: Ablation results on ROSMI using a 10-fold
Morespeciﬁcally,forthebearingpredictor,we cross validation. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1279>


<Paper ID = 128> <Table 0> <Abstractive Summary> =StayatHomeOrders Against Implicit Positive
AmericaisreadyforBusiness!”
Table 1: Examples of tweet/target pairs from the COVID-19-Stance dataset, manually annotated with respect to
user’sstancetowardsthetarget,thewaystanceopinionwasexpressed,andtheoverallsentimentofthetweet. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 128>


<Paper ID = 128> <Table 1> <Abstractive Summary> =2,085 2,443
KeepingSchoolsClosed 1,479 2,703
StayatHomeOrders 1,717 15,488
WearingaFaceMask 1,921 9,006
All 7,122 29,640
Table 4: The number of tweets selected to be labeled
(#to-label)andthenumberoftweetstobeusedasunla-
beledinself-training(#unlabeled)foreachtarget. </Abstractive Summary> <Extractive Summary> Table 1 shows several ex-
4 BaselineModels
amplesofannotatedtweetsinourdataset.  </Extractive Summary>  </Table 1>  </Paper ID = 128>


<Paper ID = 128> <Table 2> <Abstractive Summary> =F1 0.567 0.689 0.546 0.599 0.633 0.803 0.833 0.825
Table 12: Performance of the baseline models for stance detection on the four targets in the COVID-19-Stance
dataset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 128>


<Paper ID = 128> <Table 3> <Abstractive Summary> =Target: KeepingSchoolsClosed
BiLSTM Kim-CNN TAN ATGRU GCAE BERT BERT-NS BERT-DAN
Acc 0.627 0.625 0.598 0.590 0.588 0.772 0.780 0.758
Pr 0.570 0.549 0.545 0.548 0.528 0.765 0.773 0.748
Re 0.545 0.509 0.532 0.528 0.488 0.761 0.743 0.702
Average F1 0.548 0.495 0.534 0.527 0.490 0.755 0.753 0.717
Pr 0.372 0.377 0.381 0.370 0.364 0.596 0.660 0.606
AGAINST Re 0.238 0.103 0.317 0.310 0.190 0.730 0.651 0.548
F1 0.287 0.160 0.342 0.321 0.249 0.647 0.652 0.573
Pr 0.674 0.628 0.586 0.616 0.596 0.862 0.869 0.868
FAVOR Re 0.594 0.539 0.527 0.545 0.448 0.758 0.709 0.667
F1 0.629 0.580 0.554 0.572 0.510 0.806 0.779 0.751
Pr 0.665 0.642 0.667 0.657 0.624 0.836 0.791 0.771
NONE Re 0.803 0.883 0.751 0.728 0.825 0.796 0.871 0.893
F1 0.727 0.744 0.706 0.690 0.710 0.813 0.829 0.827
Table 15: Performance of the baseline models for stance detection on the target “Keeping Schools Closed”. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 128>


<Paper ID = 1281> <Table 0> <Abstractive Summary> =in real time which is relevant to the responsive-
38PureNNmodel Rule-basedmodel
relation totalinstances accuracy precision recall F1 accuracy precision recall F1
totherightof 214 0.94 1.00 0.89 0.94 0.94 0.97 0.92 0.94
totheleftof 152 0.89 0.85 1.00 0.92 0.95 1.00 0.90 0.95
infrontof 127 0.73 0.66 0.90 0.76 0.85 0.81 0.93 0.87
behind 97 0.76 0.68 0.91 0.78 0.86 0.80 0.91 0.85
above 74 1.00 1.00 1.00 1.00 0.90 1.00 0.85 0.92
below 86 0.82 0.92 0.80 0.85 0.87 0.97 0.78 0.87
between 220 0.96 1.00 0.93 0.96 0.95 1.00 0.87 0.93
nextto 331 0.97 0.97 1.00 0.98 0.95 0.94 1.00 0.97
touching 82 0.76 0.74 0.83 0.78 0.99 1.00 0.97 0.98
near 296 0.90 0.91 0.95 0.93 0.93 0.95 0.93 0.94
on 346 0.8 0.81 0.89 0.85 0.89 0.94 0.88 0.91
Table 2: Performance statistics for the rule-based (RB) and pure MLP (NN) models. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1281>


<Paper ID = 1282> <Table 0> <Abstractive Summary> =Table 2: Experimental Result with Different Train-
ingStrategies. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1282>


<Paper ID = 1283> <Table 0> <Abstractive Summary> =Parameter LawrenceandRiezler(2018) token-based character-based
Attentionmechanism bahdanau bahdanau bahdanau
RNNtype gru gru gru
Embeddingsize 1000 620 620
Encoderlayercount 1 1 1
Encoderhiddensize 1024 400 400
Decoderlayercount 1 1 1
Decoderhiddensize 1024 800 800
Table 4: Parameter overview compared to Lawrence
andRiezler(2018). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1283>


<Paper ID = 1284> <Table 0> <Abstractive Summary> =Table 4: Language N(M(D ,D )) for conﬁdence k k−1
R H
compares M(D ) and M(D ) from Table 3. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1284>


<Paper ID = 1284> <Table 1> <Abstractive Summary> =thetemplate“Wewill[N(α){aboutN(M(L))},]
These labels are allocentric, and therefore less toreachourtarget.” Itrepeatsthematerialinsquare
66Table6: Howoftenplannerswonthevote Table 7: Analysis of explanation results with number
ofuniquephrasingsandaveragereadabilityscores
Planner M5 H10 G5 Total
FASTP 25.0% 42.9% 32.4% 33.4% Uniquephrasings M5 H10 G5 All
SAFEP 37.0% 25.7% 27.5% 30.1% Whythisway? </Abstractive Summary> <Extractive Summary> a region’s perimeter, a continuous generalization Table 1 lists SemaFORR’s planners and their
ofﬁnitelymany,relativelycloseexitsbetweenits objectives.  </Extractive Summary>  </Table 1>  </Paper ID = 1284>


<Paper ID = 1285> <Table 0> <Abstractive Summary> =74Feedbackphrases Convertedvalue
Welldone 0.8
Fine 0.6
Thatisnothowyoudoit −0.699
Tryagain −0.5
Table 2: Examples of feedback phrase with converted
numericvalue. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1285>


<Paper ID = 1285> <Table 1> <Abstractive Summary> =75(a)Baseline (b)Consec-VF (c)Prdc-VF
Figure3:Lossgraphofmodels
Optimizer Baseline Consec-VF Prdc-VF Optimizer Baseline Consec-VF
SGD 80% 86% 80% SGD 80% 86%
Adam 73% 96% 60% Adam 73% 96%
Adagrad 43% 56%
Table 4: Optimal policy convergence rate of 3 experi-
Adadelta 63% 76%
mentalmodel
Table 5: Optimal policy convergence rate of the base-
line and Consec-VF models using four different opti-
Weanalyzethedifferenceinmodelperformance mizers
bythetwomethodsofprovidinginteractivevoice
feedback:Consec-VFandPrdc-VF.Voicefeedback
served during the training process. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1285>


<Paper ID = 1288> <Table 0> <Abstractive Summary> =Please refer to Zhang
Table 1: Statistics on the datasets used in the experi-
etal.(2020a)fordetails. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1288>


<Paper ID = 1288> <Table 1> <Abstractive Summary> =Comparedto
Table 2: Different experiments and the different sam-
the standard “hard” predictions, this approach is
plingmethodsusedineach. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1288>


<Paper ID = 1288> <Table 2> <Abstractive Summary> =Each table reports the
j
4AESLC Gigaword XSum
Model
R-1 R-2 R-L R-1 R-2 R-L R-1 R-2 R-L
PEG 29.96 14.54 29.17 31.81 13.19 29.12 41.81 18.32 33.50
few_shot
+RwB-Hinge 28.69 13.83 27.82 31.83 13.15 29.08 42.47† 18.82† 33.94
+RISK-2 29.35 14.14 28.39 31.96 13.22 29.27 42.57† 18.71† 33.96†
+RISK-3 29.28 14.05 28.31 32.10† 13.35† 29.43† 42.66† 19.01† 34.15†
PEG 32.63 15.84 32.19 33.81 14.26 30.89 41.52 18.21 33.31
full_data
+RwB-Hinge 34.39† 17.58† 33.71† 34.10† 14.52 31.31† 42.87† 19.36 34.56†
+RISK-2 33.55† 17.01† 32.91† 33.97 14.45 31.18† 42.93† 19.25† 34.67†
+RISK-3 33.75† 17.03† 33.04† 33.97 14.52 31.14† 42.74† 19.23† 34.60†
Table 3: Results on short datasets: AESLC, Gigaword, and XSum. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 1288>


<Paper ID = 1288> <Table 3> <Abstractive Summary> =CNN/DM Reddit-TIFU Newsroom
Model
R-1 R-2 R-L R-1 R-2 R-L R-1 R-2 R-L
PEG 40.65 17.60 37.81 24.84 7.21 20.12 33.33 20.01 29.17
few_shot
+RwB-Hinge 40.44 17.44 37.54 25.55† 7.23 20.09 34.03† 20.74† 29.86†
+RISK-2 40.52 17.48 37.62 25.69† 7.25 20.26 34.26† 21.10† 30.14†
+RISK-3 40.76 17.63 37.87 25.73† 7.30 20.35 34.40† 21.27† 30.21†
PEG 40.58 18.15 37.94 23.66 6.72 19.24 36.39 23.90 32.50
full_data
+RwB-Hinge 40.84† 17.74 38.19† 23.95† 6.93 19.69† 36.85† 24.01 33.00†
+RISK-2 40.88† 17.91 38.19† 24.25† 7.19† 20.00† 36.74 24.01 32.73
+RISK-3 40.88† 17.91 38.28† 24.70† 7.46† 20.25† 36.04 23.22 32.18
Table 4: Results on medium datasets: CNN/DM, Reddit-TIFU, and Newsroom. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 1288>


<Paper ID = 1288> <Table 4> <Abstractive Summary> =Pubmed ArXiv Billsum
Model
R-1 R-2 R-L R-1 R-2 R-L R-1 R-2 R-L
PEG 38.28 13.70 23.32 38.08 11.61 22.87 48.27 27.79 35.70
few_shot
+RwB-Hinge 40.11† 14.45† 23.88† 38.85† 11.90† 22.88 48.61† 29.35† 36.91†
+RISK-2 40.19† 14.61† 23.98† 38.98† 12.02† 22.90 48.21 28.34† 35.97
+RISK-3 40.19† 14.55† 23.95† 38.68† 11.88† 22.81 48.65 28.71† 36.37†
PEG 40.57 16.05 25.46 38.48 13.33 24.12 52.98 34.44 41.36
full_data
+RwB-Hinge 40.80 16.27 25.41 38.95† 13.69† 24.19 54.30† 36.01† 42.76†
+RISK-2 40.32 15.85 25.31 38.76 13.55 24.11 53.76† 35.54† 42.37†
+RISK-3 40.36 15.89 25.26 38.42 13.37 24.12 54.27† 35.80† 42.51†
Table 5: Results on long datasets: Pubmed, ArXiv, and Billsum. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 4>  </Paper ID = 1288>


<Paper ID = 1288> <Table 5> <Abstractive Summary> =Dataset RwB:NoHinge-Loss RwB:withHinge-Loss
XSum(short) 42.82/19.32/34.43 42.97/19.45/34.73
Newsroom(medium) 38.97/26.38/35.00 38.17/25.37/34.12
Billsum(long) 53.04/34.87/42.14 54.48/36.49/43.43
Table 8: Comparisons between REINFORCE with baseline with and without the hinge-loss modiﬁcation on the
validationsetforshort,medium,andlongdatasets,tovalidatetheuseofthehinge-lossmodiﬁcationinourmethod. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 5>  </Paper ID = 1288>


<Paper ID = 1289> <Table 0> <Abstractive Summary> =Table 1: Our relational algebra grammar, along with
Whileourrelationalalgebragrammarcanalsobe
the input and output semantic types of each opera-
tion. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1289>


<Paper ID = 129> <Table 0> <Abstractive Summary> =Transformer-XH 78.05 74.98 72.39 69.07
ourTARSA 81.24 77.96 73.97 70.70
5.3 AblationStudy
Table 2: Overall performance on the FEVER dataset To further illustrate the effectiveness of the topic
(%). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 129>


<Paper ID = 129> <Table 1> <Abstractive Summary> =The ﬁrst
BERTConcat 0.485 0.474 0.478
six rows in Table 5 present the label accuracy
GEAR 0.368 0.337 0.352
(LA) and the FEVER score on the development
KGAT 0.493 0.440 0.465
setofFEVERafterremovingvariouscomponents,
Transformer-XH 0.532 0.529 0.531
oursTARSA 0.611 0.540 0.573 whereSTI denotesthesemantic-topicinformation
in Section 3.2, TC denotes the topical coher-
ee
Table 3: Overall performance on the UKP Snopes enceamongmultiplepiecesofevidence,TC de-
ce
dataset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 129>


<Paper ID = 129> <Table 2> <Abstractive Summary> =sum 79.60 76.57 e2: TheWashingtonPost, alongtime
Aggregation
mean 79.28 76.19 democraticmouthpieceandObamasup-
attention-based 79.52 76.45 porter,downplayedthestatementbysug-
gestingitwasmadeinjestandthatPres-
ident Obama had been joking around”
Table 5: Ablation analysis in the development set of
with the reporter at the time the state-
FEVER. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 129>


<Paper ID = 129> <Table 3> <Abstractive Summary> =e5: Wouldtighterrestrictionsreallybe
Table 6: Fact veriﬁcation accuracy on claims that re- suchanimposition? </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 129>


<Paper ID = 1290> <Table 0> <Abstractive Summary> =33#sources DM PAS PSD AMR
Algorithm3:Modify-edgeswapping
2 92.2 91.9 75.6 74.3
Input: anAMdep-treeT andasetM of 3 94.5 94.8 82.7 76.5
1
4 94.4 94.7 83.4 75.9
pairsofconsecutiveedgesinT oftheform
6 92.3 93.6 80.1 73.4
(cid:104)n −M−O→Dn m,m −M−O−D→m k(cid:105)suchthatnoedge
Table 2: Development set accuracies of the neural
appearsinmultiplepairs. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1290>


<Paper ID = 1290> <Table 1> <Abstractive Summary> =G G
34Activationfunction tanh
Optimizer Adam
Learningrate 0.001
Epochs 100
Dimoflemmaembeddings 64
DimofPOSembeddings 32
DimofNEembeddings 16
Minimumlemmafrequency 7
HiddenlayersinallMLPs 1
HiddenunitsinLSTM(perdirection) 256
HiddenunitsinedgeexistenceMLP 256
HiddenunitsinedgelabelMLP 256
HiddenunitsinsupertaggerMLP 1024
HiddenunitsinlexicallabeltaggerMLP 1024
LayerdropoutinLSTMs 0.3
RecurrentdropoutinLSTMs 0.4
Inputdropout 0.3
DropoutinedgeexistenceMLP 0.0
DropoutinedgelabelMLP 0.0
DropoutinsupertaggerMLP 0.4
DropoutinlexicallabeltaggerMLP 0.4
Table 3: Common hyperparameters used in all exper-
iments (the random trees, random weights and EM
weights baselines use 40 epochs since they converge
faster). </Abstractive Summary> <Extractive Summary> Table 1 compares the baselines and the joint non-compositional phenomenon, yielding graph
neuralmethod.  </Extractive Summary>  </Table 1>  </Paper ID = 1290>


<Paper ID = 1293> <Table 0> <Abstractive Summary> =Table 7: Spearman’s correlation coefﬁcient results be- Table8andTable9showthenumberofparam-
tween change in evaluation metrics and subcategory eters in each model and average time required to
sizeforBERTmodel. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1293>


<Paper ID = 1294> <Table 0> <Abstractive Summary> =+Global 73.69%
Table 3: Exact match accuracy on the Spider dataset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1294>


<Paper ID = 1295> <Table 0> <Abstractive Summary> =WithoutBERT
BIO(w/oCRF) 77.51 59.91 73.28 71.15 81.03 67.90 72.36 71.88
±0.17 ±0.31 ±0.62 ±0.37 ±0.31 ±0.37 ±0.07
BIO(w/CRF) 78.42 60.15 73.97 71.37 81.51 68.72 72.54 72.38
±0.39 ±0.40 ±0.15 ±0.13 ±0.36 ±0.34 ±0.41
Span 79.08 62.74 74.80 72.77 82.42 68.93 74.17 73.56
±0.16 ±0.49 ±0.30 ±0.36 ±0.41 ±0.12 ±0.15
HeadSyntax 79.54 62.81 75.06 73.17 82.10 68.74 74.82 73.75
±0.37 ±0.58 ±0.25 ±0.32 ±0.30 ±0.54 ±0.19
HeadAuto 79.04 61.97 74.09 72.56 81.80 69.25 73.96 73.24
±0.22 ±0.30 ±0.25 ±0.40 ±0.40 ±0.39 ±0.19
WithBERT
BIO(w/oCRF) 83.55 73.37 80.02 78.45 87.63 74.89 79.49 79.63
±0.24 ±0.51 ±0.19 ±0.34 ±0.19 ±0.41 ±0.29
BIO(w/CRF) 83.73 75.24 80.64 78.75 87.94 75.38 79.66 80.19
±0.28 ±0.89 ±0.15 ±0.56 ±0.42 ±0.42 ±0.39
Span 83.41 74.22 80.85 78.69 87.44 75.05 79.44 79.87
±0.18 ±0.89 ±0.29 ±0.39 ±0.16 ±0.36 ±0.33
HeadSyntax 83.96 75.98 80.88 79.36 87.40 75.12 80.05 80.39
±0.34 ±0.94 ±0.17 ±0.37 ±0.25 ±0.41 ±0.20
HeadAuto 83.76 74.98 80.69 79.01 87.33 75.66 79.98 80.20
±0.28 ±0.77 ±0.21 ±0.27 ±0.36 ±0.54 ±0.10
Table 5: F1 scores of the (English) cross-genre experiments (averaged over 5 runs with different random seeds). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1295>


<Paper ID = 1295> <Table 1> <Abstractive Summary> =bc bn mz  S W
      % , 2   Z   & 5 ) 
BIO(w/oCRF) 71.19±0.61 77.56±0.68 76.63±0.51  + H D G 6 \ Q W D [
BIO(w/CRF) 72.11 76.28 75.87     
±0.98 ±0.61 ±0.69
Span 73.30 79.90 77.90  Q Z
±1.07 ±0.58 ±0.59
HeadSyntax 75.23 79.95 78.69     
±1.00 ±0.49 ±0.41
HeadAuto 73.60±0.49 78.97±0.53 77.60±0.41  E Q
      Z E
 P ]
Table 6: F1 scores of the (English) cross-genre exper-     
iments (averaged over 5 runs with different random
 W F  E F
seeds) on speciﬁc genres without excluding auxiliary     
                                       
predicates(withBERT). </Abstractive Summary> <Extractive Summary> Table 1 lists the relevant statistics.  </Extractive Summary>  </Table 1>  </Paper ID = 1295>


<Paper ID = 1295> <Table 2> <Abstractive Summary> =thegenre-levelrepresentationsareobtainedbyfur-
72Dev Test Decoding WithoutBERT WithBERT
BIO(w/oCRF) 56.73 56.18 BIO(w/oCRF) 709.8 412.3
±0.63 ±0.61 ±10.6 ±4.6
BIO(w/CRF) 56.86 56.47 BIO(w/CRF) 497.0 335.1
±1.05 ±0.95 ±4.5 ±4.3
Span 56.61 55.97 Span 355.8 261.3
±0.51 ±0.39 ±5.4 ±3.7
HeadSyntax 57.05 56.48 HeadSyntax 561.6 372.8
±0.36 ±0.34 ±5.1 ±4.5
HeadAuto 57.05 56.51 HeadAuto 454.9 311.0
±0.59 ±0.66 ±7.9 ±5.8
Table 7: Unlabeled F1 scores of English→Chinese Table9:Speedcomparisonsofdecodingmethods(eval-
zero-shotcross-lingualexperiments(averagedoverﬁve uated by number of sequences per second, averaged
runswithdifferentrandomseeds). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 1295>


<Paper ID = 1297> <Table 0> <Abstractive Summary> =Inthefor- Table 3: Accuracy in the binary classiﬁcation task for
mer(seeFigure1a),themajorityofthepointsfol- DTFit(agentandpatientroles)andWang2018datasets. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1297>


<Paper ID = 1297> <Table 1> <Abstractive Summary> =To test whether TLMS AgentDTFit 0.64 -0.13 0.62
Patient 0.64 0.26 0.51
consideranentitymoreorlesslikelytotakepart DTFit
Instrument 0.5 0.10 0.6
DTFit
inaneventdependingonthewordusedtoreferto Time 0.66 0.33 0.64
DTFit
thatentity,weevaluatedthemonanewdiagnostic LocationDTFit 0.73 0.67 0.73
datasetof39pairs,generatedfromasubsetofPa-
Table 5: Spearman Correlation for DTFit datasets us-
tient . </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1297>


<Paper ID = 1298> <Table 0> <Abstractive Summary> =In practice, the observed performance
BERT).Wedidthisforeacharchitecture,andthen
onatestisaffectedbyboththetesttakerandthe
12https://github.com/scikit-learn-contrib/scikit-learn-extra testitself.Thisintuitionisformalizedinapsycho-
18metrics approach known as item response theory
(IRT), in which both item characteristics and in- Category DT DL DR
MN 0.08,>0.5 0.29,<0.5 0.19,>0.5
dividual ability are modeled and used to predict
PP 0.48,<0.1 0.69,<0.01 -0.25,<0.5
performance(BakerandKim,2004).IRTmodels LE 0.88,<0.001 -0.06,>0.5 0.14,>0.5
areoftenregardedasmoreinformativethanclassi- Q 0.61,<0.05 0.03,>0.5 0.12,>0.5
PS 0.61,<0.05 0.05,>0.5 -0.25,<0.5
calmodelsandhavebecomestandardtoolswhen
RLS 0.16,>0.5 -0.05,>0.5 -0.31,<0.5
designingevaluationscales.Formally,letj bean WK 0.52,<0.05 0.59,<0.05 -0.1,>0.5
individual taking a test, i be an item on that test,
Table 3: Pearson correlation and p-values for
andθ bethatindividual’slatentability.Thenthe
j transformer-based (D ), LSTM-based (D ), and ran-
probabilitythatj answersicorrectlyisdeﬁnedas: T L
dom (D ) estimates of problem difﬁculty computed
R
usingRaschmodels. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1298>


<Paper ID = 13> <Table 0> <Abstractive Summary> =In SeparateSlotSelector Toexploretheeffective-
addition,weutilizeworddropout(Bowmanetal., nessofthePreliminarySelectorandUltimateSe-
2016)byrandomlyreplacingtheinputtokenswith lector respectively, we conduct an ablation study
144MultiWOZ2.0 MultiWOZ2.1 MultiWOZ2.2
Model
Noncat-
Joint Slot Joint Slot Joint Slot Cat-joint
joint
DSTreader 39.41 - 36.40 - - - - -
TRADE 48.60 96.92 45.60 - 45.40 - 62.80 66.60
NADST 50.52 - 49.04 - - - - -
PIN 52.44 97.28 48.40 97.02 - - - -
DS-DST - - 51.21 97.35 51.70 - 70.60 70.10
SAS 51.03 97.20 - - - - - -
SOM-DST 52.32 - 53.68 - - - - -
DST-Picklist 54.39 - 53.30 97.40 - - - -
SST 51.17 - 55.23 - - - - -
TripPy - - 55.30 - - - - -
56.93 97.55 60.73 98.05 58.04 97.66 76.32 73.39
DSS-DST
(±0.43) (±0.05) (±0.51) (±0.06) (±0.49) (±0.06) (±0.27) (±0.32)
Table 1: Joint accuracy (%) and slot accuracy (%) on the test sets of MultiWOZ 2.0, 2.1, and 2.2 vs. various
approachesasreportedintheliterature. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 13>


<Paper ID = 13> <Table 1> <Abstractive Summary> =Pre-Trained Model MultiWOZ2.1
MultiWOZ2.1
LanguageModel OurModel 60.73
OurModel 60.73 DialogueHistory† 58.36(-2.37)
BERT(large) 60.11(-0.62)
Table 4: The ablation study of the DSS-DST on the
ALBERT(base) 59.98(-0.75)
MultiWOZ 2.1 dataset with joint accuracy (%). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 13>


<Paper ID = 13> <Table 2> <Abstractive Summary> =†
BERT(base) 59.35(-1.38)
means attaching the dialogue of the previous turn to
the current turn dialogue as the input of the Dual Slot
Table 2: The ablation study of the DSS-DST on the
Selector. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 13>


<Paper ID = 13> <Table 3> <Abstractive Summary> =Model MultiWOZ2.1 k MultiWOZ2.1
OurModel 60.73 1 53.96
-UltimateSelector 58.82(-1.91) 2(OurModel) 60.73
-PreliminarySelector 52.22(-8.51) 3 59.34
-abovetwo 40.69(-20.04)
Table5:Thejointaccuracy(%)ofdifferentkonMulti-
Table 3: The ablation study of the DSS-DST on the WOZ2.1dataset.Thekrepresentsthedialoguehistory
MultiWOZ2.1datasetwithjointaccuracy(%). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 13>


<Paper ID = 13> <Table 4> <Abstractive Summary> =145OurModel SOM-DST MultiWOZ2.2
Model
Operation F1 Operation F1 Joint Cat-joint
inherit 99.71 CARRYOVER 98.66 OurModel 58.04 76.32
update 90.65 UPDATE 80.10 -ExtractiveMethod 50.01 66.15
DELETE 32.51
Table 8: The ablation study of the DSS-DST on the
DONTCARE 2.86
MultiWOZ 2.2 dataset with joint accuracy (%) and
jointaccuracyoncategoricalslots. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 4>  </Paper ID = 13>


<Paper ID = 13> <Table 5> <Abstractive Summary> =149Appendices
A AccuracyperSlotonMultiWOZ2.2
Testset
Domain-Slot OurModel
attraction-area 97.95
attraction-name 93.38
attraction-type 97.37
hotel-area 97.29
hotel-bookday 100
hotel-bookpeople 100
hotel-bookstay 100
hotel-internet 94.94
hotel-name 95.29
hotel-parking 95.26
hotel-pricerange 97.67
hotel-stars 97.98
hotel-type 93.24
restaurant-area 97.34
restaurant-bookday 100
restaurant-bookpeople 100
restaurant-booktime 100
restaurant-food 96.76
restaurant-name 94.26
restaurant-pricerange 97.88
taxi-arriveby 98.68
taxi-departure 97.24
taxi-destination 97.05
taxi-leaveat 99.25
train-arriveby 96.63
train-bookpeople 100
train-day 99.59
train-departure 98.32
train-destination 98.48
train-leaveat 94.14
Table 9: The detailed results of accuracy (%) per slot
on MultiWOZ 2.2 test set. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 5>  </Paper ID = 13>


<Paper ID = 130> <Table 0> <Abstractive Summary> =S A AMB NA Total classify our tweets in a 3-way classiﬁcation
problem (solidarity, anti-solidarity,
Experts 386 246 113 174 919
other), not differentiating between the classes
Crowds 768 209 186 217 1380
ambivalentandnon-applicablesinceour
main focus is on the analysis of changes in (anti-
Table 2: Number of annotated tweets (after ge-
)solidarity. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 130>


<Paper ID = 130> <Table 1> <Abstractive Summary> =From
1628MBERT XLM-R
Condition Trainsize Dev Test Dev Test
E,Hashtagonly 572 51.7±0.5 49.0±1.1 48.0±0.9 44.0±0.8
E 579 64.2±1.2 57.7±0.4 64.0 63.3
E+C 1959 66.4±0.5 64.0±1.5 65.0 64.8
E+C,NoHashtags 1959 64.0±0.3 58.0±0.5 62.0 60.0
E+C,HashtagOnly 1567 55.8±2.0 49.5±2.1 47.8 42.2
E+C+Autolabel 106959 76.4 78.3 77.5 78.4
E+C+Autolabel+Oversample 108048 76.4 76.3 77.4 76.9
E+C+Autolabel+Backtranslation 108918 76.0 77.1 77.5 78.7
E+C+Autolabel+Pretraining 106959 78.4 78.8 78.6 79.0
E+C+ALL 110007 78.8±1.3 78.6±0.8 78.9 79.7
Table 3: Macro-F1 scores (in %) for different conditions. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 130>


<Paper ID = 130> <Table 2> <Abstractive Summary> =S 63 3 2
Furtheranalysisshowsthatthesepeakshavebeen
Gold A 5 37 4
immediateresponsestodrasticpoliticallyrelevant
O 5 6 45
eventsinEurope,whichwerealsoprominentlycov-
eredbymainstreammedia,i.e.COVID-19-related
Table 4: Confusion matrix for best ensemble with
macro-F1 score of 84.5% on the test set (for one spe- news,naturaldisasters,ﬁres,majorpolicychanges. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 130>


<Paper ID = 1302> <Table 0> <Abstractive Summary> =in(2)below.8
2
Table 1: Example of generated possible next events OHj = β([S],O ,[M],O ,[E],[S],O ,H ) (2)
OHj using the LM model. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1302>


<Paper ID = 1302> <Table 1> <Abstractive Summary> =(a) GPT-2 (LMI) Table 3: Input and output format for the αNLI task:
[CLS] is a special token used for classiﬁcation, [SEP]
! </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1302>


<Paper ID = 1302> <Table 2> <Abstractive Summary> =Table 5: Examples of generated possible next events for solving αNLI using our LM model. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 1302>


<Paper ID = 1304> <Table 0> <Abstractive Summary> =pangolin),toallowtestingwhether Relation: CountryOfOrigin(Viesgo)=Spain
the model had learned an inference phenomenon
Table 1: An example from each phenomenon-speciﬁc
in a generic manner, rather than performing lex- challenge set. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1304>


<Paper ID = 1305> <Table 0> <Abstractive Summary> =.دوشرهاظیرامیبیاههناشنومئلاعولقتنمتنوفع
Table 1: Sample instances from ParsFEVER (English translations are shown for reference). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1305>


<Paper ID = 1305> <Table 1> <Abstractive Summary> =Table 2: Agreement against super-annotators of
Tosimplifytheannotationprocess,weprovide
ParsFEVERcomparedtoFEVER. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1305>


<Paper ID = 1305> <Table 2> <Abstractive Summary> =102Split SUP REF NEI Accuracy(%)
Model
Training 6,253 4,008 5,685 NoScoreEv ScoreEv
Dev 841 824 861
FEVER DA/NP 52.09 32.57
Test 853 833 863
MLP/NP 41.03 17.46
Total 7,947 5,665 7,409
MLP/RS 43.76 14.62
ParsFEVER
DA/NP 50.02 28.06
Table 4: Distribution of instances in ParsFEVER
DA/RS 48.08 19.06
across the three classes: SUPPORTED (SUP), RE-
FUTED (REF),and NOTENOUGHINFO (NEI). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 1305>


<Paper ID = 1305> <Table 3> <Abstractive Summary> =The Table 5: Accuracy performance of FEVER’s full
statisticsareforthepruneddataset,i.e.,afteromit-
pipeline system on ParsFEVER (best results for
tingclaimswhichareambiguousorcontaintypo
FEVERarereported). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 1305>


<Paper ID = 1306> <Table 0> <Abstractive Summary> =WikiHop Open ExtractiveQA 50,000 GraphTraversal Accuracy81.9
MedHop Closed ExtractiveQA 2,500 GraphTraversal Accuracy60.3
QASC Open MultipleChoice 10,000 Crowdsourcing Accuracy90
QALD-9 Open GraphRetrieval 700*11 ManualAnnotation MacroF QALD5.0
1
SciQA Closed DocumentRetrieval 10,000 AutomatedExtraction MAP24.36*
DROP Both ExtractiveQA 97000 Crowdsourcing EM90.10 F 87.04
1
Table 1: Overview of related QA datasets. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1306>


<Paper ID = 1306> <Table 1> <Abstractive Summary> =MultipleFacts 16.9 24.1
Temporal 0.0 0.0
QuestionTemplates EM F
1 Aggregation 0.0 2.5
All 38.8 39.0
AggregationTemporal 0.0 0.9
Answerable 25.4 25.8
Unanswerable 86.6 86.6 Table 3: Results for the transfer learning QA setting,
SimpleFacts 25.0 21.6 reportedresultsonthepublicdevelopmentsplit. </Abstractive Summary> <Extractive Summary> Table 1 catego-
manygoalsdidMarcoReusscoreintheﬁrsthalf rizesprominentdatasetsalongtheselinesandpro-
ofthematch?’” butalsoquestionssuchas“‘Who videsanoverviewoverthenumberofquestions/-
wonthegame?’”,requiringasystemtounderstand documents, how each dataset was collected (e.g.  </Extractive Summary>  </Table 1>  </Paper ID = 1306>


<Paper ID = 1307> <Table 0> <Abstractive Summary> =0.402 0.267 0.359
Compchain:R 0.329 0.180 0.277
Compchain:RC 0.399 0.305 0.388
Compchain:RX 0.074 0.089 0.096
LAS 1.000 0.780 0.918
MLAS 0.780 1.000 0.822
BLEX 0.918 0.822 1.000
Table 3: Coefﬁcient of determination (R2) for pair-
wise (linear) correlations of metric-scores over all
CoNLL’18SharedTaskbaselinemodels. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1307>


<Paper ID = 1308> <Table 0> <Abstractive Summary> =if the
132Fidelity↑ Recall PerfectRecall A-FFL
Perplexity↓ ILM S-FFL M-FFL A-FFL
(ord)
#Frames Single Multi All Multi All
InﬁllText 12.85 11.7 9.84 6.19 5.05
ILM(noguidance) .169 .166 .165 .091 .026
+SpToks 7.24 8.32 9.5 8.95 7.04
ILM+LCD .584 .595 .610 .418 .232
w/5FrSlots 4.06 5.12 6.34 7.32 6.03
ILM+LCD-ord – .598 .626 .427 .255
FFL .518 .559 .640 .381 .259
FFL(randsample) .461 .511 .601 .338 .224 Table 2: Model perplexity over inﬁll text tokens and
FFL-ord – .585 .669 .415 .298 inﬁlltexttokens+specialtokens(<starttoinﬁll>,<end
ofinﬁll>,<inﬁllmask>). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1308>


<Paper ID = 1308> <Table 1> <Abstractive Summary> =Table 1: Frame ﬁdelity, computed as frame recall ac-
cording to the neural frame parser (left). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1308>


<Paper ID = 1308> <Table 2> <Abstractive Summary> =poseshardconstraintsonwordsense,itisentirely
133#Frames #Frames
Confusionrate(%)↑ Averagerank(1..10)↓
Single Multi All Single Multi All
ILM(noguidance) 41 41 41 ILM(noguidance) 5.48 5.48 5.48
ILM+LCD 35 31∗ 20∗ ILM+LCD 5.85∗ 6.38∗ 7.50∗
FFL 33∗ 39 38 FFL 5.88∗ 5.57 5.11
FFL-ordered 33∗ 38 37 FFL-ordered 5.88∗ 5.53 5.02∗
Table3: Confusionratecomputedasthepercentageof Table 4: Average relative plausibility rank by human
storiesforwhichtheannotatorpicksawrongsentence annotators. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 1308>


<Paper ID = 1308> <Table 3> <Abstractive Summary> =8https://github.com/chrisdonahue/ilm AgglomerativeClustering.html
140Frames LUsclusters A-FFL
Collaboration cluster1:conspire,conspiracy,collusion,collude Perplexity ILM S-FFL M-FFL A-FFL (ord)
cluster2:together,inleague,incahoots,
worktogether,teamup
cluster3:confederate InﬁllText 13.88 11.07 8.76 5.45 4.69
cluster4:partner,jointly,cooperation,associate,afﬁliated, +SpToks 8.87 9.16 10.05 9.3 7.43
collaboration,collaborator,cooperate,collaborate
+5FrSlots 4.66 5.51 6.71 7.64 6.23
Ingestion cluster1:have,putaway,lap,putback,down
cluster2:feed,lunch,breakfast,snack,eat,drink
cluster3:swig,ingestion,quaff,swill,guzzle,
sup,nosh,gulp,devour,gobble,ingest, Table 5: Model perplexity over inﬁll text tokens and
consume,dine,nibble,imbibe,slurp,sip
inﬁlltexttokens+specialtokenswithall5ROCStory
cluster4:tuck,munch,feast,nurse
Departing cluster1:departure,depart,exit,leave sentencesmaskedout. </Abstractive Summary> <Extractive Summary> Table 3 shows that ILM
··· Idancedterriblyandbrokeafriend’stoe.  </Extractive Summary>  </Table 3>  </Paper ID = 1308>


<Paper ID = 131> <Table 0> <Abstractive Summary> =GLOVE [ALIGNED]: Average pairwise cosine
Table 1: Examples from our annotated data, showing
similarity of word embeddings between tokens
themajoritylabelforeachexample. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 131>


<Paper ID = 131> <Table 1> <Abstractive Summary> =1642Model ρ 95%CI
answer***
%-IN-T .523 [.488,.559]
PJSD .540*** [.505,.574]
reformulation***
Table 3: Results from the PJSD model. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 131>


<Paper ID = 1310> <Table 0> <Abstractive Summary> =74.5 71.7 73.1 44.9 44.2 44.5
BiLSTM(↓) 73.9 71.2 72.5 31.3 37.5 34.1 Table 2: Thread starters (self-links) performances for
DAG-LSTM 74.9 72.2 73.6 37.3 42.3 39.6 ourmodelsinTable1,beforeandafterthresholding. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1310>


<Paper ID = 1310> <Table 1> <Abstractive Summary> =75.272.773.9 42.4 41.7 42.0 terF scoredisplaysamuchlargervariancethan
1
graph F score, which is roughly four-fold after
1
Table 1: Results of our experiments (bottom, best
subtractingthescorerollingaverage. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1310>


<Paper ID = 1310> <Table 2> <Abstractive Summary> =158Parameter Domain Distribution
d {64,128,256} categorical
h
d {64,128,256} categorical
FF
worddropout {0,0.3,0.5} categorical
max-afﬁnedropout {0,0.3,0.5} categorical
feed-forwarddropout {0,0.3,0.5} categorical
learningrate [10−5,10−3] log-uniform
BiDAG-LSTM {true,false} categorical
Table 3: Hyperparameters of the model architectures. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 1310>


<Paper ID = 1311> <Table 0> <Abstractive Summary> =Precondition generation can Table 1: Top 5 preconditions generated from GPT-2
beframedasasequence-to-sequenceproblem: with beam search decoding. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1311>


<Paper ID = 1311> <Table 1> <Abstractive Summary> =0.013 -1.280
DiP 0.038 -1.111
Table 4: Diversity evaluation for different models. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1311>


<Paper ID = 1311> <Table 2> <Abstractive Summary> =Toremovepossiblyredundantpreconditionsusing Table 5: The Top 10 generated preconditions for each
targeteventwerescoredona0-2scale.Amodel"wins"
iterativeredundancyﬁltering,weneedtocompute
a target if its average is highest. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 1311>


<Paper ID = 1311> <Table 3> <Abstractive Summary> =This makes intuitive sense if you
Table 6: Examples from each type of errors. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 1311>


<Paper ID = 1311> <Table 4> <Abstractive Summary> =BERT: Pre-training of
deep bidirectional transformers for language under-
Table 7: Diversity evaluation for different samplers. </Abstractive Summary> <Extractive Summary> We use Self-BLEU (Zhu et al., 2018) and Self-
BLEURTscoretomeasurethediversityofgener- Table 4 shows the diversity metrics for all meth-
atedpreconditions.  </Extractive Summary>  </Table 4>  </Paper ID = 1311>


<Paper ID = 1311> <Table 5> <Abstractive Summary> =SCADsentstudentsfromIowaandOhioto
visitJohnsHopkins
MostSomaliswantalawthatwouldenablethem Inchampioningtheeliteclasseslastweek, publicschool
teachersmountedanextensivepublicitycampaigntoper-
suadeparents
ShortlyafterKatrina,Postservicemenwerechasingselec- Joel Packer, a Detroit Pistons and assistant coach with
torsafterthestorm’sonset Brighamcapturedalargercampusandinvitedthescouts
Eversincecollegeopenedin1983,heshoppedforschool Asthetrendforwardmovesintonextseason,largercolleges
assignments are beginning with faculty members from 75 sites on an
extensivebioharkerscholarshipsite
Table 9: Top 5 generation examples from RPS and RPS+Post-processor. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 5>  </Paper ID = 1311>


<Paper ID = 1312> <Table 0> <Abstractive Summary> =Dataset Input Output
GEOQUERY whichistheshortestriver answer(
shortest(
river(all)))
NLMAPS nameLocalitiesinNantes query(
area(keyval(’name’,’Nantes’)),
nwr(keyval(’place’,’locality’)),
qtype(findkey(’name’)))
TOP istrafﬁcheavydowntown
[IN:GET_INFO_TRAFFIC
is traffic heavy in
[SL:LOCATION
downtown]]
OVERNIGHT showmeall listValue(
importantmeetings filter(
filter(getProperty(
singleton en.meeting)
(string !type))
(string is\_important)))
AMR thismethodwillnot
(p / pollute-01 :polarity -
pollutetheenvironment :ARG0 (m / method
:mod (t / this))
:ARG1 (e / environment))
Table 1: Training examples from each of the datasets used in our experiments. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1312>


<Paper ID = 1312> <Table 1> <Abstractive Summary> =Dataset Train Dev Test SrcVocab TgtVocab
GEOQUERY 540 60 280 279 103
NLMAPS 16172 1843 10594 8628 1012
TOP 28414 4032 8241 11873 116
OVERNIGHT 18781 2093 5224 1921 311
AMR 36521 1368 1371 30169 28880
Table 2: Details of each dataset. </Abstractive Summary> <Extractive Summary> Table 1 shows a
notexpectedtohelpasmuchasmorerelatedQ&A training example fromeach dataset.  </Extractive Summary>  </Table 1>  </Paper ID = 1312>


<Paper ID = 1312> <Table 2> <Abstractive Summary> =70.7(±1.6) 82.8(±0.7) 85.2(±0.1) 68.3(±0.1) 62.9(±0.5) 18h(±4h)
SQUAREROOT 71.1(±2.5) 83.4(±1.1) 84.7(±0.0) 67.8(±0.6) 63.6(±1.0) 21h(±4h)
POWER 73.5(±1.4) 84.2(±0.5) 85.1(±0.3) 68.3(±0.4) 64.1(±0.3) 23h(±7h)
ANNEALED 72.1(±0.0) 82.1(±0.2) 85.1(±0.3) 67.8(±0.2) 63.0(±0.6) 19h(±2h)
INVERSE 69.9(±2.4) 84.3(±0.8) 84.9(±0.2) 68.4(±0.7) 64.2(±0.7) 20h(±2h)
LOSS 73.3(±1.9) 85.7(±0.0) 85.2(±0.1) 68.9(±0.2) 64.2(±0.4) 15h(±2h)
Table 3: Comparison of sampling strategies for the 1-TO-N architecture. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 1312>


<Paper ID = 1312> <Table 3> <Abstractive Summary> =183Model Batch lr Layers Units Heads Dropout
GEOQUERY 100 0.05 3 512 4 0.1
NLMAPS 50 0.05 4 512 16 0.05
BASELINE TOP 200 0.05 3 512 4 0.04
OVERNIGHT 10 0.05 3 700 4 0.03
AMR 10 0.05 4 512 4 0.03
1-TO-N 10 0.05 3 512 4 0.1
1-TO-1 10 0.05 3 1024 4 0.1
1-TO-1-SMALL 10 0.05 3 512 4 0.1
Table 8: Hyper-parameter selected for baselines and MTL models. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 1312>


<Paper ID = 1313> <Table 0> <Abstractive Summary> =[SL:CATEGORY EVENT x ]
0
[SL:DATE TIME x ] ]
1
Table 2: Replacing text in the MRL with placeholder Question(Italian):
tokensandmarkingthepositionsofplaceholdertokens Tutti i festival questo fine settimana
inthequestion(onthesameexampleasinTable1). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1313>


<Paper ID = 1313> <Table 1> <Abstractive Summary> =Directly translating the text in the
Table 3: English semantic parsing data translated into
MRLintoanotherlanguageislikelytogeneratean
Italian
incorrectMRL,asitmaynotmatchthetranslation
oftheinputquestion. </Abstractive Summary> <Extractive Summary> Table 1 shows an example of
tences in different languages and used a shared
theoriginalTOPdataanditscorrespondingMRL
decoder to predict the MRL.  </Extractive Summary>  </Table 1>  </Paper ID = 1313>


<Paper ID = 1313> <Table 2> <Abstractive Summary> =Japanese 25544 3629 8241
Table 4: The distribution of the multilingual TOP
dataset
4 MultilingualSemanticParsingModels
Figure 1: Using fast align algorithm to identify corre- 4.1 ModelArchitecture
spondingplaceholdertokensinthetranslation. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 1313>


<Paper ID = 1313> <Table 3> <Abstractive Summary> =As a heuristic Table 7: An example of missing article “i” in Italian
solution, we ﬁlter out articles from both the ex- semanticparsing
pectation and the prediction and the exact match
accuracy rises from 62.4% to 75.4% by our best
performingmodel. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 1313>


<Paper ID = 1313> <Table 4> <Abstractive Summary> =(2017)
English 85.9% 85.7% Question(Italian):
Concerti di Beyonce questo fine
German 85.5% 82.3%
settimana
Table 9: Comparing the mBERT-based model with PredictedMRL:
SOTA model on the NLMaps dataset (trained on the [IN:GET EVENT [SL:CATEGORY EVENT Concerti
fulltrainingdatafor10kiterations) ] [SL:NAME EVENT Beyonce ] [SL:DATE TIME
questo fine settimana ] ]
Table11: Anexampleofcorrectzero-shotprediction
9. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 4>  </Paper ID = 1313>


<Paper ID = 1315> <Table 0> <Abstractive Summary> =2https://github.com/cfmrp/mtool lookasif”isnode(pron)-edge(arg1)-node(look-v)-
207Precision Recall F1
System
AllData Lpps AllData Lpps AllData Lpps
Amazon(Caoetal.,2019) .75 .70 .71 .71 .730 .704
Saarland(Donatellietal.,2019) .70 .73 .63 .71 .661 .722
SJTU-NICT(Lietal.,2019) .75 .71 .68 .69 .714 .696
Suda-Alibaba(Zhangetal.,2019b) .73 .66 .70 .69 .713 .674
HIT-SCIR(Cheetal.,2019) .77 .71 .69 .65 .725 .680
+EDS(GCNs,K=1)[G1] .787 .738 .683 .671 .731 .703
+EDS(GCNs,K=2)[G2] .780 .763 .691 .689 .733 .724
+EDS(GCNs,K=3)[G3] .783 .752 .689 .674 .733 .711
+EDS(BiLSTM+GCNs,K=1)[LG1] .785 .770 .692 .687 .736 .726
+EDS(BiLSTM+GCNs,K=2)[LG2] .785 .774 .690 .678 .735 .723
Table 1: SMATCH scores on the evaluation data, ”All Data” means results on all evaluation data and ”Lpps” is
results on 100 sentences of The Little Prince. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1315>


<Paper ID = 1315> <Table 1> <Abstractive Summary> =Tops Labels Properties Edges All
System
P R F P R F P R F P R F P R F
HIT-SCIR .81 .81 .81 .78 .74 .76 .51 .57 .54 .66 .56 .61 .722 .660 .689
+EDS[G1] .84 .84 .84 .81 .77 .79 .77 .48 .59 .65 .57 .61 .746 .678 .710
+EDS[G2] .82 .84 .83 .83 .78 .81 .76 .52 .62 .69 .59 .64 .771 .697 .732
+EDS[G3] .83 .84 .83 .81 .77 .79 .73 .50 .59 .68 .58 .63 .761 .682 .720
+EDS[LG1] .86 .86 .86 .85 .79 .82 .80 .52 .63 .68 .58 .62 .779 .695 .734
+EDS[LG2] .83 .85 .84 .85 .78 .81 .84 .48 .61 .69 .58 .63 .783 .686 .732
Table 2: MRP scores of Lpps AMR sub tasks. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1315>


<Paper ID = 1316> <Table 0> <Abstractive Summary> =Thus,the time once,whenever
model is expected to learn what the next sentence
Table 1: Subordinators used to create weakly super-
should look like. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1316>


<Paper ID = 1316> <Table 1> <Abstractive Summary> =Table 8: Confusion matrices of models trained on the
ﬁrstsplitofdataforcrossvalidation. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1316>


<Paper ID = 1317> <Table 0> <Abstractive Summary> =ADP 89.36 91.55 90.44
Concatenating GloVe to the input vector pro-
ADJ 69.10 62.84 65.82
videsadditionalgeneralizednon-domain-speciﬁc
Table 2: Results by POS tags of the best model for (thepre-trainedGloVewastrainedonWikipedia)
VUA-All(BERT+GloVe+VE). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1317>


<Paper ID = 1318> <Table 0> <Abstractive Summary> =Model XNLI RFEval Model XNLI RFEval Avg
M-BERT⊕NORM +1.9 +1.7 M-BERT 17.4 24.5 21.0
M-BERT⊕JOINT-ALIGN +5.2 +7.6 XLM-R 11.1 37.8 24.5
M-BERT⊕JOINT-ALIGN⊕NORM +7.6 +10.1 M-BERT⊕JOINT-ALIGN⊕NORM 9.8 14.4 12.1
XLM-R⊕NORM +2.5 +27.1 XLM-R⊕JOINT-ALIGN⊕NORM 8.4 4.3 6.3
XLM-R⊕JOINT-ALIGN −0.2 +11.6
XLM-R⊕JOINT-ALIGN⊕NORM +2.8 +33.5 Table 4: Performance gap (lower is better) for cross-
lingualclassiﬁcationtransfer,andreference-basedand
Table3: Ablationtestsofourmodiﬁedencoders. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1318>


<Paper ID = 1319> <Table 0> <Abstractive Summary> = 3: CloselyRelated

 2: DistantlyRelated

2 RelatedWork 1: Unrelated
Our approach generally falls within the area of
Table 1: DURel relatedness scale (Schlechtweg et al.,
Bayesian probabilistic modeling (Koch, 2007). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1319>


<Paper ID = 1320> <Table 0> <Abstractive Summary> =Feature Micro-F1 Macro-F1 Feature Micro-F1 Macro-F1
Baseline 0.604 0.377 Baseline 0.376 0.137
comp TFITF 0.637 0.566 comp TFITF 0.412 0.238
FREQ head gen 0.642 0.571 FREQ mod dom 0.415 0.280
FREQ mod gen 0.645 0.619 Num comp 0.417 0.248
PROD mod gen 0.653 0.616 PROD head gen 0.426 0.306
comp WEIRD 0.709 0.690 FREQ head gen 0.435 0.290
FGM gen 0.713 0.696 FREQ mod gen 0.454 0.322
FREQ gen 0.732 0.706 PROD mod gen 0.455 0.298
comp WEIRD 0.462 0.330
FREQ gen 0.464 0.343
FGM gen 0.467 0.339
Table 4: Binary: individual features which signiﬁ- Table 5: Four-class: individual features which sig-
cantlyoutperformthebaseline. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1320>


<Paper ID = 1320> <Table 1> <Abstractive Summary> =kindsofwordembeddingsareusedinthefollow-
257CompoundandConstituent TertilesandRanges Micro-F1
Properties low mid high low high
compoundfrequency(domain) 3–4 4–8 8–444 0.773 0.722
compoundfrequency(general) 0 0–17 17–53,569 0.779 0.722
modiﬁerproductivity(domain) 1–14 14–55 55–665 0.863 0.658
modiﬁerproductivity(general) 0–101 103–588 590–4,976 0.884 0.661
headproductivity(domain) 1–14 14–61 62–1,157 0.802 0.652
headproductivity(general) 0–119 119–786 786–8,293 0.812 0.693
Table 8: Ranges of selected properties across tertiles, and results on binary classiﬁcation for extreme ‘low’ and
‘high’tertileswhenusingallfeatures(cf. </Abstractive Summary> <Extractive Summary> Table 1 shows the results for
tancesbetweencompoundmodiﬁerandcom- the decision tree classiﬁcation using all features.  </Extractive Summary>  </Table 1>  </Paper ID = 1320>


<Paper ID = 1321> <Table 0> <Abstractive Summary> =Withsingle-taskmod-
265Model Average abortion cloning death gun marijuana school minimum nuclear
penalty control legal uniforms wage energy
IN-TOPICMODELS(upperbounds)
Topic-MT-DNN† .665 .571 .733 .595 .611 .724 .707 .716 .662
CROSS-TOPICMODELS
ST-DNN .642±.011 .473±.012 .715±.012 .595±.009 .593±.011 .703±.010 .698±.015 .710±.013 .650±.002
MT-DNN+IBM .643±.009 .466±.019 .726±.010 .595±.006 .582±.004 .704±.010 .703±.010 .718±.009 .655±.006
MT-DNN+AQ .643±.011 .479±.015 .716±.006 .600±.012 .590±.010 .699±.011 .710±.010 .698±.008 .649±.015
MT-DNN+VacC .641±.010 .472±.016 .716±.008 .589±.009 .601±.009 .701±.011 .690±.010 .699±.013 .660±.006
MT-DNN+VacC+IBM+AQ .644±.011 .476±.009 .720±.021 .587±.011 .598±.005 .716±.011 .696±.003 .701±.018 .655±.006
CONSTRAINEDCROSS-TOPICMODELS(lowerbounds)
CLOSED .481±.014 .472±.016 .492±.006 .467±.013 .452±.015 .515±.021 .478±.012 .520±.012 .519±.008
CLOSED+SHARED .501±.010 .426±.012 .508±.016 .475±.009 .469±.006 .552±.004 .490±.005 .565±.017 .519±.008
Table 1: Macro F1 scores across topics of the three-class UKP data. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1321>


<Paper ID = 1321> <Table 1> <Abstractive Summary> =266Topic Argumentwords Topicwords Stancewords Other
abortion if,that,for abortion,life,women, right,legal,hates the,is,to,in,it,be
woman,human,pregnancy,
unborn
cloning would,will,if,could, cloning,clone,cloned, not,no,abnormalities the,to,is,it,have,be,do
potential genetic
deathpenalty would,if death,penalty,punishment, not,murder,murderers the,to,in,is,of,are,
killing,crime people,it
guncontrol gun,guns,criminals, no,safer,right,more,not, a,the,are,and,in,is
background,checks,disarm, abiding
arms,armed
marijuanalegalization would marijuana,use,effects, no,not,more,abuse,costs is,the,are,it
legalizing,legalization,
drug,prohibition,drugs
schooluniforms if,but uniforms,uniform,school, not,less,improve, to,can,it,without
students,clothing,wears decreased,uncomfortable,
costs
minimumwage would,that,if wage,minimum,workers, cost,more,no,many the,it,is,are,can
wages,living,jobs,hour
nuclearenergy that,if,for nuclear,power,energy, safety,less is,the,to,has,can,it
reactors,plants,waste,
chernobyl,fuel
Table 2: Top 20 words for each topic based on accumulated LIME weights towards the predicted label of each
sentence. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1321>


<Paper ID = 1321> <Table 2> <Abstractive Summary> =Asasetof
268Claimindicators indicates, because, proves, however, shows, re-
sult,opinion,conclusion,given,accordingly,since,
clearly, mean, truth, consequently, must, would,
points, therefore, whereas, obvious, demonstrates,
thus,fact,if,that,hence,i,could,should,for,con-
trary, potential, may, believe, suggests, probable,
conclude,clear,point,sum,entails,think,implies,
explanation,follows,reason
Sharedopen political,single,debate,had,asked,made,policy,
last,legal,cause,long,few,said,want,person,is-
sue,say,group,possible,use,people,believe,good,
have, fact, point, society, time, such, going, put,
used,come,based,question,think,example,part,
other,are,year,including,argument,only,way,ef-
fects, go, many, support, more, several, end, has,
day,see,need,make,get,means,public,is,high,
help,money,ﬁnd,found,same
Table 4: Claim indicators (see text) and shared open
classwordsacrosstheUKPtopics. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 1321>


<Paper ID = 1321> <Table 3> <Abstractive Summary> =One advantage of
Table 5: ST-DNN and CLOSED+SHARED models are
LIMEisthatitcanbeappliedtoanymodelpost-
trained solely on the UKP corpus, and we here report
these model’s performance (macro F1) on the binary, hoc. </Abstractive Summary> <Extractive Summary> Table 3 shows the average
ground”and“checks”receivehighweights.  </Extractive Summary>  </Table 3>  </Paper ID = 1321>


<Paper ID = 1323> <Table 0> <Abstractive Summary> =Whenwordsarescrambledbutno
Table 2: Adding background information to examples deﬁnitions are provided, an SNLI model without
fromSNLI specialtrainingachieves54.1%onSNLItrue. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1323>


<Paper ID = 1324> <Table 0> <Abstractive Summary> =Similarly to our
Table 3: Results for downstream task. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1324>


<Paper ID = 1325> <Table 0> <Abstractive Summary> =HAKIMI2020 7.13 15.43 19.38
HAKIMI2020+COPY 14.27 21.31 24.77
VECMAP 4.35 9.50 12.27 5 Conclusions
COPY 6.70 - -
Average
HAKIMI2020 8.36 17.36 21.21 We evaluated an extension of a joint training ap-
HAKIMI2020+COPY 14.27 22.83 26.50
proachtolearningcross-lingualembeddingsthat
Table 3: Precision@N for BLI for OOV source lan- incorporatessub-wordinformationduringtraining,
guage words. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1325>


<Paper ID = 1326> <Table 0> <Abstractive Summary> =cations of AT on some NLP tasks, the distin-
guishingcharacteristicsofNLPtaskshavenot
Table 1: An example from the SQuAD dataset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1326>


<Paper ID = 1326> <Table 1> <Abstractive Summary> =SQuAD1.1 SQuAD2.0 RACE Model AddSent AddOneSent Dev
Model
EM EM Acc
R.M-Reader† 58.5 67.0 86.6
BASEsetting KAR‡ 60.1 72.3 83.5
PQAT 85.87 81.66 76.32 ALUMBERT-BASE§ 60.4 69.8 90.8
(0.08) (0.21) (0.32) RoBERTaBASE 59.7 68.8 91.5
85.96 81.11↓ 76.50
PQAT+AT
(0.10) (0.14) (0.35) PQAT 64.7 73.6 92.3
85.64↓ 81.23↓ 75.94↓ AT 63.2 72.6 92.1
AT
(0.15) (0.30) (0.37)
Table 4: Model performance (F1) on AddSent, Ad-
Table 3: Comparison of PQAT, standard AT and the dOneSentandSQuAD1.1devset.ATisshortforStan-
combination. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1326>


<Paper ID = 1328> <Table 0> <Abstractive Summary> =Inor- F1-scoressimilartoHuangandLi(2019)whereas
dertoremedyforthisdisparitytosomeextent,we the accuracy is also reported on the second level
4Model Temp Cont Comp Exp 4-way 11-way
F-score Acc
Supervised 45.85 57.74 58.35 75.01 59.24 39.33 55.42
GoldConnective 77.29 96.23 88.01 93.42 88.74 57.56 78.87
MostCommonConn(but) 0.00 0.00 24.45 0.07 6.13 2.68 11.60
MostCommonSense 0.00 0.00 0.00 69.41 17.35 3.74 25.89
(Jietal.,2015) 19.26 41.39 25.74 68.08 38.62 - -
(HuangandLi,2019) 31.25 48.04 25.15 59.15 40.90 - -
BERT-base-uncased 14.97 29.06 32.05 59.45 33.88 13.88 23.16
+Margin 19.49 36.54 32.48 52.99 35.37 14.12 24.45
BERT-large-cased 9.33 27.06 36.89 68.58 35.47 12.29 24.55
+Margin 9.76 35.62 38.80 67.97 38.04 13.24 26.86
BERT-large-cased-wwm 10.89 36.29 42.69 62.38 38.06 16.79 27.23
+Margin 15.02 41.97 41.81 60.80 39.90 17.50 28.74
BERT-large-uncased 25.69 30.55 30.10 62.50 37.21 15.57 25.25
+Margin 27.32 41.01 32.28 59.07 39.92 15.67 28.01
BERT-large-uncased-wwm 18.35 35.20 40.19 58.88 38.15 16.47 26.80
+Margin 17.27 42.93 41.16 55.61 39.24 17.26 29.17
DistilBERT-base-cased 16.77 46.19 23.19 39.07 31.31 15.87 22.71
+Margin 21.09 48.05 29.25 37.04 33.86 16.68 26.38
RoBERTa-base 9.65 19.64 36.57 66.72 33.14 11.67 23.54
+Margin 9.18 22.77 35.90 66.36 33.55 13.01 25.32
RoBERTa-large 10.79 30.32 48.35 68.44 39.48 16.15 27.66
+Margin 13.30 33.19 49.52 67.90 40.98 17.63 29.57
GPT2 16.60 31.96 35.79 62.62 36.74 11.68 24.04
+Margin 18.27 37.31 35.93 61.70 38.30 13.07 26.02
GPT2-large 19.91 35.27 40.38 59.17 38.68 15.18 25.63
+Margin 23.17 40.55 40.30 60.39 41.10 16.03 27.50
GPT2-XL 21.59 30.88 40.18 63.01 38.92 16.98 26.01
+Margin 23.06 34.49 42.66 63.98 41.05 18.50 28.32
Table 2: The results of the proposed methodology with various pre-trained language models. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1328>


<Paper ID = 133> <Table 0> <Abstractive Summary> =1672Dehuman
Round Total Not Hate Animosity Derogation Support Threatening
-ization
R1 54.7% 64.6% 49.2% - - - - -
R2 34.3% 38.9% 29.7% 40.1% 25.5% 28.7% 53.8% 18.4%
R3 27.8% 20.5% 35.1% 53.8% 27.9% 29.2% 59.6% 17.7%
R4 27.7% 23.7% 31.7% 44.5% 21.1% 26.9% 49.2% 18.3%
All 36.6% 35.4% 37.7% 46.4% 24.8% 28.3% 55.4% 18.2%
Table 3: Error rate for target models in each round. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 133>


<Paper ID = 133> <Table 1> <Abstractive Summary> =ble4alsoshowsmodelstrainedonthecumulative Performance of target models trained on later
rounds of data with no upsampling, indicated by roundsissubstantiallyhigher,increasingfrom60%
M(RX+RY).Ingeneral,performanceislowerwith- (onboth‘Hate’and‘NotHate’)combinedforM1
1673Model R1 R2 R3 R4
M1(R1Target) 44.84±1.1 54.42±0.45 66.07±1.03 60.91±0.4
M2(R2Target) 90.17±1.42 66.05±0.67 62.89±1.26 60.87±1.62
M3(R3Target) 91.37±1.26 77.14±1.26 76.97±0.49 74.83±0.92
M4(R4Target) 92.01±0.6 78.02±0.91 75.89±0.62 75.97±0.96
M(R1only) 92.20±0.55 62.87±0.63 47.67±1.04 52.37±1.27
M(R2only) 80.73±0.4 76.52±0.7 77.43±0.51 74.88±0.85
M(R3only) 72.71±1.05 78.55±0.71 74.14±1.5 73.16±0.58
M(R4only) 72.26±1.3 76.78±1.65 77.21±0.43 69.6±0.6
M(R0+R1) 88.78±0.89 66.15±0.77 67.15±1.11 63.44±0.26
M(R0+R1+R2) 91.09±0.37 74.73±0.95 74.73±0.46 71.59±0.59
M(R0+R1+R2+R3) 91.17±0.99 77.03±0.72 74.6±0.48 73.94±0.94
M(R0+R1+R2+R3+R4) 90.3±0.96 77.93±0.84 76.79±0.24 72.93±0.56
Table 4: Macro F1 with standard deviation over 5 training rounds, evaluated on each rounds’ test set. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 133>


<Paper ID = 133> <Table 2> <Abstractive Summary> =Intersectional Asianwomen
Intersectional Muslimwomen
Table5: Listofhighpriorityidentities
1681Model R1 R2 R3 R4
M1(R1Target) 41.4±0.91 61.06±0.43 58.18±0.69 55.46±0.63
M2(R2Target) 95.38±0.25 68.86±0.71 66.46±1.09 63.17±0.8
M3(R3Target) 94.55±0.65 85.04±0.63 76.77±0.57 74.4±0.9
M4(R4Target) 94.92±0.45 85.32±0.29 77.52±0.68 76.42±0.82
M(R1) 95.69±0.29 61.88±0.98 57.75±0.8 58.54±0.52
M(R2) 81.28±0.2 84.36±0.4 75.8±0.55 74.29±1.05
M(R3) 76.79±1.18 79.6±0.99 75.5±0.48 74.19±1.07
M(R4) 78.05±1.09 80.21±0.31 75.63±0.49 72.54±0.64
M(R0+R1) 93.92±0.3 69.43±1.58 65.48±0.48 63.99±0.74
M(R0+R1+R2) 93.13±0.24 82.82±0.8 73.66±0.75 72.28±0.84
M(R0+R1+R2+R3) 93.43±0.39 84.66±0.6 75.81±0.29 75.85±1.0
M(R0+R1+R2+R3+R4) 92.73±0.82 86.0±0.69 77.0±0.59 75.7±0.69
Table 6: Macro F1 with standard deviation over 5 training rounds, evaluated on each rounds’ dev set. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 133>


<Paper ID = 1331> <Table 0> <Abstractive Summary> =tencecontainsaspectsofmeaningthatarecon-
textuallyunspeciﬁedandthusrequireclariﬁca- Table 1: Examples of a sentence that requires clariﬁ-
tion. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1331>


<Paper ID = 1331> <Table 1> <Abstractive Summary> =Article: CutaGlassBottle
Table 2: Revision types and example sentences that require clariﬁcation from our training set ((cid:55)). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1331>


<Paper ID = 1332> <Table 0> <Abstractive Summary> =(2017) 74.20 - - - - - - - -
BERT 85.52 86.32 89.18 92.44 92.12 94.45 81.00 77.56 91.48
Table 3: Experimental results on the MOH, TroFi and LCC datasets with the word-level classiﬁcation (WCLS),
sentence-levelclassiﬁcation(SCLS)andsequentiallabeling(SL)settings. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1332>


<Paper ID = 1334> <Table 0> <Abstractive Summary> =The
the system with only mention Bert embeddings oraclecombinationshowsanimprovementforthe
61Model Precision Recall F -score Acc
1
BERT 0.6628 0.5997 0.6275 0.6460
M+BERT 0.6459 0.3816 0.4742 0.5847
MB+BERT 0.6470 0.4906 0.5567 0.6107
M+MB+BERT 0.6455 0.4989 0.5617 0.6118
MB+BERToracle 0.6654 0.6064 0.6324 0.6493
Table 6: Results for predicting revision requirements at the sentence-level. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1334>


<Paper ID = 1335> <Table 0> <Abstractive Summary> =TTCB System Description to a Shared Task on Implicit and
Underspeciﬁed Language 2021
PerathamWiriyathammabhum
peratham.bkk@gmail.com
Abstract Table 1: Example instances from the wikiHowToIm-
prove dataset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1335>


<Paper ID = 1335> <Table 1> <Abstractive Summary> =65Table3: Developmentaccuraciesofdifferentlossfunc- Table 5: Development accuracies and F1 scores on
tionsontheXLNetmodel. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1335>


<Paper ID = 1335> <Table 2> <Abstractive Summary> =Ourreasonisitshouldbemore
Table 4: Development accuracies of data augmented certainthatmostrevisedsentencesshouldnotre-
Bigbird. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 1335>


<Paper ID = 1337> <Table 0> <Abstractive Summary> =It can be used to
evaluate Russian↔English translation quality as
Table 5: The NICT-SAP task corpora splits. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1337>


<Paper ID = 1337> <Table 1> <Abstractive Summary> =Table 11: Statistics of the dataset used for
The Japanese sentences are translated from the
Japanese↔English multi-modal tasks. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1337>


<Paper ID = 1337> <Table 2> <Abstractive Summary> =There were no participants in the Newswire
Table 12: Statistics of the restricted vocabulary in the
evaluationdata. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 1337>


<Paper ID = 1337> <Table 3> <Abstractive Summary> =Singapore
IIT-H InternationalInstitueofInformationTechnology India
*gauvar Amazon Singapore
*JBJBJB Indivisualparticipant Korea
SRPOL SamsungR&DPoland Poland
NHK NHK Japan
CFILT ComputingforIndianLanguageTechnology India
iitp IITPatna India
Volta InternationalInstituteofInformationTechnologyHyderabad India
coastal UniversityofCopenhagen Denmark
CFILT-IITB IndianInstituteofTechnologyBombay India
CNLP-NITS-PP NITSilchar India
BeringLab BeringLab SouthKorea
tpt_wat TransperfectTranslations USA
Table 13: List of participants who submitted translations for the human evaluation in WAT2021 (Note: teams
with‘*’marksdidnotsubmittheirsystemdescriptionpapers,thereforetheevaluationresultsareUNOFFICIAL
accordingtoourpolicy)
10ASPEC+ ASPEC ALT+ NICT-SAP
ParaNatCom Restricted UCSY En-Hi/Id/Ms/Th Hi/Id/Ms/Th-En
TeamID EJ EJ JE En-My My-En IT Wikinews IT Wikinews
TMU ✓
NTT ✓ ✓
NICT-2 ✓ ✓ ✓ ✓
goodjob ✓
YCC-MT1 ✓
YCC-MT2 ✓
NECTEC ✓
nictrb ✓ ✓
sakura ✓ ✓ ✓ ✓ ✓ ✓
NHK ✓ ✓
humaneval ✓ ✓ ✓ ✓ ✓
Multimodal
JPC En-Hi En-Ml Flickr MSCOCO
TeamID EJ JE CJ JC KJ JK TX HI MM TX HI EJ JE EJ
TMU ✓ ✓ ✓ ✓
NLPHut ✓ ✓ ✓ ✓
TMEKU ✓ ✓
sakura ✓ ✓
iitp ✓
Volta ✓ ✓
CNLP-NITS-PP ✓ ✓
BeringLab ✓ ✓ ✓ ✓ ✓ ✓
tpt_wat ✓ ✓ ✓ ✓ ✓ ✓
humaneval ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓
Indic21
En-X X-En
TeamID Bn Kn Ml Mr Or Hi Gu Pa Ta Te Bn Kn Ml Mr Or Hi Gu Pa Ta Te
NICT-5 ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓
NLPHut ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓
mcairt ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓
sakura ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓
IIT-H ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓
gauvar ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓
JBJBJB ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓
SRPOL ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓
CFILT ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓
coastal ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓
CFILT-IITB ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓
humaneval ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓
Table14: Submissionsforeachtaskbyeachteam. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 1337>


<Paper ID = 1338> <Table 0> <Abstractive Summary> =In this method for
this task, one of the main problems is how to ex- Table 1: Statistics of ofﬁcial data including ASPEC-
tractconstraintsfromtrainingdatasinceonlycon- JE and target vocabulary lists. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1338>


<Paper ID = 1338> <Table 1> <Abstractive Summary> =+rule 52.69 0.82 0.80 73.9 73.5 37.5
Table 3: Ofﬁcial results (Japanese tokenizer:KyTea and English tokenizer:moses). </Abstractive Summary> <Extractive Summary> Table 1 shows statistics
notgivenforthetrainingdata.  </Extractive Summary>  </Table 1>  </Paper ID = 1338>


<Paper ID = 1339> <Table 0> <Abstractive Summary> =This
+LCD(beam=30) 43.9 94.34 85.21
methodcaninformthemodelofwhatconstraints
Table 2: Comparison of translation accuracy and con- aregivenbeforedecodingtime,andthusthemodel
sistencyscoreforeachsettingonJa→En. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1339>


<Paper ID = 1339> <Table 1> <Abstractive Summary> =In some cases,
we found that constraints may contain out-of-
Table 4: Effectiveness of ﬁne-tuning. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1339>


<Paper ID = 1339> <Table 2> <Abstractive Summary> =Singlemodel 55.49 43.44
8Ensemble 56.57 44.34 5 OfﬁcialResults
Table6showstheautomaticevaluatedperformance
Table 5: Effectiveness of ensembling models. </Abstractive Summary> <Extractive Summary> Table 2 shows size(e.g.,4,000)isempiricallysuperiortothecom-
thatLeCAachievedhightranslationaccuracyand monlyusedones(e.g.,32,000).  </Extractive Summary>  </Table 2>  </Paper ID = 1339>


<Paper ID = 1339> <Table 3> <Abstractive Summary> =g3vfoh2oljpq
57BLEU
ID Setting En→Ja Ja→En
(a) BASE(§4.1) 44.64 29.30
(b) BASE+LCD(§4.2) 45.38 23.22
(c) LeCA(§4.3) 53.79 41.88
(d) LeCA+LCD 55.49 43.33
(e) (d)×8ensemble(§4.6) 56.57 44.34
(f) [(d)+ﬁne-tuning(§4.5)]×8 56.47 44.28
Table 6: The performance of the submitted systems. </Abstractive Summary> <Extractive Summary> MeCab+ipadic 44.8 68.67 43.87
Table 3 shows that mecab-ipadic-NEologd
MeCab+NEologd 46.5 72.35 49.39
signiﬁcantly improved translation accuracy and
consistency scores.  </Extractive Summary>  </Table 3>  </Paper ID = 1339>


<Paper ID = 1339> <Table 4> <Abstractive Summary> =Languagepair Finalscore (Rank) DA (Rank) CA (Rank)
En→Ja 57.2 (1) 77.5 (1) 79.7 (1)
Ja→En 44.1 (1) 75.6 (1) 74.4 (1)
Table 7: Ofﬁcial results of our team. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 4>  </Paper ID = 1339>


<Paper ID = 134> <Table 0> <Abstractive Summary> =InfoSurgeon 36.5% 31.3%
5.5 HumanTuringTestonSynthesizedText
Table 2: Knowledge element-level misinformation de-
tectionF-scoreontheVOA(VOA-KG2txt)dataset,con- Inordertoassessthequalityofthesynthesizedtext
sisting of entity swapping, link insertion, and sub- fromourKG-to-textgenerator,weconductaTur-
graphreplacementmanipulations,anditseasiervariant, ingTestby16humansubjectswhoreadnewson
VOA0,whichcontainsentityswappings. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 134>


<Paper ID = 134> <Table 1> <Abstractive Summary> =Otherapproachesincludedetectingpreviouslyfact-
Table 3: Ablation results on the VOA dataset, analyz-
checkedclaims(Shaaretal.,2020),retrievingsen-
ing the isolated components of our model using fea-
tences that explain fact-checking (Nadeem et al.,
tures from the KG, semantic representations (F ),
Sem 2019;Atanasovaetal.,2020),andleveragingcon-
andprimitiveindicators(F ). </Abstractive Summary> <Extractive Summary> (2)OurnewVOA-KG2txtdataset,which
Table 1 also presents the results on the VOA-
consistsof15krealnewsarticlescrapedfromVoice
KG2txtdatasetweassembled.  </Extractive Summary>  </Table 1>  </Paper ID = 134>


<Paper ID = 1340> <Table 0> <Abstractive Summary> =Ensemble∗ 37.01 75.38 65.15
whereYˆ isthegeneratedsequenceintimestep Table 3: Results on ASPECTJa→En testsets. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1340>


<Paper ID = 1341> <Table 0> <Abstractive Summary> =accuracydecreasesasthenumberofsegmentsin-
70Model BLEUscore Consistencyscore Finalscore
Transformer 27.78 0.220 0.27
+AppendRTVs 25.57 1.000 26.75
RecoverSAT 25.76 0.197 0.16
+Forcedtranslationwithrandomorder 26.93 0.962 26.98
+Forcedtranslationwithsortedorder 27.16 0.961 27.10
+Forcedtranslationwithoracleorder 31.14 0.966 31.02
Table 2: Results of the experiments in our evaluation. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1341>


<Paper ID = 1342> <Table 0> <Abstractive Summary> =The example of POS-tagged
2https://github.com/ye-kyaw-thu/myWord
3https://github.com/ye-kyaw-thu/sylbreak 4https://github.com/ye-kyaw-thu/myPOS
76Table 1: English-Myanmar Parallel Dataset
Data Type File Name Number of Sentence
TRAIN train.ucsy. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1342>


<Paper ID = 1342> <Table 1> <Abstractive Summary> =10https://en.wikipedia.org/wiki/Word_error_
rate
Myanmar-to-English translation results are 11https://github.com/usnistgov/SCTK
79Table 3: WER scores for English-to-Myanmar and Myanmar-to-English translation models (Generally,
lower WER indicates better translation performance)
English-to-Myanmar Myanmar-to-English
Models WER(%) WER(%)
transformer 81.3% 82.6%
multi-transformer 83.9% 90.0%
shared-multi-transformer 83.5% 88.2%
s2s 84.2% 85.1%
multi-s2s 82.7% 91.8%
shared-multi-s2s 82.5% 86.0%
Table 3 shows the WER scores of English- an, and the), and (4) the different nature and
to-Myanmar and Myanmar-to-English trans- language gaps of Myanmar and English lan-
lation models. </Abstractive Summary> <Extractive Summary> Table 1 shows data iment will be described in the following sec-
statistics used for the experiments.  </Extractive Summary>  </Table 1>  </Paper ID = 1342>


<Paper ID = 1342> <Table 2> <Abstractive Summary> =cleaning errors of English language, (3) the
Myanmar language with no articles (i.e., a, For instance, for the Myanmar sentence “သ(cid:227)
80Table 4: An example of confusion pairs of the model Transformer
EN-MY MY-EN
Freq Freq
Ref→Hyp Ref→Hyp
သည(cid:233)→တယ(cid:233) 371 apos→ quot 30
မ(cid:234)(cid:223)(cid:232)→(cid:228)တ(cid:235) 63 the → a 29
၏→ရ(cid:229) (cid:231) 33 quot → apos 24
တယ(cid:233)→သည(cid:233) 36 , → the 23
(cid:228)သ(cid:223)→တ(cid:229)(cid:231) 17 the → &amp 23
ရန(cid:233)→ဖ(cid:224)(cid:226)(cid:231) 9 in → of 18
(cid:228)ယ(cid:223)က(cid:233)→ဦ(cid:232) 9 a → the 17
မည(cid:233)→မယ(cid:233) 8 the → s 14
တ(cid:224)(cid:226)(cid:231)→မ(cid:234)(cid:223)(cid:232) 7 to → of 10
၎င(cid:233)(cid:232)→ဒ(cid:222) 3 with → and 6
က အတန(cid:233)(cid:232) ထ(cid:229) မ(cid:236)(cid:223) အ(cid:228)တ(cid:223)(cid:233)ဆ(cid:226)(cid:230)(cid:232) (cid:228)က(cid:234)(cid:223)င(cid:233)(cid:232)သ(cid:223)(cid:232) (cid:238)ဖစ(cid:233)တယ(cid:233)။”, In the Myanmar-to-English translation task,
theytranslatethissentencetotheEnglishsen- the proposed models could not provide better
tence “He is the most clever student of the translationqualitythanthebaselines. </Abstractive Summary> <Extractive Summary> Moreover, the multi-s2s and
shared-multi-s2s models also provide better
Table 2 shows the experimental results
translation results compared with the baseline
of the first and second architectures.  </Extractive Summary>  </Table 2>  </Paper ID = 1342>


<Paper ID = 1343> <Table 0> <Abstractive Summary> =main of the UCSY corpus is general and the
83
Proceedingsofthe8thWorkshoponAsianTranslation,pages83–89
Bangkok,Thailand(online),August5-6,2021.©2021AssociationforComputationalLinguisticsTable 1: Statistics of our preprocessed parallel data
Data Type # of Sentences # of Myanmar Syllables # of English Words
TRAIN (UCSY) 238,014 6,285,996 3,357,260
TRAIN (ALT) 18,088 1,038,640 413,000
DEV 1,000 57,709 27,318
TEST 1,018 58,895 27,929
original English sentences of the ALT corpus Applying the Bayes’ rule, we can factorized
was extracted from the Wikinews (Ye Kyaw into three parts. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1343>


<Paper ID = 1343> <Table 1> <Abstractive Summary> =Es-
master/WAT2021/en-my_transliteration-dict sential of hybrid translation is to integrate the
85Table 2: Some example of manually extracted transliteration word/phrase pairs. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1343>


<Paper ID = 1343> <Table 2> <Abstractive Summary> =Hybrid cally increase the translation performance up
87Table 3: BLEU, RIBES and AMFM scores for English-to-Myanmar translation (Bold number indicate
the highest score for each scoring method)
Only UCSY Training Data UCSY+ALT Training Data
Experiments BLEU RIBES AMFM BLEU RIBES AMFM
Baseline: PBSMT 15.01 0.519451 0.550400 20.80 0.542406 0.617900
Hybrid: xml-exclusive 20.80 0.551514 0.653850 24.54 0.563854 0.690020
Hybrid: xml-inclusive 20.88 0.553319 0.655310 25.11 0.567187 0.689400
Baseline: OSM 15.05 0.528968 0.557240 20.33 0.550329 0.622350
Hybrid: xml-exclusive 19.94 0.540820 0.651070 23.82 0.554226 0.691450
Hybrid: xml-inclusive 20.13 0.545962 0.654820 23.73 0.556381 0.691910
Baseline: Hiero 14.83 0.555290 0.545900 20.29 0.587136 0.612400
Hybrid: xml-exclusive 21.02 0.588198 0.653840 25.48 0.60733 0.684110
Hybrid: xml-inclusive 21.02 0.588198 0.653840 25.48 0.607339 0.684110
to 6 BLEU scores. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 1343>


<Paper ID = 1344> <Table 0> <Abstractive Summary> =Table 3: Hyperparameters for the mBART additional
usingeachsetofdomaindata. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1344>


<Paper ID = 1345> <Table 0> <Abstractive Summary> =mBART25 ﬁnetuning Regardless of the im-
Table 5: Comparisons of MNMT with UVR and
age representation, we also ﬁnetuned on the
mBART25 ﬁnetuning best models results in the
Flickr30kEnt-JPcorpususingthemBART25pre- Japanese↔English multimodal task: (a) constrained
trainedmodelundertheunconstrainedtasksetting. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1345>


<Paper ID = 1345> <Table 1> <Abstractive Summary> =models achieved signiﬁcant im- mBART and prepend source and target tokens to
10https://github.com/pytorch/fairseq/b 11https://github.com/anoopkunchukuttan
lob/master/examples/mbart/ /indic nlp library
100Language
bn gu hi kn ml mr or pa ta te
Train 1,756,197 518,015 3,534,387 396,865 1,204,503 781,872 252,160 518,508 1,499,441 686,626
-PMI 23,306 41,578 50,349 28,901 26,916 28,974 31,966 28,294 32,638 33,380
Dev 1,000 1,000 1,000 1,000 1,000 1,000 1,000 1,000 1,000 1,000
Test 2,390 2,390 2,390 2,390 2,390 2,390 2,390 2,390 2,390 2,390
Table 6: Statistics of the Multilingual Indic datasets. </Abstractive Summary> <Extractive Summary> tation(BuschbeckandExel,2020)2 andALTcor- While the mBART50 has great coverage of
pus.3 Table 1 shows the statistics of the datasets.  </Extractive Summary>  </Table 1>  </Paper ID = 1345>


<Paper ID = 1345> <Table 2> <Abstractive Summary> =datasetsinTable10:
Dataset English Myanmar
P1 original original • D1 = {P1}
P clean+tokenize original
2
P3 clean clean • D2 = {P1,P2,P6,P7}
P clean clean+wordtokenize
4
P clean clean+syllabletokenize
5 • D = {P ,P ,P ,P ,P }
P clean+tokenize clean+wordtokenize 3 1 3 4 6 7
6
P clean+tokenize clean+syllabletokenize
7
• D = {P ,P ,P ,P }
4 3 4 6 7
Table 10: Preprocessing variations for the Myanmar-
Forbothdirectionsoneachdataset,wetrainedin-
Englishdataset
dividual Transformer models using the Marian15
toolkit. </Abstractive Summary> <Extractive Summary> Table 2 models for multilingual models.  </Extractive Summary>  </Table 2>  </Paper ID = 1345>


<Paper ID = 1346> <Table 0> <Abstractive Summary> =NoFilter Filter
Test
Train Valid Train Valid
src tgt src tgt src tgt src tgt src tgt
#ofsents 224,987 224,987 5,000 5,000 214,318 214,318 5,000 5,000 5,000 5,000
#oftokens 7,319,788 7,731,924 160,773 167,888 7,117,361 7,447,350 136,496 143,044 165,781 172,590
#ofwords 1,950,669 1,900,409 42,968 41,780 1,887,843 1,830,500 36,655 35,961 43,482 41,472
avgofSL(cid:52) 32.53 34.37 32.15 33.58 33.21 34.75 27.3 28.61 33.16 34.52
avgofWS 8.67 8.45 8.59 8.36 8.81 8.54 7.33 7.19 8.7 8.29
avgofSS 7.67 7.45 7.59 7.36 7.81 7.54 6.33 6.19 7.7 7.29
#ofK-toks∗ 5,503,227 5,599,442 121,131 122,502 5,365,092 5,420,594 103,667 104,961 123,566 124,203
#ofE-toks 32,389 61,294 504 829 30,217 57,203 463 724 1,162 2,262
#ofS-toks 2,181 338,459 55 6,675 1,769 307,339 21 5,682 74 6,873
Table 1: Statistics of our parallel corpus results on TST with and without a ﬁlter. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1346>


<Paper ID = 1348> <Table 0> <Abstractive Summary> =We set the maximum n- Table 4: Correlation coefﬁcients between evaluation
gram length N to 4 in calculating the focality metrics
scores,ISDIT,andBLEU.Usingthefourmetrics,
wecomparedthefollowingtranslationmodels:
• Transformer+W +MCdropout.6
PoT
• NaiveMoses(Koehnetal.,2007);
“+”expressesacombinationoftechniques. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1348>


<Paper ID = 135> <Table 0> <Abstractive Summary> =Theﬁnal BART DECODE 94.47 80.10 79.19 88.2
θ
contradictionprobabilityisthemaximumoverall Majority
theoutputs: - - 50.00 50.00 50.00 48.7
yˆ = max(cid:8)fUB(u ,u ) : u ∈ S(cid:9) (2) Table 2: Test performance on DECODE for various
pred θ i n i methods. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 135>


<Paper ID = 135> <Table 1> <Abstractive Summary> =0.2 BeamSearch 46.1% 55.3%
A
0.15 Top-k(k=40) 2.6% 39.5%
0.04 0.06 0.08 0.1 0.12
Human Identified Contradiction Rate
Table 3: Generation Re-ranking using DECODE vs.
Figure4: Thecomparisonbetweentheaveragecontra-
standard methods, reporting the contradiction % as
diction score by the detector (y-axis) and the human
ﬂagged by our contradiction detection classiﬁer (i.e.,
identiﬁed contradiction rate (x-axis) on the utterances
an automatic metric, “DECODE Contradict%”) in ad-
bydifferentbots, averagedbytypeofbot. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 135>


<Paper ID = 135> <Table 2> <Abstractive Summary> =Table 4: Veriﬁcation Statistics. </Abstractive Summary> <Extractive Summary> The results in Table 2 also demonstrate
utterance-basedRoBERTatrainedonDECODEon
thatthemodelingofdialogueconsistencyisade-
humanutterancesis5.5%contrastingtothe74.3%
mandingtask.  </Extractive Summary>  </Table 2>  </Paper ID = 135>


<Paper ID = 135> <Table 3> <Abstractive Summary> =Wethentakethemeanoverallutterances Table 6: Performance of RoBERTa trained on DE-
ineachsettingtogivetheﬁnalcontradictioncount CODEdatawithdifferentapproaches. </Abstractive Summary> <Extractive Summary> Thisisincontrast
All-DECODE 15.63 57.74 24.60 71.82
to Table 3 where we only considered contradict- DECODE 17.05 50.13 25.45 73.40
ingutterancesbyBlenderBotonly.  </Extractive Summary>  </Table 3>  </Paper ID = 135>


<Paper ID = 135> <Table 4> <Abstractive Summary> =Table 7: RoBERTa performance on all the bot-
generated utterances from the raw interactive human-
botdialogue. </Abstractive Summary> <Extractive Summary> Table 4 shows age for strict blocking of inconsistent utterances
the veriﬁcation statistics.  </Extractive Summary>  </Table 4>  </Paper ID = 135>


<Paper ID = 135> <Table 5> <Abstractive Summary> =Table 10: Generation Re-ranking using DECODE vs.
standard methods, reporting the contradiction % as
Model+ HumanContradict% ﬂagged by our contradiction detection classiﬁer (i.e.,
DecodingStrategy 2-agree 3-agree fractional anautomaticmetric,“DECODEContradict%”)inaddi-
tion to human judgments (“Human Contradict%”). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 5>  </Paper ID = 135>


<Paper ID = 135> <Table 6> <Abstractive Summary> =We ﬁnd similar results to the
main paper’s results but where the model’s score are
Table 9: Generation Re-ranking using DECODE vs. closertogether.Thisshouldbeexpectedaswhenselect-
standard methods, reporting the contradiction % as ingmanyutterancesthatarealreadynon-contradicting
ﬂagged by human judgments (“Human Contradict%”) thereisnotmuchlefttoimprove. </Abstractive Summary> <Extractive Summary> B AnnotationQualityControl
E ExtraResultsAnalysis
Weapplythefollowingmechanismtoensurethe
qualityofcollecteddata: Table 6 shows the performance of unstructured
• Onboarding Test: Every annotator needs to methodwhentheinputconsistsofutterancesfrom
pass an onboarding test before they can actu- bothspeakers(thedefaultunstructuredapproach)
ally contribute dialogue examples.  </Extractive Summary>  </Table 6>  </Paper ID = 135>


<Paper ID = 1350> <Table 0> <Abstractive Summary> =For  the  Korean  →  Japanese  and  framework  for  explaining  how  the  various 
Language Pair  Split 32K  Split 32K + BT  Shared 32K  Shared 8K   Shared 8K + BT 
EN → JA  23.2  26.6  23.8  23.8  27.1 
JA → EN  38.9  -  39.4  40.2  - 
KO → JA  46.6  46.8  46.7  45.6  45.6 
JA → KO  52.0  -  50.8  -  - 
ZH → JA  30.6  31.6  31.8  31.9  32.9 
JA → ZH  46.2  -  37.6  47.5  - 
Table 1:  BLEU scores for different language pairs and different vocabulary configurations 
 
  139
   
 hyperparameters interact to produce such different  Papers),  pages  86–96,  Berlin,  Germany. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1350>


<Paper ID = 1351> <Table 0> <Abstractive Summary> =Len
Train 1,000,000 44.85 JP–EN 21,254,269 215.31
JP−EN
Dev 2,000 53.17 JP–KO 13,916,372 110.29
JP−EN
Test 5,668 58.63 JP–ZH 13,881,444 144.44
JP−EN
Train 1,000,000 52.27
JP−KO
Table 3: Statistics of additional parallel sentences. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1351>


<Paper ID = 1351> <Table 1> <Abstractive Summary> =We set the data type to the
Th→En 25.07 0.73 2of9
ﬂoating point 32 and applied relative positional
encoding(Shawetal.,2018)toconsiderthepair- Table 6: Rank and BLEU/AMFM scores for NICT-
wiserelationshipsbetweentheinputelements. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1351>


<Paper ID = 1351> <Table 2> <Abstractive Summary> =In
Test-n3 230 87.8 64.47 66.25 the inference time, we used the ﬁve independent
models ensemble for Ja → Zh and seven models
Table 7: Ablation studies for JPC2 Ja → Ko sub-
forZh→Ja. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 1351>


<Paper ID = 1352> <Table 0> <Abstractive Summary> =The vocabulary was
Table 1: Statistics of our data used in the learned jointly on the source and target sen-
English→Hindi and English→Malayalam Multi- tences of HVG and IIT-B for EN-HI and of
modal task: the number of sentences and tokens. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1352>


<Paper ID = 1352> <Table 1> <Abstractive Summary> =Forgeneratingtranslations, weused
xmlui/handle/11234/1-3267
6http://www.cfilt.iitb.ac.in/iitb_parallel/ greedy decoding and generated tokens autore-
7https://lindat.mff.cuni.cz/repository/
xmlui/handle/11234/1-3533 8http://data.statmt.org/pmindia/
147Language pair en-bn en-hi en-gu en-ml en-mr en-ta en-te en-pa en-or en-kn
Train (ALL) 1756197 3534387 518015 1204503 781872 1499441 686626 518508 252160 396865
Train (PMI) 23306 50349 41578 26916 28974 32638 33380 28294 31966 28901
Dev 1000
Test 2390
Table 2: Statistics of the data used for Indic multilingual translation. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1352>


<Paper ID = 1352> <Table 2> <Abstractive Summary> =Table 5: WAT2021 Automatic Evaluation Results
4 Results
forIndicMultilingualTask. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 1352>


<Paper ID = 1352> <Table 3> <Abstractive Summary> =MMCHTEXT21en-ml 12.15 12.98
MMCHHI21en-ml 0.99 -
5 Conclusions
Table 4: WAT2021 Automatic Evaluation Re-
sults for English→Hindi and English→Malayalam. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 1352>


<Paper ID = 1352> <Table 4> <Abstractive Summary> =152Gold: Gold:
एकलड़कीटेिनसखेलरहीहै आदमीसमुद्रमें सर्िंफ(cid:838)ग
Gloss: A girl is playing tennis Gloss: man surﬁng in ocean
Output: Output:
एकटेिनसरैकेटपकड़ेहुएआदमी पानीमें एकव्यिक्त
Gloss: A man holding a tennis Gloss: A man in the water
racket
Gold: Gold:
एककुत्ताकूदताहै हेलमेटपहनना
Gloss: A dog is jumping Gloss: Wearing helmet
Output: Output:
कुत्ताभागरहाहै एक आदमी के िसर पर एक
कालाहेलमेट
Gloss: A dog is running Gloss: A black helmet on the
head of a person
Gold: Gold:
തിളക്കമുള്ളപച്ചൈകറ്റ് ഒരു (cid:652)വത്തിെല (cid:501)ാഫിക്
ൈലറ്റ്
Gloss: Bright green kite Gloss: Traﬃc light at a pole
Output: Output:
ആകാശത്ത്പറ(cid:329)ന്നൈക- (cid:501)ാഫിക്ൈലറ്റ്ചുവപ്പ്തി-
റ്റ് ള(cid:437)(cid:686)
Gloss: Kite ﬂying in the sky Gloss: The traﬃc light glows
red
Gold: Gold:
തൂങ്ങികിട(cid:329)ന്നഒരുകൂട്ടംവാ- ചുമരിൽ ഒരു ഘടികാരം വാഴ-
ഴപ്പഴം പ്പഴം
Gloss: A bunch of hanging ba- Gloss: A clock on the wall
nanas
Output: Output:
ഒരുകൂട്ടംവാഴപ്പഴം ചുമരിൽഒരുചി(cid:579)ം
Gloss: A bunch of bananas Gloss: A picture on the wall
Table 6: Sample captions generated for the evaluation test set using the proposed method: the top two
rows present results of Hindi captions; and the bottom two rows are results of Malayalam caption. </Abstractive Summary> <Extractive Summary> Weare
results of our models for all the participated also working on improving the region-specific
tasks in Table 4 and Table 5.  </Extractive Summary>  </Table 4>  </Paper ID = 1352>


<Paper ID = 1353> <Table 0> <Abstractive Summary> =Monolingual Sentences Tokensinmillions
Data
En 107,597,494 1832.008594
Hi 44,949,045 743.723731
Table 2: Monolingual Data Statistics collected from
IITBandWMT16. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1353>


<Paper ID = 1355> <Table 0> <Abstractive Summary> =Train Valid Test Challenge
Nomasking EntityMasking Degradation%
#entitiesintext 29,583 1,028 1,631 1,592
mBART 44.2 15.1 65.8
#objectstagsinimages 253,051 8,679 13,855 12,507
ViTA 44.6 22.5 49.6
#entitiesinobjecttags 13,959 498 758 442
%entitiesinobjecttags 47.18% 48.44% 46.47% 27.76% ViTA-gt 43.6 25.4 41.7
Table 3: We show the overlap between the entities in Table 4: The effect of entity masking on the BLEU
the text and the object tags detected using Faster R- scoreoftheproposedmodelsonthetestset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1355>


<Paper ID = 1355> <Table 1> <Abstractive Summary> =Nomasking ColorDeprivation Degradation% Nomasking AdjectiveMasking Degradation%
mBART 44.2 39.0 11.8 mBART 44.2 36.1 18.3
ViTA 44.6 39.2 12.1 ViTA 44.6 36.1 19.1
ViTA-col 43.7 40.0 8.5 ViTA-adj 44.3 36.9 16.7
ViTA-gt-col 43.8 40.9 6.6 ViTA-gt-adj 43.9 37.2 15.3
Table 5: The effect of color deprivation on the BLEU Table6: TheeffectofadjectivemaskingontheBLEU
scoreoftheproposedmodelsonthetestset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1355>


<Paper ID = 1356> <Table 0> <Abstractive Summary> =OurreportedBLEUscores
Table 1: Flickr30kEnt-JP task: BLEU scores and hu-
manevaluationscore(fullscoreis5)ontheEn→Ja. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1356>


<Paper ID = 1358> <Table 0> <Abstractive Summary> =Sanskrit’s
morphological and agglutinative nature accounts for Table 2: Character F1, Token accuracy, BLEU, and
thelargenumberofuniquetokensinthevocabularies. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1358>


<Paper ID = 136> <Table 0> <Abstractive Summary> =Table 4: Accuracies of Seq2Seq-DU and baselines
The hidden size of LSTM decoder is also 768.
on SGD, MultiWOZ2.2 and MultiWOZ2.1 datasets. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 136>


<Paper ID = 136> <Table 1> <Abstractive Summary> =Onecansee COMER 0.886 -
Seq2Seq-DU-w/oSchema 0.912 0.850
thatSeq2Seq-DUperformssigniﬁcantlybetterthan
thebaselinesinDSTandperformsequallywellas
Table 5: Accuracies of Seq2Seq-DU and baselines
thebaselinesinNLU. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 136>


<Paper ID = 136> <Table 2> <Abstractive Summary> =Itcanworkwellinzero-shotlearning
Table 6: Accuracies of Seq2Seq-DU and baselines on
to deal with unseen schemas (SGD). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 136>


<Paper ID = 136> <Table 3> <Abstractive Summary> =Theresultssuggestthatitis Table 7: Accuracies of Seq2Seq-DU and baselines on
ATISandSNIPSdatasets. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 136>


<Paper ID = 136> <Table 4> <Abstractive Summary> =“activeintent”:ﬁnd-hotel; intent”:ﬁnd-hotel; “activeintent”:ﬁnd-hotel;
Table 8: Case study on Seq2Seq-DU and SGD-baseline on SGD and MultiWOZ2.2. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 4>  </Paper ID = 136>


<Paper ID = 136> <Table 5> <Abstractive Summary> =TripPy - - 0.684 0.733
Seq2Seq-DU 0.578 0.393 0.758 0.711
Domain JointGA IntAcc Domain JointGA IntAcc
Messaging* 0.0489 0.3510 Media* 0.2307 0.9065 Table 10: Accuracies of Seq2Seq-DU and baselines
RentalCars* 0.0625 0.7901 Events* 0.3186 0.9327 withrespecttocategoricalandnon-categoricalslotson
Payment* 0.0719 0.5835 Hotels** 0.3396 0.9891
SGDandMultiWOZ2.2. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 5>  </Paper ID = 136>


<Paper ID = 1362> <Table 0> <Abstractive Summary> =Ouraimhereistoconvertdata 4https://github.com/microsoft/MASS
5https://github.com/moses-smt/
2https://github.com/anoopkunchukuttan/ mosesdecoder/blob/RELEASE-2.1.1/scripts/
indic_nlp_library generic/multi-bleu.perl
219LangPair Size Datasources
bn-en 1.70M alt,cvit-pib,jw,opensubtitles,pmi,tanzil,ted2020,wikimatrix
gu-en 0.51M bibleuedin,cvit,jw,pmi,ted2020,urst,wikititles
hi-en 3.50M alt,bibleuedin,cvit-pib,iitb,jw,opensubtitles,pmi,tanzil,ted2020,wikimatrix
kn-en 0.39M bibleuedin,jw,pmi,ted2020
ml-en 1.20M bibleudein,cvit-pib,jw,opensubtitles,pmi,tanzil,ted2020,wikimatrix
mr-en 0.78M bibleuedin,cvit-pib,jw,pmi,ted2020,wikimatrix
or-en 0.25M cvit,mtenglish2odia,odiencorp,pmi
pa-en 0.51M cvit-pib,jw,pmi,ted2020
ta-en 1.40M cvit-pib,jw,nlpc,opensubtitles,pmi,tanzil,ted2020,ufal,wikimatrix,wikititles
te-en 0.68M cvit-pib,jw,opensubtitles,pmi,ted2020,wikimatrix
Table 1: Parallel Dataset amongst 10 Indic-English language pairs. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1362>


<Paper ID = 1362> <Table 1> <Abstractive Summary> =(bn, gu, hi, kn, ml, mr, or, pa, ta, te and en: Bengali, Gujarati, Hindi, Kannada, Malayalam, Marathi,
Oriya,Punjabi,Tamil,TeluguandEnglishrespectively
BLEU AMFM
LangPair Bilingual IA-En DR-En All-En IA-En DR-En All-En
bn-en 18.52 20.18 - 18.48 0.734491 - 0.730379
gu-en 26.51 31.02 - 28.79 0.776935 - 0.765441
hi-en 33.53 33.7 - 30.9 0.791408 - 0.775032
mr-en 21.28 25.5 - 23.57 0.767347 - 0.751917
or-en 22.6 26.34 - 25.05 0.780009 - 0.770941
pa-en 29.92 32.34 - 29.87 0.782112 - 0.772655
kn-en 17.93 - 24.18 24.01 - 0.744802 0.751223
ml-en 19.52 - 22.84 22.1 - 0.745908 0.744459
ta-en 23.62 - 22.75 21.37 - 0.74509 0.742311
te-en 19.89 - 24.02 22.37 - 0.745885 0.743435
Table 2: Results: XX-en is the translation direction. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1362>


<Paper ID = 1363> <Table 0> <Abstractive Summary> =We applied two methods of domain-
226fastTextﬁltering Source Selected BLEU Improvement
backtranslations 400M 86M Noﬁltering 2In 2En 2In 2En
bitextﬁlteredFT 11M 1,5M Bitextonly 18.81 31.80
CCAligned 15M 400k FullBT 18.77 33.02 -0.04 1.22
PMIndia 300k 300k LMﬁltering
bitextfull 11M 11M FilteredBT 20.06 35.43 1.25 3.63
LanguageModelﬁltering Source Selected TunedBitext 21.03 36.95 0.97 1.52
backtranslations 400M 58M FTPMIndia 21.39 37.26 0.36 0.31
bitextfull 11M 11M fastTextﬁltering
bitextdistilledforward 11M 11M FilteredBT 19.77 36.62 0.96 4.86
bitextdistilledbackward 11M 11M TunedBT-PMI 21.01 37.64 1.24 1.02
TunedBitext 21.31 38.47 1.54 1.85
Table 2: Components of mixed corpora used for pre-
FTPMIndia 21.91 38.72 0.60 0.25
trainings with backtranslation (4.2) using fastText ﬁl-
FTBT-PMI 21.81 38.42 0.50 -0.05
teringandlanguagemodelﬁlteringofmonolingualcor-
FTMADL 38.67 0.20
pora. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1363>


<Paper ID = 1363> <Table 1> <Abstractive Summary> =229Model Bn Gu Hi Kn Ml Mr Or Pa Ta Te AVG
BLEU
Baseline 12.03 22.99 35.25 14.72 11.93 16.07 12.33 28.65 11.44 10.65 17.61
Competitor 14.73 26.97 38.25 19.57 12.79 19.48 20.15 33.35 14.43 15.61 21.53
Bestsingle 15.58 27.31 38.04 20.91 15.43 19.93 19.15 32.88 13.89 16.82 21.99
Ensemble 15.97 27.80 38.65 21.30 15.49 20.42 19.94 33.43 14.15 16.85 22.40
RIBES
Baseline 0.7072 0.8020 0.8438 0.7281 0.6874 0.7388 0.7146 0.8203 0.6971 0.6924 0.7432
Competitor 0.7242 0.8202 0.8542 0.7601 0.7074 0.7600 0.7503 0.8376 0.7215 0.7284 0.7664
Bestsingle 0.7328 0.8223 0.8525 0.7701 0.7341 0.7669 0.7497 0.8355 0.7288 0.7345 0.7727
Ensemble 0.7336 0.8249 0.8559 0.7712 0.7369 0.7718 0.7511 0.8375 0.7307 0.7398 0.7753
AMFM
Baseline 0.7675 0.8166 0.8224 0.8091 0.7986 0.8050 0.7146 0.7733 0.7957 0.7633 0.7866
Competitor 0.7796 0.8201 0.8228 0.8178 0.8053 0.8115 0.7699 0.8137 0.8029 0.7898 0.8033
Bestsingle 0.7723 0.8199 0.8224 0.8213 0.8080 0.8108 0.7715 0.8132 0.7994 0.7930 0.8032
Ensemble 0.7710 0.8212 0.8246 0.8219 0.8081 0.8097 0.7718 0.8141 0.7988 0.7911 0.8032
Table 7: Ofﬁcial results of translations from-English by 3 metrics for submitted results of: baseline model, best
competitor’sresult,submittedsingleSRPOL’smodelandsubmittedbestSRPOL’sensemble
Model Bn Gu Hi Kn Ml Mr Or Pa Ta Te AVG
BLEU
Baseline 25.39 35.86 39.49 30.67 28.69 29.10 30.07 37.61 28.01 29.05 31.39
Competitor 29.96 39.39 43.23 35.46 33.21 34.02 34.11 41.24 31.94 35.44 35.80
Bestsingle 31.82 42.87 45.61 39.01 37.04 35.68 36.04 44.87 35.06 38.57 38.66
Ensemble 31.87 43.98 46.93 40.34 38.38 36.64 37.06 46.39 36.13 39.80 39.75
RIBES
Baseline 0.7649 0.8186 0.8448 0.7984 0.7927 0.7879 0.7895 0.8335 0.7881 0.7803 0.7999
Competitor 0.7983 0.8394 0.8591 0.8209 0.8132 0.8103 0.8017 0.8495 0.8070 0.8168 0.8216
Bestsingle 0.8001 0.8497 0.8677 0.8373 0.8304 0.8212 0.8128 0.8614 0.8160 0.8315 0.8328
Ensemble 0.8005 0.8533 0.8729 0.8405 0.8354 0.8248 0.8170 0.8658 0.8223 0.8364 0.8369
AMFM
Baseline 0.7699 0.8129 0.8250 0.7927 0.7936 0.7916 0.7940 0.8151 0.7884 0.7872 0.7970
Competitor 0.7786 0.8207 0.8345 0.8097 0.8068 0.7958 0.8082 0.8235 0.7961 0.8040 0.8078
Bestsingle 0.7924 0.8331 0.8435 0.8204 0.8207 0.8103 0.8149 0.8364 0.8036 0.8204 0.8196
Ensemble 0.7897 0.8358 0.8471 0.8237 0.8230 0.8123 0.8173 0.8416 0.8065 0.8209 0.8218
Table 8: Ofﬁcial results of translations to-English by 3 metrics for submitted results of: baseline model, best
competitor’sresult,submittedsingleSRPOL’smodelandsubmittedbestSRPOL’sensemble
230Figure1:Summaryresultsforall5manuallyevaluatedlanguages-Bengali,Kannada,Malayalam,Marathi,Oriya
231Sergey Edunov, Myle Ott, Michael Auli, and David Toshiaki Nakazawa, Hideki Nakayama, Chenchen
Grangier. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1363>


<Paper ID = 1364> <Table 0> <Abstractive Summary> =An
233
Proceedingsofthe8thWorkshoponAsianTranslation,pages233–237
Bangkok,Thailand(online),August5-6,2021.©2021AssociationforComputationalLinguisticsen-bn en-gu en-hi en-kn en-ml en-mr en-or en-pa en-ta en-te
ALT 20 - 20 - - - - - - -
Bible-uedin - 16 62 61 61 61 - - - 62
CVIT-PIB 92 58 267 - 43 114 94 101 116 45
IITB3.0 - - 1603 - - - - - - -
MTEnglish2Odia - - - - - - 35 - - -
NLPC - - - - - - - - 31 -
OdiEnCorp2.0 - - - - - - 91 - - -
OpenSubtitles 411 - 92 - 383 - - - 32 27
PMIndia 23 41 50 29 27 29 32 28 33 33
TED2020 - - - 2 - - - 0.7 - -
Total 546 115 2094 92 514 204 252 130 212 167
Table 1: Statistics of number of parallel sentences for each of the English-Indic language pairs across different
datasets used for training. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1364>


<Paper ID = 1365> <Table 0> <Abstractive Summary> =Tamil(TA) 1,354,247 91,324
Inthisapproach,withthehelpofexistingtarget-to- Telugu(TE) 457,453 111,749
sourceMTsystemtargetistranslatedintosource English(EN) - 109,480
andresultingsyntheticparallelcorpusiscombined
Table 1: Language wise training set sizes in terms of
with clean corpus and used to train source-to-
numberofsentences. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1365>


<Paper ID = 1365> <Table 1> <Abstractive Summary> =Weduplicatethe KN-EN 4.70 4.43
monolingual English data 10 times and the base- OR-EN 3.36 3.31
lineEN→XXmodelisusedtogeneratesynthetic
Table 3: Contribution of each language pair (in %) in
Indic data. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1365>


<Paper ID = 1365> <Table 2> <Abstractive Summary> =240XX→EN EN→XX
LanguagePair
BLEU RIBES AMFM BLEU RIBES AMFM
BN-EN 25.77 0.77 0.78 11.04 0.70 0.73
GU-EN 36.49 0.83 0.81 20.46 0.75 0.81
HI-EN 40.08 0.85 0.83 34.48 0.84 0.82
KN-EN 31.24 0.81 0.80 13.22 0.64 0.79
ML-EN 29.37 0.80 0.80 3.79 0.44 0.76
MR-EN 29.96 0.80 0.80 13.95 0.67 0.80
OR-EN 31.19 0.79 0.80 12.57 0.71 0.74
PA-EN 38.41 0.84 0.82 16.81 0.79 0.66
TA-EN 27.76 0.79 0.79 8.51 0.58 0.76
TE-EN 28.13 0.78 0.78 6.25 0.53 0.76
Table 4: Ofﬁcial BLEU, RIBES and AMFM scores of multilingual models for each language pair. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 1365>


<Paper ID = 1366> <Table 0> <Abstractive Summary> =Relativelyhighre-
jointvocabularyof10Indicsourcelanguages,16K sourcerelatedlanguagetrainingdataweretranslit-
vocabulary of English and character coverage of erated into low resource language using translit-
1.0. erated method as described by Ahmad Bhat et
246LowResourceLanguage RelatedLanguage source poor languages, two multilingual mod-
Oriya Bengali els were trained in (a) One-to-Many fashion for
Kannada Telugu English→Indic and (b) Many-to-One fashion for
Gujarati Hindi Indic→Englishwithsharedencoder-decoder,simi-
lartoasdescribedbyJohnsonet.al(Johnsonetal.,
Table 4: Related languages of top three low resource
2017). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1366>


<Paper ID = 1366> <Table 1> <Abstractive Summary> =Training conﬁgura-
Table 5: Statistics of ﬁnal training data after applying tionare600000stepsforIndic→English,440000
transliterationandbacktranslation stepsforEnglish→Indic,withbatchsizeof4096,
dropout 0.1, batch type tokens, adam optimizer,
warmupsteps8000,wordembeddingsize512,en-
al. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1366>


<Paper ID = 1366> <Table 2> <Abstractive Summary> =247Indic→English BLEU RIBES AM-FM English→Indic BLEU RIBES AM-FM
bn→en 29.96 0.798326 0.786717 en→bn 13.02 0.715490 0.779592
gu→en 36.77 0.829389 0.819546 en→gu 23.21 0.809389 0.816739
hi→en 40.05 0.850322 0.832119 en→hi 35.85 0.846656 0.822626
kn→en 31.16 0.803525 0.799216 en→kn 14.58 0.726259 0.805963
ml→en 28.07 0.792884 0.794932 en→ml 6.17 0.622598 0.793308
mr→en 27.29 0.785579 0.780231 en→mr 14.90 0.740079 0.791850
or→en 29.96 0.798326 0.795586 en→or 17.71 0.743984 0.763064
pa→en 38.42 0.840360 0.818332 en→pa 30.56 0.830405 0.810106
ta→en 28.04 0.793839 0.790184 en→ta 11.98 0.707054 0.801632
te→en 29.26 0.790319 0.786396 en→te 11.17 0.702337 0.783647
Table 6: Performance of ANVITA-1.0 for Table 7: Performance of ANVITA-1.0 for
Indic→English directions on the ofﬁcial WAT English→Indic directions on the ofﬁcial WAT
2021MultiIndicMTtestset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 1366>


<Paper ID = 1369> <Table 0> <Abstractive Summary> =FR-DT 5822/302 49654/2660
5 Word-LevelSubspaces
Table 2: Number of sentences and tokens of the data
used for ﬁne-tuning BERT for the sentence-level ex-
Beforemovingtothelesserexploredsentence-level
periments. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1369>


<Paper ID = 137> <Table 0> <Abstractive Summary> =Length#
∗ ∗ ∗ ∗
MMPMS 0.66 0.45 0.50 0.08/0.32 0.24 5.82
MemGM 0.53 0.37 0.34 0.09/0.33 0.20 4.08
HRED 0.54 0.43 0.19 0.08/0.26 0.20 5.04
CVAE 0.58 0.39 0.43 0.11/0.38 0.22 7.74
VHCR-EI 0.68 0.43 0.53 0.12/0.36 0.28 7.30
DVRNN-RL 0.60 0.39 0.39 0.06/0.22 0.22 7.86
GCS 1.03 0.59 0.58 0.19/0.55 0.48 8.00
GCSw/UtterG 0.93 0.56 0.55 0.16/0.47 0.34 8.00
GCSw/PhraseGraph 0.72 0.41 0.54 0.16/0.45 0.24 8.00
Table 2: Evaluation results for baselines and our system trained on Weibo corpus. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 137>


<Paper ID = 1370> <Table 0> <Abstractive Summary> =Bothtrainingandtestcon-
Table 1: MLM top 3 candidates for the templates tainanequalamountofmessageswithrespectto
“Womenare[MASK.]”. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1370>


<Paper ID = 1370> <Table 1> <Abstractive Summary> =(2020).716±.034 .531 AbusEval
HateBERT.836 .404 – –.565.567
BERT .480±.008 .633±.002
BERT .540 .220.438 .241 – –
HatEval HateBERT .516±.007 .645±.001 HatEval
HateBERT.473 .183.365 .191 – –
Best .651 .673
Table 4: BERT vs. HateBERT: Portability - Precision
Table2: BERTvs. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1370>


<Paper ID = 1370> <Table 2> <Abstractive Summary> =Theunexpectedhigher
BERT .572 .590 – Precision of HateBERT ﬁne-tuned on AbusEval
HatEval
HateBERT .543 .555 – andtestedonOffensEval2019(i.e.,fromspeciﬁc
togeneric)isduetothedatasetssharingsamedata
Table 3: BERT vs. HateBERT: Portability. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 1370>


<Paper ID = 1371> <Table 0> <Abstractive Summary> =We evaluate
transferabilitybycomparinghowagivenpairper-
Table 2: Percentage of each meme type in Pin and
forms on both datasets. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1371>


<Paper ID = 1371> <Table 1> <Abstractive Summary> =ﬁnd that Pin memes contain fewer faces than
FB memes, while other demographic factors
Table 1: Cosine similarity between predicted text and broadly match. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1371>


<Paper ID = 1371> <Table 2> <Abstractive Summary> =Tesseract,FBtuning 0.70 0.36 0.34
Tesseract,Pintuning 0.22 0.58 0.26
Table 3: Facial detection and demographic (gender,
Easy,FBtuning 0.53 0.30 0.23
Easy,Pintuning 0.32 0.67 0.35 age)distributionsfrompre-trainedFaceNetandDEX. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 1371>


<Paper ID = 1371> <Table 3> <Abstractive Summary> =maybebecausethecombinationofmultiplemodes
create meaning beyond the text and image alone
Table 4: F1 scores for pretrained baseline models on
(Kruketal.,2019). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 1371>


<Paper ID = 1372> <Table 0> <Abstractive Summary> =MODEL(TEST) AUROC↑ AUPRC↑ ACC.↑ ECE↓ BRIER↓ CALIB.AUROC↑ CALIB.AUPRC↑
DETERMINISTIC 0.9734 0.8019 0.9231 0.0245 0.0548 0.9230 0.4053
T SNGP 0.9741 0.8029 0.9233 0.0280 0.0548 0.9238 0.4063
EN MCDROPOUT 0.9729 0.8006 0.9274 0.0198 0.0508 0.9282 0.4020
X DEEPENSEMBLE 0.9738 0.8074 0.9231 0.0235 0.0544 0.9245 0.4045
SNGPENSEMBLE 0.9741 0.8045 0.9226 0.0281 0.0549 0.9249 0.4158
DETERMINISTIC 0.9730 0.8036 0.9476 0.1486 0.0628 0.9405 0.3804
L SNGP 0.9736 0.8076 0.9455 0.0076 0.0388 0.9385 0.3885
CA MCDROPOUT 0.9741 0.8076 0.9472 0.1442 0.0622 0.9425 0.3890
FO DEEPENSEMBLE 0.9735 0.8077 0.9479 0.1536 0.0639 0.9418 0.3840
SNGPENSEMBLE 0.9742 0.8122 0.9467 0.0075 0.0379 0.9400 0.3846
Table 2: Metrics for models on the Wikipedia Talk corpus (in-domain testing environment), all numbers are av-
eraged over 10 model runs. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1372>


<Paper ID = 1373> <Table 0> <Abstractive Summary> =Table 3: DALC v1.0: Distribution of Train, Dev, and
5 Baselines
Testsplitsforexplicitnessandtarget. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1373>


<Paper ID = 1374> <Table 0> <Abstractive Summary> =Fol-
lowing these strategies, we made a pool of com-
Table 2: Different orthographic forms of writing the
ments and posts from the sources in social media
text“madwitch”
thathavehigherchancesofcontaininghatespeech. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1374>


<Paper ID = 1374> <Table 1> <Abstractive Summary> =Weusethefollowingmappingstonor- B 0.79 0.92 0.85 0.83 0.60 0.69
C 0.79 0.92 0.85 0.81 0.60 0.69
malizethecharactervariants: (cid:1373)->(cid:1374),◌(cid:1324) ->◌(cid:1325) ,स-> D 0.79 0.93 0.85 0.83 0.61 0.70
श,ष->श,व->ब,उ->ऊ,◌(cid:1354) र(cid:1222)->◌(cid:1326) ,◌(cid:1354) (cid:1291)र->◌(cid:1354) र(cid:1222),इ->ई,
Table 5: Effect of prepossessing techniques and
◌(cid:1260) ->◌(cid:1281) ,न->ण,◌(cid:1260) ->ङ(cid:1354) . </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1374>


<Paper ID = 1374> <Table 2> <Abstractive Summary> =kitab ->
Table 6: Binary classiﬁcation using different machine
(cid:1292)कताव) but we found that converting Devanagari
learningmodels. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 1374>


<Paper ID = 1377> <Table 0> <Abstractive Summary> =>1 250 2 63.07% 70.81
Dumbassn****don’trealizeyouactuallyhavetoworkyour
Table 2: Annotators’ averaged accuracy and agreement
assoffonafarm. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1377>


<Paper ID = 1377> <Table 1> <Abstractive Summary> =in this paper is a list of 77 SGTs (see Appendix),
Table 1: Sample stereotypical sentences from Gab, for compiled from Dixon et al. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1377>


<Paper ID = 1377> <Table 2> <Abstractive Summary> =inwhichsubstitute(x,S)createsthesetofallper- We preferred expert annotators over novice
turbedinstancebysubstitutingtheSGTinx,with codersinthisspeciﬁccase,becausepreviousstud-
94GHC Storm
Hate EOO CTF Hate EOO CTF
F1(↑) TP(↓) TN(↓) FPR(↓) DC(↓) SC(↓) F1(↑) TP(↓) TN(↓) FPR(↓) DC(↓) SC(↓)
BERT 73.30±.2 38.3 23.0 6.6 2.22 1.99 78.52±.2 40.8 25.3 11.5 0.96 1.16
MASK 71.24±.2 39.0 20.3 2.5 1.78 1.99 70.91±.2 43.4 25.9 8.3 0.96 1.16
CLP+SG 62.10±.2 38.4 23.2 0.2 0.97 2.24 80.31±.2 41.8 25.4 9.8 0.71 1.06
CLP+Rand 66.45±.2 41.3 20.4 2.7 0.98 1.24 80.62±.2 43.7 25.8 1.6 0.83 0.99
CLP+GV 68.50±.2 38.3 23.0 3.1 1.01 1.25 79.28±.2 40.7 30.6 3.4 0.76 0.93
CLP+NEG 70.02±.2 39.6 20.1 7.7 0.76 1.98 77.62±.2 42.5 26.2 5.0 0.56 0.98
CLP+ACL 73.31±.2 37.5 20.5 2.4 0.75 0.87 81.99±.2 42.8 23.1 2.0 0.42 0.53
Table 3: Results on GHC and Storm. </Abstractive Summary> <Extractive Summary> Table 2 demonstrates
pendontheADJssosmallervaluesofCTFarein-
accuracyandagreementscoresofannotators.  </Extractive Summary>  </Table 2>  </Paper ID = 1377>


<Paper ID = 1377> <Table 3> <Abstractive Summary> =100Non-hateSample HateSample
(Gargetal.,2019) AllCounterfactuals NoCounterfactuals
Issues Adding noisy synthetic data into Not supporting fairness for speciﬁc
the model since SGTs cannot inter- SGTswithhighassociationwithhate
changeablyappearinallcontexts speech(Dixonetal.,2018)
Currentapproach Counterfactualswithhigherlikelihood
Improvement Preventing counterfactuals with Equalizing outputs for current in-
lower sentence likelihood, that can stancesandtheirmorestereotypical
benoisyinstances counterfactuals
Table 4: The through comparison of the proposed approach with Garg et al. </Abstractive Summary> <Extractive Summary> Table 3 shows the results of these ex- ({OSDI}16),pages265–283.  </Extractive Summary>  </Table 3>  </Paper ID = 1377>


<Paper ID = 1379> <Table 0> <Abstractive Summary> =92.5 89.2 7.4 98.9 85.7 97.5 64.4 92.5 16.0
% 0.1 0.7 1.0 0.0 0.0 0.0 1.4 0.1 0.4
3 DataMaps-Hard 92.60.1 89.50.4 6.30.9 98.80.0 85.70.0 97.40.0 62.01.1 92.60.1 13.70.2
3
DataMaps-Easy 91.9 86.8 5.9 98.9 83.3 97.2 60.3 91.9 19.5
0.2 0.6 0.7 0.0 3.4 0.1 3.8 0.2 2.8
Ours(RoBERTa-base)
Vanilla 91.7 90.1 8.4 98.6 81.0 97.0 63.4 95.9 16.9
0.1 0.3 0.4 0.0 3.4 0.0 1.4 0.2 1.0
lexicalremoval 90.9 86.0 18.3 98.1 78.6 96.4 61.7 95.1 18.7
0.0 0.7 1.5 0.1 0.0 0.0 0.2 0.1 0.6
InvRat(lexical) 91.0 85.5 3.4 97.5 76.2 97.2 61.1 95.0 19.6
0.5 1.6 0.6 1.0 3.4 0.2 1.5 0.5 1.0
InvRat(dialect) 91.0 85.9 3.4 97.6 71.4 97.1 57.9 93.1 14.0
0.1 0.7 0.5 0.5 5.8 0.1 2.2 1.0 1.2
Table 1: Evaluation of all debiasing methods on the Founta et al. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1379>


<Paper ID = 138> <Table 0> <Abstractive Summary> =1746RankingModel Model P@1 R10@1 R10@2
RankingModel 0.400 0.253 0.416
SMN 0.446 0.281 0.452
Transformers
MSN 0.507 0.321 0.508
SA-BERT 0.514 0.330 0.531
RankingModel 0.377 0.227 0.393
SMN 0.438 0.273 0.441
BiLSTM
MSN 0.491 0.313 0.487
SA-BERT 0.507 0.323 0.513
RankingModel 0.437 0.275 0.443
SMN 0.451 0.279 0.457
BERT-base
MSN 0.507 0.323 0.507
SA-BERT 0.511 0.329 0.535
Table 5: Comparisons of different ranking model ar-
chitectures. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 138>


<Paper ID = 1380> <Table 0> <Abstractive Summary> =Model BOW TF-IDF BERT Class Precision Recall F Support
1
LogisticRegression 0.4289 0.4472 0.4202 Far-left 0.59 0.40 0.48 215
NaiveBayes 0.4304 0.4021 0.4188 Centre-left 0.34 0.38 0.36 1,159
RandomForest 0.3980 0.4258 0.4320 Centre 0.31 0.23 0.27 1,349
EasyEnsemble 0.3811 0.3798 0.3646 Centre-right 0.51 0.55 0.53 1,754
Far-right 0.46 0.58 0.51 671
Total 0.44 0.43 0.43 5,148
Table5: Accuracyfordifferentfeaturesandclassiﬁca-
tionmethods Hyperpartisan 0.56 0.81 0.66 886
Non-hyperpartisan 0.96 0.87 0.87 4262
Total 0.76 0.84 0.79 5,148
Model BOW TF-IDF BERT
LogisticRegression 0.3132 0.2621 0.3389 Table 7: Experimental results for TF-IDF+Random
NaiveBayes 0.4243 0.2234 0.3637 Forest, per class for political bias and hyperpartisan
RandomForest 0.4007 0.4303 0.3836 classiﬁcation. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1380>


<Paper ID = 1381> <Table 0> <Abstractive Summary> =Recall F1 Model Acc(%) BLEU PPL
LR 0.875 0.980 0.897 0.883 StyleEmb 87.41 2.27 615.59
SVM 0.801 0.979 0.851 0.818 RetrieveOnly 97.77 3.83 241.04
BERT 0.977 0.967 0.974 0.970 DeleteRetrieve 81.35 23.81 857.19
RoBERTa 0.977 0.971 0.973 0.971 LingST 93.00 3.16 63.03
XLNet 0.978 0.970 0.973 0.972 Tag&Gen 30.17 85.40 637.39
Table3:AutomaticEvaluationresultsofStyleTransfer
Table 2: Automatic Evaluation Results of Classiﬁca-
modelsonthedataset
tionmodelsonthedataset
Model DOC Fluency
Thishasrecentlybeenutilizedforthepolite- Input 1.116 4.648
nesstransfertask. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1381>


<Paper ID = 1381> <Table 1> <Abstractive Summary> =Forthestyletransferexperiments,weevaluate Table 4: Human Evaluation results of Style Transfer
theperformanceonthreedifferentaspects,follow- modelsonthedataset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1381>


<Paper ID = 1382> <Table 0> <Abstractive Summary> =5, the larger the difference between the tox- Table 2: Mean Squared Error (MSE), Mean Abso-
icity scores of OC and IC annotators, hence the lute Error (MAE), Area Under Precision-Recall curve
largerthedifferencebetweenthe(OC)groundtruth (AUPR), and ROC AUC of all context sensitivity esti-
mation models. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1382>


<Paper ID = 1384> <Table 0> <Abstractive Summary> =4https://developer.twitter.com/en/
developer-terms/agreement-and-policy
159Table 1: Datasets currently included in the toxic comment collection (sorted by year of publication). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1384>


<Paper ID = 1386> <Table 0> <Abstractive Summary> =Thus, the importance
annie(6),feminism(5),bitch(5),produc- hamas(10),salon(9),jesus(9),hadith(8),
of variables for target detection is the following:
ers(4),football(4),femalecomedians(4), woman(7), prophet mohammed(7),
guys(4),gender(4) men(6),christians(6) nominaltargetcandidate>propernametargetcan-
Table 2: Concepts with the highest TF over the refer- didate>targetcandidatecomprisesentirewords
enceset,whichappearinthegrammaticalsubjectposi- >positionofthecandidateinp. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1386>


<Paper ID = 1386> <Table 1> <Abstractive Summary> =Thesecondbaselineidentiﬁesanoun
185Accuracy ROUGE-L Accuracy ROUGE-L
Algorithm Jaccard Partial Exact P R F1 Algorithmsetup Jaccard Partial Exact P R F1
index match match index match match
Targets(dev) w/olearningtargetswithrefer- 0.16 0.21 0.14 0.18 0.16 0.16
Baseline1-ﬁrstnounasa 0.1 0.08 0.08 0.11 0.1 0.10 encesetandw/otf*idffornomi-
target nalsandα1=0
Baseline2-nounwithahyper- 0.28 0.34 0.24 0.34 0.29 0.3 w/olearningtargetswithrefer- 0.38 0.49 0.36 0.43 0.39 0.39
nym“person”/“group” encesetandw/otf*idfforadjec-
GetTAPair(Tref,p,(cid:126)abest,(cid:126)vbest) 0.68 0.79 0.65 0.74 0.7 0.7 tival/pastparticiplegroups
Targets(test) w/olearningtargetswithrefer- 0.38 0.49 0.36 0.44 0.39 0.4
BERT-ﬁne-tunedonthedevset 0.58 0.76 0.45 0.65 0.67 0.63 enceset
GetTAPair(Tref,p,(cid:126)abest,(cid:126)vbest) 0.63 0.74 0.57 0.7 0.66 0.66 w/ousingsubjectpositioninref- 0.55 0.67 0.53 0.61 0.57 0.57
GetTAPair(Tref,p,(cid:126)abest,(cid:126)vbest) 0.63 0.82 0.49 0.69 0.74 0.68 erencesetfortf
+BERT w/targetexpanding(α5=1)and 0.59 0.76 0.52 0.64 0.69 0.63
Aspects(dev) w/otfandα2=0
GetTAPair(Tref,p,(cid:126)abest,(cid:126)vbest) 0.39 0.64 0.18 0.51 0.54 0.45 w/targetexpanding(α5=1)and 0.6 0.76 0.53 0.65 0.69 0.64
Aspects(test) w/otfandα4=0
BERT-ﬁne-tunedonthedevset 0.34 0.67 0.11 0.5 0.45 0.42 w/targetexpanding(α5=1)and 0.61 0.75 0.55 0.65 0.69 0.64
GetTAPair(Tref,p,(cid:126)abest,(cid:126)vbest) 0.29 0.62 0.11 0.44 0.41 0.36 w/otfandα3=0
GetTAPair(Tref,p,(cid:126)abest,(cid:126)vbest) 0.36 0.74 0.12 0.48 0.55 0.45 w/oallsubwords 0.63 0.73 0.6 0.69 0.64 0.64
+BERT w/onominalsubwords 0.63 0.74 0.61 0.7 0.65 0.65
w/targetexpanding(α5=1)and 0.63 0.79 0.57 0.68 0.71 0.66
Table 3: Evaluation of the quality of the detected tar- w/otf
w/targetexpanding(α5=1) 0.63 0.79 0.56 0.68 0.73 0.67
getsandaspectsonthedevelopmentandtestset GetTAPair(Tref,p,(cid:126)abest,(cid:126)vbest) 0.68 0.79 0.65 0.74 0.7 0.7
Table 4: Evaluation of the quality of the detected tar-
getsduringﬁne-tuningonthedevelopmentset
withahypernympersonorgroupthatisarelevant
candidate entity according to the deﬁnition of a
target. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1386>


<Paper ID = 1386> <Table 2> <Abstractive Summary> =Table 5: Evaluation of target detection on Dong et al. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 1386>


<Paper ID = 1387> <Table 0> <Abstractive Summary> =To harmonise
Table 3: Distribution of comments containing at least
thedeﬁnitionsandcomparethedatadistributions,
onetermfromHatebase
we consider that the following classes match our
deﬁnition of abuse: tweets labelled as hateful on
ALYT has a low prevalence of Hatebase key-
HSOL;sexistorracistonHSHP;andoffensiveand
words, with a distribution similar to HSHP and
targetedonOLID.Table2presentsthedistribution
OLID.Thisresultshowsthattheabusivecontent
ofabusivecontentoneachdataset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1387>


<Paper ID = 1387> <Table 1> <Abstractive Summary> =Total 11.42% 85.98% 2.61%
Topic # α Majority Grouped
VG 9.19% 38.02% 22.16%
All 300 73.8 64.3% 92.3% GI 76.17% 28.55% 51.83%
WD 14.64% 33.44% 26.01%
VG 134 64.9 88.1% 98.5%
GI 135 55.2 44.4% 84.4% Ofﬁcial 67.81% 47.99% 64.74%
WD 31 24.0 48.4% 100% Personal 17.46% 33.03% 21.39%
Reaction 14.73% 18.98% 13.87%
Ofﬁcial 76 60.0 50.0% 90.8%
Personal 179 77.9 76.5% 95.0%
Table5: Distributionofclassesinthedatasetpercate-
Reaction 45 47.3 40.0% 84.4%
gory
Table 4: Inter-annotator agreement metrics per cate-
gory samplesanddidnotbalancethedataaccordingto
content,thesecommentspotentiallyrepresentthe
Theoverallvalueofalphaindicatessubstantial actual distribution. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1387>


<Paper ID = 1388> <Table 0> <Abstractive Summary> =Fine-grainedattributes train dev unseen dev seen test seen
dehumanizing 1318 104 121 209
inferiority 658 35 49 102
inciting violence 407 23 26 68
Attacktype mocking 378 29 35 84
contempt 235 6 10 21
slurs 205 4 6 10
exclusion 114 8 13 12
religion 1078 77 95 166
race 1008 63 78 169
Protectedcategory sex 746 46 56 82
nationality 325 20 26 42
disability 255 17 22 63
Table 3: Distribution of attack types and protected characteristics on the “hateful” subset of the hateful memes
datasetinTable1
System TaskA-protectedcategory TaskB-attacktype
MajorityBaseline 0.70 0.72
VisualBERTBaseline 0.864 0.873
LTL-UDE1 0.912 -
LTL-UDE2 0.914 -
QMUL 0.901 0.913
SU1 0.876 0.881
SU2 0.865 0.89
Table4: Overallresultsfromthesharedtasksubmissionsontheblindtestsetpartition
203dataset (Lin et al., 2014). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1388>


<Paper ID = 1389> <Table 0> <Abstractive Summary> =DISABILITY+SEX 36 4 0.4
NATIONALITY+RACE 52 2 0.6
NATIONALITY+RELIGION 20 1 0.2
1 Introduction
DISABILITY+RACE 16 1 0.2
In this work, we present our submission to the Other 56 3 0.5
Shared Task on Hateful Memes at WOAH 2021: Total 8,500 640 100
WorkshoponOnlineAbuseandHarms.1 Detecting
Table 1: Overview of categories in WOAH 2021 data
hatefulmemesthatcombinevisualandtextualele-
set. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1389>


<Paper ID = 1389> <Table 1> <Abstractive Summary> =NONE F1 AUROC AUROC
Baseline * .71 .84 .75 .84 .70 .78 .62 .85
+W .79 .86 .87 .90 .92 .71 .64 .91
+W,RG – .81 .87 .91 .91 .85 .80 .70 .92 .912
+W,E .77 .85 .90 .89 .77 .75 .68 .91
+W,RG,E .76 .89 .91 .94 .81 .79 .70 .92 .914
U|+W * .81 .87 .90 .90 .91 .71 .60 .87
U|+W,RG * .83 .88 .90 .91 .87 .74 .62 .90
I|+W .79 .86 .89 .93 .91 .74 .67 .91
I|+W,RG .81 .86 .91 .88 .88 .77 .68 .92
T|+W .75 .82 .90 .84 .83 .76 .70 .91
T|+W,RG .75 .86 .86 .91 .83 .78 .70 .90
IT|+W * .72 .80 .89 .81 .87 .75 .70 .88
IT|+W,RG * .77 .88 .83 .79 .84 .77 .68 .90
Ensemble .75 .89 .92 .93 .79 .80 .71 .92
Table 2: Classiﬁcation results of hateful memes target (protected groups) classes on provided development data
set. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 1389>


<Paper ID = 139> <Table 0> <Abstractive Summary> =Training Test
#Sentences #DPs #Sentences #DPs
SPDPR 35,933 28,052 4,346 3,539
TC 6,734 5,090 1,122 774
Zhidao 7,970 5,097 1,406 786
Table 4: Statistics of training and test sets on three
conversationaldatasets. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 139>


<Paper ID = 1391> <Table 0> <Abstractive Summary> =Todothatwe Txt+ImgRAC 0.712 0.796
combinedTxtBERTandImgBERTwithMNNre- Ensemble 0.765 0.863
trievalandcallthetwonewmethodsTxtRACand
Table 1: Micro F1 and ROC AUC scores of our mod-
Txt+ImgRACrespectively. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 1391>


<Paper ID = 14> <Table 0> <Abstractive Summary> =BeliefState=Predicted BeliefState=Predicted
Source 21.1 28.6 25.2 59.6 48.7 36.6 Source 46.0 55.4 34.3 22.0 26.6 19.9 34.0
Naive 46.7 56.2 66.1 68.5 66.3 60.8 Naive 57.2 69.2 65.0 40.3 36.0 42.8 51.7
EWC 56.7 58.2 71.6 69.3 78.7 66.9 EWC 57.4 72.1 66.1 43.7 39.0 45.0 53.9
Naive+RL 57.0 66.8 72.5 72.3 75.4 68.8 Naive+RL 63.2 74.4 68.4 47.4 42.7 48.7 57.5
EWC+RL 64.6 67.8 75.8 71.6 87.6 73.5 EWC+RL 64.7 77.6 67.6 46.6 43.2 48.5 58.0
BeliefState=Oracle BeliefState=Oracle
Source 33.2 40.1 34.3 70.7 55.4 46.7 Source 82.3 93.3 76.2 36.8 55.4 42.4 64.4
Naive 85.6 84.2 77.9 96.7 93.4 87.5 Naive 88.8 98.4 85.9 72.2 79.8 76.7 83.6
EWC 84.1 85.1 89.8 101.7 97.5 91.6 EWC 95.5 96.9 89.6 70.0 81.5 79.6 85.5
Naive+RL 97.6 99.2 88.5 104.0 103.4 98.5 Naive+RL 99.7 104.3 92.0 80.6 97.2 89.3 93.9
EWC+RL 97.5 100.7 96.0 104.9 106.3 101.1 EWC+RL 100.2 103.0 93.9 82.6 95.0 89.2 94.0
Table 5: Combined scores in domain adaptation. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 14>


<Paper ID = 14> <Table 1> <Abstractive Summary> =Wesetthediscountingfactorγ to
Table 13: Error analysis on dialogue system on each
1. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 14>


<Paper ID = 14> <Table 2> <Abstractive Summary> =Table 10: The conﬁguration of turn-level rewards for
Model Restaurant Hotel Attraction Train Taxi Average
each best model in the reported benchmark results. </Abstractive Summary> <Extractive Summary> The
in Table 2 when using predicted belief state, and rest of the dialogues, not involving the hotel do-
canfurtheroutperformthepreviousworkinTable3 main, form the source data.  </Extractive Summary>  </Table 2>  </Paper ID = 14>


<Paper ID = 14> <Table 3> <Abstractive Summary> =SL 514 726 545 513 774 614
RL 1458 1666 1087 601 2313 1425
Averageofdialogueactionsperstate
A.2 DetailsofDataset
SL 3.51 3.10 3.74 3.70 2.65 3.34
RL 4.92 5.49 7.61 7.98 5.10 6.22
Asnotedinthepaper,wefollowtheoriginalsplit
of the MultiWOZ dataset and the number of dia- Table 15: Number of dialogue states and average of
dialogue actions per state in each domain adaptation
logues for train/dev/test split is 8420/1000/1000. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 14>


<Paper ID = 14> <Table 4> <Abstractive Summary> =Numberofdialoguestates
SL 250 184 118 263 352 172 223
RL 523 294 208 348 636 383 399
Data Restaurant Hotel Attraction Train Taxi Averageofdialogueactions
Train 300 300 300 300 300 SL 2.84 3.95 5.40 3.00 2.43 4.05 3.61
Dev 438 415 400 484 206 RL 6.98 13.56 17.90 21.03 11.30 21.20 15.33
Test 437 394 396 495 195
Table16: Numberofdialoguestatesandaverageofdi-
Table 11: Number of dialogues of the splits in each alogueactionsperstateineachsingle-to-multidomain
domainadaptation case. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 4>  </Paper ID = 14>


<Paper ID = 14> <Table 5> <Abstractive Summary> =Data H+T R+T A+T A+H+X H+R+X A+R+X
Train 100 100 100 100 100 100
Dev 149 157 148 110 100 131
Test 144 155 163 92 91 129
Table 12: Number of dialogues of the splits in each
scenarioinsingle-to-multidomaintransferlearning. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 5>  </Paper ID = 14>


<Paper ID = 14> <Table 6> <Abstractive Summary> =BeliefState=Predicted
Source 5.0 10.9 5.4 36.2 0.0 11.5
Naive 26.4 35.8 41.0 48.0 35.0 37.2
EWC 35.9 37.8 47.6 47.7 55.2 44.9
Naive+RL 36.8 46.0 46.2 49.8 41.4 44.1
EWC+RL 42.3 47.7 51.9 48.5 63.9 50.8
BeliefState=Oracle
Source 11.8 18.6 9.1 45.3 0.0 17.0
Naive 60.7 62.1 46.8 73.9 67.2 62.1
EWC 59.3 62.4 64.5 79.5 74.5 68.0
Naive+RL 73.1 76.2 58.5 82.6 81.4 74.4
EWC+RL 73.3 79.3 70.5 82.8 84.6 78.1
Table 17: Success rate in domain adaptation. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 6>  </Paper ID = 14>


<Paper ID = 14> <Table 7> <Abstractive Summary> =BeliefState=Predicted
Source 30.8 40.7 15.1 5.1 8.8 4.9 17.6
Naive 40.7 48.8 37.8 16.3 15.8 19.9 29.9
EWC 41.0 50.5 42.3 19.6 17.2 20.4 31.8
Naive+RL 47.2 53.8 42.9 18.1 22.0 24.0 34.7
EWC+RL 45.8 57.9 44.6 20.7 20.2 24.6 35.6
BeliefState=Oracle
Source 60.4 74.6 41.3 13.4 28.2 19.9 39.6
Naive 67.1 76.6 54.4 48.2 53.9 46.3 57.7
EWC 74.5 78.1 60.3 43.8 57.9 50.4 60.8
Naive+RL 79.6 83.4 60.3 57.3 68.1 60.2 68.2
EWC+RL 79.2 84.5 66.1 55.4 70.0 61.5 69.4
Table 18: Success rate in single-to-multiple domain
transfer where 100 dialogues on each target scenario
areusedforadaptation. </Abstractive Summary> <Extractive Summary> Theresultsshown
Results in the form of the combined score are
in Table 7 are averaged over the ﬁve adaptation
giveninTable6(refertoAppendixA.5forsuccess
domains6.  </Extractive Summary>  </Table 7>  </Paper ID = 14>


<Paper ID = 140> <Table 0> <Abstractive Summary> =371 267 330
Testset(Bothinsupport) 110.8K
Causeofdeath 314 246 299
Testset(Missingsupport) 38.3K
Table 6: Link Prediction results for COVID-19 case
Table3: Few-shotLinkPredictiondatasetstatistics. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 140>


<Paper ID = 140> <Table 1> <Abstractive Summary> =We use the March 2020
TransE(Full) 213
Wikidata and December 2020 Wikipedia to train
Table 5: Results for Missing Support Test Set (Few- the alignment models and do link prediction on
shotLinkPredictiontask). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 140>


<Paper ID = 141> <Table 0> <Abstractive Summary> =WeightedPartialWSL† 76.28 76.34 76.31
RobustWSL 66.71 42.78 52.13
4.3.3 ExtensiontoMultilingualNER
Theproposedframeworkcanbenaturallyextended
Table 2: Main Results on E-commerce English Query
to improve multilingual NER. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 141>


<Paper ID = 141> <Table 1> <Abstractive Summary> =The weakly labeled data can hurt the model SST 77.42 75.21 77.82 78.10 78.65
performanceiftheyarenotproperlyhandled; WeaklysupervisedBaseline
•SST:Semi-supervisedself-trainingoutperforms WSL 58.35 59.90 60.98 61.66 63.14
the supervised baseline and weakly supervised
Table 4: E-commerce Multilingual Query NER: Span
baselines. </Abstractive Summary> <Extractive Summary> Table 1 also
Dataset
Train Dev Test Weak Precision Recall presents the precision and recall of weak labels
performance on a evaluation golden set.  </Extractive Summary>  </Table 1>  </Paper ID = 141>


<Paper ID = 141> <Table 2> <Abstractive Summary> =BERT -/-/89.99 -/-/79.92 -/-/85.87
BioBERT -/-/92.85 -/-/84.70 -/-/89.13
SciBERT -/-/92.51 -/-/84.70 -/-/88.25
PubMedBERT -/-/93.33 -/-/85.62 -/-/87.82
Re-implementedBaselines
BERT 88.55/90.49/89.51 77.54/81.87/79.64 83.50/88.54/85.94
BERT-CRF 88.59/91.44/89.99 78.70/81.53/80.09 85.33/86.67/85.99
BioBERT 92.59/93.11/92.85 82.36/86.66/84.45 86.75/90.83/88.74
BioBERT-CRF 92.64/93.28/92.96 83.73/86.80/85.23 87.18/91.35/89.22
BasedonBioBERTandCRFlayer
SST 92.40/93.74/93.06 84.01/87.18/85.56 87.00/91.98/89.42
WSL 82.17/88.91/85.41 90.72/87.27/88.96 87.14/71.98/78.84
NEEDLEw/oWLC/NAL 92.85/93.31/93.08 91.37/88.34/89.83 91.68/91.77/91.73
NEEDLEw/oFT/NAL 79.29/84.38/81.75 82.44/94.03/87.85 87.17/90.62/88.86
NEEDLEw/oNAL 92.93/94.28/93.60 86.73/93.69/90.07 91.82/92.40/92.11
NEEDLEw/oFT 79.87/84.31/82.03 82.39/94.12/87.86 87.31/91.04/89.14
NEEDLE 92.89/94.60/93.74 87.99/93.56/90.69 91.76/92.81/92.28
Table 9: Main Results on Biomedical NER: Span Precision/Recall/F1. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 141>


<Paper ID = 141> <Table 3> <Abstractive Summary> =En Fr It De Es
mBERT-CRF(Single) 83.26/76.80/61.68 80.27/72.91/57.48 83.70/78.13/60.75 79.53/76.38/60.72 83.58/77.56/59.64
mBERT-CRF 83.37/76.97/62.21 81.43/74.92/60.35 84.31/78.06/60.65 80.48/76.82/62.47 84.94/78.23/61.44
Query-mBERT-CRF 84.15/77.85/63.44 81.36/74.91/60.17 84.83/78.46/61.26 80.93/77.40/62.81 85.20/78.27/62.12
BasedonQuery-mBERTandCRFlayer
SST 84.18/78.02/63.57 81.66/75.12/60.92 84.45/78.13/60.89 81.26/77.72/63.61 85.35/78.56/62.90
WSL 54.40/47.43/28.97 59.11/51.08/32.85 59.79/50.59/30.75 56.16/51.16/33.59 61.36/53.29/32.48
NEEDLEw/oWLC/NAL 84.42/78.12/64.43 81.65/75.24/60.74 84.76/78.65/61.77 81.32/77.59/63.37 84.82/78.84/61.95
NEEDLEw/oNAL/FT 83.46/75.80/57.93 81.20/73.04/56.90 83.48/75.97/57.22 80.31/76.00/60.79 83.90/76.80/59.30
NEEDLEw/oNAL 84.63/78.42/64.76 82.34/75.83/61.91 85.34/79.63/63.17 81.68/77.90/64.34 85.64/79.48/63.41
NEEDLEw/oFT 83.50/75.76/58.01 80.92/73.38/57.34 83.45/76.03/57.39 80.48/76.31/61.22 84.10/76.97/60.12
NEEDLE 84.74/78.59/64.86 82.14/75.80/61.96 85.65/80.12/63.71 81.79/78.15/64.84 86.00/79.80/64.03
Table 11: E-commerce Multilingual Query NER: Span Precision/Recall/F1 and Token/Span/Query level Accu-
racy. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 141>


<Paper ID = 142> <Table 0> <Abstractive Summary> =children
Finkelsteinsaysheexpectsthecompanyto“beneﬁtfromsomeof company,business,companies,
thedisruptionfacedbyourcompetitors andanyother[MASK].” group,investors
Table 1: Examples of constructed BERT MLM inputs for obtaining weak entity typing labels. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 142>


<Paper ID = 142> <Table 1> <Abstractive Summary> =For example, denoising the automati- H especiallyM 11.5
cally generated labels (Ren et al., 2016), taking
Table 2: Hypernym extraction patterns. </Abstractive Summary> <Extractive Summary> We show the performance of our method for
Consider the ﬁrst sentence in Table 1 as an ex- obtaining 10 type labels for each mention with
ample: “Inlate2015,LeonardoDiCapriostarred differentpatternsinTable2.  </Extractive Summary>  </Table 1>  </Paper ID = 142>


<Paper ID = 142> <Table 2> <Abstractive Summary> =Because
Ours(NoSelf-train) 53.5 42.8 47.5
the techniques employed in Ours (No Self-train),
Ours 53.6 45.3 49.1
includingtheuseofmultiplehypernymextraction
Table 4: Performance of different variants of our ap- patterns and the weighted loss, are both for bet-
proach on the test set. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 142>


<Paper ID = 142> <Table 3> <Abstractive Summary> =Table 7: Performance of different approaches on
Hongliang Dai, Donghong Du, Xin Li, and Yangqiu
Ontonotes. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 142>


<Paper ID = 143> <Table 0> <Abstractive Summary> =1803#Train #Dev #Test #EntityLabels Avg.Length Avg.Lengthw/Context
WNUT-16 2,394 1,000 3,849 10 19.41 138.58
WNUT-17 3,394 1,009 1,287 6 18.48 139.49
CONLL-03 14,987 3,466 3,684 4 13.64 116.23
CONLL++ 14,987 3,466 3,466 4 13.64 116.23
BC5CDR 4,560 4,581 4,797 2 25.91 144.13
NCBI 5,424 923 940 1 25.01 135.76
E-COMMERCE 38,959 5,000 5,000 26 2.54 124.61
Table 1: Statistics of the dateset split, number of entity types and the average lengths with and without external
contexts. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 143>


<Paper ID = 143> <Table 1> <Abstractive Summary> =(2019) - - - - 89.93 - -
Bio-Flair(2019) - - - - 89.42 88.85 -
Bio-BERT(2020) - - - - - 87.70 -
Evaluation: W/OCONTEXT
LUKE(2020) 54.04 55.22 92.42 93.99 89.18 87.62 77.64
W/OCONTEXT 56.04 57.86 93.03 94.20 90.52 88.65 81.47
CL-L 57.35† 58.68† 93.08 94.38† 90.70† 89.20† 82.43†
2
CL-KL 58.14† 59.33† 93.21† 94.55† 90.73† 89.24† 82.31†
Evaluation: W/CONTEXT
W/CONTEXT 57.43† 60.20† 93.27† 94.56† 90.76† 89.01† 83.15†
CL-L 58.61† 60.26† 93.47† 94.62† 90.99† 89.22† 83.87†
2
CL-KL 58.98† 60.45† 93.56† 94.81† 90.93† 88.96† 83.99†
Table 2: A comparison among recent state-of-the-art models, the baseline and our approaches. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 143>


<Paper ID = 143> <Table 2> <Abstractive Summary> =(2019) 73.59 -
W/OCONTEXT 75.87 75.74 Table 5: A comparison of different re-ranking ap-
W/CONTEXT 75.72 75.94 proaches by the F1 scores on WNUT-17. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 143>


<Paper ID = 143> <Table 3> <Abstractive Summary> =Theapproach
hasbeenwidelyappliedinalotofpreviouswork
Table 4: A comparison between of CL approaches
(Guetal.,2018;Zhangetal.,2018;Hayatietal.,
withandwithoutsemi-supervisedlearning. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 143>


<Paper ID = 143> <Table 4> <Abstractive Summary> =Most of the work takes NER as
CL-L 58.68 60.26
2
CL-KL 59.33 60.45 a sequence labeling problem and applies the
linear-chainCRF(Laffertyetal.,2001)toachieve
Table 7: An ablation study of the training and predic-
state-of-the-art accuracy (Ma and Hovy, 2016;
tionofmodels. </Abstractive Summary> <Extractive Summary> Results in Table 4 show that the accuracy of 17inTable5.  </Extractive Summary>  </Table 4>  </Paper ID = 143>


<Paper ID = 143> <Table 5> <Abstractive Summary> =(2021a) 94.60
W/DOCCONTEXT 94.12
W/OCONTEXT 93.30
W/CONTEXT 93.55
CL-L 93.68
2
CL-KL 93.85
Table 8: A comparison of retrieved contexts and
document-level contexts. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 5>  </Paper ID = 143>


<Paper ID = 144> <Table 0> <Abstractive Summary> =0.4 64.9 11.3 74.5
(§4.2) nochange 0.0 62.7 9.73 74.1
noLM 0.0 32.4 1.77 81.8
ﬁrst - - 49.6 51.5 93.6 95.9
locality(§4.3)
last - - 55.1 58.6 96.5 97.6
Table 1: Probing results. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 144>


<Paper ID = 144> <Table 1> <Abstractive Summary> =Localizer T bed has-2-blue(beaker3) Table 2: Locality of information state in TextWorld
Em (T5). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 144>


<Paper ID = 144> <Table 2> <Abstractive Summary> =Wesamplearandom
Table 3: State EM for decoding each type of fact (re-
mapping remap between entities, and construct a lations vs. properties), with each type of probe (1- vs.
localizerablationinwhichwedecodepropositions 2-argumentdecoding). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 144>


<Paper ID = 144> <Table 3> <Abstractive Summary> =Inex-
Table 4: Results of intervention experiments. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 144>


<Paper ID = 145> <Table 0> <Abstractive Summary> =oneideallyexpectsequalpreferencesformaleand
femalecompletionsgivengender-ambiguouscon-
2.2 Probing
texts(forexample,giventhepromptu“Thenurse
A separate line of analysis work has investigated said that”, we want p(she|u) ≈ p(he|u)), this is
representations associated with syntactic depen- notthecaseforsubject-verbagreement,wherewe
denciesbydeﬁningafamilyoffunctions(probes) expectverystrongpreferencesforgrammatically
1829SimpleAgreement: Size Layers Embeddingsize Heads
Theathleteconfuses/*confuse
Distil 6 768 12
WithinObjectRelativeClause: Small 12 768 12
Thefriend(that)thelawyers*likes/like Medium 24 1024 16
Large 36 1280 20
XL 48 1600 25
AcrossOneDistractor:
Thekidsgently*admires/admire
Table 1: GPT-2 sizes used in this study. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 145>


<Paper ID = 145> <Table 1> <Abstractive Summary> =3 583
Perhaps the effects for Transformer-XL are
Table 3: Difference (cid:96) norms between the hypothesis smallerduetothelongereffectivecontextsithas,
1
matrixandeachlayerofDistilGPT-2. </Abstractive Summary> <Extractive Summary> Table 1 gives model
correctcompletionsoverincorrectcompletions.  </Extractive Summary>  </Table 1>  </Paper ID = 145>


<Paper ID = 146> <Table 0> <Abstractive Summary> =Table 1: Performance (AUC score for link prediction) Tenneyetal.,2019b;Wuetal.,2021)whichhave
onrestoringgraphswithgraphembeddings
foundthatunlikesyntax,semanticsisnotcaptured
wellbythepretrainedmodels. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 146>


<Paper ID = 147> <Table 0> <Abstractive Summary> =Theboxplot
WIKI-UNI 27.12 44.19 52.18 16.47
inFigure3showstheverysigniﬁcantcorrelation
Table 1: Average percentage of instances being cov- betweenthepredictiondistributionsonLAMAand
ered by top-k answers or predictions. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 147>


<Paper ID = 147> <Table 1> <Abstractive Summary> =Figure 4 shows Table 2: The smaller KL divergence between the
theboxplot. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 147>


<Paper ID = 147> <Table 2> <Abstractive Summary> =Absent
25.37 23.26 -2.11
Toshowthis,weintroduceanewmetricreferred (54.70%)
asin-typerank,whichistherankofthecorrectan-
Table 5: Comparison between prompt-based and
swerwithintheentitiesofthesametypeforaquery. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 147>


<Paper ID = 147> <Table 3> <Abstractive Summary> =Inconclusion,thereal
efﬁcacyofcontext-basedinferencecomesfromthe
Table 7: Comparison between prompt-based and
sufﬁcientanswerevidenceprovidedbythecontext,
context-based paradigms grouped by whether the
eitherexplicitlyorimplicitly. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 147>


<Paper ID = 147> <Table 4> <Abstractive Summary> =LAMA 23.93 42.02 50.08 -
Answer
To construct WIKI-UNI, we ﬁrst collect all the WIKI-UNI 1.84 5.53 8.61 -
tripleswhichbelongtothesame41relationswith LAMA 37.48 56.85 65.45 23.65
Prediction
WIKI-UNI 36.53 55.51 63.58 13.59
LAMA from Wikidata (Vrandecˇic´ and Kro¨tzsch,
2014),thenwerandomlysample50Ktripleswith
Table 8: The percentage of instances that the topk ob-
asingle-tokenobjectforeachrelation. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 4>  </Paper ID = 147>


<Paper ID = 147> <Table 5> <Abstractive Summary> =Table 9: Performance of the case-based analogy
paradigmforRoBERTa-large
Tman
Tmine 10% 25% 40% 55%
Tauto Overall
Rank
0.2 0.4 0.6 0.8 1.0
Figure7:Thecorrelationsofthepredictiondistribution In-type
onLAMAandWIKI-UNIforRoBERTa-large. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 5>  </Paper ID = 147>


<Paper ID = 147> <Table 6> <Abstractive Summary> =WithoutContexts FullContexts MaskedContexts
23.65 31.44 24.44
Table 11: The overall performance when introducing
differentcontextsforRoBERTa-large. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 6>  </Paper ID = 147>


<Paper ID = 147> <Table 7> <Abstractive Summary> =1873Precision Type Wrong→Right Right→Wrong
Relation InducedObjectType
∆ Prec.∆ w/TypeChange w/oTypeChange
religion religion 56.92 66.36 100.00 -
positionheld religiousservant 41.86 47.42 99.03 -
countryofcitizenship sovereignstate 37.16 74.11 100.00 -
memberof organization 31.03 77.83 100.00 -
continent continent 29.51 87.80 100.00 100.00
instrument musicalinstrument 28.26 6.04 94.04 0.00
countryoforigin sovereignstate 28.18 94.92 99.61 100.00
country sovereignstate 26.64 69.84 95.22 96.55
partof object 24.57 90.22 96.98 100.00
placeofdeath city 22.88 95.35 98.95 100.00
instanceof concreteobject 14.97 20.53 34.30 97.50
locationofformation city 14.12 99.88 100.00 -
subclassof object 12.07 26.25 63.31 90.00
capital city 10.62 36.31 92.19 85.71
namedafter physicalobject 10.25 85.05 100.00 100.00
languageofworkorname Indo-Europeanlanguages 9.10 26.72 89.12 72.17
haspart abstractobject 8.79 67.99 77.65 -
worklocation city 8.09 12.43 96.95 6.45
languagesspoken,writtenorsigned Indo-Europeanlanguages 5.09 17.75 54.20 86.90
employer business 3.97 10.31 19.05 100.00
positionplayedonteam/speciality position 3.26 56.51 71.43 75.00
nativelanguage Indo-Europeanlanguages 1.09 1.63 28.21 93.10
genre series 1.05 0.23 75.00 66.67
recordlabel recordlabel 0.00 -7.55 - -
placeofbirth city -0.13 41.02 66.67 100.00
twinnedadministrativebody city -0.45 1.04 0.00 100.00
headquarterslocation city -1.00 0.00 0.00 100.00
diplomaticrelation sovereignstate -1.16 1.05 25.00 100.00
ownedby organization -1.45 43.78 64.62 94.59
ﬁeldofwork knowledge -2.10 0.69 10.53 96.77
occupation profession -2.43 0.00 0.00 100.00
ofﬁciallanguage Nostraticlanguages -3.11 3.88 18.37 97.40
locatedintheadministrativeterritorialentity community -3.35 45.81 75.93 97.50
originallanguageofﬁlmorTVshow Nostraticlanguages -5.29 -21.30 15.38 34.29
sharesborderwith community -9.82 0.16 0.00 98.86
location community -11.49 27.15 41.43 100.00
developer enterprise -12.25 6.80 37.50 79.41
originalnetwork televisionstation -16.46 -15.84 14.29 72.49
appliestojurisdiction state -18.38 2.11 35.71 98.00
capitalof politicalterritorialentity -39.44 7.22 - 100.00
manufacturer business -49.63 6.79 44.44 93.82
Table 14: A detailed analysis of all relations using case-based analogy paradigm for RoBERTa-large, which is
correspondingtoTable4inthearticle.“-”indicatesthenumberofquerieswhosepredictionsarereversedcorrectly
ormistakenlyislessthan3. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 7>  </Paper ID = 147>


<Paper ID = 148> <Table 0> <Abstractive Summary> =Wefocus s r o
ConvE (cid:104)σ(vec(σ([e ,e ]∗Ω))W),e (cid:105)
r s o
on the task of link prediction using KGE models TransE −(cid:107)e +e −e (cid:107)
s r o
andconsidertheadversarialgoalofdegradingthe
Table 1: Scoring functions f of the KGE models
predictedrankoftargetmissingfacts. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 148>


<Paper ID = 148> <Table 1> <Abstractive Summary> =The DetermineAdversarialEntities n/a n/a Sft
sro
softtruthscoreforthegroundingofapatterncan
Table 2: A summary of heuristic approaches used for
thenbeexpressedthroughlogicalcomposition(e.g. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 148>


<Paper ID = 148> <Table 2> <Abstractive Summary> =We use the publicly available im-
Table 3: Statistics for the datasets WN18RR and FB15k- plementationandthedefaultattacksettings4. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 148>


<Paper ID = 148> <Table 3> <Abstractive Summary> =Table 6: MRR and Hits@1 results for original KGE
modelsonWN18RRandFB15k-237
Basedonthediscussionabove,theoverallcom-
putational complexity is O(tE) for symmetry at-
tacks and O(R2 +tE) for inversion attacks. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 148>


<Paper ID = 148> <Table 4> <Abstractive Summary> =The Table 7: MRR of KGE models trained on original
modelimplementationusesanif-statementforthe datasetsandpoisoneddatasetsfromtheattackinZhang
forwardpassconditionedontheinputbatchmode. </Abstractive Summary> <Extractive Summary> Weevaluatefourmodelswithvaryinginductive 4.1 Results
abilities-DistMult,ComplEx,ConvEandTransE;
Table 4 and 5 show the reduction in MRR and
ontwopubliclyavailablebenchmarkdatasetsfor
Hits@1 due todifferent attacks on the WN18RR
link prediction3- WN18RR and FB15k-237.  </Extractive Summary>  </Table 4>  </Paper ID = 148>


<Paper ID = 149> <Table 0> <Abstractive Summary> =Bad Seeds: Evaluating Lexical Methods for Bias Measurement
MariaAntoniak DavidMimno
CornellUniversity CornellUniversity
maa343@cornell.edu mimno@cornell.edu
Abstract TargetConcept HighlightedSeeds
Unpleasant divorce,jail,poverty,cancer,...
A common factor in bias measurement meth- AfricanAmerican Tanisha,Tia,Lakisha,Latoya,...
ods is the use of hand-curated seed lexicons, DomesticWork mom,mum,...
butthereremainslittleguidancefortheirselec-
Ugliness fat,chubby,obese,fatty,
tion.Wegatherseedsusedinpriorwork,docu- overweight,disformed,disﬁgured,
mentingtheircommonsourcesandrationales, wrinkle,wrinkled,...
and in case studies of three English-language
corpora, we enumerate the different types of
Table 1: Examples of real seed terms used in recent
socialbiasesandlinguisticfeaturesthat,once
worktomeasurebiasesincorpora. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 149>


<Paper ID = 150> <Table 0> <Abstractive Summary> =Morepapershavebeenpublished Table 2: Racial categories used by ACL Anthology
inrecentyears(2019-2020). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 150>


<Paper ID = 152> <Table 0> <Abstractive Summary> =To this end, we start from the concept of an 3https://pushshift.io/
1942Type TargetSet#1 TargetSet#2 AttributeSet#1 AttributeSet#2
jews,jewishpeople,jewish christians,christian greed*,meek,nerd*, generosity,conﬁdent,
Religion#1
mothers,judaism mothers,christianity, violin,hook-nose,... disciplined,spiritual,...
muslims,islamicpeople, christians,christian terrorist*,threat, nonviolence,safety,
Religion#2
islam,... people,christianity,... dangerous,criminal*,... defend,lawful,friend,...
blackpeople,africans, whitepeople,americans, violent,abuse,crash,drug peaceful,pure,clean,
Race
africanamericans caucasians dealer*,uncivilized,... pleasant,nice,...
women,mothers,daughter, men,fathers,boy,son, nurse,secretary, surgeon,executive,
Gender
girl,wife,niece nephew,husband housekeep*,... manager,...
gays,lesbians, straights,heterosexuals, mentallyill,ﬂamboyant, mentallystrong,modest,
Orientation
homosexuals,... monosexuals,... pedophile*,sin,... normal,moral,...
Table 1: REDDITBIAS bias speciﬁcations used in data collection, bias evaluation, and for debiasing. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 152>


<Paper ID = 152> <Table 1> <Abstractive Summary> =Since
Race 3,000 2,620 1,270 763 253 254 (t2,a1)
Gender 2,976 2,081 2,026 1,521 252 253 the reliability of such signiﬁcance may be nega-
Queerness 1,983 1,119 1,189 720 234 235 tivelyaffectedbyoutliers(PolletandvanderMeij,
2017), we ﬁrst reduce noise by removing pairs
Table 3: Number of annotated and biased instances
(i) (i)
in which either x or xˆ have very high
(commentsandphrases)inREDDITBIAS. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 152>


<Paper ID = 153> <Table 0> <Abstractive Summary> =The MultiAtis++ corpus (Xu
Table 1: Details of POS and NER datasets in our ex-
etal.,2020)isusedintheSFevaluationswithEN
periments. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 153>


<Paper ID = 153> <Table 1> <Abstractive Summary> =Ourgradient-basedmethodproperlyranksthe
Table 5: F-1 score differences from the full mBERT headsbytheirprioritytoprune. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 153>


<Paper ID = 153> <Table 2> <Abstractive Summary> =MD and SD perform comparably well in
EC 83.49 89.20 75.86 78.04 62.33
most cases so they are also promising heuristics
Table 6: Cross-lingual NER (upper) and POS (lower) forrankingattentionheadsunderthemulti-source
evaluation results with multiple source languages. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 153>


<Paper ID = 154> <Table 0> <Abstractive Summary> =In this work, we investigate veri-
Table 1: A real example of adversarial generation for
table evaluations of NMT adversarial attacks,
Googletranslationwithantonymsubstitution(i.e.,win
and propose a novel method to craft NMT
tolost)whichreversesthesemanticsonthesourcebut
adversarial examples. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 154>


<Paper ID = 154> <Table 1> <Abstractive Summary> =Table 2: Two examples of adversarial generation for RNNsearch based NMT model with synonym substitution. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 154>


<Paper ID = 154> <Table 2> <Abstractive Summary> =70.90 59.62 68.44 60.92 61.78 51.06 62.12
Table 3: Case-insensitive BLEU scores (%) for forward-translation (Zh→En), back-translation (En→Zh), and
round-triptranslation(Zh→En→Zh)onZh-Enlanguagepair. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 154>


<Paper ID = 154> <Table 3> <Abstractive Summary> =It
showsthatbothWSLSandGOGRcaneffectively
Table 4: Case-insensitive BLEU scores (%) of BPE-
attackvariousNMTmodelsunderthestandardof
Transf. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 154>


<Paper ID = 154> <Table 4> <Abstractive Summary> =at- Table 8: Reconstruction quality on Baidu and Bing
tackedbyvariousmethodsonWMT19testsets. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 4>  </Paper ID = 154>


<Paper ID = 154> <Table 5> <Abstractive Summary> =8.23 66.03 96.24 Onthecharacterlevel,afewadversarialattacks
bymanipulatingcharacterperturbationshavebeen
Table 7: The ablation study on Transf. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 5>  </Paper ID = 154>


<Paper ID = 155> <Table 0> <Abstractive Summary> =∩ 82.50 82.35 77.06 52.58 77.51
100%
φ 81.89 82.15 76.97 52.68 78.01
Two-stagedistillation Wenowvalidatewhether
thesecond-stagedistillation(distillationbymodel Table 5: Analysis of distillation on XNER. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 155>


<Paper ID = 155> <Table 1> <Abstractive Summary> =From the ﬁg-
ure,itisevidentthattheuseofconﬁdencepenalty
Table 7: Some additional baseline results on XNER
task.Here,ensreeferstoemsemble. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 155>


<Paper ID = 156> <Table 0> <Abstractive Summary> =Thenweuseapre-trained
1996WMT14 WMT16
Models Idec EN-DE DE-EN EN-RO RO-EN SpeedUp
Transformer(Vaswanietal.,2017) T 27.30 / / / /
ATModels
Transformer(ours) T 27.48 31.27 33.70 34.05 1.0×†
NAT-IR(Leeetal.,2018) 10 21.61 25.48 29.32 30.19 1.5×
LaNMT(Shuetal.,2020) 4 26.30 / / 29.10 5.7×
IterativeNAT LevT(Guetal.,2019) 6+ 27.27 / / 33.26 4.0×
Mask-Predict(Ghazvininejadetal.,2019) 10 27.03 30.53 33.08 33.31 1.7×
JM-NAT(Guoetal.,2020b) 10 27.31 31.02 / / 5.7×
NAT-FT(Guetal.,2018) 1 17.69 21.47 27.29 29.06 15.6×
Mask-Predict(Ghazvininejadetal.,2019) 1 18.05 21.83 27.32 28.20 /
imit-NAT(Weietal.,2019) 1 22.44 25.67 28.61 28.90 18.6×
NAT-HINT(Lietal.,2019) 1 21.11 25.24 / / /
Flowseq(Maetal.,2019) 1 23.72 28.39 29.73 30.72 1.1×
NAT-DCRF(Sunetal.,2019) 1 23.44 27.22 / / 10.4×
NAT-CTC(Libovicky`andHelcl,2018) 1 16.56 18.64 19.54 24.67 /
w/CTC
Imputer(Sahariaetal.,2020) 1 25.80 28.40 32.30 31.70 18.6×
FullyNAT
NAT-FT+NPD(m=100) 1 19.17 23.20 29.79 31.44 2.4×
imit-NAT+NPD(m=7) 1 24.15 27.28 31.45 31.81 9.7×
w/NPD NAT-HINT+NPD(m=9) 1 25.20 29.52 / / /
Flowseq+NPD(m=30) 1 25.31 30.68 32.20 32.84 /
NAT-DCRF+NPD(m=9) 1 26.07 29.68 / / 6.1×
NAT-base† 1 20.36 24.81 28.47 29.43 15.3×†
CTC† 1 25.52 28.73 32.60 33.46 14.6×†
Ours GLAT 1 25.21 29.84 31.19 32.04 15.3×†
GLAT+CTC 1 26.39 29.54 32.79 33.84 14.6×†
GLAT+NPD (m=7) 1 26.55 31.02 32.87 33.51 7.9×†
Table 1: Results on WMT14 EN-DE/DE-EN and WMT16 EN-RO/RO-EN benchmarks. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 156>


<Paper ID = 156> <Table 1> <Abstractive Summary> =It is shown that the point of
199832 SamplingNumber λ BLEU
31 0.0 24.66
0.1 24.91
30
Fixed 0.2 27.12
BLEU29 WWMMTT1144  DENE--DENE 0.3 24.98
0.4 22.96
28
Adaptive - 29.61
27
26 Table 3: Performances on IWSLT16 with ﬁxed sam-
1 2 3 4 5 6 7 8
Decoding Iterations plingratio. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 156>


<Paper ID = 156> <Table 2> <Abstractive Summary> =Figure 5: The BLEU scores of GLAT with different
decodingiterations SamplingNumber λs λe BLEU
0.5 0 27.80
WMT14 Decreasing 0.5 0.1 28.21
Model EN-DE DE-EN 0.5 0.2 27.15
0.5 0.3 23.37
NAT-base 8.32% 7.10%
GLAT 1.19% 1.05% Adaptive - 29.61
GLATw/NPD 0.32% 0.16%
Table 4: Performances on IWSLT16 with decreasing
Table2: TokenrepetitionratioonWMT14EN-DEand samplingratio. </Abstractive Summary> <Extractive Summary> Table 2 AsshowninTable3andTable4, ouradaptive
presentsthetokenrepetitionratioofsentencesgen- approach(Adaptiveinthetable)outperformsthe
eratedbyNAT-baseandGLAT.Theresultsshow baselinemodelswithbigmargins.  </Extractive Summary>  </Table 2>  </Paper ID = 156>


<Paper ID = 156> <Table 3> <Abstractive Summary> =The
1999SelectionStrategy GLAT GLATw/NPD WMT14
Method
EN-DE DE-EN
random 25.21 26.55
p 24.87 25.83 GLATw/uniformsampling 19.16 23.56
ref
1−p 25.37 26.52 GLATw/[MASK]inputs 24.99 29.48
ref
mostcertain 24.99 26.22 GLAT 25.21 29.84
mostuncertain 24.86 26.13
Table 7: Ablation study for comparing GLAT and
Table 5: Performance on WMT14 EN-DE with differ- Mask-PredictonWMT14EN-DEandDE-EN. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 156>


<Paper ID = 156> <Table 4> <Abstractive Summary> =Wethinkthis
GLATw/NPD
Hamming 26.55 31.02
indicatesthatintroducingmorerandomnessinsam-
pling enable GLAT to explore more interdepen-
Table 6: Performance on WMT14 EN-DE and
dencyamongtargetwords. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 4>  </Paper ID = 156>


<Paper ID = 157> <Table 0> <Abstractive Summary> =1https://azure.microsoft.com/
en-us/services/cognitive-services/
(cid:88)m speech-to-text/
L=− logP(y |e ,v ,e ) (19)
i i (cid:54)=i (cid:54)=i 2https://github.com/
i=1 ranjaykrishna/densevid_eval/tree/
9d4045aced3d827834a5d2da3c9f0692e3f33c1c
2008Methods V/T B-3 B-4 M R-L CIDEr
Bi-LSTM+TempoAttn(Shouetal.,2016) V - 0.87 8.15 - -
EMT(Zhouetal.,2018a) V - 4.38 11.55 27.44 38
VideoBERT(Sunetal.,2019b) V 6.80 4.04 11.01 27.50 49
VideoBERT(+S3Dfeature)(Sunetal.,2019b) V 7.59 4.33 11.94 28.80 55
CBT(Sunetal.,2019a) V - 5.12 12.97 30.44 64
DPC VT 7.60 2.76 18.08 - -
AT+video(Hesseletal.,2019) VT - 9.01 17.77 36.65 112
Transformer(w/ocontext) V 12.79 6.35 16.56 37.17 113
HCN V 13.74 7.26 17.11 38.35 121
Transformer(w/ocontext) VT 15.00 7.10 18.07 38.31 123
HCN VT 15.72 9.01 19.51 41.03 141
Table 1: The dense video event captioning results on the Youcook2 dataset, and these results are based on the
validationset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 157>


<Paper ID = 157> <Table 1> <Abstractive Summary> =HCN V 5.54 2.48 10.90
Transformer(w/ocontext) VT 4.43 1.86 10.05
HCN VT 5.82 2.62 10.64
4.3 ComparewithState-of-the-artresults
Table 2: The dense video event captioning results on
We demonstrate the results of our context-aware
the Activitynet Captions dataset and these results are
modelontheYoucook2datasetinTable3. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 157>


<Paper ID = 157> <Table 2> <Abstractive Summary> =Modeling event dependency
Table 3: Ablation study on the Youcook2 dataset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 157>


<Paper ID = 158> <Table 0> <Abstractive Summary> =Thisaffectsperformance,sug- result implies we can further decide to generate
gestingthatthemodeldoesbeneﬁtfromknowing eitheracoarse-grainedorﬁne-grainedcaptionby
2019Method ROUGE-L ROUGE-1-F1 BLEU-1 BLEU-4 CIDEr-D METEOR
Baseline(Pont-Tusetetal.,2020) 31.7 47.9 32.2 8.1 29.3 -
+Trace(Pont-Tusetetal.,2020) 48.3 60.7 52.2 24.6 106.5 -
Baseline* 34.1 54.0 36.0 10.3 29.5 16.4
+Trace* 49.0 68.1 55.4 25.0 107.9 25.2
LoopCAG(our) 50.3 69.8 57.2 27.0 114.0 26.0
Table 1: Comparison with baseline methods results: Baseline means an encoder-decoder model without taking
traceasinput.+Tracemeansconcatenatingencodedtracefeaturetotheencoderinput,i.e.,tracecontrolledcaption
performance. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 158>


<Paper ID = 158> <Table 1> <Abstractive Summary> =Theresultswith*arethebaselineperformancere-implemented
byourselves
Method ROUGE-L ROUGE-1-F1 BLEU-1 BLEU-4 CIDEr-D METEOR
Baseline* 34.1 54.0 36.0 10.3 29.5 16.4
+AG 34.7(+0.6) 55.5(+1.5) 37.4(+1.4) 10.5(+0.2) 30.1(+0.6) 16.6(+0.2)
+Trace* 49.0 68.1 55.4 25.0 107.9 25.2
+Trace+C 50.1(+1.1) 69.3(+1.2) 56.7(+1.3) 26.4(+1.4) 113.6(+5.7) 25.9(+0.7)
LoopCAG 50.3(+1.3) 69.8(+1.7) 57.2(+1.8) 27.0(+2.0) 114.0(+6.1) 26.0(+0.8)
Table 2: Ablation study results: Baseline means an encoder-decoder model without taking trace as input. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 158>


<Paper ID = 159> <Table 0> <Abstractive Summary> =Automatedmetrics Humanevaluation
Head-to-
Model Perplexity↓ ROUGE-L↑ METEOR↑ Accuracy↑ Accurate%↑
Head↑
Humans n/a n/a n/a 89.8 50.0 95.2
RetrievalBaseline n/a 11.5 7.2 51.9 4.4 20.6
GPT-2(Radfordetal.,2019) 26.6 10.3 6.2 50.0 0.0 3.0
Cross-ModalityGPT-2 22.1 12.0 7.9 51.0 4.1 10.4
DynamicRA(Tanetal.,2019) 23.1 13.2 8.9 51.8 5.3 12.4
VLP(Zhouetal.,2019) 12.3 18.5 10.5 53.2 9.3 20.3
PELICANREAL(ours) 11.6 19.5 10.8 54.1 11.3 25.5
PELICAN(ours) 11.0 22.1 11.6 55.4 14.6 48.2
Table 2: Experimental results on EMU. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 159>


<Paper ID = 16> <Table 0> <Abstractive Summary> =We observe that our model achieves the
Table 2: Speed comparison. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 16>


<Paper ID = 160> <Table 0> <Abstractive Summary> =Our PIGLeT,SymbolsOnly(UpperBound) 89.3
object decoder predicts the object, given the Table 2: Ablation study on PIGPeN-NLU’s validation
LM’spooledhiddenstate. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 160>


<Paper ID = 160> <Table 1> <Abstractive Summary> =Last,webenchmarkhowmuchheadroom
Table 3: Text generation results on PIGPeN-NLG,
thereisonPIGPeN-NLUbyevaluatingmodelper- showing models of roughly equivalent size (up to
formanceona‘symbolsonly’versionofthetask, 117M parameters). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 160>


<Paper ID = 161> <Table 0> <Abstractive Summary> =(2020)(undefined) 73.0 68.1 79.7 80.5 80.5 78.1
Table 4: Macro-averaged F1
LinandJi(2019) 82.9† 77.3† 79.3 78.1 83.0 79.8
on the dev set of BBN and
FIGER. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 161>


<Paper ID = 161> <Table 1> <Abstractive Summary> =These dev sets are
Table 3: Macro-averaged F1 and Micro-averaged F1 on the test set for the
drawnfromthesamedistribu-
entity typing task of OntoNotes, BBN, FIGER. </Abstractive Summary> <Extractive Summary> UFET Table 1 shows the macro-precision, re-
Sincemodelsmaynaturallyhavedifferentscales call,andF1scoresontheUFETtestset.  </Extractive Summary>  </Table 1>  </Paper ID = 161>


<Paper ID = 161> <Table 2> <Abstractive Summary> =UFET Box 78.1
Vector 77.3
person 982 99.7 745 98.6 Box 0.5/-1.1 0.1119
Random 50.0
location 470 86.1 450 84.4 Vector 0.2/-1.1 0.3279
place 49 95.9 29 68.9
organization 496 84.6 407 77.8 OntoNotes Table 8: Accuracy
Box 0.9/-0.3 0.1358 ontheCAPtestset
Total 1,997 92.7 1,631 89.0
Vector 0.7/-0.4 0.1568 (Chenetal.,2019). </Abstractive Summary> <Extractive Summary> Table 2 breaks down the performance into the The state-of-the-art system on BBN, the sys-
coarse,fine,andultra-fineclasses.  </Extractive Summary>  </Table 2>  </Paper ID = 161>


<Paper ID = 161> <Table 3> <Abstractive Summary> =This is a binary
Table5: Consistency: accuracyevaluatedonthe30su-
Table 7: Total calibration error classificationtask. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 161>


<Paper ID = 161> <Table 4> <Abstractive Summary> =However, we can additionally investigate
Table 6: Entity typing results of the UFET dev set. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 4>  </Paper ID = 161>


<Paper ID = 161> <Table 5> <Abstractive Summary> =[0.0001,0.01]* 0.00036
organization social group
SoftplusTemp.† [0.1,10]* 1.2471
organization committee
Batchsize {16,32,64,128} 128
Vector lr(BERT) - 2e-5 Table 10: 30 supertype and subtype pairs used for the
lr(Other) [0.0001,0.01] 0.00539
consistencytest. </Abstractive Summary> <Extractive Summary> FollowingNguyenandO’Connor(2015),wesplit
Table 5 lists the total and per-supertype accu- modelconfidence(outputprobability)foreachtyp-
racy on the supertype/subtype pairs.  </Extractive Summary>  </Table 5>  </Paper ID = 161>


<Paper ID = 162> <Table 0> <Abstractive Summary> =ERNIE adopts various masking
strategies includingtoken-level, phrase-level and 6https://github.com/CLUEbenchmark/CLUE
2069CMRC XNLI
Model Dev Test Model Dev Test
Base Base
ERNIE 66.89 74.70 ERNIE 79.7 78.6
BERT 66.77 71.60 BERT 79.0 78.2
BERT◦ 66.96 73.95 BERT◦ 79.4 78.7
RoBERTa◦ 67.89 75.20 RoBERTa◦ 80.0 78.8
MacBERT – – MacBERT 80.3 79.3
ChineseBERT 67.95 75.35 ChineseBERT 80.5 79.6
Large Large
RoBERTa◦ 70.59 77.95 RoBERTa◦ 82.1 81.2
MacBERT – – MacBERT 82.4 81.3
ChineseBERT 70.70 78.05 ChineseBERT 82.7 81.6
Table 2: Performances of different models on CMRC. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 162>


<Paper ID = 162> <Table 1> <Abstractive Summary> =Table 4: Performances of different models on XNLI. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 162>


<Paper ID = 162> <Table 2> <Abstractive Summary> =(2019a)touseTHUC- 9http://thuctc.thunlp.org/
10https://github.com/gaussic/
7https://github.com/facebookresearch/ text-classification-cnn-rnn
XNLI 11https://github.com/CLUEbenchmark/CLUE
2070ChnSentiCorp THUCNews TNEWS OntoNotes4.0 Weibo
Model Dev Test Dev Test Dev Test Model P R F P R F
Base Base
ERNIE 95.4 95.5 97.6 97.5 58.24 58.33 BERT 79.69 82.09 80.87 67.12 66.88 67.33
BERT 95.1 95.4 98.0 97.8 56.09 56.58 RoBERTa◦ 80.43 80.30 80.37 68.49 67.81 68.15
BERT◦ 95.4 95.3 97.7 97.7 56.77 56.86 ChineseBERT 80.03 83.33 81.65 68.27 69.78 69.02
RoBERTa◦ 95.0 95.6 98.3 97.8 57.51 56.94 Large
RoBERTa◦ 80.72 82.07 81.39 66.74 70.02 68.35
MacBERT 95.2 95.6 98.2 97.7 – –
ChineseBERT 80.77 83.65 82.18 68.75 72.97 70.80
ChineseBERT 95.6 95.7 98.1 97.9 58.64 58.95
Large
RoBERTa◦ 95.8 95.8 98.3 97.8 58.32 58.61 Table 7: Performances of different models on NER
MacBERT 95.7 95.9 98.1 97.9 – – datasets OntoNotes 4.0 and Weibo. </Abstractive Summary> <Extractive Summary> • NamedEntityRecognition(NER)
Results are shown in Table 2 and Table 3.  </Extractive Summary>  </Table 2>  </Paper ID = 162>


<Paper ID = 162> <Table 3> <Abstractive Summary> =Table 5: Performances of different models on TC
datasetsChnSentiCorp,THUCNewsandTNEWS.The
resultsofTNEWSaretakenfromtheCLUEpaper(Xu MSRA PKU
et al., 2020). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 162>


<Paper ID = 162> <Table 4> <Abstractive Summary> =Base
BERT◦ 98.42 99.04 96.82 97.70
RoBERTa◦ 98.46 99.10 96.88 97.72
LCQMC BQCorpus ChineseBERT 98.60 99.14 97.02 97.81
Model Dev Test Dev Test Large
Base RoBERTa◦ 98.49 99.13 96.95 97.80
ERNIE 89.8 87.2 86.3 85.0 ChineseBERT 98.67 99.26 97.16 98.01
BERT 89.4 87.0 86.1 85.2
BERT◦ 89.6 87.1 86.4 85.3 Table 8: Performances of different models on CWS
RoBERTa◦ 89.0 86.4 86.0 85.0 datasets MSRA and PKU. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 4>  </Paper ID = 162>


<Paper ID = 162> <Table 5> <Abstractive Summary> =OntoNoteshas18namedentitytypesandWeibo
Table 6: Performances of different models on SPM
has4namedentitytypes. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 5>  </Paper ID = 162>


<Paper ID = 162> <Table 6> <Abstractive Summary> =Thisisbecause
–Glyph–Pinyin 78.22 81.37 79.76(-1.89) ChineseBERTstillrequiressufﬁcienttrainingdata
tofullytraintheglyphandpinyinembeddings,and
Table 9: Performances for different models without
insufﬁcienttrainingdatawouldleadtoinadequate
consideringglyphorpinyininformation. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 6>  </Paper ID = 162>


<Paper ID = 164> <Table 0> <Abstractive Summary> =Table 2: Comparisons with the models leveraging re- Table 3 shows the accuracy of our best model
lational transformers on the Spider development set. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 164>


<Paper ID = 164> <Table 1> <Abstractive Summary> =Duetologicallyequivalent
2095N Standard DT-Fixup
Spider
2 69.47±0.30 70.73±0.18
4 70.04±0.33 72.22±0.61
8 66.86±0.16 73.24±0.51
16 20.44±1.11 73.52±0.47
24 19.37±0.16 73.79±0.49
32 19.57±0.43 73.02±0.52
ReClor
4 64.05±0.44 64.31±0.68
8 56.96±6.12 65.31±0.62
16 27.10±1.50 65.68±1.12
Table 5: Ablation on the number of
transformer layers N. The means and
standard deviations are reported based Figure2: ValidationcurvesonSpiderformodelstrainedwithdifferent
on5runswithdifferentrandomseeds. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 164>


<Paper ID = 164> <Table 2> <Abstractive Summary> =3-4,“Column”means“proportionwithcolumner-
Table 7: Ablation on the batch sizes for the Spider
rors”(i.e.,ColumnorBoth);“Sketch”means“pro-
dataset. </Abstractive Summary> <Extractive Summary> Table 2 compares our proposed models
5 Experiments
with the publicly available works.  </Extractive Summary>  </Table 2>  </Paper ID = 164>


<Paper ID = 165> <Table 0> <Abstractive Summary> =By analogy, we used an
Table 1: Example of an entity-masked sentence (m )
1 entity-masked sentence as “random noise” and a
andtheoriginalsentence(s )
1
maskedentityasa“realimage.” InourGAN-style
training, we regard the vector representation of a
2020)orRoBERTa(Liuetal.,2019)forexample, maskedentity givenby generator R asa realrep-
canbeusedasasubcomponentofBERTAC. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 165>


<Paper ID = 165> <Table 1> <Abstractive Summary> =BERT-large
CFORMERRoBERTa-large 54.0 63.9 68.0 75.1
BERTAC 55.8 63.7 71.9 77.1
RoBERTa-large
Non-TLM-basedmethods BERTAC 58.0 65.8 74.0 79.2
ALBERT-xxlarge
OPENQA (Lin et al., 2018): An RNN-based method
that jointly learns passage-selection and answer extrac-
Table 7: QA test set results. </Abstractive Summary> <Extractive Summary> "+’)"),-&(#.+/0#+’)+’$+0 masked sentence m1 in Table 1 is obtained by
!$%&’()’*+%!,-.,(/0(1" !  </Extractive Summary>  </Table 1>  </Paper ID = 165>


<Paper ID = 166> <Table 0> <Abstractive Summary> =Evi-
Test 130 274
dencerecalliscomputedasthenumberofevidence
Table 3: Breakdown of claims by label for train, dev, setsthatcontainagoldevidenceoverthetotalnum-
testsets. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 166>


<Paper ID = 166> <Table 1> <Abstractive Summary> =Table 5: Performance of our system’s Evidence Re-
Baricitinibrestrainstheimmunedysregulation
trievalpart(seeSection3.1).Wecomparetheprecision C2
inCOVID-19patients
(P), Recall (R), and F1-score of top 5, top 3, top 1 re-
Here,weprovideevidencesontheefﬁcacyof
trieved sentences, ranked by SBERT cosine similarity
Baricitini,aJAK1/JAK2inhibitor,incorrecting
score. </Abstractive Summary> <Extractive Summary> Table 1 shows examples of evi-
ingtotheAcademicReportﬂair. Thus, to ﬁlter out most
ample, the second claim in Table 1 “Oxford vac-
of the titles that are not well-formed claims, we
cine triggers immune response” is reported, be-
employasimplesyntax-basedapproachtoremove
sidesthebbc.comgivenintheoriginalpost,alsoby
questionsandconsiderstatementsthathaveatleast
othertrustworthysourcessuchasusnews.com,med-
a main verb.  </Extractive Summary>  </Table 1>  </Paper ID = 166>


<Paper ID = 166> <Table 2> <Abstractive Summary> =TrainSetting Acc F1
COVID-Fact 80.8 80.0
Table7: Claims(C1&C2)whichareclassiﬁedincor-
Sci-Fact 83.7 83.0
rectly as REFUTES in the light of SUPPORTing evi-
Table 6: Two-way Veracity prediction results on Sci- dence by our best veracity models. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 166>


<Paper ID = 167> <Table 0> <Abstractive Summary> =Weobservealargerdifferenceinspeciﬁcity
Table 2: Human evaluation of SCIGEN (intro × abs) between SCIGEN and gold texts, indicating that
and IR (abs × abs) systems compared with gold ex- SCIGEN,likemanyneuraltextgenerationsystems,
planationsinpercent. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 167>


<Paper ID = 167> <Table 1> <Abstractive Summary> =Theﬁrstexampleillustrates
2136Method Context BLEU ACL-BLEU Rouge-L
principalabs×citedabs 9.82 10.40 8.4
principalintro×citedabs 9.92 11.22 8.7
SCIGEN
principalintro×citedintro 9.80 10.54 8.8
Sentence-based
principalintro×citedsampled 9.81 10.31 8.7
sourceabs×citedabs 9.93 10.50 9.7
IR
+MERT 10.23 10.29 9.8
principalintro×citedtﬁdf 13.17 16.75 12.0
SCIGEN
principalintro×citedentities 13.41 13.42 11.8
IE-based
principalintro×citedtﬁdf 13.50 15.10 12.3
+Ranking
principalintro×citedentities 13.16 14.47 11.8
Table 3: Automatic test set evaluation of generated texts for a subset of our systems. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 167>


<Paper ID = 167> <Table 2> <Abstractive Summary> =Table 6: Hyperparameters for the further pretraining Judges are shown a table of datapoints asked to
andﬁnetuning. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 167>


<Paper ID = 167> <Table 3> <Abstractive Summary> =K ExplainingwithoutCitations
Table 11: Example relationship explanations for pairs
Onedirectionoffutureworkistheabilitytopro- of papers that appeared in the same track at NAACL
videnaturallanguagerelationshipexplanationsto 2018. </Abstractive Summary> <Extractive Summary> The“Sentence-based”rows
nearest neighbor search algorithm to ﬁnd similar
of Table 3 show the test set performance of the
pairsofdocuments. arankingmechanismthatrewardsgeneratedexpla-
6.3 AutomaticEvaluation
nationswithhighercoverageofimportantentities
fromtheconditioningcontext.10 The “IE-based” rows of Table 3 show the results
Theprocessweuseisasfollows: ﬁrst,wegen- ofautomaticmetricsforthesystemsdescribedin
erate a large space of candidate explanations for this Section.  </Extractive Summary>  </Table 3>  </Paper ID = 167>


<Paper ID = 168> <Table 0> <Abstractive Summary> =Qns(kWh) Qns(USD)
QAoverasinglepassage 161 21.24
QAover150passages
5.2 DatasetandEvaluationMethodology 24,000 3,165
(ignoresearch/retrieval)
Foreachmodel,weobtainthemodeltreeandfor
Table 3: Example energy for BERT-base QA models
eachnodeinit,weassociateground-truthenergy
using batch size 16 and sequence length 256 on PC1
measurementsusingthepowermonitoranditsre-
using one GPU. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 168>


<Paper ID = 168> <Table 1> <Abstractive Summary> =Aslongas
(a)RoBERTa-base (b)GPT2
theseareavailablewecanapplyourmethodology
Table 10: Module level predicted energy breakdown tootherarchitecturesaswell. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 168>


<Paper ID = 168> <Table 2> <Abstractive Summary> =WelearnlinearregressorsforML-levelin
Table 11: Energy Prediction Errors at Module levels
usingStrubelletal.,2019methodologyonPC1. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 168>


<Paper ID = 169> <Table 0> <Abstractive Summary> =overall cyberbullying detection ac-
2164Table 3: Performance comparisons of different mod-
els on the Instagram dataset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 169>


<Paper ID = 170> <Table 0> <Abstractive Summary> =Weset512asthe
lengthlimitforboththenaturallanguageandthe
Table 1: Dataset statistics. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 170>


<Paper ID = 170> <Table 1> <Abstractive Summary> =To better understand the plotted
print((i,j),max(i,j)) −NL 27.52% 28.42% 43.75% 21.05%
results.append(max(i,j)) datapredictionperformance,inadditiontothede-
GroundTruth&Prediction Table 5: Evaluation on the full hierarchical model fault plotted data accuracy that requires the data
plt.hist(results) withdifferentinputs. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 170>


<Paper ID = 170> <Table 2> <Abstractive Summary> =(6-7)
Withcodecanonicalization
FullModel 77.17% 70.86% 61.54% 12.28% 29.69% 84.14%
−Hierarchy 70.65% 68.00% 76.92% 15.79% 39.06% 71.20% ErrorCategory %
−Link 73.55% 68.00% 69.23% 21.05% 35.94% 70.55%
LSTM 73.91% 71.43% 69.23% 21.05% 28.13% 73.79% (1)NLonlysuggeststheplottype 28.57
+codeBERT 67.39% 66.29% 76.92% 21.05% 35.94% 77.02%
(2)NLonlysuggeststheplotteddata 9.52
+RoBERTa 61.59% 62.29% 61.54% 10.53% 34.38% 80.58%
(3)NLhasnoplottinginformation 9.52
Withoutcodecanonicalization
FullModel 71.01% 74.29% 76.92% 12.28% 37.50% 65.05% (4)Needmorecodecontext 9.52
−Hierarchy 75.00% 72.00% 61.54% 14.04% 31.25% 58.25%
(5)Semanticallycorrect 14.29
−Link 72.10% 60.57% 69.23% 22.81% 37.50% 63.75%
LSTM 74.64% 74.29% 69.23% 19.30% 29.69% 65.70% (6)ChallengingNLunderstanding 19.05
+codeBERT 71.01% 56.00% 46.15% 14.04% 35.94% 55.02%
(7)Challengingcodecontextunderstanding 9.52
+RoBERTa 73.91% 47.13% 46.15% 10.53% 29.69% 74.43%
Table 8: Error analysis on Test (gold) with the hierar-
Table6: PlottypeaccuracyonTest(hard)pertype. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 170>


<Paper ID = 172> <Table 0> <Abstractive Summary> =DifferentfromunstructuredpruningusedinLTH Table 1: Comparison between randomly-pruned mod-
elsandEarlyBERTonGLUEtasks. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 172>


<Paper ID = 172> <Table 1> <Abstractive Summary> =2200   ( S R F K λ 10−4 10−3 10−2
        ( S R F K
88.55 88.43 88.42
  
 F \       #PrunedHeads 4 5 6
 D
 X U
 F F Layer-wisepruning 88.55 88.13 87.65
 $    
#PrunedNeurons 30% 40% 50%
    
Layer-wisepruning 88.18 88.22 87.90
  H     H     H     H  
 / H D U Q L Q J  5 D W H Globalpruning 88.31 88.23 87.91
Figure 2: Effect of reducing training epochs and up-
scalinglearningrateforEarlyBERTinﬁne-tuning.The Table 3: Ablation of regularization strength λ and
combinationof2-epochﬁne-tuningand4×10−5turns pruningratiosonself-attentionheadsandintermediate
outtobetheoptimalchoice. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 172>


<Paper ID = 172> <Table 2> <Abstractive Summary> =We
BASE
timebecauserandompruningskipsthesearching willusetwoepochsand4×10−5aslearningrate
2201Methods CoLA MNLI MRPC QNLI QQP RTE SST-2 SQuAD
BERT 0.45 81.40 84.07 89.86 89.80 60.29 90.48 87.60
BASE
EarlyBERT 0.41 79.97 80.39 89.86 89.44 61.01 90.94 85.48
BASE
BERT 0.50 83.56 85.90 90.44 90.45 59.93 92.55 90.43
LARGE
EarlyBERT 0.47 82.54 85.54 90.46 90.38 61.73 91.51 89.36
LARGE
Table 4: Performance of EarlyBERT (pre-training) compared with BERT baselines. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 172>


<Paper ID = 172> <Table 3> <Abstractive Summary> =All results are averages of 3
Table 8: Comparison of the accuracies of EarlyBERT
runs. </Abstractive Summary> <Extractive Summary> Results in Table 3 show that λ has
marginalinﬂuenceonEarlyBERTperformance.  </Extractive Summary>  </Table 3>  </Paper ID = 172>


<Paper ID = 172> <Table 4> <Abstractive Summary> =Table 6: We increase the number of training steps of
• Basedontheaboveobservations,wealsoap-
EarlyBERTsothatitachievesverycloseperformances
totheBERTbaselineonthelargerfourtasksinGLUE pliedlayerwisepruningforMLMexperiments
benchmark. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 4>  </Paper ID = 172>


<Paper ID = 172> <Table 5> <Abstractive Summary> =BERT-
82.85% 89.86% 89.45% 91.70%
Reduced
C TheEffectofReducedTrainingSteps
EarlyBERT 83.26% 90.16% 90.22% 91.67%
duringPre-training
Table 7: Comparison between the performance of
Weperformthesameastheanalysisoftheeffect
BERTandEarlyBERTwiththesametrainingtimeon
ofreducedtrainingstepsduringpre-traininginFig-
thelargerfourtasksonGLUEbenchmarkbyreducing
ure 4 for both the vanilla BERT and EarlyBERT. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 5>  </Paper ID = 172>


<Paper ID = 173> <Table 0> <Abstractive Summary> =IMDB
Model
(4169) (1688) (3219) (515) (180k) (115k) (115k) (20k)
RoBa.-ft† 81.91.0 63.05.8 77.31.9 86.60.9 87.20.1 93.90.2 65.13.4 95.00.2
RoBa.-ft∗ 81.70.8 65.03.6 78.51.8 88.93.3 87.00.1 93.70.2 69.10.6 95.20.1
RoBa.-adapter256 82.90.6 67.54.3 80.80.7 90.44.2 87.10.1 93.80.1 69.00.4 95.70.1
RoBa.-ft+TAPT† 82.60.4 67.41.8 79.31.5 90.45.2 87.70.4 94.50.1 68.51.9 95.50.1
RoBa.-ft+TAPT∗ 82.50.3 66.55.1 79.70.8 91.30.8 87.40.1 94.00.2 70.31.1 95.40.1
RoBa.-adapter256+TAPT 83.50.5 70.02.1 81.10.2 90.03.5 87.20.1 94.00.1 68.80.8 95.80.0
Table 1: Average results across ﬁve random seeds with standard deviations as subscripts on TAE. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 173>


<Paper ID = 173> <Table 1> <Abstractive Summary> =5% 10% 20%
Model All Target Distant All Target Distant All Target Distant
XLMR-ft 75.76 75.09 73.12 76.73 76.07 74.21 78.28 77.64 75.84
XLMR-adapter64 76.09 75.47 73.78 77.52 76.94 75.10 78.68 78.07 76.39
Table 4: Accuracy on XNLI with different amount of training data. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 173>


<Paper ID = 173> <Table 2> <Abstractive Summary> =Table 6: Mean (Best) results on the dev set across all
LearningRateRobustness Wecomparethetwo evaluationsteps. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 173>


<Paper ID = 173> <Table 3> <Abstractive Summary> =loss AAddaapptteerr6644-mixout 4422..5923 8834..8709 8800..5647 8887..0626
1 1 1 1 Table 7: Comparison with Mixout. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 173>


<Paper ID = 173> <Table 4> <Abstractive Summary> =Model en ar bg de el es fr hi ru sw th tr ur vi zh
5%trainingdata
XLMR-ft 85.09 73.53 78.7 79.58 77.26 80.13 79.36 72.07 76.52 67.8 72.53 74.53 68.3 75.24 75.74
XLMR-adapter64 84.77 73.95 78.76 79.02 78.08 80.55 79.48 72.01 76.54 68.76 73.83 75.56 68.6 75.94 75.50
10%trainingdata
XLMR-ft 85.96 75.04 79.78 79.82 78.72 80.99 80.25 73.23 77.28 68.08 74.43 75.7 69.54 76.02 76.16
XLMR-adapter64 85.74 76.78 80.27 80.77 79.72 81.87 81.13 73.87 78.42 69.3 74.25 77.08 69.54 77.30 76.82
20%trainingdata
XLMR-ft 87.26 76.48 81.07 82.03 80.47 82.55 81.53 75.06 78.04 69.96 76.00 77.36 70.75 77.74 77.94
XLMR-adapter64 87.24 78.00 81.87 82.15 80.47 82.65 81.53 75.00 78.74 70.87 75.94 78.44 70.51 78.70 78.16
Table 15: Zero-shot XNLI accuracy on the test set of each language when trained on 5%, 10%, 20% of training
datarespectively. </Abstractive Summary> <Extractive Summary> all languages (All), the target languages except Table 4 summarizes the results when trained on
English(Target),andtheNon-Indo-Europeanlan- 5%,10%,and20%oftheoriginaltrainingsets.  </Extractive Summary>  </Table 4>  </Paper ID = 173>


<Paper ID = 175> <Table 0> <Abstractive Summary> =Table 3: Qualitative analysis of the learned 128-bit hash codes on the 20Newsgroups dataset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 175>


<Paper ID = 175> <Table 1> <Abstractive Summary> =1: procedureTREEGEN(n) (cid:46)Input:#treen
1: θ,φ←Initializeparameters 2: E =[] (cid:46)Initialedgeslist
2: repeat 3: fork←0,··· ,n−1do
3: VM←{x1,··· ,xb}∼X (cid:46)Samplenodes 4: V =[False]|V| (cid:46)Visitednodelist
4: EM←{e ,··· ,e }∼E (cid:46)Sampleendges 5: whileFalseinV do
T 1 b
5: g←∇φ,θL(cid:101)MMT(θ,φ;VM,ETM) 6: i←RC[V==False] (cid:46)Choosenode
6: θ,φ ←Updateparametersusinggradientsg (e.g., 7: Q=[i] (cid:46)Initialqueue
Adamoptimizer) 8: whilelen(Q)>0do
7: untilconvergenceofparameters(θ,φ) 9: i←Q[0]
10: V[i]←True
Input documentpair(xi;xj) 11: N =ID[V[N(i)]==False]
12: iflen(N)==0then
VariationalEnc CorrelatedEnc
13: POP(Q,−1)
Linear(|V|,d) Linear(|V|,d) Linear(2|V|,d) 14: break
Encoder
µ=f(·/τ) σ=g(·) γ =2∗f(·)−1 15: endif
16: j←RC (cid:46)Chooseneighbor
Generator Linear(d,|V|) [N]
17: V[j]←True
18: APPEND(Q,j)
Table 4: The neural network architecture of the pro- 19: APPEND(E,[i,j])
posedmodel, inwhichf(·)andg(·)representthesig- 20: endwhile
moidandsoftplusfunction,respectively. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 175>


<Paper ID = 175> <Table 2> <Abstractive Summary> =In this algorithm, RC means randomly
φ i i G i φ j j G j [·]
22480.87 0.87
Datasets Methods 16bits 32bits 64bits 128bits 0.86 Reuters  0.86 Reuters 
Reuters PSRaNBirURSHHec 000...788700462038 000...888321664989 000...888143282039 000...888054866878  3 U H F L V L R Q    000...888345  3 U H F L V L R Q    000...888345
0.82 0.82
RBSH 0.7959 0.8138 0.8224 0.8193 0.810 1 2 3 4 5 6 7 8 9 10 0.810.10.20.30.40.50.60.70.80.91.0
TMC PairRec 0.7991 0.8239 0.8280 0.8303  . /  Z H L J K W  (102)  W H P S H U D W X U H 
SNUH 0.7901 0.8145 0.8293 0.8329 0.78 0.78
TMC TMC
RBSH 0.6087 0.6385 0.6655 0.6668   0.77   0.77
NG20 PSaNirURHec 0.n5.6a7.9 0.n6.4a4.4 0.n6.8a0.6 0.n7.0a0.4  3 U H F L V L R Q  00..7756  3 U H F L V L R Q  00..7756
0.74 0.74
Table 5: The precision of variant models on three 0.730 1 2 3 4 5 6 7 8 9 10 0.730.10.20.30.40.50.60.70.80.91.0
 . /  Z H L J K W  (102)  W H P S H U D W X U H 
datasetswithdifferentnumbersofbits. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 175>


<Paper ID = 176> <Table 0> <Abstractive Summary> =METEOR 0.643 0.948 0.908 0.617 0.779
CIDEr 0.633 0.949 0.866 0.639 0.772
SPICE 0.628 0.938 0.866 0.637 0.767
ure, F, as a disparity of greater than 1 between
SPARCS 0.651 0.958 0.896 0.644 0.787
SPURTS 0.496 0.503 0.604 0.485 0.522 system-levelhuman(M2)andcaption-levelalgo-
SMURF 0.621 0.939 0.912 0.610 0.771
rithmcorrelationofareferenceevaluationmetric
andatestedevaluationmetricforagivencaption
Table 3: PASCAL-50S caption-level classiﬁcation ac-
setofanimage. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 176>


<Paper ID = 177> <Table 0> <Abstractive Summary> =Withoutadaptation,
Table 5: Exact match accuracy and standard error
onschema-normalizedKaggleDBQA,averageofthree modelswithdescriptionsarenotbetterthanthose
runswithdiﬀerentrandomseeds. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 177>


<Paper ID = 178> <Table 0> <Abstractive Summary> =Weillustrateourﬁnd-
[10.0,3.9,1.1] [9.5,3.7,1.1]
BaselineE2E-T-QASR 15.1 14.7 ingswithtwotranscriptionexamplesinBuckwalter
[7.0,7.4,0.7] [7.1,7.0,0.6]
(BW)formatshowninFigure6: shortsegmentof
Table 5: WER% performance with the insertion (I%), 6seconds,andlongsegmentof10seconds. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 178>


<Paper ID = 178> <Table 1> <Abstractive Summary> =(cid:63)
87K(0.7%) 623(0.9%) 349(0.5%) 56K(1.3%)
It can be seen that the best E2E-T-MGB-2
O 12M(95.0%) 68K(93.6%) 63K(95.1%) 2M(80.6%)
achievesslightlybetterWERwithadifferenceof
Table 6: Distribution of punctuation classes in QASR
0.3% on average. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 178>


<Paper ID = 178> <Table 2> <Abstractive Summary> =DespitethefactthatArabichasaskeweddistri-
Table 7: Reported Precision (P), Recall (R) and F-
butioninpunctuation,thebaselineresultsreported
measure (F1) on test and dev set using punctuation
inTable7forthe3punctuationand‘O’labelsshow
restorationmodeltrainedonQASRdataset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 178>


<Paper ID = 178> <Table 3> <Abstractive Summary> =The aforementioned obser- Table 10: NER results: Precision (P), Recall (R) and
vationsarepre-anticipated,asanchorsareprofes- F1ontwotestsets. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 178>


<Paper ID = 179> <Table 0> <Abstractive Summary> =2287Hyperparameter Electra-grid Electra-HPO RoBERTa-grid RoBERTa-
HPO
learningrate {3e-5,1e-4,1.5e-4} log((2.99e-5,1.51e- {1e-5,2e-5,3e- (0.99e-
4)) 5} 5,3.01e-5)
warmupratio 0.1 (0,0.2) 0.06 (0,0.12)
attentiondropout 0.1 (0,0.2) 0.1 (0,0.2)
hiddendropout 0.1 (0,0.2) 0.1 (0,0.2)
weightdecay 0 (0,0.3) 0.1 (0,0.3)
batchsize 32 {16,32,64} {16,32} {16,32,64}
epochs 10forRTE/STS-B, 10forRTE/STS-B, 10 10
3forother 3forother
Table 1: The search space for grid search and HPO methods in this paper. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 179>


<Paper ID = 179> <Table 1> <Abstractive Summary> =proposetwogeneralstrategiestoimproveHPO’s
2289WNLI RTE MRPC CoLA STS-B SST QNLI MNLI
Electra-base,validation
grid 56.3 84.1 92.3/89.2 67.2 91.5/91.4 95.1 93.5 88.6
RS 56.8 82.2 93.0/90.4 68.8 90.1/90.2 94.7 93.0 88.9
RS+ASHA 57.2 80.3 93.0/90.3 67.9 91.4/91.3 94.9 93.1 88.6
BO+ASHA 58.2 82.6 93.1/90.4 69.4 91.5/91.3 94.7 93.1 89.2
Electra-base,test
grid 65.1 76.8 91.1/87.9 58.5 89.7/89.2 95.7 93.5 88.3
RS 64.4 75.6 90.7/87.5 63.0 88.0/87.6 95.1 93.0 88.7
RS+ASHA 62.6 74.1 90.6/87.3 61.2 89.5/89.1 94.9 92.9 88.5
BO+ASHA 61.6 75.1 90.7/87.4 64.1 89.7/89.1 94.8 93.0 88.7
WNLI RTE MRPC CoLA STS-B
RoBERTa-base,validation
grid 56.3 79.8 93.1/90.4 65.1 91.2/90.8
RS 57.8 80.4 93.3/90.7 64.1 91.2/90.9
RS+ASHA 57.3 80.8 93.4/90.8 64.5 91.2/90.9
BO+ASHA 56.3 80.3 93.7/91.4 64.5 91.3/91.0
RoBERTa-base,test
grid 65.1 73.9 90.5/87.1 61.7 89.3/88.4
RS 64.9 73.5 90.1/86.7 59.1 89.3/88.6
RS+ASHA 65.1 74.1 90.6/87.3 59.4 89.1/88.3
BO+ASHA 65.1 73.3 90.4/87.2 60.1 89.1/88.4
Table 3: Results of the initial comparative study on Electra (top) and RoBERTa (bottom) by varying the GLUE
taskandHPOmethodwhileﬁxingthesearchspaceandtimebudget. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 179>


<Paper ID = 179> <Table 2> <Abstractive Summary> =By com-
paring the results between random search and
Table 4: An example of executing the exper- ASHAinTable10and11,weﬁndthatbeforein-
imental procedure applied to random search for creasingthebudget,RSrarelyoutperformsASHA
Electra on RTE. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 179>


<Paper ID = 179> <Table 3> <Abstractive Summary> =Asimple
1GST,Smin yetsurprisinglyeffectivealternativeistouseran-
dom combinations of hyperparameter values, es-
Table 5: Final results of executing the troubleshoot- peciallywhentheobjectivefunctionhasalowef-
ing procedure on Electra (top) RoBERTa (bottom). </Abstractive Summary> <Extractive Summary> By comparing the performance of grid
and hidden dropout to a continuous space by
search and HPO in Table 3 we can make the fol-
expandingthegridspace. Table 3 overﬁt. We apply the same analytical strat-
egy to the RoBERTa results in Table 3 and show
yes
res overfitting?  </Extractive Summary>  </Table 3>  </Paper ID = 179>


<Paper ID = 179> <Table 4> <Abstractive Summary> =Table 6: Average numbers of trials searched by each The Pearson coefﬁcient of the original dataset is
HPOalgorithmintheinitialexperimentonElectra. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 4>  </Paper ID = 179>


<Paper ID = 179> <Table 5> <Abstractive Summary> =do
MRPC,grid 92.3/89.2 91.1/87.9 1.0e-4 0.100 32 0.100 0.100
MRPC,RS,rep1 92.7/90.0 90.4/87.1 3.9e-5 0.014 16 0.050 0.063
MRPC,RS,rep2 93.4/90.9 90.6/87.6 4.3e-5 0.005 16 0.044 0.024
MRPC,ASHA,rep1 92.8/90.0 90.8/87.6 6.5e-5 0.075 16 0.038 0.090
MRPC,ASHA,rep2 93.4/90.9 90.5/87.4 3.1e-5 0.030 16 0.067 0.097
MRPC,ASHA,rep3 92.9/90.0 90.4/86.9 1.3e-4 0.066 32 0.097 0.015
MRPC,Opt+ASHA,rep1 93.0/90.4 90.7/87.5 6.4e-5 0.084 16 0.196 0.002
MRPC,Opt+ASHA,rep2 93.3/90.7 90.4/86.9 8.0e-5 0.010 32 0.031 0.108
SST,grid 95.1 95.7 3.0e-5 0.100 32 0.100 0.100
SST,RS,rep1 95.4 95.6 3.1e-5 0.011 32 0.006 0.044
STS-B,grid 91.5/91.4 89.7/89.2 1.0e-4 0.100 32 0.100 0.100
STS-B,Opt+ASHA,rep1 91.6/91.4 89.6/89.1 4.7e-5 0.015 32 0.028 0.082
Table 8: Comparison between the hyperparameter values of the best trial of grid search and the best trials (in
validation accuracy) of all the 9 overﬁtting HPO runs (out of 72) in the initial comparative study using Electra
(Table3). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 5>  </Paper ID = 179>


<Paper ID = 179> <Table 6> <Abstractive Summary> =do wd
WNLI,grid 56.3 65.1 - 0.060 - 0.100 0.100 0.100
WNLI,RS,rep3 60.6 64.4 1.8e-5 0.111 16 0.128 0.122 0.078
CoLA,grid 65.1 61.7 3.0e-5 0.060 16 0.100 0.100 0.100
CoLA,ASHA,rep1 65.5 59.5 2.7e-5 0.020 32 0.090 0.197 0.180
CoLA,Opt+ASHA,rep1 65.4 59.4 2.3e-5 0.067 32 0.063 0.117 0.293
RTE,grid 79.8 73.9 3.0e-5 0.060 16 0.100 0.100 0.100
RTE,RS,rep1 80.5 73.6 2.8e-5 0.085 16 0.025 0.173 0.142
RTE,ASHA,rep3 80.5 73.2 2.4e-5 0.022 16 0.053 0.137 0.016
RTE,Opt+ASHA,rep2 81.9 73.5 2.7e-5 0.024 32 0.083 0.190 0.094
MRPC,grid 93.1/90.4 90.5/87.1 2.0e-5 0.060 16 0.100 0.100 0.100
MRPC,RS,rep2 93.2/90.7 89.6/86.1 2.4e-5 0.094 64 0.019 0.138 0.299
MRPC,RS,rep3 93.2/90.4 90.3/86.7 1.4e-5 0.003 16 0.011 0.062 0.176
MRPC,ASHA,rep3 93.3/90.7 90.3/86.8 2.7e-5 0.008 16 0.140 0.130 0.255
MRPC,Opt+ASHA,rep3 93.5/91.2 89.6/86.2 2.7e-5 0.036 16 0.094 0.153 0.291
STS-B,grid 91.2/90.8 89.3/88.4 2.0e-5 0.060 16 0.100 0.100 0.100
STS-B,ASHA,rep1 91.3/91.0 89.0/88.2 2.0e-5 0.042 16 0.004 0.061 0.247
STS-B,ASHA,rep2 91.4/91.1 89.0/88.2 2.1e-4 0.061 16 0.056 0.008 0.226
STS-B,Opt+ASHA,rep1 91.3/90.9 89.1/88.2 2.7e-5 0.052 16 0.096 0.070 0.224
Table 9: Comparison between the hyperparameter values of the best trial of grid search and the best trials (in
validationaccuracy)ofallthe11overﬁttingHPOruns(outof45)intheinitialcomparativestudyusingRoBERTa
(Table3). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 6>  </Paper ID = 179>


<Paper ID = 179> <Table 7> <Abstractive Summary> =darkgrey indicatesthevalueishigherthangridsearch; lightgrey indicatesthevalueislowerthan
gridsearch
2298RandomSearch ASHA
round0 round1 round2 round3 round0 round1 round2 round3
val test val test val test val test val test val test val test val test
56.3 65.1 ↓space ↓space
57.7 62.3 57.7 65.8 57.7 63.0 59.2 65.8
WNLI
56.3 65.8 57.7 65.1 57.7 59.6 57.7 65.1
56.3 65.1 57.7 65.1 56.3 65.1 57.7 65.8
56.8 64.4 57.7 65.3 57.2 62.6 58.2 65.6
84.1 76.8 ↑res ↓space ↓space ↑res
81.9 76.1 84.5 74.6 84.1 76.1 84.8 75.3 81.9 76.2 83.4 75.3
RTE
81.6 75.1 83.8 74.5 83.0 74.0 84.1 75.7 75.5 72.1 81.9 73.9
83.0 75.7 83.4 74.7 82.3 73.1 83.8 75.2 83.4 74.1 83.8 74.4
82.2 75.6 83.9 74.6 83.1 74.4 84.2 75.4 80.3 74.1 83.0 74.5
89.2 87.9 ↓space ↓space ↓space ↓space
90.9 87.6 90.7 86.3 90.4 86.5 90.9 87.4 90.0 87.2 90.2 87.6
MRPC
90.0 87.1 90.2 87.2 90.7 86.5 90.0 86.9 90.4 87.8 90.9 88.3
90.2 87.8 90.7 86.9 90.7 87.8 90.0 87.6 89.5 86.0 90.7 87.6
90.4 87.5 90.5 86.8 90.6 87.4 90.3 87.3 90.4 87.0 90.6 87.8
91.4 89.2 ↑res ↑res
90.8 89.1 91.5 89.4 91.3 89.2 91.5 89.8
STS-B
89.6 85.9 91.4 89.6 91.5 89.7 91.4 89.2
90.1 87.7 91.5 89.9 91.0 88.3 91.4 89.2
90.2 87.6 91.4 89.6 91.3 89.1 91.4 89.4
95.1 95.7 ↓space ↑res ↓space ↑res ↓space ↓space
95.4 95.6 93.2 93.8 96.0 94.7 95.6 95.2 95.4 95.8 95.5 95.3 95.5 95.2 95.2 94.9
SST
94.3 95.1 94.7 95.0 95.3 95.7 95.1 95.7 94.4 94.1 95.1 94.7 94.8 94.3 94.2 93.6
94.5 94.6 95.8 95.7 95.5 95.8 95.0 94.5 95.0 94.9 95.4 95.4 94.5 93.5 94.8 94.5
94.7 95.1 94.6 94.8 95.6 95.4 95.2 95.1 94.9 94.9 95.3 95.1 94.9 94.3 94.7 94.3
93.5 93.5 ↑res ↑res
93.0 92.9 93.2 93.4 92.5 92.4 93.4 93.2
QNLI
93.1 93.6 93.3 93.3 93.4 93.0 93.2 93.1
92.9 92.5 93.3 93.1 93.4 93.4 93.2 93.0
93.0 93.0 93.3 93.3 93.1 92.9 93.3 93.1
Table 10: The execution results of applying the procedure on Electra. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 7>  </Paper ID = 179>


<Paper ID = 179> <Table 8> <Abstractive Summary> =2299RandomSearch ASHA
round0 round1 round2 round3 round0 round1 round2 round3
val test val test val test val test val test val test val test val test
56.3 65.1 ↓space ↓space ↓space ↓space
60.6 64.4 62.0 64.4 57.7 62.3 59.2 65.1 59.2 65.1 57.7 65.8
WNLI
56.3 65.1 56.3 65.1 56.3 65.1 56.3 65.1 56.3 65.1 56.3 65.1
56.3 65.1 56.3 65.1 56.3 65.1 56.3 65.1 56.3 65.1 56.3 65.1
57.8 64.9 58.2 64.9 56.8 64.2 57.3 65.1 57.3 65.1 56.8 65.3
79.8 73.9 ↓space ↓space ↓space ↓space
81.2 73.9 80.1 72.8 81.6 72.2 80.5 73.2 80.5 73.3 79.8 72.5
RTE
80.5 73.6 81.2 72.9 75.5 72.1 80.2 74.9 82.0 72.9 79.1 73.4
79.4 73.1 79.8 73.6 79.8 72.6 80.5 74.1 80.5 73.5 79.8 73.7
80.4 73.5 80.4 73.1 78.9 72.3 80.8 74.1 80.5 73.3 79.5 73.2
90.4 87.1 ↓space ↓space ↓space
90.7 86.1 90.7 86.9 91.2 86.7 90.7 86.8 91.4 87.7
MRPC
90.4 86.7 90.4 88.0 90.2 87.6 90.4 87.4 90.4 87.2
90.9 87.2 91.2 87.2 90.4 87.0 91.4 87.6 90.4 87.6
90.7 86.7 90.8 87.4 90.6 87.1 90.8 87.3 90.8 87.5
65.1 61.7 ↑res ↓space ↓space ↓space ↓space
64.3 60.1 66.0 59.3 65.8 59.2 65.3 60.2 65.5 59.5 65.0 60.9 65.9 58.2
CoLA
64.6 60.5 65.0 60.5 65.0 61.7 65.4 62.5 63.6 58.8 62.9 58.4 63.9 58.9
63.5 56.8 64.4 60.3 65.2 60.7 64.6 58.5 64.6 60.0 64.9 62.0 64.4 59.0
64.1 59.1 65.1 60.0 65.3 60.5 65.1 60.4 64.5 59.4 64.3 60.4 64.7 58.7
90.8 88.4 ↓space ↓space ↓space
90.8 88.3 91.0 88.9 91.1 88.2 90.9 88.3 90.8 88.6
STS-B
90.8 88.9 90.8 88.6 91.0 88.2 90.8 88.5 91.0 88.5
91.2 88.7 90.9 88.9 90.7 88.5 90.9 88.4 90.9 88.7
90.9 88.6 90.9 88.8 90.9 88.3 90.8 88.4 90.9 88.6
Table 11: The execution results of applying the procedure on RoBERTa. </Abstractive Summary> <Extractive Summary> Thus one potential ex-
A.3 ChoosingtheHyperparametertoFix
planationoftheobservedoverﬁttinginthiswork
Thehyperparametersofthebesttrialsinoverﬁting isduetodifferentdistributionbetweenvalidation
runs are shown in Table 8 and Table 9.  </Extractive Summary>  </Table 8>  </Paper ID = 179>


<Paper ID = 18> <Table 0> <Abstractive Summary> =Then,theﬁnalmultitasklossis Dataset train dev test
#sentences 14,987 3,466 3,684
aweightedsumofthethreelosses: CoNLL2003
#entities 23,499 5,942 5,648
#sentences 3,394 1,009 1,287
L = LNER+LType+LBdy (13) WNUT2017 #entities 3,160 1,250 1,589
#sentences 16,691 1,853 3,855
JNLPBA
#entities 46,388 4,902 8,657
4 Experiments
Table 1: Statistics of CoNLL2003, WNUT2017, and
Inthissection,weﬁrstintroducethedatasets,base-
JNLPBAdatasets. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 18>


<Paper ID = 180> <Table 0> <Abstractive Summary> =MEDIANvs.BT 9% 41% 55%
Inparticular,thepairedt-testistheonethatmost
Table 1: Disagreement between aggregation mecha- often ﬁnds differences to be signiﬁcant (for 41%
nisms. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 180>


<Paper ID = 180> <Table 1> <Abstractive Summary> =Forsuchinstances,
weﬁrstdrawthescoresforeachsystemsaccording
Table 2: Example of two systems S and B with their
to their distribution and then perform a random
strengthsλ andλ ,i∈[1,5]associatedtoeachtype
ti,S ti,B permutation,sothateachsystemreceivesascore
oftestinstances. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 180>


<Paper ID = 180> <Table 2> <Abstractive Summary> =Inthiscontext,
Arrow (1950) proved that no aggregation mecha- Table 4: Global disagreement (as in Table 1) be-
nismwithmorethan2votersand3possibilitiescan tween aggregation mechanisms repeated with Elo and
TrueSkill. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 180>


<Paper ID = 181> <Table 0> <Abstractive Summary> =Table 2: Experimental results on the development set
ofSParCandCoSQL.‘Indep.’ and‘Dep.’ areshortfor
BenchmarkApproach WeconsiderthreeSOTA
‘context-independent’and‘context-dependent’. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 181>


<Paper ID = 181> <Table 1> <Abstractive Summary> =4 Independent
y3 selectavg(t3.population)fromcountryast1joincountrylanguageast2joincityast3wheret2.language=“Dutch”
4
Table 15: Question sequence examples in CoSQL. </Abstractive Summary> <Extractive Summary> Table 1 presents the contextual dependency char-
4.1 DataStatistics acteristic of CHASE.  </Extractive Summary>  </Table 1>  </Paper ID = 181>


<Paper ID = 182> <Table 0> <Abstractive Summary> =Label: Negative
3 Method
Prediction: Positive
AsstatedintheobservationsinSection2,weex-
Table 3: Wrong predictions made by the FreeLB ver-
plorestrategiesthatcouldimprovethesensitivity
sionofBERTonthecontrastiveset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 182>


<Paper ID = 182> <Table 1> <Abstractive Summary> =And
wealsouseaSOTAalgorithm,BertScore(Zhang
et al., 2020) to compute similarity scores of sen-
Table 7: The max Hits(%) on all layers of the
Transformer-based encoder. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 182>


<Paper ID = 183> <Table 0> <Abstractive Summary> =WhileforTSNTM,we
noticethatthereisalowdegreeofdiscrimination
Table 2: CLNPMI, TU, and OR scores of tree-
betweentopicsatthesecondandthethirdlevels. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 183>


<Paper ID = 185> <Table 0> <Abstractive Summary> =Inotherwords,therearenoabsolutelycor-
2370SemanticSpace EmotionSpace
SourceEmotions Human
GloVe SSWE EWE TextCNN BiLSTM BERT
admiration joy disgust anger anger joy joy joy
amusement joy anger joy disgust joy joy joy
annoyance anger anger disgust anger anger anger anger
approval joy fear disgust fear surprise surprise joy
caring joy anger anger anger sadness sadness sadness
confusion surprise anger joy anger surprise surprise surprise
curiosity surprise fear surprise surprise surprise surprise surprise
desire joy fear joy joy joy joy joy
disappointment sadness fear fear anger sadness sadness sadness
disapproval anger disgust anger disgust anger anger disgust
embarrassment sadness disgust sadness fear disgust disgust disgust
excitement joy anger joy joy joy joy joy
gratitude joy joy joy joy joy joy joy
grief sadness anger disgust sadness sadness sadness sadness
love joy joy surprise surprise joy joy joy
nervousness fear anger joy sadness fear fear fear
optimism joy anger joy anger joy joy joy
pride joy anger joy anger joy joy joy
realization surprise sadness joy joy surprise surprise surprise
relief joy anger joy anger joy joy joy
remorse sadness disgust anger sadness sadness sadness sadness
Score — 3 10 7 18 18 18
Table 4: The results of mapping Cowen taxonomy to Ekman taxonomy. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 185>


<Paper ID = 185> <Table 1> <Abstractive Summary> =I 0.917 0.873 1.000 0.867
T 0.936 0.926 0.867 1.000 Acknowledgments
Table 5: Pearson correlation coefﬁcients between co- Wewouldliketothanktheanonymousreviewers
sinesimilarities. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 185>


<Paper ID = 186> <Table 0> <Abstractive Summary> =We collect total 500 sample texts from
2378Sentiment 0.81 Sarcasm 0.38 positive </s> 
Politeness 0.75 Country 0.38 informal </s> 
FoGrmeanlditeyr 00..4487 EducatioHnulemvoerl 00..3376 ...
Emotion:Valence 0.43 Age 0.35
Pretrained  Pretrained 
Emotion 0.42 Politicalview 0.32
Encoder Decoder
Romance 0.42 Metaphor 0.29
Offense 0.41 Emotion:Arousal 0.26
Ethnicity 0.41 Emotion:Dominance 0.24
STYLE: sentiment TEXT: I feel happy.. <s> positive 
Table 3: Annotator’s agreement (Krippendorff’s al- STYLE: formality TEXT: what the hell.. <s> informal 
pha). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 186>


<Paper ID = 186> <Table 1> <Abstractive Summary> =31.3 39.5 43.6 48.3 42.9 46.4 - - -
TI DailyDialog 12.8 27.6 48.7 46.9 49.2 49.0 22.4 26.9 33.3
C
FE Offense HateOffens 28.5 68.2 91.9 92.4 91.7 93.4 34.4 36.9 45.9
F
A
Romance ShortRomance 33.3 90.6 99.0 100.0 98.0 99.0 53.9 55.2 48.2
Sentiment SentiBank 33.3 82.8 96.9 97.4 97.0 96.6 80.4 79.7 84.6
Gender PASTEL 25.7 45.5 47.7 47.9 47.3 50.5 29.2 32.4 42.3
L Age PASTEL 7.3 15.2 23.0 21.7 21.3 23.3 36.1 27.0 28.1
A
N Country PASTEL 49.2 49.3 54.5 49.3 51.8 58.4 49.4 46.7 48.7
O
S Politicalview PASTEL 20.0 33.5 46.1 44.6 44.3 46.7 27.7 20.6 21.3
R
E Education PASTEL 4.7 15.0 24.6 22.4 21.4 27.3 10.3 11.4 15.7
P
Ethnicity PASTEL 8.5 17.6 24.4 22.5 22.4 23.8 10.8 8.8 9.1
Avearge 26.8 56.9 64.8 64.9 64.2 65.9 39.6 38.4 40.7
Table 4: Individual style (left) and cross style (right) classiﬁcation in XSLUE. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 186>


<Paper ID = 186> <Table 2> <Abstractive Summary> =Excitementemotion 2.7
VUA Offense 3.0
PASTEL(Ethnicity) Mastereducation Doctorateeducation 4.2
TroFi Caucasian NoHispanic 4.2
-1 0 1 2 3 4
Table 5: Some example pairs of positively (or neg-
Figure 2: F1 improvement by our cross model over
atively for “No”) correlated styles with human judge-
BERTinindividualstyleclassiﬁcationtask. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 186>


<Paper ID = 186> <Table 3> <Abstractive Summary> =Outputwithoutstylecondition:
Sentiment Politeness Formality Offense
‘Everynaturaltextis’aseriesofimages.Theimages,asthey XSLUE(F1) 96.5 71.2 89.8 93.3
areknownwithinthetext,aretheprimarymeansbywhicha Auto(F1) 73.7 70.1 60.0 63.7
textisread,andthereforeare.. Human(1st) 3.4/3.5/2.8 3.6/3.6/3.3 3.4/3.7/3.1 4.0/3.9/3.3
Human(2nd) 2.4/3.2/2.3 2.8/3.4/2.7 2.9/2.8/2.0 2.9/3.3/2.5
OutputconditionedonFormality(F1=89.9%)
:Formal(left)andInformal(right)
Table 7: Automatic and human evaluation on gen-
‘Everynaturaltextis’differ- ‘Every natural text is’ a bit erated text. </Abstractive Summary> <Extractive Summary> siﬁer by choosing the majority label in training
Table 3 shows annotator’s agreement on the data, Bidirectional LSTM (biLSTM) (Hochreiter
cross-set.  </Extractive Summary>  </Table 3>  </Paper ID = 186>


<Paper ID = 186> <Table 4> <Abstractive Summary> =In
Table 8: Stylistic appropriateness scores (human
judgement) on model-generated text with Likert scale the cross-style setting, we also faced a new chal-
(left) and style correlation scores from the correlation lenge;styledrift,wheredifferentstylesarecoupled
matrix(right)betweenpolitenessandsentiment. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 4>  </Paper ID = 186>


<Paper ID = 187> <Table 0> <Abstractive Summary> =2391SST-3 Yelp Amazon Round1 Round2
Dev Test Dev Test Dev Test Dev Test Dev Test
Positive 85.1 89.0 88.3 90.5 89.1 89.4 33.3 33.3 58.4 63.0
Negative 84.1 84.1 88.8 89.1 86.6 86.6 33.3 33.3 61.0 63.1
Neutral 45.4 43.5 58.2 59.4 53.9 53.7 33.3 33.3 38.4 44.3
Macroavg 71.5 72.2 78.4 79.7 76.5 76.6 33.3 33.3 52.6 56.8
Table 3: Model 0 performance (F1 scores) on external assessment datasets (Table 1). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 187>


<Paper ID = 187> <Table 1> <Abstractive Summary> =facewecreatedforDynaSentaswellthecomplete
Table 6: Estimates of human performance (F1 scores) instructions and training items given to workers. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 187>


<Paper ID = 187> <Table 2> <Abstractive Summary> =NoMajority 15 24 25
C.3 DataCollectionPipeline Table 11: Comparison of the SST-3 labels (dev set)
withlabelsderivedfromourseparatevalidation. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 187>


<Paper ID = 188> <Table 0> <Abstractive Summary> =Fordifferentevaluation
a φ f s θ s f
2409Sentiment Formality
Yelp Amazon GAB Music Family
Methods Cgeonn.trol SIntvyelersion Cgeonn.trol SIntvyelersion CGoenn.trol StyleInversion CGoenn.trol StyleInversion CGoenn.trol StyleInversion
H-NH NH-H C-F F-C C-F F-C
ctrlGen 0.72 0.52(0.71) 0.62 0.65(0.66) 0.50 0.22(0.52) 0.30(0.73)* 0.63 0.18(0.40) 0.21(0.52) 0.60 0.21(0.50)* 0.38(0.65)
DAE 0.95 0.49(0.55) 0.84 0.32(0.43) 0.98* 0.12(0.51) 0.05(0.05) 0.69* 0.07(0.30) 0.24(0.32) 0.71* 0.12(0.39) 0.30(0.31)
probTrans - 0.63(0.80) - 0.40(0.98) - 0.02(0.02) 0.01(0.05) - 0.22(0.62)* 0.44(0.68)* - 0.19(0.71) 0.55(0.64)*
entangleGen - 0.83(0.86) - 0.67(0.95)* - 0.55(0.97)* 0.16(0.72) - 0.11(0.54) 0.34(0.54) - 0.19(0.45) 0.37(0.61)
CTVAE-NR 0.82 0.51(0.60) 0.69* 0.40(0.57) - - - - - - - - -
CTVAE 0.95 0.72(0.88)* 0.84 0.72(0.97) 0.98 0.58(0.93) 0.31(0.98) 0.79 0.40(0.62) 0.53(0.77) 0.87 0.28(0.73) 0.58(0.85)
Table 2: Controlled generation and Style inversion (Related content) accuracy achieved by different methods
acrossdatasetsforτ =0.71. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 188>


<Paper ID = 189> <Table 0> <Abstractive Summary> =t <t
can be formulated as taking the X = [x ,...,x ] Therefore,foreachy inY ,weﬁrstneedtouse
1 n t <t
as input and outputting a target sequence Y = the following Index2Token module to conduct a
241914res 14lap 15res 16res
Dataset Subtasks
#s #a #o #p #s #a #o #p #s #a #o #p #s #a #o #p
train 304436993484 - 304823732504 - 131511991210 - - - - - AE,OE,ALSC,
D
17 test 800 11341008 - 800 654 674 - 685 542 510 - - - - - AESC
train 16272643 - - 11581634 - - 754 1076 - - 10791512 - -
D AOE
19
test 500 865 - - 343 482 - - 325 436 - - 329 457 - -
train 1300 - - 2145 920 - - 1265 593 - - 923 842 - - 1289
AE,OE,ALSC,AOE,
D20a dev 323 - - 524 228 - - 337 148 - - 238 210 - - 316 AESC,Pair,Triplet
test 496 - - 862 339 - - 490 318 - - 455 320 - - 465
train 1266 - - 2338 906 - - 1460 605 - - 1013 857 - - 1394
AE,OE,ALSC,AOE,
D20b dev 310 - - 577 219 - - 346 148 - - 249 210 - - 339 AESC,Pair,Triplet
test 492 - - 994 328 - - 543 148 - - 485 326 - - 514
Table 1: The statistics of four datasets, where the #s, #a, #o, #p denote the numbers of sentences, aspect terms,
opinionterms,andthe<a,o>pairs,respectively. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 189>


<Paper ID = 189> <Table 1> <Abstractive Summary> =Ourmethodachieves
nearly 13, 9, 7, 12 points improvements on each Table 7: The errors for Triplet on the test set of the
dataset for the recall scores compared with other D20b. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 189>


<Paper ID = 19> <Table 0> <Abstractive Summary> =Weformalizethetaskofeventargumentex-
Table 1: Experimental results of CNN and its variant traction as a Seq2Seq-like learning problem
onACE2005. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 19>


<Paper ID = 19> <Table 1> <Abstractive Summary> =Moreentitiesusuallymeanmorecom-
215Model Subset-O Subset-N
DMBERT
64 HMEAE DMBERT 56.4 59.4
BERT(Inter)
BERT(Intra) HMEAE 58.8 59.6
62
BERD BERT(Inter) 57.3 58.8
60 BERT(Intra) 58.5 59.2
Score(%)58 BERD 60.5 60.1
F1- Table 3: Comparison on sentences with and with-
56
out overlapping entities (Subset-O v.s. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 19>


<Paper ID = 190> <Table 0> <Abstractive Summary> =(2014)’s method has a
Table 2: Slot candidate ranking average precision for slightly higher precision, but our recall is much
alldatasets(seeSections5.2and5.3fordetails). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 190>


<Paper ID = 190> <Table 1> <Abstractive Summary> =A compari-
Ours 0.359 0.207 0.101 0.117 0.194
sonbetweenOurs-notagandOurs-fullshowsthat
Table 3: Slot merging evaluation using RI and NMI applying the slot tagger improves both precision
(cf. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 190>


<Paper ID = 190> <Table 2> <Abstractive Summary> =Al-
Table 5: Cluster assignment accuracy of our methods though candidates in the CamRest676 data are
if we interpret the clustering as user intent detection. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 190>


<Paper ID = 190> <Table 3> <Abstractive Summary> =However, they are
Ours-TextRank 0.514±0.006
typicallyjoinedwithsimilarcandidatesinthemerg-
Table 6: Ablation study of slot ranking features on ingprocess. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 190>


<Paper ID = 190> <Table 4> <Abstractive Summary> =0.771 0.486 0.813 0.529 0.384 0.579 0.362 0.462 0.701 0.583 – –
Ours-nocl 0.537 0.347 0.616 0.371 0.101 0.218 0.244 0.340 0.634 0.595 0.662 0.704
Ours-notag 0.561 0.586 0.690 0.688 0.369 0.607 0.335 0.575 0.715 0.642 0.685 0.623
Ours-nothr 0.636 0.549 0.585 0.566 0.458 0.575 0.394 0.561 0.701 0.687 0.710 0.697
Ours-full 0.752 0.643 0.718 0.703 0.494 0.750 0.373 0.606 0.684 0.672 0.703 0.725
Table 7: Precision (P) and recall (R) values slot tagging performance comparison among different methods (see
Section 5.2; frames are used as weak supervision in all setups, the rightmost column on ATIS additionally uses
NER).Wecanseeconsistentrecallimprovementwhenusingourslottagger. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 4>  </Paper ID = 190>


<Paper ID = 190> <Table 5> <Abstractive Summary> =SlotF1 JointGoalAccuracy EntityMatchRate
method
onto no-onto onto no-onto onto no-onto
Jinetal.supervised 0.969±.001 0.967±.001 0.911±.002 0.897±.002 0.892±.004 0.869±.004
Jinetal.unsupervised 000...888777333±.003 0.719±.002 000...666333222±.009 0.385±.003 0.398±.010 0.019±.002
Ours-full(unsupervised) 0.821±.004 000...777555666±.004 0.533±.007 000...444666555±.007 000...444444555±.009 000...333666888±.008
Table 9: Evaluation on the downstream task of dialogue generation on CamRest676 data. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 5>  </Paper ID = 190>


<Paper ID = 193> <Table 0> <Abstractive Summary> =√
SpeechDisﬂuency(SD)
ForexampleinTable2,“Cambridge”isreplaced
by“Liverpool”,wherebothbelongtothesameslot
Table 1: The capacity that each augmentation method
evaluates, including Language Variety (LV), Speech name“dest”(destination). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 193>


<Paper ID = 193> <Table 1> <Abstractive Summary> =DA attraction{inform(dest=Cambridge)}
Table 3: A pair of examples that consider contextual
Syno. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 193>


<Paper ID = 193> <Table 2> <Abstractive Summary> =Table 7: Statistics of augmented MultiWOZ data and
Classiﬁcation based models (Hakkani-Tu¨r et al.,
their results of quality annotation. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 193>


<Paper ID = 193> <Table 3> <Abstractive Summary> =Original 91.33 88.26 87.20 77.98 83.67 84.28 -7.05 /
MILU
Augmented 91.39 90.01 88.04 86.97 89.54 88.64 -2.75 +4.36
Original 93.40 90.96 88.51 82.35 85.98 86.95 -6.45 /
BERT
Augmented 93.32 92.23 89.45 89.86 92.71 91.06 -2.26 +4.11
Original 93.28 91.27 88.95 81.16 87.18 87.14 -6.14 /
ToD-BERT
Augmented 93.29 92.40 89.71 90.06 92.85 91.26 -2.03 +4.12
Original 90.97 85.25 87.40 71.06 77.66 80.34 -10.63 /
CopyNet
Augmented 90.49 89.19 89.53 85.69 89.83 88.56 -1.93 +8.22
Original 91.53 85.35 88.23 80.74 84.33 84.66 -6.87 /
GPT-2
Augmented 91.59 90.26 89.92 86.55 90.55 89.32 -2.27 +4.66
(b)MultiWOZ
Table 8: Robustness test results. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 193>


<Paper ID = 193> <Table 4> <Abstractive Summary> =Table 9: Features of base models. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 4>  </Paper ID = 193>


<Paper ID = 193> <Table 5> <Abstractive Summary> =3showshowtheperformanceofBERTand Table 10: Ablation study between augmentation ap-
GPT-2 changes on MultiWOZ when the ratio of proaches for two models on MultiWOZ. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 5>  </Paper ID = 193>


<Paper ID = 193> <Table 6> <Abstractive Summary> =88.90 0.64 91.27 0.48 BERT Augmented 93.32 91.06 69.12
-Insert 88.90 0.64 91.30 0.51
-Delete 88.97 0.71 91.20 0.41
Table 12: User evaluation results on MultiWOZ. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 6>  </Paper ID = 193>


<Paper ID = 193> <Table 7> <Abstractive Summary> =IntheSDutterance,therepair
Table 14: Robustness on different schemes on Multi-
termfoolsallthemodels. </Abstractive Summary> <Extractive Summary> In summary, all the high
ChangeRate/% HumanAnnot./% scores in Table 7 demonstrate that LAUG makes
Method
Char Word Slot Utter. monlyregardedasamulti-labelclassiﬁcationtask,
andslottaggingisoftentreatedasasequencelabel-
Table 7 shows the change rates in different as-
ingtaskwithBIOformat (RamshawandMarcus,
7SeeappendixforthehyperparametersettingofLAUG.  </Extractive Summary>  </Table 7>  </Paper ID = 193>


<Paper ID = 194> <Table 0> <Abstractive Summary> =Models Openvocabulary Encoder Decoder Trackingstrategy
SpanPtr(XuandHu,2018) (cid:88) RNN Extractive scratch-based
TRADE(Wuetal.,2019) (cid:88) RNN Generative scratch-based
BERTDST(ChaoandLane,2019) (cid:88) BERT Extractive previous-based
SOMDST(Kimetal.,2020) (cid:88) BERT Generative previous-based
SUMBT(Leeetal.,2019) × BERT Classiﬁcation previous-based
Table 2: Statistics on the characteristics of the 5 baselines studied in the paper. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 194>


<Paper ID = 194> <Table 1> <Abstractive Summary> =Base,Uncased)whichhas12hiddenlayersof768 Itcanbefoundthatsomedialoguestatetracking
unitsand12self-attentionheads,whileRNNuses modelsdonottaketheappropriategranularity,and
2https://github.com/clovaai/som-dst their performance is greatly improved when they
3https://github.com/SKTBrain/SUMBT aretrainedwiththethecontextofappropriategran-
2484WOZ2.0 DSTC2 MultiWOZ2.1
Models TG IG
Jointacc Slotacc Jointacc Slotacc Jointacc Slotacc
0* 0* 0.4455 0.7475 0.6234 0.8461 0.4415 0.9570
-1 -1 0.5012 0.7786 0.5829 0.8251 0.3868 0.9495
SpanPtr
-2 -2 0.5881 0.8121 0.4825 0.7728 0.3726 0.9499
-3 -3 0.6330 0.8350 0.4737 0.7628 0.3745 0.9507
0* 0* 0.5808 0.8186 0.6493 0.8590 0.4420 0.9655
-1 -1 0.5194 0.7833 0.5013 0.7834 0.3963 0.9613
TRADE
-2 -2 0.5680 0.8107 0.4185 0.7488 0.3528 0.9569
-3 -3 0.5292 0.7886 0.5171 0.7963 0.3564 0.9552
1* 1* 0.8194 0.9307 0.6395 0.8537 0.4140 0.9584
2 2 0.8220 0.9318 0.5830 0.8271 0.4586 0.9636
BERTDST
3 3 0.8190 0.9318 0.5614 0.8103 0.4772 0.9646
4 4 0.8256 0.9344 0.5666 0.8152 0.4917 0.9659
1* 1* 0.8540 0.9471 0.6975 0.8828 0.5029 0.9715
2 2 0.8274 0.9341 0.7022 0.8808 0.5179 0.9730
SOMDST
3 3 0.8280 0.9356 0.7121 0.8851 0.5128 0.9720
4 4 0.8620 0.9491 0.7176 0.8882 0.5085 0.9718
Table 3: Joint accuracy and slot accuracy on WOZ2.0, DSTC2 and MultiWOZ2.1 when the same granularities
are used in the training and inference phases. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 194>


<Paper ID = 195> <Table 0> <Abstractive Summary> =replyingtoorcontinuingtheﬁrst
overlap Mean Mode(freq)
topicwithoutanyattentionpaidtothesecondtopic)
utt.-topics 0.842 1.0(1274)
utt.-KGpath 0.751 0.667(451) oroff-topicwhentheutterancehadnothingtodo
witheitherofthetwotopics(e.g.randomgreetings
Table 3: Overlap in entities between transition utter-
orgenericquestions). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 195>


<Paper ID = 195> <Table 1> <Abstractive Summary> =Spearmanρ Pearsonr The initial inter-annotator agreement was 71%,
Cambridge 0.039∗ 0.046∗ classiﬁedassubstantial(Krippendorff’sα = 0.34),
PDTB3 0.003 0.001
after which the annotators collaborated to reach
turnlength 0.139 −0.001
a consensus annotation for each of the examples
Table 4: Correlations between the KG distance be- that presented a disagreement. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 195>


<Paper ID = 196> <Table 0> <Abstractive Summary> =simpleradversarialtrainingmethodbasedonthe
2509model Spider Spider-Syn Approach Spider Spider-Syn
GNN+SPR(Boginetal.,2019a) 48.5% 23.6%
SPR 69.7% 48.2%
IRNet+SPR(Guoetal.,2019) 53.2% 28.4%
RAT-SQL+SPR(Wangetal.,2020) 62.7% 33.6% SPRSYN 67.8% 59.9%
RAT-SQLB+SPR(Wangetal.,2020) 69.7% 48.2% SPR 68.1% 58.0%
SPR&SYN
ADV 48.7% 27.7%
Table 1: Exact match accuracy on the Spider and GLOVE
Spider-Syndevelopmentset,wheremodelsaretrained ADVBERT 68.7% 58.5%
ontheoriginalSpidertrainingset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 196>


<Paper ID = 196> <Table 1> <Abstractive Summary> =SPR+ManualMAS 67.4% 62.6%
SPR+AutoMAS 68.7% 56.0%
SQLComponent Spider Spider-Syn
Table 3: Exact match accuracy on the Spider and
SELECT 0.910 0.699
Spider-Syn development set. </Abstractive Summary> <Extractive Summary> 4.2 ResultsofModelsTrainedonSpider
WecomparetheresultofRAT-SQL trainedon
B
Table 1 presents the exact matching accuracy of Spider(SPR)asabaselinewithotherapproaches.  </Extractive Summary>  </Table 1>  </Paper ID = 196>


<Paper ID = 196> <Table 2> <Abstractive Summary> =Using BERT for input em-
KEYWORDS 0.897 0.876
beddingsufferslessperformancedegradationthan
modelswithoutBERT,butthedropisstillsigniﬁ-
Table 2: F1 scores of component matching of
cant. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 196>


<Paper ID = 197> <Table 0> <Abstractive Summary> =3https://github.com/slundberg/shap
4https://github.com/marcotcr/lime
5https://github.com/commonsense/conceptnet5/ 7https://nlp.stanford.edu/projects/snli/snli 1.0.zip
6https://dictionary.cambridge.org/ 8https://github.com/OanaMariaCamburu/e-SNLI
2520Table 1: Different types of explanations, including token-level explanation, e-SNLI explanation and contrastive
explanation.Theexplanationofe-SNLIexplainswhythelabelofagivenpairiscontradiction,whilethecontrastive
explanationspeciﬁeswhythelabeliscontradictionandnotneutralorentailment. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 197>


<Paper ID = 197> <Table 1> <Abstractive Summary> =toextracthiddenrepresentationsandsetthelearn-
ing rate to 2e-5, dropout to 0.02, batch size to 8 Table 3: The accuracy (%) of our method compared
withRoBERTa-largeandBERT-largeonSNLI. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 197>


<Paper ID = 198> <Table 0> <Abstractive Summary> =(2017)) 74.40 85.59 85.18 +SG-OPT 82.47 87.42 95.40 88.92 86.20 91.60 74.21 86.60
MBERT BERT-large
+CLS 30.57 29.38 24.97 +Mean 84.38 89.01 95.60 86.69 89.20 90.90 72.79 86.94
+Meanpooling 51.09 54.56 54.86 +WK 82.68 87.92 95.32 87.25 87.81 91.18 70.13 86.04
+WKpooling 50.38 55.87 54.87 +SG-OPT 86.03 90.18 95.82 87.08 90.73 94.65 73.31 88.26
+Contrastive(BT) 54.24 68.16 73.89
+Contrastive(SG) 57.09 78.93 78.24 SBERT-base
+Contrastive(SG-OPT) 58.52 80.19 78.03 +Mean 82.80 89.03 94.07 89.79 88.08 86.93 75.11 86.54
+WK 82.96 89.33 95.13 90.56 88.10 91.98 76.66 87.82
+SG-OPT 83.34 89.45 94.68 89.78 88.57 87.30 75.26 86.91
Table 3: Results on SemEval-2017 Task 1: Track 1
(Arabic),Track3(Spanish),andTrack5(English). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 198>


<Paper ID = 198> <Table 1> <Abstractive Summary> =A.1 Hyperparameters
A.4 GLUEExperiments
Hyperparameters Values
Randomseed 1,2,3,4,1234,2345,3456,7890 Models QNLI SST2 COLA MRPC RTE
Evaluationstep 50
Epoch 1 BERT-base90.97±0.4991.08±0.7356.63±3.8287.09±1.8762.50±2.77
Batchsize(b) 16 +SG-OPT 91.28±0.2891.68±0.4156.36±3.9886.96±1.1162.75±3.91
Optimizer AdamW(β1,β2=(0.9,0.9))
Learningrate 0.00005
Table 10: Experimental results on a portion of the
Earlystoppingendurance 10
τ 0.01 GLUEvalidationset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 198>


<Paper ID = 198> <Table 2> <Abstractive Summary> =RoBERTa-base
+Notuning CLS 45.41 61.89 16.67 45.57 30.36 55.08 56.98 44.57
+Notuning Mean 54.53 62.03 32.11 56.33 45.22 61.34 61.98 53.36
+Notuning WK 35.75 54.69 20.31 36.51 32.41 48.12 46.32 39.16
+Contrastive(BT) CLS 79.93±1.08 71.97±1.00 62.34±2.41 78.60±1.74 68.65±1.48 79.31±0.65 77.49±1.29 74.04±1.16
+Contrastive(SG) CLS 78.38±0.43 69.74±1.00 62.85±0.88 78.37±1.55 68.28±0.89 80.42±0.65 77.69±0.76 73.67±0.62
+Contrastive(SG-OPT) CLS 77.60±0.30 68.42±0.71 62.57±1.12 78.96±0.67 69.24±0.44 79.99±0.44 77.17±0.24 73.42±0.31
RoBERTa-large
+Notuning CLS 12.52 40.63 19.25 22.97 14.93 33.41 38.01 25.96
+Notuning Mean 47.07 58.38 33.63 57.22 45.67 63.00 61.18 52.31
+Notuning WK 30.29 28.25 23.17 30.92 23.36 40.07 43.32 31.34
+Contrastive(BT) CLS 77.05±1.22 67.83±1.34 57.60±3.57 72.14±1.16 62.25±2.10 71.49±3.24 71.75±1.73 68.59±1.53
+Contrastive(SG) CLS 76.15±0.54 66.07±0.82 64.77±2.52 71.96±1.53 64.54±1.04 78.06±0.52 75.14±0.94 70.95±1.13
+Contrastive(SG-OPT) CLS 78.14±0.72 67.97±1.09 64.29±1.54 76.36±1.47 68.48±1.58 80.10±1.05 76.60±0.98 73.13±1.20
Table 11: Performance of RoBERTa on STS tasks when combined with different sentence embedding methods. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 198>


<Paper ID = 199> <Table 0> <Abstractive Summary> =Train Dev
#ofsamples 8659 1034
(x Wh )(x Wh )T
γh =softmax si sq qj sk , #ofdatabases 146 20
ji j (cid:112)d/H Avg#ofquestionnodes 13.4 13.8
Avg#oftablenodes 6.6 4.5
H Avg#ofcolumnnodes 33.1 25.8
(cid:88)
x˜ =( (cid:110) γhx Wh )W , Avg#ofnodes 53.1 44.1
si ji qj sv so
Avg#ofactions 16.3 15.4
h=1 j
where Wshq,Wshk,Wshv ∈ Rd×d/H and Wso ∈ Table 1: Statistics for dataset Spider. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 199>


<Paper ID = 2> <Table 0> <Abstractive Summary> =G1 G2 G3 Number of label suggestion corrections (G2)
Acc IAA Acc IAA Acc IAA
Refute 10 25 16 0
Round1 .74 .48 .90 .76 .84 .62 80
Round2 .68 .47 .92 .81 .82 .67
Total .71 .48 .91 .78 .83 .65 Support 50 51 0 27 60
N
u
m
Table 3: Annotation accuracy (Acc) and IAA (Fleiss’ be
r
40
κ) on the quality control instances for each annotator Comment 99 0 46 42
groupandround. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 2>


<Paper ID = 20> <Table 0> <Abstractive Summary> =225ACE05 SciERC ACE05 SciERC
Settings Model Parameters W Rel Speed Rel Speed
Ent Rel Ent Rel
(F1) (sent/s) (F1) (sent/s)
Default 88.8 64.3 68.4 36.9 Z&C(2020) 219M 100 64.6 14.7 36.7 19.9
Z&C(2020)† 219M 100 - 237.6 - 194.7
w/osymmetryloss 88.9 64.0 67.3 35.5
UNIRE 110M 100 63.6 340.6 34.0 314.8
w/oimplicationloss 89.0 63.3 68.0 37.1
UNIRE 110M 200 64.3 194.2 36.9 200.1
w/ologitdropout 88.8 61.8 66.9 34.7
harddecoding 110M 200 34.6 139.1 17.8 113.0
w/ocross-sentencecontext 87.9 62.7 65.3 32.1
harddecoding 74.0 34.6 46.1 17.8 Table 5: Comparison of accuracy and efﬁciency on
ACE05andSciERCtestsetswithdifferentcontextwin-
Table 4: Results (F1 score) with different settings dowsizes. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 20>


<Paper ID = 200> <Table 0> <Abstractive Summary> =Theﬁrst
2562Stage(s) Stage(s)
VQA GQA NLVR2 IR ZS-IR TR ZS-TR
Tasksused
count used test dev test dev test-p avg avg avg avg
None vanilla None 68.1 55.71 51.07 55.27 - 58.07 -
MLMMRFRMOCTITS
70.25 57.66 70.23 73.86 54.64 78.3 59.73
ITM HS
S
Single -ITM HS 69.87 57.48 70.98 71.46 51.79 75.6 53.33
-ITM HS -TITS 69.79 57.47 70.73 70.17 49.38 74.1 50.3
T+P+S MLMMRFRMOCITM 70.1 57.58 72.24 74.31 59.31 77.87 63.33
MLMMRFRMOCTITS
70.71 58.39 73.85 75.68 61.53 80.27 65.47
T→S ITM HSIFRS
Two -IFRS 70.54 58.4 73.93 76.08 60.5 80.6 65.03
MLMMRFRMOCTITS
70.58 57.96 72.96 74.81 57.66 79.5 61.13
P→S ITM HSTITP
-TITP 70.52 58.17 71.18 75.49 59.28 80.4 62.73
MLMMRFRMOCTITS
71.1 58.7 74.72 76.55 63.01 80.83 68.6
T→P→S ITM HSIFRSTITP
Three -TITP 71.01 58.3 74.48 76.07 63.07 80.96 67.77
MLMMRFRMOCTITS
S→P→T 69.43 57.98 56.75 71.03 - 74.87 -
ITM HSIFRSTITP
MLMMRFRMOCTITS
P→T→S 70.92 58.05 73.62 76.69 61.29 81.63 67
ITM HSIFRSTITP
Table 4: Use VQA, GQA, NLVR2, Image-Text Retrieval (Flickr30k) downstream tasks to evaluate the MSP
methodandpre-trainingtasks. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 200>


<Paper ID = 201> <Table 0> <Abstractive Summary> =(alsoattraining),asshowninTable1(11,12),sub-
2570Model BLEU APT
22.8
SWBD 22.70 62.83
SWBD+RandomCxn 22.31 61.16 22.6
IMED 22.86 62.56 U
E22.4
IMED+RandomCn 21.83 59.95 L
x B
IMED+RandomCn 21.99 60.01
y 22.2
IMED+RandomCn&Cn 21.76 59.67
y y
22.0
Table 2: Case-sensitive tokenized BLEU and APT for
context-awareSTwithrandomsource/targetcontextonMuST-
CEn-Detestset.Wereportaverageperformanceoverthree 63.0
runswithdifferentrandomseeds.C =2,λ=0.5.Incorrect
62.5
contexthurtsourmodel. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 201>


<Paper ID = 202> <Table 0> <Abstractive Summary> =https://github.com/hpanwar08/detectron2
2583Model FUNSD CORD SROIE Kleister-NDA
BERT 0.6026 0.8968 0.9099 0.7790
BASE
UniLMv2 0.6648 0.9092 0.9459 0.7950
BASE
BERT 0.6563 0.9025 0.9200 0.7910
LARGE
UniLMv2 0.7072 0.9205 0.9488 0.8180
LARGE
LayoutLM 0.7866 0.9472 0.9438 0.8270
BASE
LayoutLM 0.7895 0.9493 0.9524 0.8340
LARGE
LayoutLMv2 0.8276 0.9495 0.9625 0.8330
BASE
LayoutLMv2 0.8420 0.9601 0.9781 0.8520
LARGE
BROS(Hongetal.,2021) 0.8121 0.9536 0.9548 –
SPADE(Hwangetal.,2020) – 0.9150 – –
PICK(Yuetal.,2020) – – 0.9612 –
TRIE(Zhangetal.,2020) – – 0.9618 –
Top-1onSROIELeaderboard(until2020-12-24) – – 0.9767 –
RoBERTa in(Gralin´skietal.,2020) – – – 0.7930
BASE
Table 2: Entity-level F1 scores of the four entity extraction tasks: FUNSD, CORD, SROIE and Kleister-NDA. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 202>


<Paper ID = 202> <Table 1> <Abstractive Summary> =Foreachbaselineapproach,experiments
at https://rrc.cvc.uab.es/?ch=13&com=eval
areconductedusingboththeBASEandLARGE uation&task=3
2584Model Accuracy Model Fine-tuningset ANLS
BERT 89.81% BERT train 0.6354
BASE BASE
UniLMv2 90.06% UniLMv2 train 0.7134
BASE BASE
BERT 89.92% BERT train 0.6768
LARGE LARGE
UniLMv2 90.20% UniLMv2 train 0.7709
LARGE LARGE
LayoutLM (w/image) 94.42% LayoutLM train 0.6979
BASE BASE
LayoutLM (w/image) 94.43% LayoutLM train 0.7259
LARGE LARGE
LayoutLMv2 95.25% LayoutLMv2 train 0.7808
BASE BASE
LayoutLMv2 95.64% LayoutLMv2 train 0.8348
LARGE LARGE
VGG-16(Afzaletal.,2017) 90.97% LayoutLMv2LARGE train+dev 0.8529
Singlemodel(Dasetal.,2018) 91.11% LayoutLMv2LARGE+QG train+dev 0.8672
Ensemble(Dasetal.,2018) 92.21%
Top-1(30modelsensemble)
InceptionResNetV2(Szegedyetal.,2017) 92.63%
onDocVQALeaderboard - 0.8506
LadderNet(SarkhelandNandi,2019) 92.77%
(until2020-12-24)
Singlemodel(Dauphineeetal.,2019) 93.03%
Ensemble(Dauphineeetal.,2019) 93.07%
Table 4: ANLS score on the DocVQA dataset, “QG”
Table 3: Classiﬁcation accuracy on the RVL-CDIP denotesthedataaugmentationwiththequestiongener-
dataset ationdataset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 202>


<Paper ID = 202> <Table 2> <Abstractive Summary> =5https://gitlab.com/filipg/geval
2590Model Precision Recall F1
BERT 0.5469 0.6710 0.6026
BASE
UniLMv2 0.6349 0.6975 0.6648
BASE
BERT 0.6113 0.7085 0.6563
LARGE
UniLMv2 0.6780 0.7391 0.7072
LARGE
LayoutLM 0.7597 0.8155 0.7866
BASE
LayoutLM 0.7596 0.8219 0.7895
LARGE
LayoutLMv2 0.8029 0.8539 0.8276
BASE
LayoutLMv2 0.8324 0.8519 0.8420
LARGE
BROS (Hongetal.,2021) 0.8056 0.8188 0.8121
Table6: Modelaccuracy(entity-levelPrecision,Recall,F1)ontheFUNSDdataset
Model Precision Recall F1
BERT 0.8833 0.9107 0.8968
BASE
UniLMv2 0.8987 0.9198 0.9092
BASE
BERT 0.8886 0.9168 0.9025
LARGE
UniLMv2 0.9123 0.9289 0.9205
LARGE
LayoutLM 0.9437 0.9508 0.9472
BASE
LayoutLM 0.9432 0.9554 0.9493
LARGE
LayoutLMv2 0.9453 0.9539 0.9495
BASE
LayoutLMv2 0.9565 0.9637 0.9601
LARGE
SPADE(Hwangetal.,2020) - - 0.9150
BROS(Hongetal.,2021) 0.9558 0.9514 0.9536
Table7: Modelaccuracy(entity-levelPrecision,Recall,F1)ontheCORDdataset
Model Precision Recall F1
BERT 0.9099 0.9099 0.9099
BASE
UniLMv2 0.9459 0.9459 0.9459
BASE
BERT 0.9200 0.9200 0.9200
LARGE
UniLMv2 0.9488 0.9488 0.9488
LARGE
LayoutLM 0.9438 0.9438 0.9438
BASE
LayoutLM 0.9524 0.9524 0.9524
LARGE
LayoutLMv2 0.9625 0.9625 0.9625
BASE
LayoutLMv2 0.9661 0.9661 0.9661
LARGE
LayoutLMv2 (ExcludingOCRmismatch) 0.9904 0.9661 0.9781
LARGE
BROS(Hongetal.,2021) 0.9493 0.9603 0.9548
PICK(Yuetal.,2020) 0.9679 0.9546 0.9612
TRIE(Zhangetal.,2020) - - 0.9618
Top-1onSROIELeaderboard(ExcludingOCRmismatch) 0.9889 0.9647 0.9767
Table8: Modelaccuracy(entity-levelPrecision,Recall,F1)ontheSROIEdataset(until2020-12-24)
Model F1
BERT 0.779
BASE
UniLMv2 0.795
BASE
BERT 0.791
LARGE
UniLMv2 0.818
LARGE
LayoutLM 0.827
BASE
LayoutLM 0.834
LARGE
LayoutLMv2 0.833
BASE
LayoutLMv2 0.852
LARGE
RoBERTa in(Gralin´skietal.,2020) 0.793
BASE
Table 9: Model accuracy (entity-level F1) on the validation set of the Kleister-NDA dataset using the ofﬁcial
evaluationtoolkit
2591 </Abstractive Summary> <Extractive Summary> 3.3 Results
Entity Extraction Tasks Table 2 shows the
Fine-tuning LayoutLMv2 We use the [CLS]
model accuracy on the four datasets FUNSD,
outputalongwithpooledvisualtokenrepresenta-
CORD, SROIE, and Kleister-NDA, which we re-
tionsasglobalfeaturesinthedocument-levelclassi-
gard as sequential labeling tasks evaluated using
ﬁcationtaskRVL-CDIP.Fortheextractivequestion
entity-level F1 score.  </Extractive Summary>  </Table 2>  </Paper ID = 202>


<Paper ID = 203> <Table 0> <Abstractive Summary> =SST-2 MNLI CoLA STS-B CoQA SQuAD-QG CNNDM Gigaword
Model
Acc Acc-(m/mm) Mat Per Acc B4/ME/R-L R-1/2/L R-1/2/L
BERT-base 92.7 84.4/- - - - - - -
RoBERTa-base 94.8 - 63.6 - 77.4 22.15/24.58/51.12 42.31/20.04/39.49 38.65/19.66/36.04
UNIMO-base 95.1 86.8/86.7 65.4 91.0 80.2 22.78/25.24/51.34 42.42/20.12/39.61 38.80/19.99/36.27
w/osingle-modal 82.0 59.9/64.9 15.0 88.8 67.1 17.09/21.04/46.47 41.06/19.01/38.23 38.06/18.91/35.41
BERT-large 93.2 86.6/- 60.6 90.0 - - - -
RoBERTa-large 96.4 90.2/90.2 68.0 92.4 85.1 23.39/25.73/52.11 43.10/20.29/40.24 39.32/20.01/36.58
XLNet-large 95.6 89.8/- 63.6 91.8 - - - -
UniLM-large 94.5 87.0/85.9 61.1 87.7 82.5 22.12/25.06/51.07 43.33/20.21/40.51 38.45/19.45/35.75
UNIMO-large 96.8 89.8/89.5 68.5 92.6 84.9 24.59/26.39/52.47 43.51/20.65/40.63 39.71/20.37/36.88
Table 2: Comparison on the single-modal downstream tasks. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 203>


<Paper ID = 204> <Table 0> <Abstractive Summary> =The intuitive solution “Aug-
Learningrate Adam optimizer with learning rate of 0.001,
mented baseline”, which combines the missing-
ReLUactivation
modalitytrainingsetwiththefull-modalitytrain-
Table3: ImplementationDetails
ing set to train the baseline model, does signif-
train test WA UA icantly improves over the full-modality baseline
Ourfull-modalitybaseline 0.7651 0.7779
undermissing-modalitytestingconditions,which
cLSTM-MMA(Panetal.,2020) {a,v,t} {a,v,t} 0.7394 –
SSMM(Liangetal.,2020) 0.7560 0.7450 indicatesthatdataaugmentationcanhelpalleviate
Table 4: Multimodal Emotion Recognition Results on theproblemofdatamismatchbetweentrainingand
IEMOCAPunderfull-modalitycondition. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 204>


<Paper ID = 204> <Table 1> <Abstractive Summary> =AsMCTNcan-
2614TestingCondition
Dateset Model Metric
{a} {v} {t} {a,v} {a,t} {v,t} Average {a,v,t}
WA(↑) 0.4190 0.4574 0.5646 0.5488 0.7018 0.6217 0.5522 0.7651
Full-modalitybaseline
UA(↑) 0.4719 0.3966 0.5549 0.5762 0.7257 0.5971 0.5537 0.7779
WA(↑) 0.5303 0.4864 0.6564 0.6395 0.7251 0.7082 0.6243∗ 0.7617
Augmentedbaseline
UA(↑) 0.5440 0.4598 0.6691 0.6434 0.7435 0.7162 0.6293∗ 0.7767
IEMOCAP
WA(↑) 0.5658 0.5252 0.6657 0.6399 0.7294 0.7267 0.6410∗(cid:78) 0.7650
proposedMMIN
UA(↑) 0.5900 0.5160 0.6802 0.6543 0.7514 0.7361 0.6524∗(cid:78) 0.7812∗(cid:78)
WA(↑) 0.4975 0.4892 0.6242 0.5634 0.6834 0.6784 0.5894∗ –
MCTN(Phametal.,2019)
UA(↑) 0.5162 0.4573 0.6378 0.5584 0.6946 0.6834 0.5913∗ –
Full-modalitybaseline F1(↑) 0.2824 0.3295 0.4576 0.4721 0.5655 0.5368 0.4543 0.6523
Augmentedbaseline F1(↑) 0.4278 0.4185 0.5544 0.5396 0.6038 0.6295 0.5455∗ 0.6663∗
MSP-IMPROV
proposedMMIN F1(↑) 0.4647 0.4471 0.5573 0.5740 0.6188 0.6411 0.5649∗(cid:78) 0.6855∗(cid:78)
MCTN(Phametal.,2019) F1(↑) 0.3285 0.3810 0.5050 0.4683 0.5611 0.5886 0.4721∗ –
Table 5: Performance comparison under six possible missing-modality testing conditions and the full-modality
testingcondition(i.e.testingcondition“{a}”meansthatonlytheacousticmodalityisavailableandbothvisualand
textual modalities are missing. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 204>


<Paper ID = 205> <Table 0> <Abstractive Summary> =6BLEU+case.mixed+numrefs.1+smooth.exp+tok.13a
3http://opus.nlpl.eu/OpenSubtitles-v2018.php +version.1.4.14
2624Method Restricted Unrestricted Method Restricted Unrestricted
ESPnetMT∗ 27.63 - ESPnetMT∗ 18.09 -
ESPnetCascaded∗ 23.65 - ESPnetCascaded∗ 16.96 -
MT 26.9 31.1 MT 17.5 21.3
CascadedST 23.3 28.1 CascadedST 16.3 20.6
ESPnetE2EST∗ 22.33 - ESPnetE2EST∗ 16.22 -
E2EST 22.1 23.6 E2EST 16.7 17.7
+Pre-training 23.1 25.6 +Pre-training 17.1 20.0
SATE 23.3 23.6 SATE 17.6 18.1
+Pre-training 24.1 27.3 +Pre-training 17.4 20.8
+MTKD 24.7 27.9 +MTKD 17.7 20.8
+SpecAug 25.2 28.1 +SpecAug 18.3 20.8
Table 2: BLEU scores [%] on the test set of MuST-C Table 3: BLEU scores [%] on the test set of Lib-
En-Decorpus.∗:resultsreportedintheESPnettoolkit. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 205>


<Paper ID = 205> <Table 1> <Abstractive Summary> =2625Method BLEU RTF/Speedup Design MuST-C LibriSpeech
CascadedST 23.3 0.0286/1.00× None 25.7 21.7
Soft 25.7 21.9
E2EST 22.1
0.0150/1.91× Mapping 26.0 21.8
+Pre-training 23.1
Fusion 26.4 21.9
E2EST(Enc18) 22.8
0.0155/1.85×
+Pre-training 23.5 Table 6: BLEU scores [%] of different adaptor setups
onthedevelopmentsetundertheunrestrictedsetting. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 205>


<Paper ID = 205> <Table 2> <Abstractive Summary> =-ASREnc 24.7 19.9
-MT 25.1 19.4
-MTEnc 25.7 20.7
ASR encoder provides a rich representation and
-MTDec 25.3 19.9
actsaspartoftheMTencoder,thisleadstolower
performancedegradationwhenthetextualencoder
Table 5: Effects of the pre-trained modules on BLEU
trainsfromscratch. </Abstractive Summary> <Extractive Summary> ofESPnet(Inagumaetal.,2020),weremovethe
5.3 Results
utterancesofmorethan3,000framesandaugment
speechdatabyspeedperturbationwithfactorsof Results on MuST-C En-De Table 2 summaries
0.9,1.0,and1.1.  </Extractive Summary>  </Table 2>  </Paper ID = 205>


<Paper ID = 206> <Table 0> <Abstractive Summary> =(2015) – – 84.22
Baseline 98.35 96.32 91.38     
Ours 98.92 96.70 91.84
    
                                              !         
 , P P H G L D W H  & K L O G U H Q  1 X P E H U
Table 4: Joint-task performances on test set of CTB. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 206>


<Paper ID = 207> <Table 0> <Abstractive Summary> =(2020) 90.1 94.1 95.2
XLM-R+Fine-tune 87.7 91.4 94.1 89.3 95.3 XLM-R+Fine-tune 92.3 93.7 95.4
ACE+Fine-tune 88.3 91.7 94.6 95.9 95.7 ACE+Fine-tune 93.4 94.4 95.8
Table 2: Comparison with state-of-the-art approaches in NER and POS tagging. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 207>


<Paper ID = 207> <Table 1> <Abstractive Summary> =(2020) 93.6 89.1 - - - -
WangandTu(2020) 96.9 95.3 F&G(2020) 94.4 91.0 95.1 93.4 82.6 82.0
XLNET+Fine-tune 97.0 95.6 XLNet+Fine-tune 94.2 90.6 94.8 93.4 82.7 81.8
ACE+Fine-tune 97.2 95.8 ACE+Fine-tune 95.6 92.6 95.8 94.6 83.8 83.4
Table 4: Comparison with state-of-the-art approaches in DP and SDP. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 207>


<Paper ID = 207> <Table 2> <Abstractive Summary> =Wedesignasimplesearchspace
Table 6: A comparison among All, Random, ACE, and use the reinforcement learning with a novel
All+WeightandEnsemble. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 207>


<Paper ID = 207> <Table 3> <Abstractive Summary> =2659NER POS
de de(Revised) en es nl Ritter ARK TB-v2
BERT+Fine-tune 76.9 79.4 89.2 83.3 83.8 91.2 91.7 94.4
MBERT+Fine-tune 81.6 86.7 92.0 87.1 87.2 90.8 91.5 93.9
XLM-R+Fine-tune 87.7 91.4 94.1 89.3 95.3 92.3 93.7 95.4
RoBERTa+Fine-tune - - 93.9 - - 92.0 93.9 95.4
XLNET+Fine-tune - - 93.6 - - 88.4 92.4 94.4
ACE+Fine-tune 88.3 91.7 94.6 95.9 95.7 93.4 94.4 95.8
Table 9: A comparison between ACE and the ﬁne-tuned embeddings that are used in ACE for NER and POS
tagging. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 207>


<Paper ID = 208> <Table 0> <Abstractive Summary> =ed
bel#200070.9471.0975.1876.1576.5476.3778.4877.66
fullmodel 84.95 76.16 83.85 79.79 81.19 unla#400071.7871.8976.4976.4177.5276.5978.7777.69
ww//ooLLSCTCEE 8844..9828 7755..8599 8833..3383 7799..4392 8800..9728 Target All 74.6174.6676.5676.4478.2677.0779.1877.76
w/oLS &LT 84.34 74.07 83.07 79.19 80.17
CE CE Table 4: Results on different sizes of target unlabeled
w/oL 72.59 54.60 57.19 71.06 63.86
KL dataandlabeleddataonDeofNERtasks. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 208>


<Paper ID = 208> <Table 1> <Abstractive Summary> =Ineachcell,
theright(underlined)andleftpartdenotetheresultsof
Table 3: Ablation study of Ours-sub model on
theaggregatedsourceviewandtargetviewrespectively. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 208>


<Paper ID = 208> <Table 2> <Abstractive Summary> =Gold B-LOC O O B-PER O O O ...
Table 6: A negative transfer example on Spanish tar-
Zhi-Hua Zhou and Ming Li. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 208>


<Paper ID = 208> <Table 3> <Abstractive Summary> =Wedonotusesyntac-
ticinformationlikegoldPOStagsasmanysuper-
Table 5: Direct bilingual transfer results on the
viseddependencyparsersdosincewecan’tassume
CoNLL02/03 NER task measured in F1 scores (%). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 208>


<Paper ID = 208> <Table 4> <Abstractive Summary> =(2020)
basedonthescoreofthedevelopmentsetonhigh-
Table 7: The average results ( twenty-ﬁve runs)
resources language, which is English in practice,
of randomness test of ﬁfty labeled data on
andadoptthehyper-parameterstootherlanguages. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 4>  </Paper ID = 208>


<Paper ID = 210> <Table 0> <Abstractive Summary> =InthespiritofCPD,weintro-
probabilityandthefactorizationareillustratedin ducealatent-variableH todecomposetheorder-6
2690jÿ´1 jÿ´1 ÿ ÿp kÿ´1 ÿ
sAi,j,p “ sBi,k,p¨sCk,,jq¨ppArwpsÑBrwpsCrwqsq` sBi,k,q¨sCk,,jp¨ppArwpsÑBrwqsCrwpsq (3)
kl“oopoo`oo1ooqo“ookooBooo,Coooooooooooooooooomoooooooooooooooooooooooooooooooooon kl“oooio`oo1ooqo“ooiooBoo,oCoooooooooooooooooomoooooooooooooooooooooooooooooooooon
TermA1 TermA2
jÿ´1 ÿ jÿ´1ÿ ÿp ÿ kÿ´1ÿ
“ sBi,k,p sCk,,jq¨ppArwpsÑBrwpsCrwqsq` sCk2,p,j sBi,k,q¨ppArwpsÑBrwqsCrwpsq (4)
k“p`1 B ql“oookooCoooooooooooooooooooomooooooooooooooooooooooooon k“i`1 C lq“oooiooBoooooooooooooooooooomooooooooooooooooooooooooon
TermB1 TermB2
jÿ´1 jÿ´1 ÿ
TermA1“ sBi,k,p¨sCk,,jq¨ plopoBooo,oðoooo,oCooo|oAoom,woopoqoo¨oopoopowoooqo|oCoonq (5)
k“p`1q“kB,C
factorizationofppArwpsÑBrwpsCrwqsq
jÿ´1 ÿ ÿ jÿ´1
“ sBi,k,p ppB,ð,C|A,wpq sCk,,jq¨ppwq|Cq (6)
k“p`1 B C ql“ookoooooooomoooooooooon
looooooooooooooooooooooooomoooooooooTooeormoooCo1o-o1ooooooon
TermC1-2
jÿ´1 jÿ´1 ÿ ÿ
TermA1“ sBi,k,p¨sCk,,jq¨ ppH|A,wpqppB|HqppC,ð|Hqppwq|Hq (7)
k“p`1q“kB,C lHoooooooooooooooooooooooooooomoooooooooooooooooooooooooooon
factorizationofppArwpsÑBrwpsCrwqsq
ÿ jÿ´1 ÿ jÿ´1ÿ
“ ppH|A,wpq sBi,k,pppB|Hq sCk,,jqppC ð|Hqppwq|Hq (8)
H k“p`1lBoooooooomoooooooonql“ookoooCoooooooooooooomooooooooooooooooooon
TermD1-1 TermD1-2
Table 1: Recursive formulas of the inside algorithm for Eisner and Satta (1999) (Equation 4), Zhu et al. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 210>


<Paper ID = 210> <Table 1> <Abstractive Summary> =VPsareusuallyleft-headedinEnglish,so
D-B 47.8 36.9 54.0 169.6
ourmodelhasamuchhigherrecallonVPsandcor-
Table 3: Binding the head direction D with different rectlypredictstheirheadwords. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 210>


<Paper ID = 211> <Table 0> <Abstractive Summary> =Table 3: Top PMI scoring words for each of the 5 of-
fensivenessscorebins. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 211>


<Paper ID = 211> <Table 1> <Abstractive Summary> =0.625
Thisguyisgivingmefuckingaids 0.792
fuckyou,you’rejustpretendingtobeblocked.getbacktoworkRIGHTNOWyoupieceofshitpiping 0.938
Table 6: More sample comments from Ruddit for each of the 5 score bins. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 211>


<Paper ID = 212> <Table 0> <Abstractive Summary> =QuantiDCE 0.412 0.393 0.274 0.360
Table 1: Correlations between automatic evaluation
Pre-TrainingObjective. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 212>


<Paper ID = 212> <Table 1> <Abstractive Summary> =CoherenceScore(Human/QuantiDCE/GRADE):2.50/3.94/4.27
Table4:AblationstudiesontheConvAI2datasetbyre-
movingoneofthecomponentinQuantiDCE,including Table 5: Two representative examples to show the
the MLR loss (w/o MLR pre-training), the KD+MSE strength and weakness of our QuantiDCE where U1
loss (w/o KD ﬁne-tuning), and three secondary losses and U2 are two utterances of the context and R is the
oftheMLRloss. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 212>


<Paper ID = 213> <Table 0> <Abstractive Summary> =); and (iii) the Head 0.33 0.38 0.66 0.53
degreeofcompositionalityofthecompound(i.e., Modiﬁer 0.45 0.42 0.56 0.48
towhatextentthemeaningoftheNCcanbeseen
Table 1: Krippendorff’s α inter-annotator agreement
as a combination of its parts). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 213>


<Paper ID = 213> <Table 1> <Abstractive Summary> =4.13 0.67 3.61 0.94 4.23 0.66 4.20 0.93 4.34 0.66 3.90 0.87
Table 3: Mean compositionality scores for each class in English and Portuguese (from 0, fully idiomatic, to 5,
fullycompositional),andstandarddeviations. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 213>


<Paper ID = 213> <Table 2> <Abstractive Summary> =Table 4: Annotation example of the English NC disc jockey. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 213>


<Paper ID = 213> <Table 3> <Abstractive Summary> =Model
ave. ρ StDev ave. ρ StDev ave. ρ StDev ave. ρ StDev
BERT 0.006 0.70 0.083 0.71 -0.050 0.71 -0.017 0.69
DBERT 0.031 0.72 0.050 0.75 0.083 0.71 -0.058 0.70
SBERT 0.001 0.72 -0.025 0.72 0.008 0.72 0.036 0.72
ELMO -0.008 0.71 -0.017 0.75 0.042 0.72 -0.050 0.67
GLOVE -0.006 0.72 -0.017 0.77 -0.058 0.66 0.058 0.73
Table 6: Average correlations (Spearman ρ) and standard deviations (StDev) on the whole dataset (Total) and in
the three classes: idiomatic, partially compositional, and compositional noun compounds. </Abstractive Summary> <Extractive Summary> Idiomaticity values: with regards to the id-
iomaticity values of each class, Table 3 displays
Paraphrases: asmentioned,weaskedthepartic-
boththeaveragescoresandthestandarddeviation
ipantstoprovidesynonymsorparaphrasesforthe
in both languages.  </Extractive Summary>  </Table 3>  </Paper ID = 213>


<Paper ID = 214> <Table 0> <Abstractive Summary> =Table 3: Argument coreference baselines scored with
Foreachargumentwhosevalueisprovided,we
usual metrics. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 214>


<Paper ID = 214> <Table 1> <Abstractive Summary> =(2020), assume that the em-
F1 54.7±33.4 55.1
bedded case is represented by the sequence of
Table 4: Exact match coreference results for BERT- vectors t ,...,t and the embedded subsection
1 m
based argument identiﬁcation followed by string by s ,...,s . </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 214>


<Paper ID = 214> <Table 2> <Abstractive Summary> =Counts SARA Random
0 33 24
Subsectiontoapply: Tax 1 40 22
2 44 18
Argument-value pairs: {Taxy=“2017”,
3 30 23
Taxp=“Alice”} 4 15 18
5 10 14
6 13 13
Output3
7 5 8
8 4 2
{Tax=116066,@truth=True}
9 0 3
10 0 1
total 161 146
B Datasetstatistics Statistics
average 2.4 3.1
stddev 2.0 2.4
median 2 3
B.1 Argumentidentiﬁcation
Table 7: Number of arguments per subsection. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 214>


<Paper ID = 214> <Table 3> <Abstractive Summary> =Statistics
average 3.0 1.0
stddev 2.6 2.4
median 3 1
Table 9: Number of arguments and dependencies of
eachsubsection,asrepresentedinthestructureannota-
tions. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 214>


<Paper ID = 215> <Table 0> <Abstractive Summary> =JSD - - - - 0.619
(I) (II) (III) (IV) (V) (VI) Table 5: System ranking similarity in terms of
κ (cid:88) (cid:88) A good good Kendall’s τ for each OQ task (NTCIR). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 215>


<Paper ID = 215> <Table 1> <Abstractive Summary> =Ontheother
hand,ifthetasksdoinvolvesuchbaselineruns(as
Table 4: Summary of the properties of OC measures. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 215>


<Paper ID = 215> <Table 2> <Abstractive Summary> =Our future
Table 7: Summary of the properties of OQ measures. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 215>


<Paper ID = 215> <Table 3> <Abstractive Summary> =Table 8: System ranking similarity in terms of
Figure3showsthediscriminativepowercurves
Kendall’s τ for each OQ task (SemEval). </Abstractive Summary> <Extractive Summary> Forexample,Part(a)showsthat
α-INT 0.935♣ α-INT 0.863♠
MAEµ 0.929♣ HMPR 0.799♣ whenthe100topicsofSem16T4Cwererandomly
HMPR 0.904♦ MAEM 0.780♥ splitinhalf1,000times,κstatisticallysigniﬁcantly
MAEM 0.901♦ F1M 0.758‡
outperformed all other measures, as indicated by
F1M 0.884‡ MAEµ 0.753‡
CEMORD 0.806 Accuracy 0.625† a “(cid:93).” Table 3 (b) and (d) show variants of these
Accuracy 0.799 CEMORD 0.595 experimentswhereonly10topicsareusedineach
Sem17T4C topicsubset,todiscusstherobustnessofmeasures
(c)Fullsplit(62vs.63) (d)10vs.10
tosmallsamplesizes.  </Extractive Summary>  </Table 3>  </Paper ID = 215>


<Paper ID = 216> <Table 0> <Abstractive Summary> =This HIF+KATID3 95.9 98.1 90.2 59.3 89.7 80.5 94.9 99.3 99.6
HIF+KATXGB 95.5 98.1 90.1 63.3 89.3 80.4 96.5 99.7 99.9
kindofinterpretabilitywilleasethecollaboration
withdomainexperts,andincreasethetrustworthi- Table 5: F scores of all methods under sufﬁcient re-
1
ness, compared with uninterpretable end-to-end sourcesetting(%). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 216>


<Paper ID = 216> <Table 1> <Abstractive Summary> =2779I-A D-A D-S
Methods 1 1 1
P R F P R F P R F
1 1 1
DM-RNN 69.1 60.9 63.6 81.7 90.3 85.4 69.9 80.9 74.8
DM-ATT 54.2 58.4 55.8 75.3 91.2 82.5 75.0 83.5 79.0
DM-HYB 58.4 64.1 60.9 84.3 89.2 86.6 74.3 82.4 78.0
HierMatcher 64.1 61.8 61.9 41.6 38.9 37.5 72.1 67.2 68.2
Magellan 92.3 92.7 92.3 95.4 92.2 93.7 80.7 90.2 85.1
HIF+LN 84.1 73.0 77.9 15.0 97.1 21.0 96.1 44.3 54.7
HIF+LR 79.9 89.1 84.2 86.7 95.7 87.1 85.2 84.2 84.6
HIF+DT 97.1 94.9 96.0 95.9 97.0 96.4 90.0 85.1 87.5
HIF+KAT 97.1 94.7 95.8 95.8 97.4 96.6 87.8 88.7 88.2
ID3
HIF+KAT 87.7 94.0 90.6 91.1 95.7 93.3 88.4 87.4 87.9
XGB
I-A D-A D-S
Methods 2 2 2
P R F P R F P R F
1 1 1
DM-RNN 43.3 42.4 42.3 39.1 55.5 45.7 31.9 50.7 39.0
DM-ATT 46.4 50.4 46.5 42.5 48.3 45.2 55.5 60.4 57.8
DM-HYB 51.1 54.5 49.5 48.8 44.6 46.2 57.3 65.1 60.4
HierMatcher 41.2 43.9 37.8 48.5 27.8 32.6 50.4 44.1 45.8
Magellan 51.8 49.4 50.6 58.5 74.8 65.6 72.6 69.7 71.1
HIF+LN 54.1 34.0 41.6 - - - 73.1 84.7 78.5
HIF+LR 49.5 44.5 46.5 - - - 62.1 75.7 68.1
HIF+DT 55.6 54.5 54.9 75.4 85.5 80.1 77.8 70.9 74.2
HIF+KAT 50.6 53.4 51.6 73.6 85.4 79.0 81.9 77.2 79.5
ID3
HIF+KAT 35.9 51.0 41.5 75.4 86.1 80.3 82.1 77.1 79.5
XGB
Phone Skirt Toner
Methods
P R F P R F P R F
1 1 1
DM-RNN 88.1 92.1 90.0 62.3 73.8 67.6 60.3 80.8 68.6
DM-ATT 77.1 83.8 80.3 44.5 70.1 54.4 40.6 62.2 48.8
DM-HYB 93.9 90.1 91.9 55.6 76.1 64.2 55.0 87.3 67.4
HierMatcher 83.6 89.2 86.2 51.7 77.0 61.7 46.7 67.9 55.2
Magellan 95.1 92.1 93.6 96.1 97.2 96.6 96.7 97.6 97.2
HIF+LN 80.5 65.5 72.2 93.8 51.5 62.8 88.4 83.8 86.0
HIF+LR 97.3 80.0 87.5 99.9 26.4 41.7 62.6 89.8 62.0
HIF+DT 93.0 97.0 94.9 96.7 96.7 96.7 97.6 96.7 97.2
HIF+KAT 92.2 96.9 94.5 96.9 96.6 96.7 97.6 96.7 97.2
ID3
HIF+KAT 92.6 96.1 94.4 99.0 93.5 96.2 97.6 96.8 97.2
XGB
Table 6: Experimental results under low-resource setting with precision, recall, and F measure (%). </Abstractive Summary> <Extractive Summary> The comparison fea-
ture metrics in Table 1 are implemented with
py-entitymatching 0.4.0.  </Extractive Summary>  </Table 1>  </Paper ID = 216>


<Paper ID = 218> <Table 0> <Abstractive Summary> =These methods can be divided
TEXT2EVENT 3.7 30.9 44.7 52.6
into: 1)pipelineclassiﬁcation(Ahn,2006;Jiand
w/oCD 2.3 27.3 44.4 52.3
w/oES 0.0 7.0 8.2 28.9 Grishman,2008;LiaoandGrishman,2010;Hong
etal.,2011,2018;HuangandRiloff,2012;Chen
Table 5: Experiment results of variants trained with et al., 2015; Sha et al., 2016; Lin et al., 2018;
different-sized training set on the development set of Yang et al., 2019; Wang et al., 2019; Ma et al.,
ACE05-EN. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 218>


<Paper ID = 219> <Table 0> <Abstractive Summary> =(2)
Table 5: The statistics of different errors that occur in Leveraging the acoustic modality can effectively
theoutputofNERmodelsonthedevelopmentset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 219>


<Paper ID = 22> <Table 0> <Abstractive Summary> =7Wewillreleaseoursynonymdictionary
246En-Fr En-Tr En-Es En-Ro En-Fi
Avg ∆
wmt14 wmt17 wmt13 wmt16 wmt17
→ ← → ← → ← →(*) ← → ←
bilingual
Transformer-6(Linetal.,2020) 43.2 39.8 - - - - 34.3 34.0 - - -
Transformer-12(Liuetal.,2020) 41.4 - 9.5 12.2 33.2 - 34.3 36.8 20.2 21.8 -
pre-train&ﬁne-tuned
Adapter(BapnaandFirat,2019) - - - - 35.4 33.7 - - - - -
mBART(Liuetal.,2020) 41.1 - 17.8 22.5 34.0 - 37.7 38.8 22.4 28.5 -
XLM(ConneauandLample,2019) - - - - - - - 38.5 - - -
MASS(Songetal.,2019) - - - - - - - 39.1 - - -
mRASP(Linetal.,2020) 44.3 45.4 20.0 23.4 - - 37.6 38.9 24.0 28.0 -
uniﬁedmultilingual
Multi-Distillation (Tanetal.,2019) - - - - - - 31.6 35.8 22.0 21.2 -
m-Transformer 42.0 38.1 18.8 23.1 32.8 33.7 35.9 37.7 20.0 28.2 31.03
mRASP w/oﬁnetune(**) 43.1 39.2 20.0 25.2 34.0 34.3 37.5 38.8 22.0 29.2 32.33 +1.30
mRASP2 43.5 39.3 21.4 25.8 34.5 35.0 38.0 39.1 23.4 30.1 33.01 +1.98
Table 1: Performance (tokenized BLEU) on WMT supervised translation directions. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 22>


<Paper ID = 22> <Table 1> <Abstractive Summary> =Hence, there has been
a massive increase in work on MT systems that
Table 6: Non-English: The averaged sentence sim- involve more than two languages (Chen et al.,
ilarity search top-1 accuracy on Ted-M testset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 22>


<Paper ID = 221> <Table 0> <Abstractive Summary> =ψ ,ψ ,andψ aresetto0.5,0.5
S V T
Table 3: Statistics of OntoEvent compared with ex-
and1respectively. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 221>


<Paper ID = 221> <Table 1> <Abstractive Summary> =2838C OverviewofTemporal&Causal
Event-EventCorrelations
E-ERelation HeadEventType TailEventType
Personnel.Start-Position Personnel.End-Position
Personnel.Nominate Personnel.Elect
Commerce.Commerce-Sell Commerce.Commerce-Buy
Commerce.Manufacturing Commerce.Carry-Goods
Life.Marry Life.Divorce
Life.Be-Born Life.Name-Conferral
Justice.Arrest Justice.Prison
Justice.Sue Justice.Criminal-Investigation
Justice.Criminal-Investigation Justice.Legal-Rulings
BEFORE
Transaction.Transaction Transaction.Earnings-And-Losses
Proecess.Confronting-Problem Proecess.Resolve-Problem
Justice.Justifying Justice.Committing-Crime
Justice.Convict Justice.Execute
Justice.Convict Justice.Fine
Justice.Convict Justice.Extradition
Justice.Convict Justice.Sentence
Justice.Sentence Justice.Release-Parole
Justice.Acquit Justice.Pardon
Movement.Arriving Movement.Transport-Artifact
Movement.Arriving Movement.Departing
Movement.Arriving Movement.Transport-Person
Business.End-Org Business.Start-Org
Life.Death Life.Be-Born
AFTER
Life.Cure Life.Bodily-Harm
Proecess.Process-End Proecess.Process-Start
Justice.Appeal Justice.Sue
Conﬂict.Escaping Conﬂict.Besieging
Conﬂict.Bearing-Arms Conﬂict.Use-Firearm
Commerce.Commerce-Pay Commerce.Commerce-Buy
Business.Declare-Bankruptcy Business.End-Org
Business.Merge-Org Business.Collaboration
Transaction.Getting Transaction.Receiving
Transaction.Giving Transaction.Supply
Transaction.Renting Transaction.Exchange
Movement.Traveling Movement.Transport-Person
Natural-Disaster.Damaging Natural-Disaster.Destroying
Movement.Body-Movement Movement.Traveling
Life.Cure Life.Recovering
EQUAL
Justice.Extradition Justice.Legal-Rulings
Conﬂict.Revenge Conﬂict.Hostile-Encounter
Conﬂict.Protest Conﬂict.Quarreling
Conﬂict.Protest Conﬂict.Use-Firearm
Conﬂict.Protest Conﬂict.Violence
Conﬂict.Protest Conﬂict.Attack
Conﬂict.Protest Conﬂict.Killing
Conﬂict.Protest Conﬂict.Besieging
Conﬂict.Protest Conﬂict.Conquering
Conﬂict.Protest Conﬂict.Defending
Cause-Effect.Causation Cause-Effect.Inﬂuence
Natural-Disaster.Catastrophe Natural-Disaster.Damaging
CAUSE
Conﬂict.Attack Life.Bodily-Harm
Conﬂict.Killing Life.Death
Justice.Arrest Crime.Kidnapping
Justice.Arrest Crime.Robbery
CAUSEDBY Justice.Arrest Crime.Theft
Justice.Arrest Conﬂict.Attack
Justice.Arrest Conﬂict.Killing
Table 9: Overview of temporal & causal event-event
correlationsinOntoEvent. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 221>


<Paper ID = 222> <Table 0> <Abstractive Summary> =(2020)
+RANDSAMP – – – – 41.9 –
BITEXT 39.6 31.0 35.3 37.1 42.5 39.8
ThisWork +RANDSAMP 41.6 33.1 37.3 37.6 43.8 40.7
+SRCLM 41.7 33.1 37.4 37.3 44.0 40.7
+UNCSAMP 42.5⇑ 34.4⇑ 38.4 38.2⇑ 44.3↑ 41.3
Table 4: Translation performance on WMT En⇒De and WMT En⇒Zh test sets. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 222>


<Paper ID = 222> <Table 1> <Abstractive Summary> =# Data 2019 2020 Avg Data 2019 2020 Avg
1 BITEXT 36.9 27.7 32.3 RANDSAMP 40.9 31.6 36.2
2 +RANDSAMPORA 37.4 28.0 32.7 DWF 39.6 30.1 34.8
3 +UNCSAMPORA 37.8 28.2 33.0 SRCLM 41.1 32.0 36.5
4 +RANDSAMPST 40.0 30.1 35.0
UNCSAMP 41.6 32.3 36.9
5 +UNCSAMPST 40.4 30.5 35.4
+Filtering 41.5 32.7 37.1
Table 2: Comparison of our UNCSAMP and RAND-
Table 3: Comparison of the proposed uncertainty-
SAMP with manual translations (Ora: manual transla-
basedsamplingstrategywithrelatedmethodsonWMT
tions; ST: pseudo-sentences) on WMT En⇒De new-
En⇒Denewstest2019andnewstest2020. </Abstractive Summary> <Extractive Summary> dispelthedoubt,westillusedtheaforementioned
Table 1 reported the impact of β and R on the 8Mbitextasthebilingualdata,andusedtherestof
BLEUscore.  </Extractive Summary>  </Table 1>  </Paper ID = 222>


<Paper ID = 222> <Table 2> <Abstractive Summary> =As High 31.0 33.4 34.4 10.9
shown,ourTRANSFORMER-BIGmodelstrainedon
theauthenticparalleldataachievetheperformance Table 5: Translation performance on uncertain sen-
competitive with or even better than the submis- tences. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 222>


<Paper ID = 222> <Table 3> <Abstractive Summary> =With our uncertainty- Med 65.2 66.5 66.9 2.6
basedsamplingstrategy UNCSAMP,self-training High 70.3 71.6 72.0 2.4
achievesfurthersigniﬁcantimprovementby+1.1
Table 6: Prediction accuracy of low-frequency words
and+0.6BLEUpointsovertherandomsampling
in the translation outputs. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 222>


<Paper ID = 223> <Table 0> <Abstractive Summary> =# Model
sent doc BLEU Meteor BLEU Meteor BLEU Meteor BLEU Meteor BLEU Meteor
DocT(Zhangetal.,2018) (cid:55) (cid:55) 40.32 27.93 24.00 44.69 23.08 42.40 29.32 46.72 29.18 40.43
HAN(Miculicichetal.,2018) (cid:55) (cid:55) 40.83 28.19 24.58 45.48 25.03 44.02 28.60 46.09 29.76 40.94
SAN(Marufetal.,2019) (cid:55) (cid:55) 41.01 28.37 24.42 45.26 24.84 44.17 29.75 47.22 30.00 41.26
QCN(Yangetal.,2019) (cid:55) (cid:55) - - 25.19 46.09 22.37 41.88 29.82 47.86 - -
MCN(Zhengetal.,2020) (cid:55) (cid:55) 40.92 28.25 25.10 - 24.91 - 30.40 - 30.33 -
#1 Transformer (cid:55) (cid:55) 39.64 27.56 23.02 43.66 22.03 41.37 28.65 45.83 28.33 39.61
#2 Ours-sent (cid:55) (cid:55) 40.73 27.97 24.75 45.83 24.19 43.96 29.10 47.55 29.69 41.33
#3 Ours-doc (cid:55) (cid:55) 41.27 28.46 25.31 46.30 24.70 44.38 30.07 47.93 30.34 41.76
#4 Transformer (cid:51) (cid:51) 46.30 32.91 26.94 47.06 26.80 46.99 29.90 47.50 32.48 43.62
#5 Ours-sent (cid:51) (cid:51) 49.58 35.97 28.73 48.80 28.41 48.52 30.61 48.29 34.33 45.40
#6 Ours-doc (cid:51) (cid:51) 50.03 36.50 29.31 49.40 29.01 48.83 31.52 49.02 34.97 45.94
Table 1: Performance (BLEU and Meteor scores) on test sets. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 223>


<Paper ID = 223> <Table 1> <Abstractive Summary> =(cid:55) (cid:51) 40.32 28.64 24.62 44.83 Table 3: Performance on ZH-EN translation with re-
Ours (cid:55) (cid:51) 42.64 30.19 25.30 45.60
specttodifferentﬁne-tuningstrategiesanddifferentin-
Trans. </Abstractive Summary> <Extractive Summary> Table 1 shows the performance
aredownloadedfromMarufetal.  </Extractive Summary>  </Table 1>  </Paper ID = 223>


<Paper ID = 223> <Table 2> <Abstractive Summary> =Table 2: Ablation studies on ZH-EN and EN-DE Model Bi-sent Mo-doc deixis lex.c ell.inﬂ. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 223>


<Paper ID = 223> <Table 3> <Abstractive Summary> =(cid:51) (cid:51) 71.02 70.51
Ours (cid:51) (cid:51) 72.11 70.89 Table 7: Performance (BLEU scores) on dev and test
setsofZH-ENtranslationwithrespecttodifferentpre-
Table5:EvaluationonpronountranslationsofZH-EN. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 223>


<Paper ID = 223> <Table 4> <Abstractive Summary> =30 50.59 49.70
6 RelatedWork
Table 6: Performance (BLEU scores) on dev and test
setsofZH-ENtranslationwithrespecttodifferentgap We describe related studies in the following two
sentence ratios in pre-training task of document-level perspectives. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 4>  </Paper ID = 223>


<Paper ID = 223> <Table 5> <Abstractive Summary> =Model ZH-EN EN-DE
Transformer 80.6M 61.4M
Ours 86.2M 64.0M
Table 9: Model parameters for ZH-EN and EN-DE
translations. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 5>  </Paper ID = 223>


<Paper ID = 223> <Table 6> <Abstractive Summary> =#Epoch #Epoch
Translation onBi-sent onMo-doc Time
ZH-EN 35 3.0 120h
EN-DE 20 1.2 130h
Table 10: Statistics on our two pre-trained models for
ZH-ENandEN-DEtranslations. </Abstractive Summary> <Extractive Summary> Table 6 shows that we achieve umentstoexploremulti-tasktrainingviatheBERT-
thebestperformancewhentheratioissetas20%.  </Extractive Summary>  </Table 6>  </Paper ID = 223>


<Paper ID = 224> <Table 0> <Abstractive Summary> =CN EN EN DE
→ →
2017 ∆ 2019 ∆ TIME 2016 ∆ 2019 ∆ TIME
TRANSFORMER 23.75 26.00 1.0 33.49 36.20 1.0
TWINNET 23.39 -0.36 26.09 +0.09 2.58 33.05 -0.44 35.69 -0.51 2.57
EVANMT – – – – – 34.00 +0.51 37.25 +1.05 2.48
SEER+L2 23.95 +0.20 25.82 -0.18 1.93 33.58 +0.09 36.65 +0.45 1.53
SEER+AL 24.01 +0.26 26.47* +0.47 2.29 34.03 +0.54 36.81 +0.61 2.39
OurMethod 24.35* +0.60 26.80** +0.80 1.97 34.25** +0.76 37.34* +1.14 1.57
Table 2: BLEU scores on big data sets. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 224>


<Paper ID = 224> <Table 1> <Abstractive Summary> =2867MT03 MT04 MT05 MT06 MT08 AVG
CDw/oCA 6.24 6.68 6.70 6.77 4.49 6.12
SDw/oCA 16.39 16.70 16.64 17.21 11.97 15.78
CDwithCA 29.45 25.03 30.14 32.07 23.39 28.02
SDwithCA 52.61 45.57 52.02 52.68 44.14 49.40
Table 3: BLEU scores of teacher forcing and seer forcing with and without cross-attention on NIST CN EN
→
translation. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 224>


<Paper ID = 224> <Table 2> <Abstractive Summary> =-FUTURE 45.38 -0.86
Theﬁgureconﬁrmsourconjecturethatatﬁrst,the
-PAST 45.42 -0.82
-KD 44.84 -1.40 fused information is highly related to the future
TRANSFORMER 44.40 -1.84 information,andovertimethesimilaritytopastin-
formationincreasesgraduallywhilethesimilarity
Table 5: Ablation study on NIST CN EN transla-
→ tofutureinformationdecreasesfaster. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 224>


<Paper ID = 225> <Table 0> <Abstractive Summary> =However, since ST systems
C 25.69 23.29 30.04∗ 54.01 28.56 56.29
take as input an audio signal, we also provided it D 26.14 23.26 28.81 54.06 28.56 55.35∗
translatorswiththeaudioﬁleofeachsegment,ask-
ingthemtopost-editstrictlyaccordingtoit.6 For Table 1: Performance of (C)ascade and (D)irect sys-
tems on the PE-sets and MuST-C Common test sets. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 225>


<Paper ID = 225> <Table 1> <Abstractive Summary> =Our classiﬁer
combinesn-gramlanguagemodelswiththeNaive Table 10: Lexical diversity of the human (R)eference,
Bayesalgorithm,asproposedin(PengandSchu- (C)ascadeand(D)irectoutputs. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 225>


<Paper ID = 225> <Table 2> <Abstractive Summary> =Knowledgedistil-
en-es 70.1M 972.5M 1024.9M
lationisperformedfromateacher MTmodelby
en-it 67.9M 792.6M 770.2M
optimizingtheKLdivergencebetweenthedistribu-
Table 11: Statistics of the parallel training sets col- tionsproducedbytheteacherandthestudent ST
lected from the OPUS repository for the three lan- modelbeingtrained(Liuetal.,2019). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 225>


<Paper ID = 226> <Table 0> <Abstractive Summary> =2892Medical Law EUB Medical Law EUB Subtitles Law EUB GV Europarl EUB
Dout Koran IT GV Koran IT GV Europarl IT GV Subtitles Medical Koran
Model
Subtitles Europarl Medical Law
Din De-En En-De epoch De-En En-De epoch De-En En-De epoch De-En En-De epoch
Unadapted 9.46 7.54 - 22.31 15.82 - 21.30 19.23 - 31.1 25.35 -
Transfer 10.92 9.18 4 22.96 16.78 3 22.77 19.78 6 31.69 25.59 4
Mixed 11.77 9.96 15 22.99 17.05 5 22.98 19.99 8 31.69 25.74 6
MetaUMT 12.95 10.58 3 24.53 18.59 2 24.6 21.86 4 32.51 27.22 3
MetaGUMT 13.45 10.89 2 25.13 18.95 2 25.32 22.79 4 34.26 29.37 2
SupervisedNMT 2.24 2.49 8 1.88 1.52 7 7.71 9.80 11 11.29 10.07 13
UnsupervisedNMT 1.26 0.94 5 1.53 0.76 23 3.37 2.72 9 6.07 4.73 11
Table 1: BLEU scores on various out-domain (D ) and in-domain (D ) combinations for the language pairs
out in
ofDe-EnandEn-De.The”epoch”columnindicatestheconvergednumberofepochsforeachin-domaindataset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 226>


<Paper ID = 226> <Table 1> <Abstractive Summary> =In other experimentsetting5.1istheconditionthatthein-
words,MetaUMTdemonstratespoorperformances domaincorpusisunbalanced.Wealsoincludethe
2895#tokens Mixed MetaUMT MetaGUMT MetaGUMT MetaUMT Transfer Mixed
En De En-De De-En En-De De-En En-De De-En #Dout En-De De-En En-De De-En En-De De-En En-De De-En
4 5.97 7.47 5.87 7.24 5.75 7.17 5.87 7.22
5k 10k 26.04 31.90 28.80 32.65 29.43 34.28
5 7.58 9.49 7.33 9.01 7.17 8.08 7.20 8.68
8k 16k 26.09 32.01 27.84 32.93 29.62 34.39 6 10.89 13.45 10.58 12.95 9.18 10.92 9.96 11.77
16k 32k 26.44 32.37 27.92 32.96 30.10 34.44
32k 64k 27.39 32.84 28.67 33.52 29.83 34.77 Table5:Effectivenessofthedifferentnumberofsource
domainsbetweenmeta-learningbasedapproachesand
Table 4: Results on the unbalanced monolingual Law
thetransferlearningapproach,where#D represents
out
domaindataduringtheﬁnetuningstage,whereD is
out the number of out-domain datasets in the pretraining
GV,Euorparl,EUB,Subtitles,MedicalandKoran. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 226>


<Paper ID = 227> <Table 0> <Abstractive Summary> =(2018) 80.8 81.0 80.2 77.1 74.1 74.1 70.8 74.8 76.6
LASER(ArtetxeandSchwenk,2019b) 78.0 80.1 86.3 80.8 79.3 69.6 70.2 74.2 77.3
T-LASER(LiandMak,2020) 70.7 78.2 86.8 79.0 71.4 74.5 68.7 76.0 75.7
Ours 85.1 82.4 88.8 80.8 80.8 79.2 74.3 79.9 81.4
reference:globalﬁne-tuningstylemethods
mBERT(Devlinetal.,2019) 83.0 - 82.4 - 75.0 - 68.3 - -
MultiFit(Eisenschlosetal.,2019) 89.4 - 91.6 - 79.1 - 76.0 - -
Table 3: MLDoc benchmark results (zero-shot scenario). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 227>


<Paper ID = 227> <Table 1> <Abstractive Summary> =Forﬁxed-dimensionalmethods,justan
performthebilingualpooling-basedrepresentation
learning methods by a signiﬁcant margin, which
11https://github.com/facebookresearch/
MLDoc reﬂectsthebasicabilityofthecontextualizedrep-
2908MLDoc XSR
N M T
en fr fr en en es es en en fr fr en en es es en
→ → → → → → → →
1 7,135 19 81.7 79.4 75.5 74.9 89.4 90.0 86.4 87.7
2 11,607 24 85.1 82.4 80.8 79.2 90.2 90.8 90.7 91.2
3 16,804 29 84.2 81.9 81.2 78.1 90.9 91.5 91.1 92.0
4 21,923 34 84.2 82.0 81.1 78.7 91.4 91.5 91.5 92.2
6 28,024 44 83.0 80.8 79.8 78.3 91.2 92.0 91.7 91.9
Table 5: Training efﬁciencies with different numbers of layers. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 227>


<Paper ID = 227> <Table 2> <Abstractive Summary> =MLDoc XSR
Tasks
en fr fr en en es es en en fr fr en en es es en
→ → → → → → → →
MLM 78.5 77.6 74.6 75.9 19.6 25.4 11.2 28.5
SMLM 75.0 78.7 75.3 74.0 85.0 85.3 86.4 87.1
XTR 84.2 81.2 79.9 77.6 89.5 90.8 90.3 89.5
MLM XTR 82.2 78.2 78.4 76.7 84.1 85.0 87.6 88.9
⊕
UGT(SMLM XTR) 85.1 82.4 80.8 79.2 89.8 90.6 89.4 89.6
⊕
Table 6: Effectiveness of different generative tasks. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 227>


<Paper ID = 228> <Table 0> <Abstractive Summary> =F1 F1
LSTM(Graveetal.,2016) - 48.7 RoBERTa(Liuetal.,2019) 95.3 95.0 87.8
LSTM+Neuralcache(Graveetal.,2016) - 40.8
Longformer(Beltagyetal.,2020) 95.7 - 94.8
GCNN-14(Dauphinetal.,2017) - 37.2
BigBird(Zaheeretal.,2020) - 95.2 92.2
QRNN(Merityetal.,2018) 151M 33.0
Transformer-XLBase(Daietal.,2019) 151M 24.0 ERNIE-DOC 96.1 96.1 96.3
SegaTransformer-XLBase(Baietal.,2020) 151M 22.5 XLNet-Large(Yangetal.,2019) 96.8 - -
ERNIE-DOCBase 151M 21.0 ERNIE-DOC-Large 97.1 97.1 96.6
Resultsof largemodels
AdaptiveInput(BaevskiandAuli,2018) 247M 18.7 Table 3: Results on the IMDB and HYP dataset for
Transformer-XLLarge(Daietal.,2019) 247M 18.3 long-textclassiﬁcation. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 228>


<Paper ID = 228> <Table 1> <Abstractive Summary> =We limited the
length of the sentences in each mini-batch to
Table 1: Comparison between Transformer-XL and
competitivebaselineresultsonWikiText-103. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 228>


<Paper ID = 228> <Table 2> <Abstractive Summary> =We report the results of base-
ERNIE-DOC-Large 82.5 82.2 87.6 73.7
sizemodelsinTab.5underno-visual-featuresset-
Table 4: Results on TQA and HQA dev dataset for ting for easy and fair comparison with baselines. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 228>


<Paper ID = 228> <Table 3> <Abstractive Summary> =Hyperparameters BASE LARGE
IMDB HYP IMDB HYP Batch Learning
Tasks Epochs Dropout
Batchsize 32 32 32 16 size rate
Learningrate 7e-5 1e-4 1e-5 4e-6 DRCD 64 2.25-4 5 0.1
Epochs 3 15 3 15 CMRC2018 64 1.75e-4 5 0.2
LRschedule linear linear linear linear DuReader 64 2.75e-4 5 0.1
LayerwiseLRdecay 1 0.7 0.9 1 C3 24 1e-4 8 0.1
Warmupproportion 0.1 0.1 0.1 0.1 CAIL 48 5e-5 15 0.1
Weightdecay 0.01 0.01 0.01 0.01 THU 16 1.5e-4 16 0.1
IFK 16 1.5e-4 5 0.1
Table 13: Hyperparameters used for ﬁnetuning on
IMDBandHyperpartisan(HYP). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 228>


<Paper ID = 229> <Table 0> <Abstractive Summary> =OveracertainthresholdofAHSK,the
2934Method CoLA SST-2 QNLI MNLI-m/mm MRPC RTE STS-B Avg
BERT (T) 60.1 93.5 91.5 84.7/84.7 86.0 67.5 88.5 82.1
BASE
TinyBERT 29.8 89.7 87.2 81.0/81.4 82.4 64.7 85.1 75.2
Dev 4
w/HSKcompression 37.5 90.6 88.1 81.5/81.7 83.3 66.3 86.1 76.9
ROSITA 30.6 90.1 87.6 81.2/81.5 80.7 64.9 83.4 75.0
6
w/HSKcompression 43.0 91.6 88.2 81.8/82.0 80.9 68.0 87.2 77.8
BERT (G) 52.1 93.5 90.5 84.6/83.4 88.9 66.4 85.8 80.7
BASE
TinyBERT 28.2 90.9 86.4 81.0/80.3 85.6 61.5 76.8 73.8
Test 4
w/HSKcompression 30.6 90.6 87.3 81.5/80.8 85.4 61.7 79.0 74.6
ROSITA 28.1 90.5 87.0 81.5/80.4 83.0 61.7 73.9 73.3
6
w/HSKcompression 35.3 91.3 86.7 81.9/80.9 84.5 61.7 79.9 75.3
Table 2: Dev and test set performance of BERT and KD-based BERT compression methods. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 229>


<Paper ID = 229> <Table 1> <Abstractive Summary> =This
isrelatedtoalineofstudiescalledtheattribution
Table 3: Memory consumption of different AHSK on
methods, which attempt to attribute a neural net-
MNLItrainingset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 229>


<Paper ID = 229> <Table 2> <Abstractive Summary> =(1,2,0.5) (1,10,0.3) (2,24,0.1) (3,5,0.7) (2,27,0.9)
(1,5,0.2) (1,5,0.6) (1,25,0.2) (1,25,0.4) (6,9,0.9)
(1,1,1.0) (2,15,0.1) (1,6,0.8) (2,7,0.7) (6,12,0.7)
(3,3,0.1) (5,2,0.3) (7,7,0.1) (3,16,0.2) (6,27,0.3)
(3,1,0.3) (5,1,0.6) (6,8,0.1) (7,14,0.1) (7,24,0.3)
(1,10,0.1) (5,6,0.1) (4,4,0.3) (2,8,0.6) (4,18,0.7)
(2,5,0.1) (3,5,0.2) (2,6,0.4) (5,3,0.7) (3,21,0.8)
(1,1,0.9) (1,30,0.1) (2,3,0.8) (3,7,0.5) (5,10,1.0)
(5,1,0.2) (5,3,0.2) (3,8,0.2) (4,8,0.3) (7,23,0.3)
(1,3,0.3) (1,6,0.5) (4,12,0.1) (5,7,0.3) (5,25,0.4)
(1,15,0.2) (1,7,0.7) (6,8,0.2) (4,26,0.5)
(2,3,0.5) (1,49,0.1) (5,5,0.4) (6,17,0.5)
(1,3,1.0) (2,4,0.6) (6,2,0.8) (2,26,1.0)
(2,5,0.3) (5,10,0.1) (5,4,0.5) (6,8,1.0)
(3,10,0.1) (1,5,1.0) (4,5,0.5) (4,12,1.0)
(3,2,0.5) (3,4,0.4) (1,13,0.8) (2,43,0.6)
(3,1,1.0) (1,10,0.5) (1,32,0.3) (5,16,0.6)
(2,13,0.2) (3,33,0.1) (4,25,0.5)
(3,2,0.8) (3,34,0.1)
(4,3,0.4) (4,25,0.1)
(1,8,0.6) (6,4,0.4)
(5,2,0.5) (5,10,0.2)
(2,5,0.5) (2,26,0.2)
(6,1,0.8) (7,15,0.1)
(4,6,0.2) (1,11,0.9)
(1,16,0.3) (4,6,0.4)
(4,13,0.1) (2,6,0.8)
(6,4,0.2) (2,10,0.5)
(1,10,1.0)
(4,26,0.1)
(5,2,1.0)
(3,4,0.8)
(4,3,0.8)
Table 5: Conﬁgurations (ND,NL,NW) of 3D HSK
compression for different AHSK. </Abstractive Summary> <Extractive Summary> 3.4x 2.7x
Table 2 presents the results of different KD-
basedBERTcompressionmethods.  </Extractive Summary>  </Table 2>  </Paper ID = 229>


<Paper ID = 23> <Table 0> <Abstractive Summary> =Thisisinlinewiththeﬁndings
Table 1: Utility functions used with MBR. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 23>


<Paper ID = 230> <Table 0> <Abstractive Summary> =2946Dataset #Train #Val #Test Metric
BoolQ 6,363 1,491 2,817
Movie 1,600 200 200 EM
SciFact 405 100 188
Table 1: Summary of datasets, dataset sizes, and their
correspondingmetrics. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 230>


<Paper ID = 230> <Table 1> <Abstractive Summary> =LAMOL 57.39 55.98 65.89 66.71 67.63 60.08 62.28 5.09
PartialBruteForce 62.97 64.05 66.73 67.75 65.22 69.05 65.96 2.30
block
RationalLAMOL 62.49 59.55 66.09 68.04 68.55 59.94 64.11 4.57
block
RationalLAMOL 64.35 61.70 65.22 67.76 56.59 60.62 62.71 3.93
head
Gen-RationalLAMOL 66.82 59.97 66.38 65.11 66.94 64.49 64.95 2.63
block
Gen-RationalLAMOL 67.35 57.36 66.51 63.85 63.98 65.52 64.10 3.57
head
Multitask 67.32
Table 2: Accuracy of different methods evaluated on the models at the last epoch of the last task, averaged over
three seeds. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 230>


<Paper ID = 230> <Table 2> <Abstractive Summary> =Table 3: Token-based precision, recall, and F1 show-
ingtheagreementbetweentherationalesgeneratedby ZhiyuanChen, NianzuMa, andBingLiu.2015. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 230>


<Paper ID = 231> <Table 0> <Abstractive Summary> =Wesetthemini-batchsizeas8,thenumber Table 4: ROUGE scores on CNN/DM and Xsum test
set, where the results are cited from Liu and Lapata
oftrainingepochsas5. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 231>


<Paper ID = 232> <Table 0> <Abstractive Summary> =Method #Param Speed-up MNLI MRPC SST-2
Devset
BERT-base 108M 1.00x 83.5 88.3 91.5
BERT-6L 66M 1.96x 79.1 83.9 89.6
BERT-9L 87M 1.30x 80.4 85.8 90.5
DistillBERT 66M 1.96x 79.8 85.3 89.3
BERT-PKD 66M 1.96x 80.6 85.5 89.7
BERT-of-Theseus 66M 1.96x 80.7 85.4 89.6
PABEE 108M 1.86x 81.5 86.2 90.4
FastBERT 108M 1.95x 82.1 86.7 90.8
LeeBERT(ours) 108M 1.97x 83.1 88.5 91.8
Testset
BERT-base 108M 1.00x 83.3 87.2 92.7
PABEE 108M 1.86x 81.6 85.2 91.3
FastBERT 108M 1.96x 82.0 85.7 91.7
LeeBERT(ours) 108M 1.97x 83.1 87.1 92.6
Table 5: Experimental results of models with BERT backbone on the development set and GLUE test set. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 232>


<Paper ID = 233> <Table 0> <Abstractive Summary> =Ourexplainabilitystudydemon-
strates the superiority of and preference for
summary-level explanations over other expla- Table 1: Illustration of the different types of explana-
nationtypes. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 233>


<Paper ID = 234> <Table 0> <Abstractive Summary> =8https://github.com/google-research/bert
2995Character-level(%) Sentence-level(%)
Category Method Detection-level Correction-level Detection-level Correction-level
P R F P R F P R F P R F
Hybrid(Wangetal.,2018) 54.0 69.3 60.7 - - 52.1 - - - - - -
PN(Wangetal.,2019) 66.8 73.1 69.8 71.5 59.5 69.9 - - - - - -
SOTA FASPell(Hongetal.,2019) - - - - - - 67.6 60.0 63.5 66.6 59.1 62.6
SKBERT(Zhangetal.,2020) - - - - - - 73.7 73.2 73.5 66.7 66.2 66.4
SpellGCN(Chengetal.,2020) 88.9 87.7 88.3 95.7 83.9 89.4 74.8 80.7 77.7 72.1 77.7 75.9
cBERT-Pretrain 64.2 83.2 72.5 85.6 71.2 77.7 37.9 49.5 42.9 32.1 42.0 36.4
Pretrain
PLOME-Pretrain 68.1 74.2 71.0 83.2 61.7 70.9 41.8 47.5 44.5 34.2 38.9 36.4
BERT-Finetune 90.9 84.9 87.8 95.6 81.2 87.8 68.4 77.6 72.7 66.0 74.9 70.2
Finetune cBERT-Finetune 92.4 87.7 90.0 96.2 84.4 89.9 75.3 78.9 77.1 72.7 76.1 74.4
PLOME-Finetune 94.5 87.4 90.8 97.2 84.3 90.3 77.4 81.5 79.4 75.3 79.3 77.2
Table 2: The performance of our approach and baseline models. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 234>


<Paper ID = 234> <Table 1> <Abstractive Summary> =SIGHAN13
BERT 80.6 88.4 84.3 98.1 87.2 92.3
SpellGCN 82.6 88.9 85.7 98.4 88.4 93.1
Previouswork(Wangetal.,2019;Chengetal.,
2020)conductedthecharacter-levelevaluationon PLOME 85.0 89.3 87.1 98.7 89.1 93.7
positive sentences which contain at least one er-
Table 5: The character-level performance of PLOME
ror(sentence-levelmetricswereevaluatedonthe
onSIGHAN13andSIGHAN14. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 234>


<Paper ID = 235> <Table 0> <Abstractive Summary> =Be-
sides, in Table 2, we further select six existing
6.3 MetricsandSettings state-of-the-artmodels,i.e.,HRGR-Agent(Lietal.,
Weadoptthewidely-usedBLEU(Papinenietal., 2018), CMAS-RL (Jing et al., 2019), SentSAT +
2002),METEOR(BanerjeeandLavie,2005)and KG (Zhang et al., 2020a), Up-Down (Anderson
ROUGE-L(Lin,2004),whicharereportedbythe etal.,2018),Transformer(Chenetal.,2020)and
4https://ii.nlm.nih.gov/MTI/ 5https://github.com/tylin/coco-caption
3007Dataset:MIMIC-CXR(Johnsonetal.,2019) Dataset:IU-Xray(Demner-Fushmanetal.,2016)
Methods
B-1 B-2 B-3 B-4 M R-L B-1 B-2 B-3 B-4 M R-L
NIC(Vinyalsetal.,2015)† 0.290 0.182 0.119 0.081 0.112 0.249 0.352 0.227 0.154 0.109 0.133 0.313
w/CMCL 0.301 0.189 0.123 0.085 0.119 0.241 0.358 0.223 0.160 0.114 0.137 0.317
Spatial-Attention(Luetal.,2017)† 0.302 0.189 0.122 0.082 0.120 0.259 0.374 0.235 0.158 0.120 0.146 0.322
w/CMCL 0.312 0.200 0.125 0.087 0.118 0.258 0.381 0.246 0.164 0.123 0.153 0.327
Adaptive-Attention(Luetal.,2017)† 0.307 0.192 0.124 0.084 0.119 0.262 0.433 0.285 0.194 0.137 0.166 0.349
w/CMCL 0.302 0.192 0.129 0.091 0.125 0.264 0.437 0.281 0.196 0.140 0.174 0.338
CNN-HLSTM(Krauseetal.,2017)† 0.321 0.203 0.129 0.092 0.125 0.270 0.435 0.280 0.187 0.131 0.173 0.346
w/CMCL 0.337 0.210 0.136 0.097 0.131 0.274 0.462 0.293 0.207 0.155 0.179 0.360
HLSTM+att+Dual(Harzigetal.,2019)† 0.328 0.204 0.127 0.090 0.122 0.267 0.447 0.289 0.192 0.144 0.175 0.358
w/CMCL 0.330 0.206 0.133 0.088 0.119 0.272 0.461 0.298 0.201 0.150 0.173 0.359
Co-Attention(Jingetal.,2018)† 0.329 0.206 0.133 0.095 0.129 0.273 0.463 0.293 0.207 0.155 0.178 0.365
w/CMCL 0.344 0.217 0.140 0.097 0.133 0.281 0.473 0.305 0.217 0.162 0.186 0.378
Table 1: Performance of automatic evaluations on the test sets of the MIMIC-CXR and the IU-Xray datasets. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 235>


<Paper ID = 235> <Table 1> <Abstractive Summary> =Dataset:MIMIC-CXR(Johnsonetal.,2019) Dataset:IU-Xray(Demner-Fushmanetal.,2016)
Methods
B-1 B-2 B-3 B-4 M R-L B-1 B-2 B-3 B-4 M R-L
HRGR-Agent(Lietal.,2018) - - - - - - 0.438 0.298 0.208 0.151 - 0.322
CMAS-RL(Jingetal.,2019) - - - - - - 0.464 0.301 0.210 0.154 - 0.362
SentSAT+KG(Zhangetal.,2020a) - - - - - - 0.441 0.291 0.203 0.147 - 0.367
Up-Down(Andersonetal.,2018) 0.317 0.195 0.130 0.092 0.128 0.267 - - - - - -
Transformer(Chenetal.,2020) 0.314 0.192 0.127 0.090 0.125 0.265 0.396 0.254 0.179 0.135 0.164 0.342
R2Gen(Chenetal.,2020) 0.353 0.218 0.145 0.103 0.142 0.277 0.470 0.304 0.219 0.165 0.187 0.371
CMCL(Ours) 0.344 0.217 0.140 0.097 0.133 0.281 0.473 0.305 0.217 0.162 0.186 0.378
Table 2: Comparison with existing state-of-the-art methods on the test set of the MIMIC-CXR dataset and the
IU-X-raydataset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 235>


<Paper ID = 236> <Table 0> <Abstractive Summary> =L2)            326 
(KET)  (PET)  (FCE)  (CAE)  (CPE) 
Table 2: Number of documents for each grade level in each data set 
 
documents  that  are  fill-in-the-blank  tests  or  and Retrofitting respectively to learn the optimized 
duplicate. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 236>


<Paper ID = 238> <Table 0> <Abstractive Summary> =Itcanbeinferredthat SEQA 4.1 3.2 5.8 4.7
thesemanticscoresarebeneﬁcialforcommonsense
Table 3: Consistency testing where the methods rank
question answering due to the reduction of dis-
80choicestoﬁnd4correctonesforeachexample.The
tractingfactors. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 238>


<Paper ID = 238> <Table 1> <Abstractive Summary> =Differentfromour SRoBERTa-base 72.4 72.0 75.4
SRoBERTa-large 74.2 75.2 79.4
method, they use the generated answers to form
partofthequestion,andthencalculatethegener-
Table 7: SEQA’s accuracy with different feature ex-
ative probability of the choice based on the aug-
tractors and language models on COPA. </Abstractive Summary> <Extractive Summary> wherethesentencesarecalledthechoice’ssupport-
Table 1 shows three representative methods,
ers.  </Extractive Summary>  </Table 1>  </Paper ID = 238>


<Paper ID = 238> <Table 2> <Abstractive Summary> =3043Score 3 2 1
Grammar 84.8% 12.8% 2.4%
Logic 40.8% 25.6% 33.6%
Table 8: Manual evaluation of the quality of voters
(generatedbyGPT-2-xlargeconditionedonquestions). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 238>


<Paper ID = 238> <Table 3> <Abstractive Summary> =Table 9: An example of voters as well as their voting 2019. </Abstractive Summary> <Extractive Summary> MI-QAandPro-Qaredesignedtoreducetheim- Table 3 shows the average standard deviation
pact of statistic bias in choices, so that they can of the ranks.  </Extractive Summary>  </Table 3>  </Paper ID = 238>


<Paper ID = 238> <Table 4> <Abstractive Summary> =Table 13: Templates and a rewritten example of CosmosQA. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 4>  </Paper ID = 238>


<Paper ID = 238> <Table 5> <Abstractive Summary> =T Dev Test
10 70.0 75.6
1 70.4 76.4
0.2 71.8 77.0
0.1 75.4 79.4
0.05 74.4 80.2
Table 15: Hyperparameter Search of SEQA. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 5>  </Paper ID = 238>


<Paper ID = 239> <Table 0> <Abstractive Summary> =achievesasimilarityscoreof61.9,wherelast
twoscoresarebasedonahumancorrelatedse-
Table 1: An example from CQA dataset along with
manticsimilaritymetric. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 239>


<Paper ID = 239> <Table 1> <Abstractive Summary> =ForScienceQAtask,anexpla-
2https://github.com/dair-iitd/
ECQA-Dataset 3https://github.com/dair-iitd/ECQA
3051KnowledgeBase FreeFlow
Datasets ReasoningType ReasoningSteps Refutation
ofFacts Explanation
WorldTree V2 Scientiﬁc Multi-hop N Y N
COS-E Common-sense Single-hop N N Y
QASC Scientiﬁc Two-hop N Y N
OpenBookQA Scientiﬁc Multi-hop N Y N
ECQA Common-sense Multi-hop Y Y Y
Table 2: Comparison of various properties of the different multi-choice QA explanation datasets. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 239>


<Paper ID = 239> <Table 2> <Abstractive Summary> =Table 4: Comparing information content through im-
portantwordsinCQA,CoS-EandECQA. </Abstractive Summary> <Extractive Summary> Table 2 compares
attempts to explain the predicted answers.  </Extractive Summary>  </Table 2>  </Paper ID = 239>


<Paper ID = 239> <Table 3> <Abstractive Summary> =Aspect µ σ e ρ
S+ 1.799 0.566 0.057 0.765
4.2 HumanValidationExperiments S− 1.588 0.604 0.060 0.748
Weperformedtwohumanvalidationexperiments
to assess the absolute (and relative to CoS-E) Table 5: Absolute Dataset Quality Experiment: Posi-
quality of our ECQA dataset. </Abstractive Summary> <Extractive Summary> Our
of Table 3 gives the average count and the word
ECQAdatasethaspreciselyannotatedthesesetsfor
lengthofpropertiesperquestion.  </Extractive Summary>  </Table 3>  </Paper ID = 239>


<Paper ID = 239> <Table 4> <Abstractive Summary> =Table 8: Explanation retrieval results over gold and
silver corpus for different choices of property ranker Inference: WeusetestsetofECQAtotestXGP. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 4>  </Paper ID = 239>


<Paper ID = 239> <Table 5> <Abstractive Summary> =herneighbour’}
Query (q,a,c): (two friends wanted to spend
Table11: ExampleofCommonsenseQAwithouran-
aquieteveningtogether,whatdidtheygosee?,
notatedexplanation
Restaurant,False)
Goldset(p∗): {’restaurantwillnotbequiet’}
A.2 ExperimentalDetails Ours+top-k: {’restaurant is where people go
andeat’}
Computing Infrastructure: We run all our
BM25+top-k: {’restaurantwillnotbequiet’}
experimentsonamachinewithasingleTeslaP100
GPU (16 GiB) and 8 Intel(R) Xeon(R) E5-2690
Table 12: Anecdotal examples of retrieved properties
v4 @ 2.60GHz CPUs with 59 GiB of physical
byourproposedXRsystem. </Abstractive Summary> <Extractive Summary> Overall 92.33 0.33 0.33 7.00
Table 5 lists down the mean (µ), standard devia-
tion(σ),standarderror(e),andaveragePearson’s Table6: HumanJudgementsforRelativeDatasetQual-
correlation coefﬁcient (ρ) for both positive and ity Experiment: ECQA and CoS-E.  </Extractive Summary>  </Table 5>  </Paper ID = 239>


<Paper ID = 239> <Table 6> <Abstractive Summary> =Table 16: Pearson’s correlation coefﬁcient for Rela-
Thresholdsveriﬁcation: Wedesignedanother
tive Dataset Quality Experiment: ECQA and CoS-E.
experimenttoverifythesethresholds. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 6>  </Paper ID = 239>


<Paper ID = 239> <Table 7> <Abstractive Summary> =Generation
Measure ST SP C M R XGP-W 33.0 30.1 9.8 12.3 22.6
XGP 36.4 32.2 11.1 13.7 25.7
Threshold 0.6 0.4 0.3 0.3 0.3
F Score(%) 78.1 64.7 35.3 54.3 36.5
1
Table 17: Explanation retrieval results over silver cor-
PC(%) 59.6 35.0 31.0 47.7 21.8
pus for different XR systems and property generation
results by the XGP models for all 5 metrics. </Abstractive Summary> <Extractive Summary> Table 7 shows
ECQAvalset.  </Extractive Summary>  </Table 7>  </Paper ID = 239>


<Paper ID = 239> <Table 8> <Abstractive Summary> =ST: STS-
Table 15: Human correlation with different metrics. </Abstractive Summary> <Extractive Summary> Table 8 shows
thesemanticsimilarityofthecorrespondingprop-
theperformancecomparisonofXRsystemongold
ertysentences. Note that we have
6.1 PropertyGeneration(XGP) alsoincludedthebestretrievalmodelonthesilver
corpus from Table 8 to show that our generation
InputtotheXGPisatuple(q,a,c)anditgenerates
models perform signiﬁcantly better than it. We used the same thresholds (τ) for
BM25+AIR 15.1 18.4 3.2 4.3 13.1
retrieval using silver corpus and property genera-
BM25+top-k 16.2 19.8 4.1 4.5 10.1
tion results reported in the Table 8 and 9 of the
Ours+AIR 25.0 25.4 3.3 5.4 14.7
mainpaperusingourproposedunweightedbipar-
Ours+top-k 27.6 28.5 4.0 5.5 14.1
titematchingbasedmetric.  </Extractive Summary>  </Table 8>  </Paper ID = 239>


<Paper ID = 239> <Table 9> <Abstractive Summary> =We analyzed the rare novel words present in
our annotations and found that on average, every
Dataset BLEU-4 ROUGE
annotation has 0.23 words which do not appear
CoS-E\CQA 18.0 16.2
anywhereelseinthecorpus,0.7wordswhichap-
ECQA\CQA 18.3 24.5
pear less than 10 times and 2.4 words appearing
less than 100 times in the whole corpus of about
Table 19: Comparing information content through
1.5 million words. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 9>  </Paper ID = 239>


<Paper ID = 24> <Table 0> <Abstractive Summary> =(M)
Train Decode
AttentionBased
Transformer(Vaswanietal.,2017) 27.55 62.37 1.00 1.00
AAN(Zhangetal.,2018a) 27.63 74.97 1.04 1.52
Recurrent
LN-LSTM(Chenetal.,2018) 27.96 68.69 0.45 1.47
ATR(Zhangetal.,2018b) 27.93 59.23 0.50 1.69
Ours
MHPLSTM 28.37 62.80 1.16 1.69
Table 2: Comparison on WMT 14 En-De. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 24>


<Paper ID = 240> <Table 0> <Abstractive Summary> =We observe
3071Model SQuAD TriviaQA NQ NewsQA SearchQA HotpotQA BioASQ TextbookQA
16Examples
RoBERTa 7.7 7.5 17.3 1.4 6.9 10.5 16.7 3.3
SpanBERT 12.5 12.8 19.7 6.0 13.0 12.6 22.0 5.6
SpanBERT(Reimpl) 18.2 11.6 19.6 7.6 13.3 12.5 15.9 7.5
Splinter 54.6 18.9 27.4 20.8 26.3 24.0 28.2 19.4
128Examples
RoBERTa 43.0 19.1 30.1 16.7 27.8 27.3 46.1 8.2
SpanBERT 48.5 24.2 32.2 17.4 34.3 35.1 55.3 9.4
SpanBERT(Reimpl) 55.8 26.3 36.0 29.5 26.3 36.6 52.2 20.9
Splinter 72.7 44.7 46.3 43.5 47.2 54.7 63.2 42.6
1024Examples
RoBERTa 73.8 46.8 54.2 47.5 54.3 61.8 84.1 35.8
SpanBERT 77.8 50.3 57.5 49.3 60.1 67.4 89.3 42.3
SpanBERT(Reimpl) 77.8 55.5 59.5 52.2 58.9 64.6 89.0 45.7
Splinter 82.8 64.8 65.5 57.3 67.3 70.3 91.0 54.5
FullDataset
RoBERTa 90.3 74.0 79.6 69.8 81.5 78.7 - -
SpanBERT 92.0 77.2 80.6 71.3 80.1 79.6 - -
SpanBERT(Reimpl) 92.0 75.8 80.5 71.1 81.4 79.7 - -
Splinter 92.2 76.5 81.0 71.3 83.0 80.7 - -
Table 1: Performance (F1) across all datasets when the number of training examples is 16, 128, and 1024. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 240>


<Paper ID = 240> <Table 1> <Abstractive Summary> =Having said that, SpanBERT 0.23
SpanBERT(Reimpl) 0.19
mostofSplinter’simprovementsintheextremely
Splinter 0.89
lowdataregimedostemfromcombiningtheQASS
layer with our pretraining scheme, and this com- Table 2: Cosine similarity of the representations pro-
binationstilloutperformsallothervariantsasthe ducedbythetransformerencoderbeforeandafterﬁne-
amountofdatagrows. </Abstractive Summary> <Extractive Summary> 6 Results
6.2 High-ResourceRegime
Our experiments show that Splinter dramatically
improvesperformanceinthechallengingfew-shot Table 1 also shows the performance when ﬁne-
setting,unlockingtheabilitytotrainquestionan- tuning on the entire training set, when an order
swering models with only hundreds of examples.  </Extractive Summary>  </Table 1>  </Paper ID = 240>


<Paper ID = 241> <Table 0> <Abstractive Summary> =3083Model ReaderType ReaderSize(M) NQ TriviaQA
REALM(Guuetal.,2020) Extractive 110 40.4 N/A
RAG(Lewisetal.,2020) Generative 400 44.5 56.1
DPR(Karpukhinetal.,2020) Extractive 110 41.5 57.9
T5-FID (IzacardandGrave,2021) Generative 220 48.2 65.0
base
T5-FID (IzacardandGrave,2021) Generative 770 51.4 67.6
large
UnitedQA-E (Ours) Extractive 110 47.7 66.3
base
UnitedQA-E (Ours) Extractive 330 51.8 68.9
large
UnitedQA-G (Ours) Generative 770 52.3 68.6
large
UnitedQA-E ++(Ours) Ensemble 3x330 52.4 69.6
large
UnitedQA-G ++(Ours) Ensemble 3x770 53.3 69.2
large
UnitedQA(Ours) Hybrid 2x770+330 54.7 70.5
Table 2: Comparison to state-of-the-art models on the test sets of NaturualQuestions (NQ) and TriviaQA. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 241>


<Paper ID = 241> <Table 1> <Abstractive Summary> =Lastly,weseethatbothextrac-
Retrieval 79.9 84.4 +6%
tiveandgenerativemodelssuffersomesigniﬁcant
TriviaQA United-E 67.1 68.9 +3%
performancedegradationforthe“NoOverlap”col-
United-G 65.4 68.6 +5%
umnwhichhighlightsmodel’sgeneralizationeval-
Table 5: Retieval top-k accuracy and end-to-end QA uation. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 241>


<Paper ID = 241> <Table 2> <Abstractive Summary> =Thishigh-
3086No Answer
Question Answer No
Dataset Model Total Question Overlap
Overlap Overlap Overlap
Overlap Only
UnitedQA-G 52.3 72.2 40.5 62.7 45.4 34.0
NQ
UnitedQA-E 51.8 69.4 41.5 60.1 45.1 37.6
UnitedQA-G 68.6 88.4 62.5 78.1 69.6 44.5
TriviaQA
UnitedQA-E 68.9 89.3 62.7 78.6 70.6 44.3
Table 6: Breakdown evaluation on NaturalQuestions (NQ) and TriviaQA based on test splits deﬁned in (Lewis
etal.,2021). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 241>


<Paper ID = 242> <Table 0> <Abstractive Summary> =Count 60.21 83.11 61.58 83.41
Min/Max 70.88 93.25 71.80 93.41
Average 65.96 86.51 67.36 86.82
Inter-factattention ApplyingFiD,whichdoes
not capture inter-fact attention, to scale to larger Table 4: Precision and recall of supervised SSG w.r.t. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 242>


<Paper ID = 243> <Table 0> <Abstractive Summary> =thesharedtask’sofﬁcialtop3,aftergoingthrough
3109Iteration 10 50 100 500 1000 1997
Top 1 3 1 3 1 3 1 3 1 3 1 3
human-zero 0.00 0.33 0.00 0.00 0.00 0.33 1.00 0.67 1.00 0.67 0.00 0.67
F
A human-avg 0.00 0.00 1.00 0.67 1.00 0.33 0.00 1.00 0.00 1.00 0.00 1.00
W
E human-comet 0.00 0.33 0.00 1.00 0.00 0.67 0.00 1.00 0.00 1.00 0.00 1.00
human-zero 0.00 0.33 0.00 0.00 0.00 0.00 0.00 0.33 1.00 0.33 1.00 0.33
3
P human-avg 0.00 0.00 0.00 0.33 0.00 0.67 0.00 0.33 0.00 0.33 0.00 0.33
X
E human-comet 0.00 0.00 0.00 0.00 0.00 0.33 0.00 0.00 0.00 0.00 0.00 0.33
Table 3: Overlap ratios of top 1 and top 3 systems in common between the online approaches and the ofﬁcial
rankingforen-de. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 243>


<Paper ID = 243> <Table 1> <Abstractive Summary> =Iteration 10 50 100 500 1000 1701
Top 1 3 1 3 1 3 1 3 1 3 1 3
human-zero 0.00 0.67 0.00 0.33 0.00 0.33 0.00 0.67 0.00 0.67 1.00 0.67
F
A human-avg 0.00 0.67 0.00 0.67 0.00 0.67 0.00 0.33 0.00 0.33 0.00 0.33
W
E human-comet 1.00 1.00 1.00 0.67 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00
human-zero 0.00 0.67 0.00 0.33 0.00 0.33 0.00 0.33 1.00 0.67 1.00 0.67
3
P human-avg 0.00 0.33 0.00 0.33 0.00 0.33 0.00 0.33 0.00 0.33 0.00 0.33
X
E human-comet 0.00 0.33 0.00 0.67 0.00 0.67 0.00 0.33 0.00 0.67 0.00 0.67
Table 4: Overlap ratios of top 1 and top 3 systems in common between the online approaches and the ofﬁcial
rankingforfr-de. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 243>


<Paper ID = 243> <Table 2> <Abstractive Summary> =Iteration 10 50 100 500 1000 1997
Top 1 3 1 3 1 3 1 3 1 3 1 3
human-zero 0.00 0.33 1.00 0.67 1.00 0.67 0.00 0.67 1.00 1.00 0.00 1.00
F
A human-avg 0.00 0.33 0.00 0.33 1.00 0.67 1.00 0.67 1.00 0.67 1.00 1.00
W
E human-comet 0.00 0.33 1.00 0.67 1.00 0.67 1.00 1.00 1.00 1.00 1.00 1.00
human-zero 0.00 0.33 0.00 0.67 0.00 0.67 0.00 0.67 0.00 0.67 1.00 1.00
3
P human-avg 0.00 0.33 0.00 0.33 0.00 0.33 0.00 0.67 1.00 0.67 1.00 0.67
X
E human-comet 0.00 0.33 1.00 0.33 1.00 0.33 1.00 0.67 1.00 0.67 1.00 0.67
Table 5: Overlap ratios of top 1 and top 3 systems in common between the online approaches and the ofﬁcial
rankingforde-cs. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 243>


<Paper ID = 243> <Table 3> <Abstractive Summary> =3110Iteration 10 50 100 500 1000 1016
Top 1 3 1 3 1 3 1 3 1 3 1 3
F human-zero 1.00 0.67 1.00 1.00 1.00 1.00 1.00 0.67 1.00 0.67 1.00 0.67
A
W human-comet 1.00 0.67 0.00 0.67 0.00 0.67 0.00 0.67 0.00 0.33 0.00 0.33
E
3 human-zero 0.00 0.33 0.00 0.67 0.00 0.33 0.00 0.33 0.00 0.33 0.00 0.33
P
X human-comet 0.00 0.33 1.00 0.33 1.00 0.33 1.00 0.33 0.00 0.67 0.00 0.67
E
Table 6: Overlap ratios of top 1 and top 3 systems in common between the online approaches and the ofﬁcial
ranking for gu-en. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 243>


<Paper ID = 243> <Table 4> <Abstractive Summary> =Iteration 10 50 100 500 1000
Top 1 3 1 3 1 3 1 3 1 3
EWAF human-zero 0.00 0.00 0.00 0.67 0.00 0.67 1.00 0.67 0.00 1.00
EXP3 human-zero 0.00 0.33 0.00 0.00 0.00 0.33 1.00 0.67 1.00 0.67
Table 7: Overlap ratios of top 1 and top 3 systems in common between the online approaches and the ofﬁcial
rankingforlt-en. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 4>  </Paper ID = 243>


<Paper ID = 244> <Table 0> <Abstractive Summary> =3120Language ISO LanguageFamily PretrainedBERTModel NER SA QA UDP POS
Arabic AR Afroasiatic AraBERT(Antounetal.,2020) Lg Model Test Test Dev Test Test
English EN Indo-European BERT(Devlinetal.,2019) F1 Acc EM/F1 UAS/LAS Acc
Finnish FI Uralic FinBERT(Virtanenetal.,2019) Monolingual 91.1 95.9 68.3/82.4 90.1/85.6 96.8
Indonesian ID Austronesian IndoBERT(Wilieetal.,2020) AR mBERT 90.0 95.4 66.1/80.6 88.8/83.8 96.8
Japanese JA Japonic Japanese-charBERT5
Monolingual 91.5 91.6 80.5/88.0 92.1/89.7 97.0
Korean KO Koreanic KR-BERT(Leeetal.,2020) EN
mBERT 91.2 89.8 80.9/88.4 91.6/89.1 96.9
Russian RU Indo-European RuBERT(KuratovandArkhipov,2019)
Turkish TR Turkic BERTurk(Schweter,2020) Monolingual 92.0 —– 69.9/81.6 95.9/94.4 98.4
Chinese ZH Sino-Tibetan ChineseBERT(Devlinetal.,2019) FI mBERT 88.2 —– 66.6/77.6 91.9/88.7 96.2
Monolingual 91.0 96.0 66.8/78.1 85.3/78.1 92.1
Table 1: Overview of selected languages and their re- ID mBERT 93.5 91.4 71.2/82.1 85.9/79.3 93.5
spectivepretrainedmonolingualBERTmodels. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 244>


<Paper ID = 244> <Table 1> <Abstractive Summary> =We employ: HARD AVG mBERT 87.0 91.0 69.7/83.3 88.4/84.4 96.4
(Elnagar et al., 2018), IMDb Movie Reviews
Table 2: Performance on Named Entity Recognition
(Maas et al., 2011), Indonesian Prosa (Purwari-
(NER),SentimentAnalysis(SA),QuestionAnswering
anti and Crisdayanti, 2019), Yahoo Movie Re-
(QA),UniversalDependencyParsing(UDP),andPart-
views,7 NSMC,8 RuReviews (Smetanin and Ko-
of-Speech Tagging (POS). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 244>


<Paper ID = 244> <Table 2> <Abstractive Summary> =(2020) 16424 47.4 ZH GSD (Zemanetal.,2020) 3997/500/500
RU DeepPavlov/rubert-base-cased KuratovandArkhipov(2019) 119547 21.1
TZRH dbbermt-dbza/sbee-rcth-binaessee-turkish-cased SDcehvwlineteerta(2l.0(2200)19) 3221010208 2739..04 Table 7: Named entity recognition (NER), sentiment
analysis(SA),questionanswering(QA),anduniversal
Table5: Selectionofpretrainedmodelsusedinourex-
dependencies (UD) datasets used in our experiments
periments. </Abstractive Summary> <Extractive Summary> (2011) 20000/5000/25000
FI — — —
ID IndonesianProsa PurwariantiandCrisdayanti(2019) 6853/763/409
the full results corresponding to Table 2 (initial SA JA YahooMovieReviews 7 30545/3818/3819
KO NSMC 8 120000/30000/50000
results),Table9showsthefullresultscorrespond- RU RuReviews SmetaninandKomarov(2019) 48000/6000/6000
TR Movie&ProductReviews DemirtasandPechenizkiy(2013) 13009/1627/1629
ing to Table 3 (results for our new models), and ZH ChnSentiCorp 9 9600/1200/1200
AR TyDiQA-GoldP Clarketal.  </Extractive Summary>  </Table 2>  </Paper ID = 244>


<Paper ID = 244> <Table 3> <Abstractive Summary> =Pro- MBERTMODEL-MBERTTOK 91.3 90.3 90.5 90.7 66.4/81.3 85.1/80.0 86.6/81.7 95.8 95.9
mBERT 91.2 90.4 90.5 90.0 66.3/81.2 84.7/79.6 86.1/81.0 95.6 95.6
portion), a relative decrease in fertility, and a rela-
tive increase in pretraining corpus size with a relative Table 9: Full Results - Performance of our new
increase in downstream performance over fully ﬁne- MONOMODEL-* and MBERTMODEL-* models (see
tunedmBERT. </Abstractive Summary> <Extractive Summary> (2011) 20000/5000/25000
FI — — —
ID IndonesianProsa PurwariantiandCrisdayanti(2019) 6853/763/409
the full results corresponding to Table 2 (initial SA JA YahooMovieReviews 7 30545/3818/3819
KO NSMC 8 120000/30000/50000
results),Table9showsthefullresultscorrespond- RU RuReviews SmetaninandKomarov(2019) 48000/6000/6000
TR Movie&ProductReviews DemirtasandPechenizkiy(2013) 13009/1627/1629
ing to Table 3 (results for our new models), and ZH ChnSentiCorp 9 9600/1200/1200
AR TyDiQA-GoldP Clarketal.  </Extractive Summary>  </Table 3>  </Paper ID = 244>


<Paper ID = 244> <Table 4> <Abstractive Summary> =Monolingual 95.4 91.5 91.6 91.6 80.5/88.0 92.6/90.3 92.1/89.7 97.1 97.0
EN mBERT 95.7 91.2 90.1 89.8 80.9/88.4 92.1/89.6 91.6/89.1 97.0 96.9
Monolingual 93.3 92.0 —– —– 69.9/81.6 95.7/93.9 95.9/94.4 98.1 98.4
FI mBERT 90.9 88.2 —– —– 66.6/77.6 91.1/88.0 91.9/88.7 96.0 96.2 NER SA QA UDP POS
Monolingual 90.9 91.0 94.6 96.0 66.8/78.1 84.5/77.4 85.3/78.1 92.0 92.1 Lg Model Dev Test Dev Test Dev Dev Test Dev Test
ID mBERT 93.7 93.5 93.1 91.4 71.2/82.1 85.0/78.4 85.9/79.3 93.3 93.5 F1 F1 Acc Acc EM/F1 UAS/LAS UAS/LAS Acc Acc
mBERT 90.3 90.0 95.8 95.4 66.1/80.6 87.8/83.0 88.8/83.8 97.2 96.8
JA MmBonEoRlTingual 7732..14 7732..44 8888..87 8887..08 ——––//——–– 9956..50//9944..27 9944..07//9923..30 9988..13 9987..81 AR ++AATTaasskk+ALang 9900..02 8899..67 9966..11 9955..67 6666..79//8811..01 8876..07//8811..96 8887..08//8822..86 9977..33 9966..88
Monolingual 88.6 88.8 89.8 89.7 74.2/91.1 88.5/85.0 90.3/87.2 96.4 97.0 +ATask+ALang+MONOTOK 91.5 91.1 96.0 95.7 67.7/82.1 87.7/82.8 88.5/83.4 97.3 96.5
KO mBERT 87.3 86.6 86.7 86.7 69.7/89.5 86.9/83.2 89.2/85.7 95.8 96.0 mBERT 90.9 88.2 —– —– 66.6/77.6 91.1/88.0 91.9/88.7 96.0 96.2
+ATask 91.2 88.5 —– —– 65.2/77.3 90.2/86.3 90.8/87.0 95.8 95.7
RU MmBonEoRlTingual 9910..92 9910..00 9955..22 9955..02 6634..33//8832..76 9921..45//9880..81 9913..91//8889..59 9988..46 9988..24 FI ++AATTaasskk++AALLaanngg+MONOTOK 9910..68 8888..41 ——–– ——–– 6665..77//7797..01 9921..81//8879..79 9912..88//9880..15 9966..93 9967..63
Monolingual 93.1 92.8 89.3 88.8 60.6/78.1 78.0/70.9 79.8/73.2 97.0 96.9 mBERT 93.7 93.5 93.1 91.4 71.2/82.1 85.0/78.4 85.9/79.3 93.3 93.5
TR mBERT 93.7 93.8 86.4 86.4 57.9/76.4 72.6/65.2 74.5/67.4 95.5 95.7 ID ++AATTaasskk+ALang 9933..36 9933..55 9923..91 9903..66 7700..68//8822..52 8834..73//7767..54 8845..84//7778..41 9933..56 9933..44
ZH MmBonEoRlTingual 7776..00 7766..51 9943..81 9953..38 8822..03//8899..33 8887..11//8843..97 8888..61//8855..60 9966..61 9976..27 mB+EARTTask+ALang+MONOTOK 9837..03 9863..64 9846..57 9836..87 7649..47//8849..45 8864..69//7873..62 8859..12//8758..73 9935..78 9936..50
+ATask 87.1 86.2 86.7 86.5 69.8/89.7 85.5/81.1 87.8/83.9 95.9 96.2
AVG MmBonEoRlTingual 8887..29 8877..40 9921..52 9921..40 6790..78//8834..30 8897..57//8853..88 9808..04//8864..34 9966..94 9966..94 KO ++AATTaasskk++AALLaanngg+MONOTOK 8877..37 8866..52 8876..96 8876..93 7730..10//9809..48 8875..09//8812..67 8888..93//8845..32 9966..03 9966..25
mBERT 93.7 93.8 86.4 86.4 57.9/76.4 72.6/65.2 74.5/67.4 95.5 95.7
Table 8: Full Results - Performance on Named Entity TR ++AATTaasskk+ALang 9933..03 9933..05 8866..12 8834..98 5556..39//7755..18 7701..41//6623..00 7723..40//6644..17 9956..50 9955..79
Recognition (NER), Sentiment Analysis (SA), Ques- +ATask+ALang+MONOTOK 92.7 92.7 86.1 85.3 60.0/77.0 73.5/65.6 75.7/68.1 96.4 96.3
mBERT 91.2 90.4 90.5 90.0 66.3/81.2 84.7/79.6 86.0/81.0 95.6 95.6
tion Answering (QA), Universal Dependency Parsing AVG ++AATTaasskk+ALang 9901..92 9900..32 9900..55 9809..21 6665..15//8811..12 8833..93//7787..53 8845..37//7799..07 9955..68 9955..86
(UDP),andPart-of-SpeechTagging(POS).Weusede- +ATask+ALang+MONOTOK 91.1 90.4 91.1 90.7 68.4/82.6 85.1/79.7 86.2/81.0 96.1 96.0
velopment(dev)setsonlyforQA.Finnish(FI)SAand Table 10: Full Results - Performance on the different
Japanese(JA)QAlackrespectivedatasets. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 4>  </Paper ID = 244>


<Paper ID = 245> <Table 0> <Abstractive Summary> =3139Train ○Fusional ØIsolating (cid:20)Agglutinative (cid:24) Introﬂexive
Test mBERT XLM-R mBERT XLM-R mBERT XLM-R mBERT XLM-R
○Fusional 81.2 82.3 63.6 65.2 61.3 62.4 65.8 65.8
ØIsolating 52.8 58.2 55.0 60.3 52.9 58.4 51.5 57.3
(cid:20)Agglutinative 59.4 61.8 57.4 60.1 61.3 65.0 56.4 57.8
(cid:24) Introﬂexive 43.2 43.5 40.7 40.6 39.1 39.3 46.6 45.6
Train ○Fusional ØIsolating (cid:20)Agglutinative (cid:24) Introﬂexive
Test mBERT XLM-R mBERT XLM-R mBERT XLM-R mBERT XLM-R
○Fusional 56.7 74.3 57.9 69.1 59.2 70.9 50.2 58.7
ØIsolating 50.5 76.2 59.9 71.3 55.6 75.4 41.9 52.8
(cid:20)Agglutinative 53.8 77.5 55.9 69.1 54.7 72.7 45.7 60.8
(cid:24) Introﬂexive 50.0 60.7 54.2 58.2 52.4 59.4 49.9 55.2
Table 3: Group-to-group cross-lingual accuracy scores (%) in part-of-speech tagging (top) and macro F scores
1
(%)insentimentanalysis(bottom)foreachﬁne-tuning(column)andtesting(row)morphologicalgroup,andeach
modelarchitecture. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 245>


<Paper ID = 245> <Table 1> <Abstractive Summary> =3140Train ○Fusional ØIsolating (cid:20)Agglutinative (cid:24) Introﬂexive
Test mBERT XLM-R mBERT XLM-R mBERT XLM-R mBERT XLM-R
○Fusional 16.6 15.3 28.8 27.7 34.2 33.2 26.3 26.7
ØIsolating 45.0 39.4 37.4 32.6 42.6 37.2 40.6 35.2
(cid:20)Agglutinative 38.5 35.8 34.9 32.8 34.3 30.5 35.7 34.7
(cid:24) Introﬂexive 54.6 54.2 51.7 52.3 56.5 56.3 45.5 46.9
Train ○Fusional ØIsolating (cid:20)Agglutinative (cid:24) Introﬂexive
Test mBERT XLM-R mBERT XLM-R mBERT XLM-R mBERT XLM-R
○Fusional 26.5 13.5 31.2 22.8 26.5 19.4 33.0 22.7
ØIsolating 32.7 11.6 29.2 20.6 30.1 15.0 41.3 28.6
(cid:20)Agglutinative 29.4 10.3 33.2 22.8 31.0 17.7 37.5 20.6
(cid:24) Introﬂexive 33.2 27.1 34.9 33.8 33.3 31.0 33.3 26.3
Table 4: Group-to-group transfer loss (in percentage points) in the part-of-speech tagging (top) and sentiment
analysis(bottom)tasksforeachﬁne-tuning(column)andtesting(row)language’smorphologicalgroup, aswell
aseachmodelarchitecture. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 245>


<Paper ID = 246> <Table 0> <Abstractive Summary> =We use the real monolin-
TCS(S) 59.57±0.57 59.39±0.81 gual sentence as the reference and the generated
All-CS 59.74±0.96 58.77±0.44
CSsentenceasthecandidate,excludingsentences
fromTCS(S)andTCS(U)thatexactlymatchthe
Table 7: GLUECoSEvaluation: Meanandstandarddevia-
tionofscoresafterevaluatingon5seeds. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 246>


<Paper ID = 246> <Table 1> <Abstractive Summary> =देश का आंत(cid:464)रक कजर् ूबन्ध (cid:465)कए जाने योग्य सीमा में है
(Thecountry’sinternaldebtiswithinmanageablelimits)
G DetailsofGLUECoSExperiments देश काinternalloanmanage(cid:465)कए जाने योग्य सीमा में है
Formaskedlanguagemodeling(MLM),weselect Table 10: More examples of code-switching generated by
TCS(U). </Abstractive Summary> <Extractive Summary> Table 1 shows two tions for Movie-CS and Treebank-CS, along with
HindisentencesfromMovie-CSandTreebank-CS, histogramsaccumulatingEnglishsegmentsofdif-
alongwiththedifferentvariantsofCSsentences.  </Extractive Summary>  </Table 1>  </Paper ID = 246>


<Paper ID = 247> <Table 0> <Abstractive Summary> =lationtasksintotal: English↔German(En↔De),
3174TM-specializedTasks GeneralWMTTasks SentsPercents Baseline StdTrain JointTrain
Similarity
Fr↔EnEs↔EnDe↔En En→De Zh→En (#) (%) TF TF-SA TF-SA
Train/Sent(#) 740467673856693011 4558262 20605452 [0,0.1) 2 0.08 36.91 64.05 74.48
[0.1,0.2) 138 5.34 38.53 37.70 39.52
Dev/Sent(#) 2649 2511 2440 3000 2002
[0.2,0.3) 462 17.87 47.88 47.07 49.09
Test/Sent(#) 2650 2585 2461 3003/3004 2001 [0.3,0.4) 305 11.80 54.02 54.75 56.19
[0.4,0.5) 272 10.52 62.29 64.01 66.18
En/Word(#) 29.44 32.68 34.00 28.94 25.46
[0.5,0.6) 206 7.97 65.94 71.32 72.48
Other/Word(#) 33.35 35.58 34.22 29.90 23.03
[0.6,0.7) 203 7.85 71.88 79.63 80.08
[0.7,0.8) 188 7.27 77.20 85.96 86.45
Table 1: Statistics of the datasets. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 247>


<Paper ID = 247> <Table 1> <Abstractive Summary> =Batchsize 3500 2500 4096
Sourcevocab 20000 32000 75000
Targetvocab 20000 32000 63000
Baseline systems We compare our proposed
modelwiththestrongbaselinesasfollows:
Table 2: Training settings. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 247>


<Paper ID = 247> <Table 2> <Abstractive Summary> =Fromthistable,wecanseethatourmod- Table 5: BLEU comparison on Es→En and Zh→En
els achieve substantial improvements over Trans- tasks. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 247>


<Paper ID = 247> <Table 3> <Abstractive Summary> =ploy the same retrieval metric and their retrieval
3176Time(s) TF TF-P TF-SEQ TF-G FM+ TF-S TF-SS TF-SA
Train 3727 - 17841 7074 7720 4350 4361 4518
Test 0.30 0.71 1.91 0.55 0.33 0.39 0.40 0.41
Table 7: Running time comparison on Es→En task. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 247>


<Paper ID = 249> <Table 0> <Abstractive Summary> =Hence, we ﬁrst FEW-NERD(INTRA) 99,519 19,358 44,059
splittheoverallentityset(denotedasE)intothree FEW-NERD(INTER) 130,112 18,817 14,007
mutually disjoint subsets, respectively denoted
(cid:83) (cid:83) Table 3: Statistics of train, dev and test sets for three
as E ,E ,E , and E E E = E,
E tr(cid:84)ainE dev(cid:84)Etest = ∅. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 249>


<Paper ID = 249> <Table 1> <Abstractive Summary> =OntoNotes5.0 90.00 88.24 89.11
The ﬁrst baseline model we implement is Proto-
FEW-NERD(SUP) 67.39(↓) 70.45(↓) 68.88(↓)
BERT, which is a method based on prototypical
network (Snell et al., 2017) with a backbone of Table 4: Results of BERT-Tagger on previous NER
BERT (Devlin et al., 2019a) encoder. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 249>


<Paper ID = 249> <Table 2> <Abstractive Summary> =Table 7: Error analysis of 5 way 5∼10 shot on
Acknowledgements
FEW-NERD(INTER), “Within” indicates “within the
coarsetypes”and“Outer”is“outerthecoarsetypes”. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 249>


<Paper ID = 25> <Table 0> <Abstractive Summary> =ferent,thoughgrow-diagonal-ﬁnal-andgenerally
288DeEn EnFr RoEn
BTBA +FCBO +SST BTBA +FCBO +SST BTBA +FCBO +SST
forward 20.2% 18.3% 14.3% 13.6% 12.8% 7.3% 24.7% 22.4% 20.5%
backward 23.8% 23.3% 17.2% 14.6% 13.3% 7.5% 27.3% 26.1% 22.0%
union 20.6% 18.3% 14.5% 15.7% 14.3% 7.5% 24.1% 21.2% 18.9%
intersection 23.7% 23.9% 17.1% 11.6% 11.2% 7.4% 28.3% 27.9% 24.0%
grow-diagonal 19.9% 18.5% 14.3% 11.2% 10.7% 6.9% 23.6% 21.6% 18.6%
grow-diagonal-and 21.0% 20.6% 17.3% 9.5% 8.9% 6.7% 26.1% 25.4% 23.6%
grow-diagonal-ﬁnal 19.5% 17.3% 14.4% 14.4% 13.4% 7.4% 23.4% 20.8% 18.6%
grow-diagonal-ﬁnal-and 17.8% 16.3% 14.3% 11.9% 11.2% 7.0% 22.9% 20.6% 18.5%
Table 4: Comparison of different heuristics for symmetrizing the BTBA alignments. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 25>


<Paper ID = 25> <Table 1> <Abstractive Summary> =DeEn EnFr RoEn DeEn EnFr RoEn
forward 19.0% 10.3% 25.6% forward 14.5% 5.8% 21.4%
backward 22.5% 9.1% 29.7% backward 17.6% 4.2% 21.9%
union 22.1% 12.9% 27.5% union 15.1% 5.3% 19.9%
intersection 19.0% 5.2% 27.8% intersection 17.2% 4.7% 23.6%
grow-diagonal 18.4% 7.7% 24.5% grow-diagonal 14.7% 4.6% 19.7%
grow-diagonal-and 18.9% 5.7% 26.1% grow-diagonal-and 17.5% 4.4% 23.7%
grow-diagonal-ﬁnal 21.1% 11.7% 26.0% grow-diagonal-ﬁnal 15.1% 5.3% 19.8%
grow-diagonal-ﬁnal-and 18.9% 8.5% 24.2% grow-diagonal-ﬁnal-and 14.8% 4.7% 19.8%
Table 5: Comparison of different heuristics for sym- Table 6: Comparison of different heuristics for sym-
metrizingGIZA++alignments. </Abstractive Summary> <Extractive Summary> the test set as shown in Table 1 any more.  </Extractive Summary>  </Table 1>  </Paper ID = 25>


<Paper ID = 25> <Table 2> <Abstractive Summary> =SHIFT-AET 34.8 28.0
Ours 35.1 28.7
Table 8: Translation results (BLEU) for dictionary- References
guidedNMT. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 25>


<Paper ID = 252> <Table 0> <Abstractive Summary> =1.8% - - -
allpassages
For the ﬁrst issue, we use related passages in →QA-ﬁnetune
SQuAD to further extra pre-train BART, which
Table 2: Closed-book QA performance of BART on
wecallasLM-ﬁnetuning,andtesttheratioofre-
four datasets. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 252>


<Paper ID = 252> <Table 1> <Abstractive Summary> =bart-large/tree/main
3242Dataset\OverlapType AnswerOverlap QuestionOverlap Overlap Non-Overlap
NaturalQuestions 61.5% 32.5% Correct 29.8%(604) 0.2%(5)
TriviaQA 78.7% 33.6% Incorrect 58.7%(1189) 11.3%(228)
WebQuestions 59.3% 27.5% (a)OnWebQuestions
SQuAD 24.0% 1.0% Overlap Non-Overlap
Correct 1.3%(77) 0.1%(6)
Table 3: Question and Answer Overlaps on four Incorrect 38.5%(2272) 60.1%(3530)
(a)OnSQuAD
datasets. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 252>


<Paper ID = 252> <Table 2> <Abstractive Summary> =ALLSQuAD
Models\Dataset
(20279)
3 TaskDesign
random-initializedBART 0.0%
originalBART 2.2%
Theoriginalpurposeofpreviousresearch(Petroni BART→LM-ﬁnetuning 2.7%
et al., 2019; Roberts et al., 2020) is to use pre-
Table 6: The reciting performance on all SQuAD pas-
trained language models (PLMs) as knowledge
sages. </Abstractive Summary> <Extractive Summary> Wereportperformanceonthenewtestsetsin SQuAD passages to further pre-train BART and
Table 2 while analyzing the overlaps on the two thenconductQA-ﬁnetuning.  </Extractive Summary>  </Table 2>  </Paper ID = 252>


<Paper ID = 252> <Table 3> <Abstractive Summary> =For example, in the ﬁrst row of
used in previous closed-book QA work (Roberts Table9,forthequestion“WhatisSouthernCali-
etal.,2020;Lewisetal.,2020b),wealsoconsider forniaoftenabbreviatedas?”,despiteofthemodel
324620(16/2/2;125/8/10) 160(128/16/16;653/107/93) 547(442/53/52;2334/314/306)
Models\Dataset
RA(%) EM(%) HE(%) F1(%) RA(%) EM(%) HE(%) F1(%) RA(%) EM(%) HE(%) F1(%)
BART→QA-ﬁnetuning 1.5 0.0 0.0 11.0 5.2 2.2 4.3 6.4 3.6 1.9 4.9 7.0
BART→LM-ﬁnetuning
87.3 10.0 30.0 15.4 72.6 3.2 6.5 9.0 66.3 2.3 6.9 6.7
→QA-ﬁnetuning
BART→LM-ﬁnetuning
→QA-ﬁnetuning 85.5 10.0 30.0 21.0 79.6 3.2 10.8 10.1 59.5 2.9 7.8 8.2
(AddedPreﬁx/Sufﬁx)
BART→LM-ﬁnetuning
87.3 20.0 40.0 27.8 72.6 9.7 20.4 15.3 66.3 4.6 11.8 9.3
→QA-bridge-tuning
BART→LM-ﬁnetuning
→QA-bridge-tuning 85.5 20.0 40.0 31.7 79.6 11.8 22.6 16.3 59.5 5.6 12.7 10.3
(AddedPreﬁx/Sufﬁx)
Table 8: QA performance on three subsets of SQuAD. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 252>


<Paper ID = 252> <Table 4> <Abstractive Summary> =ModelOutput A>B A=B A<B
Question&Answer
QA-bridge-tune Relevance 30.2% 53.3% 16.6%
QA-ﬁnetune
Table 10: Human-evaluated relevance between the re-
Q:WhatisSouthern
SouthernCalifornia,often sultsusingandnotusingQA-bridge-tunewithcorrect
Californiaoften Southern
abbreviatedSoCal,is... answers. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 4>  </Paper ID = 252>


<Paper ID = 252> <Table 5> <Abstractive Summary> =Table 9: Four real output examples on QA-ﬁnetuning ‘BART’denotesthe‘BART-Large’checkpoint. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 5>  </Paper ID = 252>


<Paper ID = 253> <Table 0> <Abstractive Summary> =Allmodelsuse Table 5: Results on WikiQA and TREC-QA, using
RoBERTa-Base pre-trained checkpoint and start RoBERTaLargeTransformer. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 253>


<Paper ID = 253> <Table 1> <Abstractive Summary> =bestmatchesthesyntactic/semanticpatternofthe
Table 8: A question with answer candidates
question,whichasksforatypeofcolor,indeed,the
{c ,c ,c ,c } ranked by PR; ASR reranks as
0 1 2 3
answerofferssuchtype,primarycolors. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 253>


<Paper ID = 254> <Table 0> <Abstractive Summary> =EDIT-F1
BLEU EDIT-F1
Table 3: Results on NQ-OPEN and TriviaQA test set. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 254>


<Paper ID = 254> <Table 1> <Abstractive Summary> =ans ans BLEU EDIT-F1
REFUELw/oRTP 1.55 48.4 37.0 16.0 11.2 59.6
+Round-TripGeneration 2.06(↑33.5%) 47.6 37.4 16.0 11.4 59.0 (↓0.9%)
+Round-TripGeneration&LMVeriﬁcation 1.72(↑11.1%) 48.3 37.3 16.2 11.8* 60.1 (↑0.7%)
+Round-TripGeneration&EMVeriﬁcation 1.43(↓ 7.7%) 47.6 35.4 15.7 11.6 57.2 (↓4.0%)
DPRReader 1.62 38.9 29.9 12.5 6.8 45.7
+Round-TripGeneration&LMVeriﬁcation 1.81(↑11.7%) 40.1* 31.6* 13.3* 7.3* 47.4*(↑3.7%)
SPANSEQGEN 1.14 41.7 29.3 12.7 7.1 48.8
+Round-TripGeneration&LMVeriﬁcation 1.28(↑12.3%) 42.4* 29.9* 13.0* 7.4* 49.8*(↑2.1%)
Table 4: Effect of round-trip prediction to harvest more interpretations (QA pairs) on the development set of
AMBIGQA.“↑and↓”denotestheimprovementgainoverthemodelwithoutround-tripprediction. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 254>


<Paper ID = 254> <Table 2> <Abstractive Summary> =PromptBaseline 18.9 0.0
Reference:
None+QDF 16.2 10.1
None+QDF(w/ﬁlteredpassages) 16.4 9.4 Q1:Whatisthehighestamountofpointsscoredbyasingle
QGP+QDF 15.9 10.3 teaminregularseasonNBAgames?/A1:186
TDP+QDF 16.5 10.9 Q2:Whatisthehighestamountofpointsscoredbyasingle
TDP+QDF(w/insertion-basedloss) 16.0 11.2 teaminregularseasongamesinregulation?/A2:162
Q3:Whatisthehighestamountofpointsscoredbyasingle
Table 6: Ablation Study of REFUEL for the question teaminplayoffgames?/A3:153
disambiguationsubtaskonthedev.set. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 254>


<Paper ID = 255> <Table 0> <Abstractive Summary> =Finally, we attain a total of Table 2: Question distribution regarding different an-
2,757hybridcontextsand16,552corresponding swertypesandsourcesinTAT-QA
question-answer pairs from 182 ﬁnancial reports. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 255>


<Paper ID = 255> <Table 1> <Abstractive Summary> =The HyBrider is the worst among HybridQA
HyBrider 6.6 8.3 6.3 7.5
allbaselinemodels,becauseitisdesignedforHy-
bridQA(Chenetal.,2020b)whichdoesnotfocus TAGOP 55.2 62.7 50.1 58.0
onthecomprehensiveinterdependenceoftableand
Table 3: Performance of different models on dev and
paragraphs,nornumericalreasoning. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 255>


<Paper ID = 255> <Table 2> <Abstractive Summary> =Table 9: The proportion of ground truth scale on dev
and test set of TAT-QA with prediction accuracy by
#ofRowHeader Proportion(%) scalepredictorofTAGOP. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 255>


<Paper ID = 255> <Table 3> <Abstractive Summary> =1 21
2 68
3 9
morethan3 2
Table 7: Distribution of no. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 255>


<Paper ID = 255> <Table 4> <Abstractive Summary> =Dev Test
Operator
% Acc % Acc
Span-in-text 20.9 92.3 21.3 91.6
Cell-in-table 21.1 91.2 21.6 86.7
Spans 13.0 96.8 12.6 93.8
Sum 3.4 86.0 2.5 76.2
Count 1.9 93.8 2.4 100.0
Average 8.5 100.0 5.9 100.0
Multiplication 0.2 33.3 0.1 0.0
Division 1.0 76.5 1.0 87.5
Difference 14.1 96.6 15.9 96.6
Changeratio 9.3 96.1 10.2 95.3
Other 6.6 0.0 6.6 0.0
Table 8: Ground truth proportion of questions that
should be fed to different operators and prediction ac-
curacybyoperatorclassiﬁerofTAGOPondevandtest
setofTAT-QA. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 4>  </Paper ID = 255>


<Paper ID = 256> <Table 0> <Abstractive Summary> =away from the topic entities (or focal entities in Surprisingly,weﬁndthatsimplymodelingthecon-
versationhistorythroughastandardtwo-levelhi-
4https://convex.mpi-inf.mpg.de/
5https://amritasaha1812.github.io/ erarchical sequence model does not consistently
CSQA/
6https://demo.allennlp.org/ 7https://nlp.stanford.edu/projects/
named-entity-recognition glove/
3293ConvQuestions ConvCSQA Methods Q1 Q2 Q3 Q4 Q5
Methods
Dev Test Dev Test
SingleTurn 49.2 33.5 22.1 19.6 12.3
SingleTurn 29.7 27.3/30.5 61.8 56.8/65.0 ConvHistory 50.1 31.7 23.5 19.2 9.2
ConvHistory 29.1 27.2/30.2 62.0 57.0/65.1 OurMethod 50.0 35.0 28.7 20.1 15.4
OurMethod 31.9 29.8/33.3 63.2 57.8/66.9
Table 3: Accuracy results breakdown by conversation
Table1: F1resultsondevelopmentandAcc/F1results turnsonConvQuestions. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 256>


<Paper ID = 256> <Table 1> <Abstractive Summary> =ConvQuestions ConvCSQA
Methods
Movies TVseries Music Books Soccer QT QT QT QT
1 2 3 4
CONVEX(Christmannetal.,2019) 25.9 17.8 19.0 19.8 18.8 38.9 14.8 4.6 47.8
Star(Christmannetal.,2019) 25.7 19.4 24.1 24.1 17.9 - - - -
Chain(Christmannetal.,2019) 9.4 3.1 4.0 5.3 1.6 - - - -
HRED+KVmem(Sahaetal.,2018) - - - - - 13.6 7.1 8.8 21.4
D2A(Guoetal.,2018) 9.0 6.7 7.2 12.1 10.7 61.0 43.4 4.7 45.8
MaSP(Shenetal.,2019) - - - - - 82.7 45.2 3.8 46.3
OurMethod 29.0 30.4 30.1 30.1 29.6 81.2 64.6 23.1 58.0
Table 4: Comparison with other systems. </Abstractive Summary> <Extractive Summary> 4.2 ExperimentSettings
4.3 MainResults
ToevaluatetheeffectivenessofourproposedEntity
Transition Graph and Focal Entity Predictor, we Table 1 shows the overall results.  </Extractive Summary>  </Table 1>  </Paper ID = 256>


<Paper ID = 257> <Table 0> <Abstractive Summary> =(2020)M+C Gold White-box White-box 32.2 10.7 5.0
Table 2: Aggregated scores from human evaluation considering intelligibility, whether generated instances were
supportedbyevidenceanderrorscorrected. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 257>


<Paper ID = 257> <Table 1> <Abstractive Summary> =(2020), and
Table 3: Both SARI and ROUGE automated scoring
a pre-trained BERT language model, generated
metricshavehighcorrelationtomanualevaluation. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 257>


<Paper ID = 257> <Table 2> <Abstractive Summary> =MaskedLM .561 .529 .078 .389
Fortheblack-boxmasker,usingretrievedevidence
reducedthenumberofmaskedtokensfromanaver- Table 5: Using random masks at training resulted in
higherscoreswhentestingwithdifferentmaskers
ageof4.7perclaimto3.9. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 257>


<Paper ID = 257> <Table 3> <Abstractive Summary> =Heuristic(IR) .651 .574 .041 .422
MaskedLM .538 .509 .062 .370
Random .619 .475 .087 .390
SARIScore
System
Table 4: Extrinsic evaluation of maskers, varying the Keep Delete Add Final
useofevidencewhengeneratingthemasks, evaluated DualEncPtr(Gold) .452 .569 .039 .353
usingtheT5Masker+Correctormodel. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 257>


<Paper ID = 257> <Table 4> <Abstractive Summary> =For example, the name of the TV
Black-box(IR) .364 .003 .001 .122
show was masked in the claim “Two and a half
menstarredJamieFox[sic]”,butasnomentionof
Table 7: Correcting claims using a language model
doesnotconditionthegenerationonevidence. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 4>  </Paper ID = 257>


<Paper ID = 258> <Table 0> <Abstractive Summary> =8https://github.com/huggingface/neuralcoref
3317ExactAlign Ablations ExactAlign
P R F1 P R F1
RelationAlignmentsBreakdown Subgraphs 93.91 94.02 93.97
Oursystem:all(1163) 85.67 85.37 85.52 Subgraphs(−distance) 92.69 92.85 92.77
...singlerelations(121) 53.49 56.56 54.98 Subgraphs(−inductivebias) 93.88 93.44 93.66
...argumentstructures(1042) 89.67 88.73 89.20 Relations 85.67 85.37 85.52
ISI:all(1163) 59.28 8.51 14.89 Relations(−distance) 85.14 84.77 84.95
...singlerelations(121) 82.89 52.07 63.96 Relations(goldsubgraphs) 91.21 90.59 90.90
...argumentstructures(1042) 39.56 3.45 6.35
ReentrancyAlignmentsBreakdown Table 5: Results when the aligner is trained without
Oursystem:all(293) 62.37 61.09 61.72
projection distance probabilities (−distance) and with-
...primary(128) 79.37 78.12 78.74
...coref(41) 57.14 58.54 57.83 out the subgraph inductive bias (−inductive bias), as
...control(36) 73.08 52.78 61.29 wellasarelationalignerwithaccesstogold(insteadof
...coordination(29) 57.14 58.54 57.83 trained)subgraphs. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 258>


<Paper ID = 258> <Table 1> <Abstractive Summary> =Forexample,theexpression“onthe
onehand”appearsintestandshouldbealignedto
Table 4: Detailed results for relation alignments and
reentrancyalignments. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 258>


<Paper ID = 259> <Table 0> <Abstractive Summary> =-2.00
onestochasticgradientdescentsteponthisbatch
Table 1: Top scoring examples according to the tree
θ(cid:48) ← θ−α∇ L (θ) (2) kernel, string kernel and Levenshtein distance for the
θ Bt sentence ‘The girl changed a sandwich beside the ta-
ble.’ andaccompanyingscores. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 259>


<Paper ID = 26> <Table 0> <Abstractive Summary> =∆ +2.1 +1.7 +1.7 +2.1
We observe that with the dataset scale of lan-
guagepairsincreasing,theimprovementsofBLEU
Table 1: Results on IWLST dataset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 26>


<Paper ID = 26> <Table 1> <Abstractive Summary> =We show
296Low Medium Rich All
ArchSetting Model
BLEU WR BLEU WR BLEU WR BLEU WR
Baseline 16.7 - 18.8 - 25.3 - 20.4
Transformer-base Random -2.2 0.0 -2.3 0.0 -2.6 0.0 -2.4 0.0
LaSS +0.7 80.0 +1.3 85.7 +1.7 100.0 +1.2 88.9
Baseline 18.8 - 22.2 - 29.0 - 23.5 -
Transformer-big Random -1.3 0.0 -1.8 0.0 -1.5 0.0 -1.6 0.0
LaSS +0.1 50.0 +0.7 92.9 +0.8 100.0 +0.6 83.3
Table 2: Average BLEU↑ and Win Ratio (WR) of WMT dataset on Low (<1M), Medium (1M∼10M) and Rich
(>10M) resource dataset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 26>


<Paper ID = 26> <Table 2> <Abstractive Summary> =32.0 30.5 29.6 30.9 29.6 -
Futureworkincludesdesigningamorededicated
Table 5: Performance of applying Fr→X or X→Zh end-to-endtrainingstrategyandincorporatingthe
mask to Fr→Zh testset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 26>


<Paper ID = 26> <Table 3> <Abstractive Summary> =it Italian Romance Latin 167k
es Spanish Romance Latin 169k
pl Polish Slavic Latin 128k
Table 6: Statistics and Language Family of IWSLT. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 26>


<Paper ID = 260> <Table 0> <Abstractive Summary> =In a 8https://github.com/huggingface/transformers
3340DOMAIN BIOMED CS NEWS REVIEWS
DATASET CP RCT CI SE HP AG AM IMDB
RoBERTa+FT 81.10 80.72 56.74 74.06 88.15 88.60 63.04 92.29
0.70 0.40 5.47 5.25 1.51 0.01 0.69 0.23
+T-DNA 82.66 81.52 64.95 78.61 92.49 88.91 63.92 92.91
0.31 0.41 4.98 2.00 0.69 0.06 0.62 0.71
RoBERTa+TAPT 82.24 82.73 63.44 77.85 92.70 88.84 64.13 92.77
1.33 0.23 2.30 1.12 0.73 0.01 0.22 0.25
+T-DNA 83.89 83.94 69.73 79.40 93.91 89.05 64.36 93.13
0.76 0.27 2.87 0.48 1.48 0.03 0.34 0.15
Table 2: The overall performance of T-DNA and the comparison against existing models on eight target down-
streamdatasts. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 260>


<Paper ID = 260> <Table 1> <Abstractive Summary> =Additionally,wewouldlike
6 Analyses
to explore whether T-DNA is complementary to
moretrainingstrategies,suchastask-adaptivepre- Weanalyzeseveralaspectsof T-DNA,including
training(TAPT).TAPThasbeenshownusefulfor theeffectsofdifferentgranularitiesandtheeffects
3341Task RCT AG AM IMDB
Model w.o w. w.o w. w.o w. w.o w.
10% 80.78 82.23↑1.45 90.11 92.01↑1.90 63.13 64.10↑0.97 92.29 92.91↑0.62
20% 85.22 86.16↑0.94 91.71 92.14↑0.43 64.01 65.12↑1.11 92.11 92.89↑0.78
50% 87.10 87.69↑0.59 92.17 92.58↑0.41 65.52 66.10↑0.58 93.13 93.32↑0.19
100% 87.31 87.69↑0.38 93.75 94.00↑0.25 66.79 67.14↑0.35 94.34 94.81↑0.47
Table 3: Performance gains of T-DNA w.r.t. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 260>


<Paper ID = 261> <Table 0> <Abstractive Summary> =Basedonthehumanevaluationonarandom RoBERTa 26.3 61.2 69.7 46.0 80.3 88.8
ERICA 40.0 61.9 69.8 46.3 80.4 89.2
sampleofthedataset,weﬁndthatitachievesanF1 RoBERTa
scoreof84.7%fornamedentityrecognition,and
Table 2: Results (test F1) on sentence-level RE (TA-
anF1scoreof25.4%forrelationextraction. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 261>


<Paper ID = 261> <Table 1> <Abstractive Summary> =fromdifferentsources;(3)CorefBERT(Yeetal.,
7https://spacy.io/ 2020)whichproposesapre-trainingmethodtohelp
8https://github.com/google-research/bert
BERTcapturethecoreferentialrelationsincontext;
9https://github.com/huggingface/
transformers (4) SpanBERT (Joshi et al., 2020) which masks
3354Metrics MacroF1 MicroF1 Setting Standard Masked
BERT 75.50 72.68 Size 1% 10% 100% 1% 10% 100%
MTB 76.37 72.94
FastQA - 27.2 - 38.0
CP 76.27 72.48
BiDAF - 49.7 - 59.8
ERNIE 76.51 73.39
ERICABERT 77.85 74.71 BERT 35.8 53.7 69.5 37.9 53.1 73.1
CorefBERT 38.1 54.4 68.8 39.0 53.5 70.7
RoBERTa 79.24 76.38
SpanBERT 33.1 56.4 70.7 34.0 55.4 73.2
ERICA 80.77 77.04
RoBERTa MTB 36.6 51.7 68.4 36.2 50.9 71.7
CP 34.6 50.4 67.4 34.1 47.1 69.4
Table 3: Results on entity typing (FIGER). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 261>


<Paper ID = 261> <Table 2> <Abstractive Summary> =Weﬁrstconcatenatetheques- RD
-NSP+LT+s,T+s 47.3 73.5 51.2
tion and documents into a long sequence, then RD
-NSP+L 48.0 74.0 52.0
RD
we ﬁnd all the occurrences of an entity in the ERICA 48.3 74.7 58.1
BERT
documents, encode them into hidden representa-
tions and obtain the global entity representation Table 6: Ablation study. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 261>


<Paper ID = 261> <Table 3> <Abstractive Summary> =We also found empiri-
ED RD
3356Size 1% 10% 100% 36 48
34 55.5
BERT 28.9 44.9 54.5 47
ERICABERT 36.0 48.3 55.9  32  46  55.0
ERICADocRED 36.3 48.6 55.9 30
BERT 45 54.5
0%10%30%50%70%100% 0%10%30%50%70%100% 0%10%30%50%70%100%
1% DocRED 10% DocRED 100% DocRED
Table 7: Effects of pre-training data’s entity distribu-
tionshifting. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 261>


<Paper ID = 261> <Table 4> <Abstractive Summary> =Thereasonisthat Table 8: Results (IgF1) on how entity encoding strat-
the size and diversity of entities and relations in egyinﬂuencesERICA’sperformanceonDocRED.We
also show the impacts of entity distribution shifting
downstreamtrainingdataarelimited. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 4>  </Paper ID = 261>


<Paper ID = 262> <Table 0> <Abstractive Summary> =Table 2: F1 score and relative drop (marked with ↓) Wewillleavetheextractionofevent-drivencom-
of different ECE models on adversarial samples. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 262>


<Paper ID = 263> <Table 0> <Abstractive Summary> =(2020), R 0.88 0.70 0.47
exceptforusingRoBERTa-largeinsteadofBERT-
Table 4: Sentiment classiﬁcation results on held-out
base,withlearningrateof1e-5. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 263>


<Paper ID = 263> <Table 1> <Abstractive Summary> =Restaurants 0.62 0.95
Table 7: Key point quality assessment. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 263>


<Paper ID = 263> <Table 2> <Abstractive Summary> =3385Positive Negative
Validity Conﬁdence>0.85 Conﬁdence<0.8
Sentiment Clearsentimentwithconﬁdence>0.6 Nosentimentorsentimentconﬁdence<0.5
Toospeciﬁc\notinformative;
Informativeness Informativewithconﬁdence>0.6 ordoesn’trefertoanaspectwith
conﬁdence>0.6
MultipleAspects Conﬁdence<=0.57 conﬁdence>=0.85
Table 8: Criteria for creating the key point quality dataset from crowd annotations. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 263>


<Paper ID = 264> <Table 0> <Abstractive Summary> =Here,
nodescorrespondone-to-onetothetokensofthese-
Table 2: Metrics used to evaluate performance. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 264>


<Paper ID = 265> <Table 0> <Abstractive Summary> =Forthecross-lingualtransfersetting,
Table 4: Comparison between different data augmen- weutilizecode-switchsubstitutionasdataaugmen-
tationstrategies. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 265>


<Paper ID = 265> <Table 1> <Abstractive Summary> =InProceedingsofthe2018
Conference on Empirical Methods in Natural Lan-
guage Processing, Brussels, Belgium, October 31 - Table 6: Statistics for the datasets in the XTREME
November 4, 2018, pages 2465–2474. </Abstractive Summary> <Extractive Summary> For
4.2 Results thecross-lingualtransfersetting,XTUNEachieves
an absolute 2.8-point improvement compared to
Table 1 shows our results on XTREME.  </Extractive Summary>  </Table 1>  </Paper ID = 265>


<Paper ID = 265> <Table 2> <Abstractive Summary> =3413Variable XNLI PAWS-X POS NER XQuAD MLQA TyDiQA
Stage1 A∗ CS CS SS SS CS CS SS
A CS CS SS SS SS SS SS
Stage2
A(cid:48) CS CS SS SS SS SS SS
λ 5.0 5.0 5.0 5.0 5.0 5.0 5.0
1
Hyper-parameters
λ 5.0 2.0 0.3 5.0 5.0 5.0 5.0
2
Table 7: The best hyper-parameters used for XTUNE under the cross-lingual transfer setting. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 265>


<Paper ID = 265> <Table 3> <Abstractive Summary> =Machine 1
Translation XTUNER1 6.9 - - -
XTUNER2 7.2 19.6 17.1 14.6 D.3 SequenceLabeling
Table 9: Cross-lingual transfer gap, i.e., averaged per- Similar to span extraction, the two distribution
formance drop between English and other languages in example consistency R1 can not be aligned in
in zero-shot transfer. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 265>


<Paper ID = 266> <Table 0> <Abstractive Summary> =MBERT* 70.3 62.2 64.5/49.4 61.4/44.2 59.7/43.9 65.4 81.9 63.1
XLM* 70.1 61.2 59.8/44.3 48.5/32.6 43.6/29.1 69.1 80.9 58.6
MT5base - 56.6 67.0/49.0 64.6/45.0 58.1/42.8 75.4 87.4 -
XLM-R 75.6 61.8 71.9/56.4 65.1/47.2 55.4/38.3 75.0 84.9 66.4
base
XLM-ALIGN 76.0 63.7 74.7/59.0 68.1/49.8 62.1/44.8 76.2 86.8 68.9
Table 1: Evaluation results on XTREME structured prediction, question answering, and sentence classiﬁcation
tasks. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 266>


<Paper ID = 266> <Table 1> <Abstractive Summary> =Besides, un-
3423Models XNLI POS NER MLQA Avg Layer XNLI POS NER MLQA Avg
XLM-R* 74.6 75.7 61.6 65.7 69.4 Layer-8 75.1 75.3 61.9 66.7 69.8
XLM-ALIGN 75.2 75.6 62.6 66.7 70.0 Layer-10 75.2 75.6 62.6 66.7 70.0
−DWA 75.1 75.2 62.0 65.8 69.5
Layer-12 75.2 75.8 62.3 67.0 70.1
−TLM 74.4 76.0 60.4 66.0 69.2
Table 4: Results of XLM-ALIGN with different lay-
Table3: AblationstudiesonthecomponentsofXLM-
ers used for word alignment self-labeling during pre-
ALIGN. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 266>


<Paper ID = 266> <Table 2> <Abstractive Summary> =Recent studies have shown
3424Filtering XNLI POS NER MLQA Avg Position XNLI POS NER MLQA Avg
Enable 75.2 75.6 62.6 66.7 70.0 masked 75.2 75.6 62.6 66.7 70.0
Disable 74.2 75.3 61.6 65.3 69.1 unmasked 75.5 75.5 62.0 66.5 69.8
all-aligned 75.3 75.9 61.6 66.7 69.9
Table 6: Effects of alignment ﬁltering in word align- no-query 75.1 75.2 62.0 65.8 69.5
mentself-labeling. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 266>


<Paper ID = 266> <Table 3> <Abstractive Summary> =Table 7: Effects of the query positions in the pointer
networkfordenoisingwordalignment. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 266>


<Paper ID = 267> <Table 0> <Abstractive Summary> =s (cid:55)→ tLFWLinks t (cid:55)→ sLFWLinks Data Sentence
Data
R P F1 R P F1 Raw 海克曼 和奥德海姆 提出... 模型
S
Raw HackmanandOldhampropose... model
Raw 66.4 81.9 73.3 72.3 80.6 76.2 T
−→ −→
KD 73.4 89.2 80.5 69.9 79.1 74.2 KD HeckmanandOddheimpropose... model
←− ←−T
KD 61.2 79.4 69.1 82.9 83.1 83.0 KD 哈克曼和奥尔德姆提出... 模式
S
Table 1: Evaluation on aligned links between source- Table2: Anexampleindifferentkindsofdata. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 267>


<Paper ID = 267> <Table 1> <Abstractive Summary> =Model
BLEU ALF BLEU ALF AT 41.5 30.8 27.5 8.6 15.4
AT 25.3 66.2 29.8 70.8 MaskT 37.3 28.2 24.6 7.3 11.2
+LFR 38.1† 28.8 25.4† 8.9† 14.3†
MaskT 24.2 61.5 28.9 66.9
+LFR 25.1† 64.8 29.6† 68.9 LevT 37.5 28.4 24.7 7.5 12.4
+LFR 38.5† 29.4† 25.9† 8.4† 14.5†
LevT 24.4 62.7 29.1 66.8
+LFR 25.1† 65.3 29.7 69.2
Table 5: Performance on domain shift setting. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 267>


<Paper ID = 267> <Table 2> <Abstractive Summary> =Mod-
els are trained on WMT14 En-De news domain but
Table 4: Performance on other language pairs, includ-
evaluated on out-of-domain test sets, including law,
ing WMT17 Zh-En and WAT17 Ja-En. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 267>


<Paper ID = 267> <Table 3> <Abstractive Summary> =+LFT 78.1 83.2 78.7 72.5
Table 11: Analysis on AT models in term of the accu-
# Strategy BLEU ALF
racyoflexicalchoiceonWMT14En-De.Wesplit“All”
1 Raw 24.1 69.3 wordsinto“High”,“Medium”and“Low”categories. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 267>


<Paper ID = 267> <Table 4> <Abstractive Summary> =Our Approach Works for AT Models Al-
Table 10: Performances of different strategies. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 4>  </Paper ID = 267>


<Paper ID = 268> <Table 0> <Abstractive Summary> =K X
3446Method TED News Europarl
s-BLEU d-BLEU s-BLEU d-BLEU s-BLEU d-BLEU
SENTNMT(Vaswanietal.,2017) 23.10 - 22.40 - 29.40 -
HAN(Miculicichetal.,2018b) 24.58 - 25.03 - 28.60 -
SAN(Marufetal.,2019) 24.42 - 24.84 - 29.75 -
HybridContext(Zhengetal.,2020) 25.10 - 24.91 - 30.40 -
Flat-Transformer(Maetal.,2020) 24.87 - 23.55 - 30.09 -
Transformeronsent(baseline) 24.82 - 25.19 - 31.37 -
Transformerondoc(baseline) - 0.76 - 0.60 - 33.10
G-Transformerrandominitialized(ours) 23.53 25.84* 23.55 25.23* 32.18* 33.87*
G-Transformerﬁne-tunedonsentTransformer(ours) 25.12 27.17* 25.52 27.11* 32.39* 34.08*
Fine-tuningonPre-trainedModel
Flat-Transformer+BERT(Maetal.,2020) 26.61 - 24.52 - 31.99 -
G-Transformer+BERT(ours) 26.81 - 26.14 - 32.46 -
Transformeronsentﬁne-tunedonBART(baseline) 27.78 - 29.90 - 31.87 -
Transformerondocﬁne-tunedonBART(baseline) - 28.29 - 30.49 - 34.00
G-Transformerﬁne-tunedonBART(ours) 28.06 30.03* 30.34* 31.71* 32.74* 34.31*
Table 2: Case-sensitive BLEU scores on En-De translation. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 268>


<Paper ID = 268> <Table 1> <Abstractive Summary> =25.84 25.23 33.87 -
-target-sidecontext 25.05 25.41 32.16 -0.14 -word-dropout 25.49 24.65 33.70 -0.37
-source-sidecontext 24.56 24.58 31.39 -0.70 -languagelocality 22.47 22.41 33.63 -1.78
-translationlocality 0.76 0.60 33.10 -14.68
Table 3: Impactof source-side and target-side context
reportingins-BLEU.Here,fnt. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 268>


<Paper ID = 268> <Table 2> <Abstractive Summary> =sent(Voitaetal.,2019b) 50.0 53.0 28.4 Combinedattention 25.84 25.23 33.87 -
concat(Voitaetal.,2019b) 83.5 76.2 76.6 Onlygroupattention 25.62 25.14 33.12 -0.35
G-Transformer 89.9 84.8 82.4 Onlyglobalattention 25.00 24.54 32.87 -0.84
Table 4: Impact on discourse by the source-side con- Table 6: Separate effect of group and global attention
text, inaccuracyofcorrectlyidentifyingthediscourse reporting in d-BLEU. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 268>


<Paper ID = 269> <Table 0> <Abstractive Summary> =(2017)* 38.1 - - -
MRT*(Shenetal.,2016) 27.71 - NMT(Transformer) 41.07 ref 25.75 ref
SimpleFusion**(Stahlbergetal.,2018) 27.88 - +LM 41.14 +0.07 25.90 +0.15
Localness(Yangetal.,2018) 28.11 - +MTO 41.56†‡ +0.49 26.94†‡ +1.19
Context-Aware(Yangetal.,2019) 28.26 - +MSO 41.70†‡ +0.63 27.25†‡ +1.50
AOL(Kongetal.,2019) 28.01 -
Eval.Module(Fengetal.,2019) 27.55 - Table 2: Case-sensitive BLEU scores (%) on the test
Past&Future(Zhengetal.,2019) 28.10 - set of WMT14 En→Fr and WMT19 Zh→En. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 269>


<Paper ID = 269> <Table 1> <Abstractive Summary> =Wespeculatethereasonisthat
3462Function BLEU ↑ 0.072 25.0
Propotion of I=0
NMT(Transformer) 25.75 ref 0.070 MMSTOO 2244..86
0.068
+LM 25.90 +0.15 n 24.4
++LCiunbeear 2266..1435 ++00..3680 roportio000...000666264 222344...820 BLEU
P 23.6
0.060
+Quintic 26.94 +1.19 23.4
0.058 23.2
+Log(α = 5) 26.12 +0.37
0.056 23.0
+Log(α = 10) 26.07 +0.32 155K 175K 195K 215K 235K 255K 275K 295K
Training steps
+Log(α = 20) 26.24 +0.49
Figure4: ChangesoftheproportionofI =
R(x,y)<30%
Table 5: Case-sensitive BLEU scores (%) on Zh→En 0 on Zh→En during ﬁnetuning for MSO, and BLEU
test set of MTO with several variations of M(∆). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 269>


<Paper ID = 269> <Table 2> <Abstractive Summary> =Table 6: Case-sensitive BLEU scores (%) on Zh→En
Case Study. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 269>


<Paper ID = 27> <Table 0> <Abstractive Summary> =usingourautomaticallygeneratedcounterfactuals
310Models Parameter Training/Testingdata AC:(Ourmethod)
O/O CF/O CF/CF O/CF C/O AC/O C/CF AC/CF
SVM(TF-IDF) - 80.0 58.3 91.2 51.0 83.7 84.8 87.3 86.1
Bi-LSTM 0.2M 79.3 62.5 89.1 55.7 81.5 82.2 92.0 88.5
Transformer-basedModels
BERT[ICLR,2021] 110M 87.4 80.4 90.8 82.2 88.5 90.6 95.1 92.2
WWM-BERT-Large 335M 91.2 86.9 96.9 93.0 91.0 91.8 95.3 94.1
XLNet-Large 340M 95.3 90.8 98.0 93.9 93.9 94.9 96.9 95.5
RoBERTa-Large 355M 93.4 91.6 96.9 93.0 93.6 94.1 96.7 94.3
Table 2: The accuracy of various models for sentiment analysis using different datasets, including the human-
generatedcounterfactualdataandcounterfactualsamplesgeneratedbyourpipeline. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 27>


<Paper ID = 27> <Table 1> <Abstractive Summary> =Whilewefurther
Table 4: Out-of-domain test accuracy of SVM and
conductexperimentsonvariousTransformer-based
BERT-base-uncased models trained on the original
models with different parameter sizes to explore (Orig.) </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 27>


<Paper ID = 27> <Table 2> <Abstractive Summary> =We ﬁnd
that the sentiment-ﬂipped instances generated by Table 6: Ablation study on the inﬂuence of the edit-
style-transfer methods degrade the test accuracy distancecontrolledbythethresholdofMoverScore. </Abstractive Summary> <Extractive Summary> We can see
outperformtheBERTmodeltrainedontheoriginal
that all of the models trained on automatic CAD
data with average 6.5% and 5.3% accuracy im-
– shown as AC in the Table 2 – can outperform
provements,respectively. IfweadopttheautomaticCAD(AC),we model with automatic CAD is more robust than
note a distinct improvement in Table 2 across all other automated methods (Sudhakar et al., 2019;
models trained on the challenge data in terms of Madaanetal.,2020)acrossalldatasets.  </Extractive Summary>  </Table 2>  </Paper ID = 27>


<Paper ID = 270> <Table 0> <Abstractive Summary> =Seeker tionalproblems(ratedbythesupporter) required
Averagelengthofutterances >=6
4.1 Supporter-speciﬁcTasks
Table 1: Criteria of high-quality conversations. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 270>


<Paper ID = 270> <Table 1> <Abstractive Summary> =Win Lose Win Lose Win Lose
Vanilla 15.51 5.13 15.26 49.80
Fluency 71‡ 24 52† 35 53† 35
DialoGPT Joint - 5.00 15.09 49.97
Identiﬁcation 65‡ 25 50 34 54† 37
Oracle 15.19 5.52 15.82 50.18 Comforting 75‡ 20 54‡ 34 47 39
Vanilla 16.23 5.45 15.43 50.49 Suggestion 72‡ 21 47 39 48† 27
BlenderBot Joint - 5.35 15.46 50.27 Overall 73‡ 20 51† 34 56‡ 36
Oracle 16.03 6.31 17.90 51.65
Table 5: Results of the human interactive evaluation. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 270>


<Paper ID = 270> <Table 2> <Abstractive Summary> =AllthemodelsuseBlenderBotas
Table 4: Results of automatic evaluation. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 270>


<Paper ID = 270> <Table 3> <Abstractive Summary> =Inthecontextofeachconversation,the Qu→RP→AR→Qu 3.85‰
strategies used by supporters are labeled and the
Table 6: Proportions of top-5 strategy transitions in
seeker’sfeedbackscorepertwoutterancesofthe
supporterutterances.Abbreviationsareconsistentwith
supporter’sresponsesarealsogiveninourdataset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 270>


<Paper ID = 271> <Table 0> <Abstractive Summary> =But under the same setting of
Mask 90.08 23.10 37.91 86.52 25.07 45.92 83.37 32.14 50.68
Remove 93.10 31.67 46.97 90.18 32.19 53.75 86.26 38.64 55.24 Multiple,thereisnoconsistentsuperioritybetween
Table 7: Comparison between different data the two distance strategies. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 271>


<Paper ID = 271> <Table 1> <Abstractive Summary> =Object name City 57.92 21.42
ROSE-mean 40.73 34.71
Object name State 56.32 19.27
ROSE-100% 40.39 33.74 TimeRange Party size number 71.27∗ 51.03∗
ROSE-50% 41.00 35.46 City State 29.33∗ 27.14∗
Table 8: ROSE metrics on Snips-NSD using
Table10:Resultsofcombiningmultipleunknownslots. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 271>


<Paper ID = 271> <Table 2> <Abstractive Summary> =Each typeofprob-
Table 11: Relative proportions of several types of er-
lem contains two aspects, corresponding to NSD
rors. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 271>


<Paper ID = 272> <Table 0> <Abstractive Summary> =answer (PQA) triple into two parts: post-
question(PQ)andquestion-answer(QA)pairs, Table 1: An example of CQG task which is talking
whichmayhurttheoverallcoherence.Besides, aboutaperson’seatingactivity. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 272>


<Paper ID = 273> <Table 0> <Abstractive Summary> =isdeterminedwiththegridsearchbasedontheDist
3517DailyDialog OpenSubtitles
Model
Dist-1,2 Ent-1,2 LF BLEU-2,3,4 Dist-1,2 Ent-1,2 LF BLEU-2,3,4
CE 1.79 8.21 4.19 5.90 2.57 4.06 2.49 1.58 2.48 9.21 4.07 5.74 0.76 7.03 4.26 2.82
LS 1.71 8.01 4.16 5.89 2.17 4.13 2.55 1.65 2.89 12.79 4.27 6.24 0.47 8.24 5.57 4.20
FL 2.40 11.37 4.39 6.35 4.46 6.01 3.95 2.75 3.10 12.37 4.25 6.13 0.82 7.13 4.56 3.25
FACE 1.80 9.47 4.54 6.40 3.48 5.65 3.43 2.17 3.12 12.62 4.47 6.40 1.02 5.97 3.63 2.43
F2 1.61 7.22 4.04 5.70 2.11 4.32 2.55 1.52 2.89 10.63 4.03 5.72 0.89 6.92 4.27 2.91
CP 2.30 10.39 4.28 6.16 3.25 5.31 3.39 2.30 3.14 11.87 4.17 5.97 0.85 7.28 4.60 3.21
UL 2.42 11.0 4.40 6.42 4.55 7.94 5.26 3.69 2.77 10.43 3.98 5.62 0.62 6.89 4.36 3.03
NL 1.61 7.53 4.19 6.05 4.02 7.09 4.41 2.91 2.65 10.14 4.21 6.05 0.75 7.16 4.32 2.85
D2GPo 1.57 7.83 4.14 5.91 2.26 4.47 2.71 1.71 2.06 10.43 4.15 6.00 0.12 7.32 4.69 3.33
AdaLabel 4.25 21.47 4.95 7.51 7.68 14.71 11.63 9.80 4.91 21.53 4.71 7.08 1.35 8.68 6.08 4.68
AdaLabel
3.96 23.53 5.17 8.00 8.49 17.42 13.38 11.01 4.78 22.88 4.96 7.66 1.47 9.80 6.48 4.75
(Greedy)
Human 6.59 37.74 5.67 8.91 13.7 N/A N/A N/A 8.62 43.16 5.89 9.36 4.75 N/A N/A N/A
Table 6: Automatic evaluation results (%) using the beam search decoding scheme (beam size is 5). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 273>


<Paper ID = 274> <Table 0> <Abstractive Summary> =tional outlier detector – local outlier factor
3525CLINC150 StackOverﬂow Banking M-CID-EN
Methods Accuracy Macro-F1 Accuracy Macro-F1 Accuracy Macro-F1 Accuracy Macro-F1
MSP 66.60 51.20 33.94 45.68 48.15 48.47 52.05 43.14
DOC 64.43 44.60 60.68 60.51 37.78 46.35 49.32 46.59
SEG 72.86 65.44 47.00 52.83 51.11 55.68 44.51 50.14
25%
LMCL 68.57 62.42 41.60 48.21 52.77 56.73 41.44 46.99
Softmax 76.50 67.74 46.17 50.78 57.88 58.32 41.95 45.46
Ours 88.44 80.73 68.74 65.64 74.11 69.93 87.08 79.67
MSP 68.61 51.20 56.33 62.92 53.83 65.33 61.21 54.33
DOC 62.46 70.01 61.62 68.97 58.29 57.30 59.97 62.28
SEG 77.05 79.42 68.50 74.18 68.44 76.48 67.91 72.37
50%
LMCL 78.63 80.42 64.34 71.80 63.59 73.99 63.42 69.04
Softmax 82.47 82.86 65.96 71.94 67.44 74.19 64.72 69.35
Ours 88.33 86.67 75.08 78.55 72.69 79.21 81.05 79.73
MSP 73.41 81.81 76.73 77.63 71.92 80.77 72.89 77.34
DOC 74.63 78.63 63.98 62.07 72.02 78.04 69.79 71.18
SEG 81.92 86.57 80.83 84.78 78.87 85.66 75.73 79.97
75%
LMCL 84.59 88.21 80.02 84.47 78.66 85.33 77.11 80.96
Softmax 86.26 89.01 77.41 82.28 78.20 84.31 76.99 80.82
Ours 88.08 89.43 81.71 85.85 81.07 86.98 80.24 82.75
Table 1: Overall accuracy and macro f1-score for unknown intent detection with different proportion of seen
classes. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 274>


<Paper ID = 274> <Table 1> <Abstractive Summary> =Open-bigstandsforthesourceofopen-domainout-
Table 4: An ablation study on the effectiveness of liersusedinotherexperiments,whichconsistsof
pseudooutliers. </Abstractive Summary> <Extractive Summary> Finally,com- in Table 1 and Table 3.  </Extractive Summary>  </Table 1>  </Paper ID = 274>


<Paper ID = 274> <Table 2> <Abstractive Summary> =AsshowninFigure5,
evenwiththepseudooutliers,thetrainingtimeof
Table 5: Results on CLINC150 with different sets of ourmethodiscomparabletothatofthebaselines. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 274>


<Paper ID = 275> <Table 0> <Abstractive Summary> =Doc2EDAG/blob/master/Data.zip
3537Model EF ER EU EO EP Overall Model I II III IV
DCFEE-S 46.7 80.0 47.5 46.7 56.1 60.3
DCFEE-S 64.6 70.0 57.7 52.3
DCFEE-M 42.7 73.3 45.8 44.6 53.8 56.6
DCFEE-M 54.8 54.1 51.5 47.1
Greedy-Dec 57.7 79.4 51.2 50.0 54.2 61.0
Doc2EDAG 71.0 88.4 69.8 73.5 74.8 77.5 Greedy-Dec 67.4 68.0 60.8 50.2
Doc2EDAG 79.6 82.4 78.4 72.0
GIT(ours) 73.4 90.8 74.3 76.3 77.7 80.3
GIT(ours) 81.9 85.7 80.0 75.7
Table 1: F1 scores on test set. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 275>


<Paper ID = 275> <Table 1> <Abstractive Summary> =WealsolisttheresultsreportedinZheng
Table 2: F1 scores on four sets with growing average
etal. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 275>


<Paper ID = 275> <Table 2> <Abstractive Summary> =TheF1gapbetweenw/(GIT)and
Table 4: The decrease of F1 scores on ablation study w/oTracker(GIT-NT)becomeswiderasthenumberof
forGIT’sheterogeneousgraphinteractionnetwork.Re- eventrecordsofdocumentsincreases. </Abstractive Summary> <Extractive Summary> As Table 2 shows, GIT
tainsentenceandentityembeddings,followedby consistently outperforms Doc2EDAG, especially
anothertransformertofusecross-sentencecontext.  </Extractive Summary>  </Table 2>  </Paper ID = 275>


<Paper ID = 275> <Table 3> <Abstractive Summary> =DCFEE-M 86.6 89.0 87.8
Greedy-Dec 87.5 89.8 88.6
Doc2EDAG 88.0 90.0 89.0
GIT(ours) 85.8 92.6 89.1
Table 7: Results of entity extraction sub-task on the
testset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 275>


<Paper ID = 275> <Table 4> <Abstractive Summary> =Model BestEpoch EF ER EU EO EP Overall
DCFEE-S 86 51.3 73.0 44.1 51.4 58.6 58.7
DCFEE-M 87 52.5 69.1 43.9 47.2 55.9 55.8
Greedy-Dec 90 57.5 76.0 55.1 49.3 57.0 59.1
Doc2EDAG 89 75.2 85.2 71.6 80.0 77.9 78.7
GIT(ours) 89 78.3 87.6 74.7 80.9 79.8 80.7
Table 9: The best epoch in which the models achieve the highest micro F1 score on the dev set and the corre-
spondingperformance. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 4>  </Paper ID = 275>


<Paper ID = 275> <Table 5> <Abstractive Summary> =6577 6477 7
♦ ♦ ♠ ♠
♦S♦MDecAG♠S♠MDecAG♠s)
del FEE-FEE-edy-2ED FEE-FEE-edy-2ED (our
Mo DCDCGreDoc DCDCGreDoc GIT
Table 10: Comprehensive results of event record extraction. </Abstractive Summary> <Extractive Summary> As Table 5 shows, the F1 dencytreeinformation(Liuetal.,2018;Yanetal.,
in GIT-OT/GIT-OPdecreasesby0.5/1.2,suggest- 2019).  </Extractive Summary>  </Table 5>  </Paper ID = 275>


<Paper ID = 276> <Table 0> <Abstractive Summary> =(2020)[B+F] 87.01 86.55 86.78 84.90 86.08 85.49 79.98 78.51 79.24
OurMethod(naive)[B+F] 86.56 85.65 86.11(0.24) 84.17 84.88 84.52(0.21) 79.28 78.31 78.79(0.17)
OurMethod(max)[B+F] 86.96 85.45 86.19(0.17) 84.70 84.76 84.73(0.21) 79.51 78.25 78.87(0.04)
OurMethod(logsumexp)[B+F] 86.74 86.11 86.42(0.31) 84.81 85.06 84.93(0.24) 79.20 78.67 78.93(0.26)
Table 2: Experimental results on the ACE2004, ACE2005 and GENIA datasets. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 276>


<Paper ID = 276> <Table 1> <Abstractive Summary> =WehypothesizethatBERTandFlaircan
OurMethod 32 7,219.57 6,893.03
provide rich contextual information, then select- 64 10,584.80 11,652.92
ingchunksintheoriginalorderissufﬁcient,thus
ourdynamicselectingmechanismcanonlyslightly Table 4: Speed comparison on the ACE2005 dataset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 276>


<Paper ID = 276> <Table 2> <Abstractive Summary> =Table 5: Precision and recall scores at each level with Generally,thechunkdistributionoflogsumexp
eachpotentialfunctions. </Abstractive Summary> <Extractive Summary> We average all Table 2 shows the performance of previous work
BERT subword embeddings in the last four and our model on the ACE2004, ACE2005, and
layerstobuild1024-dimensionalvectors.  </Extractive Summary>  </Table 2>  </Paper ID = 276>


<Paper ID = 277> <Table 0> <Abstractive Summary> =Speciﬁcally, as the number of training
with the same knowledge base, our dual aug- rounds of dual learning increases, the generated
menteddatacanfurtherimprovetheperformance datagraduallylearnstask-relatedinformation,fur-
3564Method P R F Method P R F
BERT(Ourbasicidentiﬁer) 36.1 56.0 43.9 BERT(Ouridentiﬁer) 36.1 56.0 43.9
BERT 36.6 59.7 45.4* TextSurface 37.0 57.5 45.0*
OrgAug BERT
BERT 37.8 65.6 48.0* BackTranslation 36.8 61.0 45.9*
DualAug BERT
LearnDA 36.8 63.0 46.5* EDA 36.6 62.4 46.1*
Dual BERT
LearnDA 37.5 67.0 48.1* LearnDA 37.8 65.6 48.0*
DualAug−w/o.KB BERT
−LearnDA 39.0 66.0 49.0*
DualAug−w/.intro
−LearnDADualAug−w/.verbnet 39.4 66.7 49.5* Table 4: Results of different data augmentation meth-
−LearnDA 39.6 67.6 49.9*
DualAug−w/.wordnet odsoneventcausalityidentiﬁcationonESCdataset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 277>


<Paper ID = 277> <Table 1> <Abstractive Summary> =Table 3: Ablation results on event causality identiﬁca-
Gold EDA BackTrans LearnDA
tion on ESC. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 277>


<Paper ID = 277> <Table 2> <Abstractive Summary> =BERT and BERT denote the Well-formedness 3.95 2.75 3.83 3.64
OrgAug DualAug
Diversity(Man/Auto) 0.0/1.0 3.08/0.70 2.80/0.85 3.51/0.66
BERTisfurthertrainedonno-dualanddualaugmented
data respectively; LearnDADual denotes our identiﬁer Table 5: Manual (4-score rating (0, 1, 2, 3)) and
isonlytrainedbyduallearningwithoutfurthertraining; automatic (BLEU score) evaluation of the gener-
LearnDADualAug−w/o.KB denotes the LearnDADual ated sentences via different methods from causality,
is further trained by dual augmented data without well-formedness and diversity. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 277>


<Paper ID = 28> <Table 0> <Abstractive Summary> =322SynBridgeandSemBridgefurtherimproveBase- Table 3: Comparison of different methods. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 28>


<Paper ID = 28> <Table 1> <Abstractive Summary> =324Table 6: Top-10 prototypes in SemBridge. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 28>


<Paper ID = 28> <Table 2> <Abstractive Summary> =Models
AS OP AS OP AS OP AS OP AS OP AS OP AS OP
RNSCN 40.43 65.85 52.91 72.51 35.10 60.17 48.36 73.75 40.42 61.15 51.14 71.18 44.73 67.44
TRNN 40.15 65.63 53.78 73.40 37.33 60.32 51.17 74.37 41.19 60.20 51.66 68.79 45.88 67.12
TIMN 43.68 68.44 54.12 73.69 35.45 59.05 53.82 76.52 38.63 62.22 52.46 69.32 46.36 68.21
BERT-Base 34.70 73.84 37.07 80.12 37.17 64.52 40.54 60.45 43.45 59.59 44.19 58.77 39.52 66.22
SA-EXAL 47.59 75.79 54.67 80.05 40.50 63.33 54.54 71.57 42.19 60.19 47.72 63.98 47.87 69.15
BERT-Cross 44.00 75.38 54.31 81.97 43.12 66.57 51.97 70.58 44.35 58.49 50.01 63.81 48.35 69.47
BaseTagger 47.78 70.61 58.39 79.53 39.71 63.63 57.56 80.18 44.49 64.14 52.77 72.30 50.12 71.73∗
SynBridge 50.59 70.74 60.94 79.86 42.42 63.37 59.92 79.88 45.30 64.22 51.97 72.33 51.86∗ 71.73∗
SemBridge 50.67 71.51 63.04 80.48 43.34 63.46 60.19 80.21 44.91 64.15 53.02 72.63 52.53∗ 72.08∗
B ModiﬁcationofSALandUDA Table 10: Comparison of different bridge-based meth-
ods. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 28>


<Paper ID = 280> <Table 0> <Abstractive Summary> =3600Dataset x y sd(x) µp sw(x) µp
applausive pos applause, ##ive .847 app, ##laus, ##ive .029
Amazon superannoying neg super, -, annoying .967 super, ##ann, ##oy, ##ing .278
overseasoned neg over, -, seasoned .956 overseas, ##oned .219
isotopize phy isotope, ##ize .985 iso, ##top, ##ize .039
ArXiv antimicrosoft cs anti, -, microsoft .936 anti, ##mic, ##ros, ##oft .013
inkinetic phy in, -, kinetic .983 ink, ##ine, ##tic .035
prematuration dis premature, ##ation .848 prem, ##at, ##uration .089
Reddit nonmultiplayer ent non, -, multiplayer .950 non, ##mu, ##lt, ##ip, ##layer .216
promosque dis pro, -, mosque .961 promo, ##sque .066
Table 3: Error analysis. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 280>


<Paper ID = 281> <Table 0> <Abstractive Summary> =Theabilitytorecognize (4) tale:story
analogiessuchas“eyeistoseeingwhatearis (5) week:year
to hearing”, sometimes referred to as analogi-
calproportions,shapehowwestructureknowl- Table 1: An example analogy task from the SAT
edge and understand language. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 281>


<Paper ID = 281> <Table 1> <Abstractive Summary> =Dataset
(val/test) candidates groups
SAT 37/337 5 2
UNIT2 24/228 5,4,3 9
UNIT4 48/432 5,4,3 5
Google 50/500 4 2
BATS 199/1799 4 3
Figure1:Solvingawordanalogyproblembyselecting
Table 2: High-level statistics of the analogy datasets
onewiththehighestLMscoreamongthecandidates. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 281>


<Paper ID = 281> <Table 2> <Abstractive Summary> =According presented in Section 4.2, i.e., s (perplexity),
PPL
3614Model Score Tuned SAT U2 U4 GoogleBATS Avg
32.9 32.9 34.0 80.8 61.5 48.4
s
PPL (cid:88) 39.8 41.7 41.0 86.8 67.9 55.4
BERT 27.0 32.0 31.2 74.0 59.1 44.7
s
PMI (cid:88) 40.4 42.5 27.8 87.0 68.1 53.2
s (cid:88) 41.8 44.7 41.2 88.8 67.9 56.9
mPPL
35.9 41.2 44.9 80.4 63.5 53.2
s
PPL (cid:88) 50.4 48.7 51.2 93.2 75.9 63.9
M
GPT-2 34.4 44.7 43.3 62.8 62.8 49.6
L s
PMI (cid:88) 51.0 37.7 50.5 91.0 79.8 62.0
s (cid:88) 56.7 50.9 49.5 95.2 81.2 66.7
mPPL
42.4 49.1 49.1 90.8 69.7 60.2
s
PPL (cid:88) 53.7 57.0 55.8 93.6 80.5 68.1
RoBERTa 35.9 42.5 44.0 60.8 60.8 48.8
s
PMI (cid:88) 51.3 49.1 38.7 92.4 77.2 61.7
s (cid:88) 53.4 58.3 57.4 93.6 78.4 68.2
mPPL
FastText - 47.8 43.0 40.7 96.6 72.0 60.0
E
W GloVe - 47.8 46.5 39.8 96.0 68.7 59.8
Word2vec - 41.8 40.4 39.6 93.2 63.8 55.8
e PMI - 23.3 32.9 39.1 57.4 42.7 39.1
s
Ba Random - 20.0 23.6 24.2 25.0 25.0 23.6
Table 3: Accuracy results on each analogy dataset, categorized into language models (LM), word embeddings
(WE),andbaselines(Base). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 281>


<Paper ID = 281> <Table 3> <Abstractive Summary> =Table 7: Custom templates used in our experiments. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 281>


<Paper ID = 281> <Table 4> <Abstractive Summary> =However, the selected candidate pair
ishungy:water ratherthanhungry:food,whichis
3623Query Candidates
hilarious:funny right:wrong,hard:boring,nice:crazy,
great:good
poor:money tired:energy,angry:emotion,hot:ice,
hungry:water
wrench:tool cow:milk,radio:sound,tree:forest,
carrot:vegetable
beautiful:pretty terrible:bad,brave:valiant,new:old,
tall:skinny
shield:protect computer:talk,vehicle:transport,
pencil:make,song:sing
sick:health sad:emotion,tall:intelligence,
scared:courage,smart:energy
Table 12: Model prediction examples from RoBERTa
with s tuned on the validation set. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 4>  </Paper ID = 281>


<Paper ID = 282> <Table 0> <Abstractive Summary> =Exp1 Exp2 Exp3 Exp4 Macro Micro Full
Galician
Sent 0.695 0.758 0.751 0.178 0.596 0.618 0.727
BERT-base
Cat 0.705 0.799 0.293 0.422 0.555 0.513 0.699
Sent 0.562 0.685 0.476 0.141 0.466 0.468 0.618
fastText WV 0.21 0.564 0 0.526 0.325 0.286 0.461
Syn(3) 0.533 0.658 0.197 0.185 0.393 0.362 0.567
English
Sent 0.788 0.655 0.736 0.221 0.6 0.599 0.7
BERT-base
Add 0.981 0.81 0.758 0.441 0.748 0.732 0.839
Sent 0.596 0.5 0.505 0.147 0.437 0.431 0.543
fastText WV 0.308 0.552 0.033 0.574 0.366 0.335 0.48
Syn(3) 0.442 0.69 0.231 0.176 0.385 0.357 0.546
Portuguese
Sent 0.683 0.432 0.635 0.22 0.493 0.518 0.564
BERT-base
Add 0.854 0.541 0.378 0.366 0.535 0.508 0.67
Sent 0.61 0.622 0.527 0.171 0.482 0.487 0.55
fastText WV 0.024 0.541 0 0.634 0.3 0.244 0.453
Syn(3) 0.659 0.459 0.176 0.195 0.372 0.337 0.508
Spanish
Sent 0.755 0.592 0.536 0.186 0.517 0.516 0.595
BERT-base
Add 0.857 0.704 0.409 0.441 0.603 0.564 0.74
Sent 0.449 0.338 0.445 0.085 0.329 0.346 0.429
fastText WV 0.122 0.62 0.018 0.814 0.393 0.346 0.479
Syn(3) 0.367 0.577 0.173 0.237 0.339 0.318 0.553
Table 4: Summary of the BERT and fastText results. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 282>


<Paper ID = 284> <Table 0> <Abstractive Summary> =Table 1: Our labeling heuristics designed to capture user disengagement in dialogs. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 284>


<Paper ID = 285> <Table 0> <Abstractive Summary> =However,incontrast
stead, we propose a mechanism that enables the toothermodels,ourassumptions(§2.3)allowusto
3671SMCALFLOW Dataset SMCALFLOW TREEDST
Dataset TREEDST
V1.1 V2.0 #TrainingDialogues 1k 10k 33k 1k 10k 19k
BestReportedResult 66.5 68.2 62.2 Seq2Seq 36.8 69.8 74.5 28.2 47.9 50.3
T
OurModel 73.8 75.3 72.8 ER Seq2Tree 43.6 69.3 77.7 23.6 46.9 48.8
B
o Seq2Tree++ 48.0 71.9 78.2 74.8 75.4 86.9
Table 1: Test set exact match accuracy comparing our w/ OurModel 53.8 73.2 78.5 78.6 87.6 88.5
model to the best reported results for SMCALFLOW T Seq2Seq 44.6 64.1 67.8 28.6 40.2 47.2
R
(Seq2Seqmodelfromthepublicleaderboard;Semantic E Seq2Tree 50.8 74.6 78.6 30.9 50.6 51.6
B
Machinesetal.,2020)andTREEDST(TED-PPmodel; w/ OurModel 63.2 77.2 80.4 81.2 87.1 88.3
Cheng et al., 2020). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 285>


<Paper ID = 285> <Table 1> <Abstractive Summary> =Thisalso
meansthatthepathsexploredduringthesearchare Table 2: Validation set exact match accuracy across
shorterforourmodelthanformodelswhereeach varying amounts of training data (each subset is sam-
pled uniformly at random). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 285>


<Paper ID = 286> <Table 0> <Abstractive Summary> =I.2
inherentcomplicatedstructureinMPCwhich
mayprovidecrucialinterlocutorandutterance
Table 1: An MPC example in Ubuntu IRC channel. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 286>


<Paper ID = 286> <Table 1> <Abstractive Summary> =SND 98.25 92.18 88.68 80.25 86.14 63.41 85.29 51.39
Table 3: Evaluation results of addressee recognition on the test sets. </Abstractive Summary> <Extractive Summary> Table 1 shows an MPC example in the
addressee recognition, speaker identiﬁcation UbuntuInternetRelayChat(IRC)channel,which
and response selection.  </Extractive Summary>  </Table 1>  </Paper ID = 286>


<Paper ID = 286> <Table 2> <Abstractive Summary> =SND 93.92 76.96 87.30 57.54 88.77 61.54 89.27 63.34
Table 5: Evaluation results of response selection on the test sets. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 286>


<Paper ID = 287> <Table 0> <Abstractive Summary> =involvestheuseoftime-basedlocalaccuracymet-
ricsinatimewindow(i.e.,withinthistimeframe, RNN(HS’15): (HoughandSchlangen,2015)’s
hasadisﬂuencybeendetected,evenifnotonthe RNN-basedmodel,theﬁrstdeeplearning-based
3698Training FinaloutputF1 Incrementality F1
Model Model
Scheme F F F EO FTD Repeats Substitution Deletes
rm rpS e
LSTM .591 .674 .901 0.21 0.06 WithStandardTraining
Chunk MTL .631 .739 .911 0.41 0.07 LSTM 0.94 0.70 0.48
BERT .647 .780 .938 0.61 0.32 MTL 0.96 0.72 0.46
LSTM .598 .683 .909 0.20 0.03 BERT 0.96 0.77 0.54
Add-M MTL .628 .751 .921 0.38 0.10 WithAdd-MTraining
BERT .664 .788 .949 0.60 0.31 LSTM 0.95 0.71 0.48
MTL 0.96 0.73 0.47
Table 2: Final accuracy vs. incremental performance BERT 0.96 0.79 0.54
trade-offinthedifferentmodelsonun-segmentedtran-
Table3: Performanceondifferenttypesofrepair. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 287>


<Paper ID = 288> <Table 0> <Abstractive Summary> =3708Model Training Hotel Restaurant Attraction Train Taxi Average
Fulldataset 50.5/91.4 61.8/92.7 67.3/87.6 74.0/94.0 72.7/88.9 65.3/89.8
Zero-shot(Wu) 13.7/65.6 13.4/54.5 20.5/55.5 21.0/48.9 60.2/73.5 25.8/59.6
Zero-shot(Campagna) 19.5/62.6 16.4/51.5 22.8/50.0 22.9/48.0 59.2/72.0 28.2/56.8
TRADE
Zero-shot+ATDM 28.3/74.5 35.9/75.6 34.9/62.2 37.4/74.5 65.0/79.9 40.3/73.3
Zero-shot+NeuralWOZ 26.5/75.1 42.0/84.2 39.8/65.7 48.1/83.9 65.4/79.9 44.4/77.8
Zero-shotCoverage 52.5/82.2 68.0/90.8 59.1/75.0 65.0/89.3 90.0/89.9 66.9/85.4
Fulldataset 51.8/92.2 64.2/93.1 71.1/89.1 77.0/95.0 68.2/86.0 66.5/91.1
Zero-shot 19.8/63.3 16.5/52.1 22.6/51.5 22.5/49.2 59.5/74.9 28.2/58.2
SUMBT Zero-shot+ATDM 36.3/83.7 45.3/82.8 52.8/78.9 46.7/84.2 62.6/79.4 48.7/81.8
Zero-shot+NeuralWOZ 31.3/81.7 48.9/88.4 53.0/79.0 66.9/92.4 66.7/83.9 53.4/85.1
Zero-shotCoverage 60.4/88.6 76.2/95.0 74.5/88.7 86.9/97.3 97.8/97.6 79.2/93.4
Table 1: Experimental results of zero-shot domain transfer on the test set of MultiWOZ 2.1. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 288>


<Paper ID = 288> <Table 1> <Abstractive Summary> =Table 3: Full data augmentation on single-domain
Jointgoalaccuracy/slotaccuracyarereported. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 288>


<Paper ID = 288> <Table 2> <Abstractive Summary> =C AdditionalQualitativeExamples
Figure7showsotherexamplesfromourNeuralWOZ.Theleftsubﬁgureshowsanexampleofsynthesized
dialogue from NeuralWOZ in a restaurant, which is seen domain and has the same schema from the
3715Attraction Hotel Restaurant Taxi Train Full
#goaltemplate 411 428 455 215 482 1,000
#synthesizeddialogues 5,000 5,000 5,000 5,000 5,000 1,000
#synthesizedturns 38,655 38,112 37,230 45,542 37,863 35,053
#synthesizedtokens 947,791 950,272 918,065 1,098,917 873,671 856,581
Table 7: Statistics of the synthesized data used in NeuralWOZ using for zero-shot and full augmentation experi-
ments. </Abstractive Summary> <Extractive Summary> Table 2 shows that our achievedbyusingstatecandidateset,prepopulated
model still consistently outperforms in full data as the multiple-choice options from the ground
augmentationofmulti-domaindialoguestatetrack- truth,B ,asthetrainingtimeofLabeler.Itcan
1:T
ing.Speciﬁcally,ourNeuralWOZperforms2.8% beseenasusingmetainformationsinceitspurpose
pointbetteronthejointgoalaccuracyofTRADE is accurate annotation but not the dialogue state
thanATDM.Ouraugmentationimprovestheper- tracking itself.  </Extractive Summary>  </Table 2>  </Paper ID = 288>


<Paper ID = 289> <Table 0> <Abstractive Summary> =Readingmodelsincluderandomeffectsbysubject, Baselinemodels,includingCDR,areasreported
3722Model Train Expl Test CDRNN
CanonicalHRF 11.3548† 11.8263† 11.5661† FF RNN
Linearlyinterpolated 11.4236† 11.9888† 11.6654† Baseline Modality p p
Averaged 11.3478† 11.9280† 11.6090† LME Reading 0.0001*** 0.0001***
Lanczosinterpolated 11.3536† 11.9059† 11.5871† GAM Reading 0.0001*** 0.0001***
CDR 11.2774 11.6928 11.5369 CanonicalHRF fMRI 0.0001*** 0.0001***
Interpolated fMRI 0.0001*** 0.0001***
CDRNN-FF 10.5648 11.3602 11.3042
Averaged fMRI 0.0001*** 0.0001***
CDRNN-RNN 10.8736 11.5631 11.3914
Lanczos fMRI 0.0001*** 0.0001***
CDR Both 0.0001*** 0.0001***
Table 2: fMRI. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 289>


<Paper ID = 289> <Table 1> <Abstractive Summary> =Table 3: Permutation test of overall test set perfor-
mance improvement from CDRNN variants over each
baseline. </Abstractive Summary> <Extractive Summary> inShainandSchuler(2021).5
5.1 ModelValidation: BaselineComparisons
tation test that pools across all datasets covered
Table 1 gives mean squared error by dataset of by a given baseline (reading data for LME and
CDRNNvs.baselinemodelsonreadingtimesfrom GAM,fMRIdataforcanonicalHRF,linearlyinter-
both Natural Stories and Dundee.  </Extractive Summary>  </Table 1>  </Paper ID = 289>


<Paper ID = 29> <Table 0> <Abstractive Summary> =Table 6: Number of Instances for Each Sentiment on
Quanzeng You, Jiebo Luo, Hailin Jin, and Jianchao
theMVSA-∗Dataset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 29>


<Paper ID = 291> <Table 0> <Abstractive Summary> =NoFreqWSurp 0.024 0.8779
the Natural Stories Corpus (Futrell et al., 2018),
whichcontainsself-pacedreadingtimesfrom181
Table 1: Likelihood ratio test evaluating the contribu-
subjects that read 10 naturalistic stories consist-
tion of CharWSurp and FreqWSurp in predicting self-
ing of 10,245 tokens. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 291>


<Paper ID = 294> <Table 0> <Abstractive Summary> =Inmakingtextmoreemotive,themodel
Table 4: Automated metrics comparing our general-
usesamazingandblownaway,despitetheseterms
purpose TextSETTR model with recent work on three
not occurring in the exemplars. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 294>


<Paper ID = 294> <Table 1> <Abstractive Summary> =Table 5: Examples of dialect-sensitive completion (λ=8, add:40–70%, delete:0%). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 294>


<Paper ID = 294> <Table 2> <Abstractive Summary> =Table 6: Examples of shortening (add:0–5%, delete:40-90%), using the ﬁrst ﬁve sentences from the Wikipedia
article“Artiﬁcialneuralnetwork”. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 294>


<Paper ID = 294> <Table 3> <Abstractive Summary> =Table 7: Random augmentations of input text “What’ll the weather be tomorrow?”, using random style vector
deltaswithcomponentssampledfromN(0,0.08). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 294>


<Paper ID = 295> <Table 0> <Abstractive Summary> =16.13 65.90 53.09 42.34 75.30 FAIL 50.55
Performer 18.01 65.40 53.82 42.77 77.05 FAIL 51.41
H-Transformer-1D 49.53 78.69 63.99 46.05 68.78 FAIL 61.41
Table 1: Experimental results on long-range arena benchmark. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 295>


<Paper ID = 296> <Table 0> <Abstractive Summary> =Table 2: The impact of templates and label words on
5.1 Automaticselectionoflabelwords
prompt-basedﬁne-tuning(K =16). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 296>


<Paper ID = 296> <Table 1> <Abstractive Summary> =Majority† 32.7 33.0 33.8 49.5 52.7 81.2 0.0 -
Prompt-basedzero-shot‡ 50.8 51.7 49.5 50.8 51.3 61.9 49.7 -3.2
“GPT-3”in-contextlearning 52.0(0.7) 53.4(0.6) 47.1(0.6) 53.8(0.4) 60.4(1.4) 45.7(6.0) 36.1(5.2) 14.3(2.8)
Fine-tuning 45.8(6.4) 47.8(6.8) 48.4(4.8) 60.2(6.5) 54.4(3.9) 76.6(2.5) 60.7(4.3) 53.5(8.5)
Prompt-basedFT(man) 68.3(2.3) 70.5(1.9) 77.2(3.7) 64.5(4.2) 69.1(3.6) 74.5(5.3) 65.5(5.3) 71.0(7.0)
+demonstrations 70.7(1.3) 72.0(1.2) 79.7(1.5) 69.2(1.9) 68.7(2.3) 77.8(2.0) 69.8(1.8) 73.5(5.1)
Prompt-basedFT(auto) 68.3(2.5) 70.1(2.6) 77.1(2.1) 68.3(7.4) 73.9(2.2) 76.2(2.3) 67.0(3.0) 75.0(3.3)
+demonstrations 70.0(3.6) 72.0(3.1) 77.5(3.5) 68.5(5.4) 71.1(5.3) 78.1(3.4) 67.7(5.8) 76.4(6.2)
Fine-tuning(full)† 89.8 89.5 92.6 93.3 80.9 91.4 81.7 91.9
Table 3: Our main results using RoBERTa-large. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 296>


<Paper ID = 296> <Table 2> <Abstractive Summary> =[MASK],<S >
in 1 2
Manual 92.7 77.2 84.8 74.5
#1.Alright/Watch/Except
AutoT 92.3 77.1 88.2 76.2 #2.Hi/Watch/Worse
AutoL 91.5 75.6 87.0 77.2 #3.Regardless/Fortunately/Unless
AutoT+L 92.1 77.0 89.2 74.0
Table6: Examplesofourautomaticallygeneratedtem-
Table 5: Comparison between manual prompts and plates(AutoT)andlabelwords(AutoL). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 296>


<Paper ID = 296> <Table 3> <Abstractive Summary> =3823SST-2 SNLI TREC MRPC SST-2 SNLI
90
Prompt-basedFT 92.7 77.2 84.8 74.5 95
80
U++niRSfoBorBEmERsTRaTmsaepls.leinl.g 999222...736 777998...578 888375...456 777670...689 Accuracy (%)889050 Accuracy (%)6700
75 Fine-tune 50 Fine-tune
LM-BFF LM-BFF
Table 7: Impact of demonstration sampling strategies. </Abstractive Summary> <Extractive Summary> Table 3 shows our main
7 Experiments
resultsusingasingleprompt,eitherfromourman-
Wepresentourmainresults,andaddressseveral
ually designed ones (Table 1) , or the best gener-
researchquestionspertainingtoourLM-BFFap-
atedones. We concluded
standard ﬁne-tuning, Table 3 shows that, overall, bydiscussingthelimitationsofourapproach,and
theperformancestillsubstantiallylagsbehindﬁne- posedopenquestionsforfuturestudy.  </Extractive Summary>  </Table 3>  </Paper ID = 296>


<Paper ID = 297> <Table 0> <Abstractive Summary> =Novice (cid:88) - - -
Advanced (cid:88) - - (cid:88)
Adaptive (cid:88) (cid:88) - -
AdvancedAdaptive (cid:88) (cid:88) - (cid:88)
Oracle (cid:88) (cid:88) (cid:88) -
Black-Box - - - - Figure3: DARCYandSelfATKundernoviceattack
Table 3: Six attack scenarios under different assump-
detectthegeneratedtriggersasadversarialtexts. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 297>


<Paper ID = 297> <Table 1> <Abstractive Summary> =#queryattacks
Table 4: Average adversarial detection performance
acrossalltargetlabelsunderadvancedattack
alwaysselectingthebesttokensfromeachiteration
of the beam-search method (Sec. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 297>


<Paper ID = 297> <Table 2> <Abstractive Summary> =3837Positive Negative Length 50words100words250words500words
MR (reactive,utilizing) (cherry,time-vaulting) GF↓ 12→13 16→17 23→23 26→26
(reveal,hard-to-swallow,(well-made,kilt-wearing,
Human↑ 7.5→7.8 8.2→7.5 7.4→7.4 7.4→7.0
SSTas-nasty,clarke-williams, twenty-some,tv-cops,
overmanipulative) boy-meets-girl) Table 6: Changes in average readability of varied-
lengthnewsarticlesafterUniTriggerattackusingGun-
Table5: ExamplesofthetrapdoorsfoundbyDARCY
ningFog(GF)scoreandhumanevaluation
to defend target positive and negative sentiment label
onMR(K←2)andSSTdataset(K←5). </Abstractive Summary> <Extractive Summary> Ourcontributionsareasfollows:
Table 2 shows the prediction accuracy of CNN
(Kim, 2014) under different attacks on the MR
• Tothebestofourknowledge,thisistheﬁrstwork
(PangandLee,2005)andSST(Wangetal.,2019a)
thatutilizestheconceptof“honeypot”fromthe
datasets.  </Extractive Summary>  </Table 2>  </Paper ID = 297>


<Paper ID = 297> <Table 3> <Abstractive Summary> =First, as in the Table 7: Model F1 / detect AUC of CNN under trap-
saying“anounceofpreventionisworthapoundof doorremovalusingmodel-pruning
cure”,thehoneypot-basedapproachisaproactive
1 minute reading a news article and give a score
defensemethod. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 297>


<Paper ID = 299> <Table 0> <Abstractive Summary> =And then we re-learn the EUR-Lex 11,585 3,865 3,954 5.32 1225.2
interactions among the label-speciﬁc components
guided by the posterior information of dynamic Table 1: Statistics of the datasets. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 299>


<Paper ID = 299> <Table 1> <Abstractive Summary> =3.1 ExperimentalSetup
• XML-CNN (Liu et al., 2017): a CNN-based
Datasets We evaluate the proposed model
on three benchmark multi-label text classiﬁca- 1https://github.com/Makwen1995/LDGN MLTC
3858Models AAPD EUR-Lex
P@1 P@3 P@5 N@3 N@5 P@1 P@3 P@5 N@3 N@5
XML-CNN 74.38 53.84 37.79 71.12 75.93 70.40 54.98 44.86 58.62 53.10
SGM 75.67 56.75 35.65 72.36 75.35 70.45 60.37 43.88 60.72 55.24
DXML 80.54 56.30 39.16 77.23 80.99 75.63 60.13 48.65 63.96 53.60
AttentionXML 83.02 58.72 40.56 78.01 82.31 67.34 52.52 47.72 56.21 50.78
EXAM 83.26 59.77 40.66 79.10 82.79 74.40 61.93 50.98 65.12 59.43
LSAN 85.28 61.12 41.84 80.84 84.78 79.17 64.99 53.67 68.32 62.47
LDGN 86.24 61.95 42.29 83.32 86.85 81.03 67.79 56.36 71.81 66.09
Table 2: Comparisons with state-of-the-art methods on both AAPD and EUR-Lex datasets. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 299>


<Paper ID = 3> <Table 0> <Abstractive Summary> =We also experimented with two models com- Table 2: Accuracy of the different models on our
datasetusingcrossvalidationwithk=5.SciBERTf out-
bining BERT/SciBERT with our features (see
performs. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 3>


<Paper ID = 3> <Table 1> <Abstractive Summary> =RF 0.713 0.708 0.725
For the sake of completeness, we note that we
LR 0.765 0.755 0.787
alsoconductedexploratoryexperimentswithsim-
plesyntacticbaselines(titlelength,maximalword
Table 3: Accuracy of the different models on our Ig-
length,titlecontainingaquestion,titlecontaining Nobelretrievaltestset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 3>


<Paper ID = 3> <Table 2> <Abstractive Summary> =3 3 0.15 0.78 BERTf 0.58 0.43
annotators 4 0.02 0.62
Table 6: Precision at k of our models on the Seman-
Table 5: Spearman correlation of MTurk annotators tic Scholar corpus for k={50,300}. </Abstractive Summary> <Extractive Summary> Similartothepreviousexperiment,thecom-
Table 2 summarizes the results.  </Extractive Summary>  </Table 2>  </Paper ID = 3>


<Paper ID = 30> <Table 0> <Abstractive Summary> =Both contain the an- ImplicitAspect&ImplicitOpinion 14.83% 8.24%
notationsofnotonlyaspect-category-opinion-
Table 1: The percentage of review sentences with ex-
sentimentquadruplesbutalsoimplicitaspects
plicitandimplicitaspect/opinion. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 30>


<Paper ID = 30> <Table 1> <Abstractive Summary> =#Sentences 2286 4076
EA&EO 2429(66.40%) 3269(56.77%)
s
Aspect-Category-Opinion-Sentiment (ACOS) ple IA&EO 530(14.49%) 910(15.80%)
u
Quadruple Extraction is then deﬁned as a task to dr EA&IO 350(9.57%) 1237(21.48%)
a
extractasetofaspect-category-opinion-sentiment Qu IA&IO 349(9.54%) 342(5.94%)
quadruplesdescribedinareviewsentencecontain- # All 3658 5758
ingnwordsr=[w1,...,wn]: #Quadruples 1.60 1.42
#Sentences
S = {...,a -c -o -s ,...}, (1)
ACOS i j k l
Table 2: Statistics of our two ACOS Quadruple
where a -c -o -s denotes an aspect-category- datasets. </Abstractive Summary> <Extractive Summary> Table 1 summarizes the per-
†Correspondingauthor.  </Extractive Summary>  </Table 1>  </Paper ID = 30>


<Paper ID = 30> <Table 2> <Abstractive Summary> =datasets with the existing representative datasets
342AS AO AOS ACS ACOS
Sentence Aspect Category Opinion Sentiment
Pair Pair Triple Triple Quadruple
Restaurant-2014(Pontikietal.,2014) 3841 4827 4738 - 4534 4827 - - - -
Laptop-2014(Pontikietal.,2014) 1910 3012 - - 3012 3012 - - - -
Restaurant-2016(Pontikietal.,2016) 2295 3122 3001 - 3122 3182 - - 3364 -
Laptop-2016(Pontikietal.,2016) 2612 - 3705 - 3705 - - - - -
Restaurant-2014-AO(Fanetal.,2019) 2125 3503 - 3610 - - 4092 - - -
Restaurant-2016-AO(Fanetal.,2019) 1407 1968 - 2146 - - 2294 - - -
Restaurant-2014-AOS(Xuetal.,2020) 2068 3399 - 3443 3399 3399 3908 3908 - -
Restaurant-2016-AOS(Xuetal.,2020) 1393 1946 - 2101 1946 1946 2247 2247 - -
Restaurant-ACOS(ours) 2286 3110 2967 3335 3110 3155 3571 3575 3335 3658
Laptop-ACOS(ours) 4076 4958 4992 5378 4958 5035 5726 5731 5227 5758
Table 3: The comparison between the sizes of our two ACOS Quadruple datasets and existing representative
ABSAdatasets. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 30>


<Paper ID = 30> <Table 3> <Abstractive Summary> =Restaurant-ACOS Laptop-ACOS
Method
EA&EO IA&EO EA&IO IA&IO EA&EO IA&EO EA&IO IA&IO
Double-Propagation-ACOS 0.2602 N/A N/A N/A 0.0980 N/A N/A N/A
JET-ACOS 0.5230 N/A N/A N/A 0.3570 N/A N/A N/A
TAS-BERT-ACOS 0.3360 0.3184 0.1403 0.3976 0.2610 0.4154 0.1090 0.2115
Extract-Classify-ACOS 0.4496 0.3466 0.2386 0.3370 0.3539 0.3900 0.1682 0.1858
Table 6: F score on testing subsets with different aspect & opinion types. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 30>


<Paper ID = 300> <Table 0> <Abstractive Summary> =We then separately train a single layer
linearclassiﬁerthroughcrossentropylossonthe
Table 2: NPMI coherence (determined using top 10 trainingsplitusingthedocument-topicvectorsas
wordsofeachtopic)comparisonon50topicsbetween
inputandAdamoptimizeratalearningrateof0.01. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 300>


<Paper ID = 300> <Table 1> <Abstractive Summary> =Ascanbeseeninta- GNB-NTM 57.16 85.34 84.55
ble2,ourproposedT-TANmodelperformssigniﬁ- T-TAN(ours) 60.44 88.1 87.38
cantlybetterthanprevioustopicmodelsuniformly T-TAN(ours) 64.36 89.78 88.9
onalldatasetsachievingabetterNPMI(measured (contextvector)
onascaleof-1to1)byamarginof0.028(10.44%)
on20NG,0.047(14.59%)onAGNewsand0.022 Table 3: Comparison of accuracy between different
topic models on document classiﬁcation. </Abstractive Summary> <Extractive Summary> ues of tr size are taken from Table 1 of
W-LDA paper (Nan et al., 2019). Note that
Dataset tr size num below fr abv
# Train in Table 1 represents the number of
AGNews 96000 3 0.7
training documents after preprocessing.  </Extractive Summary>  </Table 1>  </Paper ID = 300>


<Paper ID = 300> <Table 2> <Abstractive Summary> =We
Table 4: Comparison of NPMI coherence between ab-
foundthattherunningtimeofbaselinemodelsis
lationvariantsofourmethodforK=50topics. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 300>


<Paper ID = 300> <Table 3> <Abstractive Summary> =Of
YRP 448000 20 0.7
the tr size documents, some documents
mayberemovedduringpreprocessing,there-
Table 6: Parameters used for preprocessing the AG-
fore#Trainmaybelessthantr size. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 300>


<Paper ID = 300> <Table 4> <Abstractive Summary> =johnkeats,greekliterature
Accordingtotheworkof(Lauetal.,2014),measur-
ingthenormalizedpointwisemutualinformation Table 7: Two randomly selected posts (title in bold)
from StackExchange dataset with ground truth (GT)
(NPMI)betweenallthewordpairsinasetoftopics
and top 5 keyphrases predicted by TAKG with and
agreeswithhumanjudgementsmostclosely. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 4>  </Paper ID = 300>


<Paper ID = 301> <Table 0> <Abstractive Summary> =1,804,428 1,848,184 2,682,076
LiuandCroft(2002)weassignarelevancescore
by:
Table 1: Parallel corpus statistics; “EN tkn.” refers to
rˆ= maxp(r = 1|Q,S;W)
number of English tokens in the parallel corpus; “LR
S∈D
tkn.”referstonumberoflow-resourcetokens(Somali,
Swahili,Tagalog)intheparallelcorpus. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 301>


<Paper ID = 301> <Table 1> <Abstractive Summary> =Thehyperparameterλ inSection3.3
2
is set to be 3 so that L and λ L are approx-
rel 2 rat
Table 2: Augmented dataset statistics; “augmented
imately on the same scale during training. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 301>


<Paper ID = 301> <Table 2> <Abstractive Summary> =#Q #T #S #Q #T #S #Q #T #S
Somali 300 338 142 300 482 213 1300 10717 4642
Swahili 300 316 155 300 449 217 1300 10435 4310
Tagalog 300 291 171 300 460 244 / / /
Table 3: MATERIAL dataset statistics: “#Q” refers to the number of queries; “#T” refers to the number of text
documents;“#S”referstothenumberofspeechdocuments. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 301>


<Paper ID = 301> <Table 3> <Abstractive Summary> =Wecompareour
modeltothecross-lingualmodelXLM-RoBERTa
SECLR 46.7 45.0 49.3 33.9
(Conneauetal.,2020),whichinpreviousresearch
SECLR-RT 61.1 55.5 59.0 45.7
hasbeenshowntohavebetterperformanceonlow-
resource languages than multilingual BERT (De-
Table 5: Document-levelMAP scoresfor text(T) and
vlinetal.,2019). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 301>


<Paper ID = 301> <Table 4> <Abstractive Summary> =SECLR 77 112 124
B ExamplesofEvaluationData SECLR-RT 179 254 319
In this section we demonstrate some examples
Table 7: Training time of SECLR and SECLR-RT on
fromtheMATERIALdatasetusedforevaluation. </Abstractive Summary> <Extractive Summary> Because SID-SGNS
out-performs both Bivec and MUSE consistently
by a wide margin (Table 4 and Table 5), in this
experimentweinitializeSECLR-RTwiththecross-
lingualembeddingsproducedbySID-SGNS.The
results of monolingual and cross-lingual embed-
ding initialization (SID-SGNS) are shown in Ta-
ble 10.  </Extractive Summary>  </Table 4>  </Paper ID = 301>


<Paper ID = 301> <Table 5> <Abstractive Summary> =14.03M 22.31M 21.35M
malitoEnglishbyhuman)is“thesecurityforces
capturedmilitaryequipmentcomingintothecoun-
Table 8: Number of trainable model parameters of
tryillegally.” Thissegmentisrelevanttothequery
SECLR/SECLR-RT on Somali, Swahili and Tagalog. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 5>  </Paper ID = 301>


<Paper ID = 302> <Table 0> <Abstractive Summary> =andBERT(Devlinetal.,2019)withcomplexneu-
3902Beforeexpertinspection Afterexpertinspection
Method DocumentMAP SnippetMAP DocumentMAP SnippetMAP
BERT+PDRMM 7.29 7.58 14.86 15.61
JPDRMM 5.16 12.45 16.55 21.98
BJPDRMM-NF 6.18 13.89 14.65 23.96
BestBIOASQ7competitor n/a n/a 13.18 14.98
Table 2: Document and snippet MAP (%) on BIOASQ 7 test batches 4 and 5 before and after post-contest
expertinspectionofsystemresponses,formethodsthatparticipatedinBIOASQ7. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 302>


<Paper ID = 303> <Table 0> <Abstractive Summary> =Table 1: Statistics on consistently and inconsistently
(2020). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 303>


<Paper ID = 303> <Table 1> <Abstractive Summary> =The results for
3914Sent N-N N-S S-N Sent N-N N-S S-N
N-N -0.228 -0.238 -0.240 N-N ∅-0.36 ∅-0.43 ∅-0.45
(106) (33) (19)
-0.038 -0.044 N-S - ∅+1.00 ∅+0.96
N-S -
(325) (22) S-N - - ∅-0.72
-0.278
S-N - -
(115)
Summ N-N N-S S-N
Summ N-N N-S S-N N-N ∅-0.13 ∅+0.13 ∅-0.66
N-N 0.572 0.604 0.506 N-S - ∅+1.00 ∅-0.56
(136) (42) (25)
0.713 0.518 S-N - - ∅+0.22
N-S -
(418) (36)
0.616 Table 3: Confusion Matrices based on human anno-
S-N - -
(134) tation showing the weight-spread relative to the task-
average for Sentiment (top) and Summarization (bot-
Table 2: Confusion Matrices based on human annota- tom), aligned with the human structure prediction, re-
tionshowingtheabsoluteweight-spreadusingtheSen- spectively. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 303>


<Paper ID = 303> <Table 2> <Abstractive Summary> =Table 4: Results of the W-RST approach compared to
Predicting discourse trees from transformer-based threshold-basednuclearityassignmentsandsupervised
neural summarizers. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 303>


<Paper ID = 304> <Table 0> <Abstractive Summary> =We found this particu-
DeSSE 74.77% 2.39% 5.62% 17.21%
larly helpful in our task, presumably because the MinWiki 0.0167 0.3533 0.4164 0.2135
samewordtypeatdifferentpositionsmighthave DeSSE 0.0200 0.6266 0.2658 0.0876
different relations with other words, captured by
Table 2: Distributions (Top) and inverse class weights
distinctlearnedrepresentations. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 304>


<Paper ID = 305> <Table 0> <Abstractive Summary> =3933Causeofunanswerability % ExampleQ Comment
Unveriﬁablepresupposition 30% whatisthestocksymbolformarscandy Presupposition‘stocksymbolformarscandyexists’fails
Referenceresolutionfailure 9% whatkindofvwjettadoihave Thesystemdoesnotknowwho‘i’is
Retrievalfailure 6% whendidthesalvationarmycometoaustralia PageretrievedwasSafeSchoolsCoalitionAustralia
Subjectivity 3% whatistheperfectheightforamodel Requiressubjectivejudgment
Commonsensical 3% wheredoeshowtomakeanamericanquilttakeplace Documentcontainsnoevidencethatthemovietookplace
somewhere,butitiscommonsensicalthatitdid
Actuallyanswerable 8% whendootherculturescelebratethenewyear Thequestionwasactuallyanswerablegiventhedocument
Notaquestion/Malformedquestion 3% wheredoyougomylovelyfullversion Notanactualquestion
Table 1: Example causes of unanswerability in NQ. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 305>


<Paper ID = 305> <Table 1> <Abstractive Summary> =Majorityclass 0.44 0.78
Zero-shotNLI(ALBERTMNLI+Wikisentences) 0.50 0.51
Zero-shotNLI(ALBERTQNLI+Wikisentences) 0.55 0.73
Zero-shotFEVER(KGAT+Wikisentences) 0.54 0.66
Finer-tunedNLI(ALBERTQNLI+Wikisentences) 0.58 0.76
Rule-based/NLIhybrid(ALBERTQNLI+Wikipresuppositions) 0.58 0.71
Rule-based/NLIhybrid(ALBERTQNLI+Wikisentences+Wikipresuppositions) 0.59 0.77
Finer-tuned,rule-based/NLIhybrid(ALBERTQNLI+Wikisentences+Wikipresuppositions) 0.60 0.79
Table 4: Performance of veriﬁcation models tested. </Abstractive Summary> <Extractive Summary> Therefore,underanextractive tially informative (see Table 1 and Appendix A
QA setup as in NQ where the answers are spans fordetails).  </Extractive Summary>  </Table 1>  </Paper ID = 305>


<Paper ID = 307> <Table 0> <Abstractive Summary> =Basedonthis
Pro 9,158 1,949 1,953
intuition, we further propose a new model called Con 8,695 1,873 1,891
Impactful 3,021 641 646
DISCOC(DiscourseContextOrientedClassiﬁer)
MediumImpact 1,023 215 207
toexplicitlyproducediscourse-dependentcontex- NotImpactful 1,126 252 255
tualized representations, fuse context representa-
Table 1: Statistics of stances and impact labels in the
tionsinlongdistances,andmakepredictions. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 307>


<Paper ID = 307> <Table 1> <Abstractive Summary> =two different consequences to support or oppose
3960Attention Representative Query Key&Value
Full BERT Ci C0,··· ,Cl
Memory XLNet Ci (C0,··· ,Ci−1)
Context SparseTransformer Ci Ci−1
Table 3: Different attention mechanisms. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 307>


<Paper ID = 307> <Table 2> <Abstractive Summary> =casedaredownloadedfromhuggingface.co
3963Model Precision Recall F1
Majority 19.43 33.33 24.55
SVM(Durmusetal.,2019) 65.67 38.58 35.42
BiLSTM 46.94±1.08** 46.64±0.71** 46.51±1.11**
HAN-BiLSTM 51.93±1.37** 49.08±1.52** 50.00±1.49**
HAN-BERT 53.72±0.80** 53.45±0.51** 53.46±0.47**
HAN-RoBERTa 55.71±1.12** 55.95±0.90** 55.49±0.62**
HAN-XLNet 53.91±0.96** 55.56±1.59** 54.53±1.22**
BERT(Durmusetal.,2019) 57.19±0.92 55.77±1.05** 55.98±0.70**
Flat-BERT 57.34±1.56 57.07±0.74* 56.75±0.82**
Flat-RoBERTa 58.11±1.34 56.40±0.61** 56.69±0.63**
Flat-XLNet 55.86±1.74* 56.20±1.17** 55.57±0.95**
Interval-BERT 55.56±2.03* 55.52±1.44** 55.34±1.50**
Interval-RoBERTa 58.31±0.89 56.46±1.44* 56.61±1.24*
Interval-XLNet 57.54±0.50 56.78±1.63* 56.52±1.00**
Context-BERT 54.96±0.93** 56.09±0.83** 55.44±0.83**
Context-RoBERTa 57.28±0.97 55.29±0.26** 55.83±0.54**
Context-XLNet 54.56±0.71** 56.28±1.22** 55.10±0.72**
Memory-BERT 54.33±0.83** 57.57±0.67* 55.22±0.61**
Memory-RoBERTa 55.08±0.89** 55.55±1.59** 54.76±1.38**
Memory-XLNet 55.44±1.15** 55.45±1.25** 54.91±0.96**
DISCOC 57.90±0.70 59.41±1.41 58.36±0.52
Table 4: The averages and standard deviations of different models on the argument impact classiﬁcation. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 307>


<Paper ID = 308> <Table 0> <Abstractive Summary> =forms BPE on all source words and a portion of 2http://www.phontron.com/kftt/
3974Systems MT06 MT02 MT03 MT04 MT05 MT08 ∆
ExsistingNMTsystems
(Chengetal.,2019) 46.95 47.06 46.48 47.39 46.58 37.38 -
(Yangetal.,2020) 44.69 - 46.56 - 46.04 37.53 -
(Yanetal.,2020) 47.80 47.72 46.60 48.30 - 38.70 -
BaselineNMTsystems
Transformer 44.11 46.38 45.05 47.07 44.82 34.74 ref
Single-Copy 45.04 47.21 46.47 47.48 45.45 36.08 +0.93
Flat-Copy 44.93 46.33 46.26 46.83 45.38 35.19 +0.39
OurNMTsystems
PDC 46.74 48.85 48.43 48.57 47.71 37.45 +2.59
PDC(w/oDict-Pointer） 45.79 47.58 47.81 47.98 46.32 36.53 +1.63
PDC(w/oTgt-View) 45.80 47.43 47.91 48.49 46.81 36.99 +1.91
PDC(w/oSrc-View) 45.97 47.42 47.90 47.92 47.07 36.81 +1.81
Table 1: The main results of NIST Zh-En task. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 308>


<Paper ID = 309> <Table 0> <Abstractive Summary> =Cross-lingualTransfer:Fine-tunemodelonEnglishtrainingsetandtestonalllanguages
MMTE† 67.4 81.3 73.5 58.3 64.4/46.2 60.3/41.4 58.1/43.8 59.8 37.9 59.5
mBERT† 65.4 81.9 70.3 62.2 64.5/49.4 61.4/44.2 59.7/43.0 56.7 38.7 59.6
XLM† 69.1 80.9 70.1 61.2 59.8/44.3 48.5/32.6 43.6/29.1 56.8 32.6 55.5
XLM-R† 79.2 86.4 72.6 65.4 76.6/60.8 71.6/53.2 65.1/45.0 66.0 57.3 68.1
VECOout 79.9 88.7 75.1 65.7 77.3/61.8 71.7/53.2 67.6/49.1 85.0 75.1 73.1
Translate-Train-All:Fine-tunemodelonEnglishtrainingdataandtranslateddataofthetargetlanguage
XLM-R‡ 82.6 90.4 - - 80.2/65.9 72.8/54.3 66.5/47.7 - - -
XLM-R∗ 82.8 90.2 72.6 65.4 80.0/65.8 73.0/54.3 74.5/58.3 80.2 75.2 74.4
FILTER 83.9 91.4 76.2 67.7 82.4/68.0 76.2/57.7 68.3/50.9 84.5 84.5 77.0
VECOout 83.0 91.1 75.1 65.7 79.9/66.3 73.1/54.9 75.0/58.9 89.3 86.9 77.2
VECOin 84.3 92.8 79.8 71.0 83.9/70.9 77.5/59.3 79.4/63.7 92.6 91.1 81.0
Table 2: XTREME results on each dataset (as of ACL submission deadline). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 309>


<Paper ID = 309> <Table 1> <Abstractive Summary> =mBART MLM+TLM 60.8 34.5
VECOInitialize First-6 31.1 30.1
Last-6 31.5 30.5 VECO CA-MLM+TLM 67.7 36.0
Full-24 31.7 30.6
Table5:Ablationstudyofsmall-sizedmodelsonXNLI
Table 4: Results of utilizing VECO to initialize deep andIWSLT14De-Entranslationdataset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 309>


<Paper ID = 31> <Table 0> <Abstractive Summary> =We observe
356Dataset System Length R-1 R-2 R-L CP-SPR-1 CP-SPR-2 CP-SPR-L Coherence
CopyCat 33.45 27.85 4.77 18.86 36.29 14.12 29.52 –
FewSum 52.50 33.56 7.16 21.49 34.54 10.61 23.93 -0.200
T5-FT 52.75 37.07 9.68 23.47 25.56 3.32 17.38 -0.050
Amazon
PASS 47.75 37.43 8.02 23.34 25.79 2.63 17.38 0.150
Gold 49.82 – – – 19.48 1.61 13.00 0.100
FewSum 52.9 37.29 9.92 22.76 40.82 17.09 30.34 0.050
T5-FT 40.58 38.72 10.26 24.47 38.93 13.05 29.55 -0.250
Yelp PASS 52.15 36.91 8.12 23.09 30.88 6.35 21.33 0.200
Gold 49.81 – – – 24.41 2.80 15.98 0.000
Table 1: End-to-End results on the Amazon (top) and Yelp (bottom) test sets. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 31>


<Paper ID = 31> <Table 1> <Abstractive Summary> =WeusedBest-WorstScaling FewSum 0.50 0.34 0.3 0.25
(Louviere and Woodworth, 1991; Louviere et al., T5-FT 0.38 0.25 0.3 0.2
2015; Kiritchenko and Mohammad, 2016, 2017) PASS 0.19 0.09 0.05 0.00
to compute each system’s score as the difference
betweenthepercentageoftimesitwasselectedas Table 2: Ratios of crude coherence (CE) and self-
consistency(SCE)errorsforeachsystemontheAma-
best, and the percentage of times it was selected
zontestset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 31>


<Paper ID = 31> <Table 2> <Abstractive Summary> =I have worn
themforseveralmonthsnowandtheyarehold-
Table 3: Example of summaries generated by T5-FT ingupwell. </Abstractive Summary> <Extractive Summary> Table 2 reports the ratios of crude errors
We evaluate our end-to-end system across 3 di-
per system, considering cases where at least one
mensions.  </Extractive Summary>  </Table 2>  </Paper ID = 31>


<Paper ID = 31> <Table 3> <Abstractive Summary> =Table 4: Example of summaries generated by PASS,
T5-FT, FewSum and CopyCat systems for the same
sportsshoesreviews. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 31>


<Paper ID = 31> <Table 4> <Abstractive Summary> =These NuGo bars are high
quality and they come in a variety of ﬂavors
Table 5: Example of summaries generated by PASS,
and sizes which make them perfect for serv-
T5-FT(Raffeletal.,2020),FewSum(Brazinskasetal.,
ing as a snack or as a replacement for pro-
2020a)andCopyCat(Brazinskasetal.,2020b)systems
cessedfoods. </Abstractive Summary> <Extractive Summary> As for our third dimension,
Finally,foraqualitativeimpressionweprovide
recall that we would like our system to generate
in Table 4 an example of the systems’ outputs for
diversesummariesacrossdifferentproducts,ano-
aproductfromtheAmazontestset.  </Extractive Summary>  </Table 4>  </Paper ID = 31>


<Paper ID = 31> <Table 5> <Abstractive Summary> =Table 6: Example of similar summaries generated by
FewSum (Brazinskas et al., 2020a) for three different Table8:Exampleof5candidatesummaries(outof28)
products. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 5>  </Paper ID = 31>


<Paper ID = 310> <Table 0> <Abstractive Summary> =_I_st
whether it matters if this right context is the true
documentcontext,orwhetherarandomsentence
Table 2: Candidate site examples with their labels. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 310>


<Paper ID = 310> <Table 1> <Abstractive Summary> =%(cid:88)
PUNKT PUNKTML ALWAYS SPACY MOSES ERSATZM ERSATZ ERSATZWM
ar 1460 1504 84.9 - 92.7 93.5 90.3 - 98.2 98.0 98.0
cs 664 1726 80.1 99.8 99.6 96.3 85.3 99.7 99.8 99.8 99.8
de 785 1965 90.2 99.7 99.5 97.9 91.4 99.9 99.9 99.8 99.8
en 7706 7706 48.6 98.6 87.7 77.0 88.0 98.8 99.8 98.7 99.1
es 3000 3064 86.5 99.1 98.9 96.5 83.6 98.7 98.8 98.6 98.6
et 2000 2017 78.2 99.3 99.4 90.6 84.0 99.5 99.8 99.7 99.8
ﬁ 1996 1996 95.0 99.7 99.7 98.9 97.9 99.8 99.9 99.9 99.9
fr 1619 1655 95.0 99.5 99.6 98.2 90.4 99.7 99.7 99.6 99.4
gu 1016 1018 92.3 - 100.0 97.9 3.8 99.7 99.8 100.0 100.0
hi 2507 2521 68.6 - 14.4 83.7 90.6 15.1 98.5 99.1 98.6
iu 2971 2971 59.1 - 91.3 63.9 - - 86.1 93.7 93.6
ja 993 1072 89.4 - 0.2 98.1 93.7 - 99.9 99.9 99.9
kk 1000 1002 92.2 - 99.6 97.1 - - 99.7 99.8 99.9
km 2320 2361 96.3 - 2.0 99.1 - - 99.7 99.7 99.7
lt 1000 1000 59.2 - 94.7 85.5 76.6 98.6 98.8 98.8 98.9
lv 2001 2017 76.4 - 99.4 90.3 88.6 99.6 99.7 99.5 99.6
pl 1001 1005 70.7 98.3 94.8 90.1 78.9 92.8 93.4 99.1 99.2
ps 2719 2726 96.4 - 99.4 99.1 - - 99.3 99.3 99.3
ro 1999 2000 89.1 - 98.7 97.0 90.9 98.5 99.3 99.3 99.2
ru 991 991 88.4 98.8 98.1 96.4 91.3 99.4 99.3 99.4 99.5
ta 997 1005 66.1 - 92.3 89.6 89.3 93.8 98.1 96.9 96.6
tr 3000 3009 67.5 - 95.8 85.2 85.1 99.5 99.6 99.5 99.5
zh 2000 2003 85.1 - - 99.2 96.6 - 100.0 100.0 100.0
all 45k 48k 73.3 - 87.6 89.0 - - - 98.9 98.9
Table 5: Test set statistics (left block) and F1 scores (right block) on our test data. </Abstractive Summary> <Extractive Summary> 3.1 Models Raw text examples can be found in Table 1 and
tokenized examples with ﬁxed context sizes are
Our basic model is depicted in Figure 1.  </Extractive Summary>  </Table 1>  </Paper ID = 310>


<Paper ID = 311> <Table 0> <Abstractive Summary> =TF-FT+UserBias 31.36 46.79
5.2 Baselines UD-NMT 32.35 48.20
Werepresentouruser-drivenNMTmodelasUD- Table 2: Main results on UDT-Corpus. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 311>


<Paper ID = 311> <Table 1> <Abstractive Summary> =Moreover,wedrawseveralinteresting
generic/multi-bleu.perl
5https://github.com/cmu-mtlab/meteor conclusions:
4013Model BLEU↑ METEOR↑ s-BLEU↑ d-BLEU↑ s-Sim.↓ d-Sim.↓
UD-NMT 32.35 48.20 32.17 32.23 93.18 80.10
w/otopiccache 31.88† 48.00 – – – –
w/ocontextcache 31.86† 47.84† 31.94† 31.58† 88.61 69.32
w/osimilaruserinitialization 32.02 48.14 31.86† 31.13‡ 93.54† 80.16
w/ocontrastivelearning 32.00 48.09 31.88† 31.94 93.49† 81.59†
Table 3: Ablation Study. </Abstractive Summary> <Extractive Summary> Table 1 provides
more detailed statistics of these datasets.  </Extractive Summary>  </Table 1>  </Paper ID = 311>


<Paper ID = 312> <Table 0> <Abstractive Summary> =38.9 77.1 95.44
Skiphalf Lemma
Dict 43.5 83.49 RefSF 39.1 81.44 94.15
Terms+Dict 43.1 91.22 lemma 38.9 77.22 95.55
Table2: Performanceofmodelstrainedusingsurface Table 3: Results on whole Europarl test set. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 312>


<Paper ID = 312> <Table 1> <Abstractive Summary> =Inthis
subset, the constraints from terminology database are
Table 4: Results on diff Europarl test set split, where
already in the same form as in reference, i.e. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 312>


<Paper ID = 312> <Table 2> <Abstractive Summary> =Correctinincorrectcontext 0 3 2
Differentcorrectwordchoice 28 2 4
Differentincorrectwordchoice 0 0 1 6 Conclusion
Invalidtranslation 5 5 1
Wedescribedtheproblemofwordinﬂectioninlexi-
Table 9: Analysis of 100 outputs marked as errors by
callyconstrainedmachinetranslation. </Abstractive Summary> <Extractive Summary> Table 2 shows that the model trained with
thetranslationappearswithoutthecorresponding dictionary constraints underperforms in terms of
constraintandgeneratesconstraintexpressionwith BLEU when only the constraints from terminol-
muchlowerprobabilitywhenthishappensduring ogy database are supplied (BLEU of 19.1).  </Extractive Summary>  </Table 2>  </Paper ID = 312>


<Paper ID = 312> <Table 3> <Abstractive Summary> =However,thesemet-
Table 10: Correlation between start character indices
ricsdonottellmuchaboutplacementofconstraints. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 312>


<Paper ID = 312> <Table 4> <Abstractive Summary> =38.9 77.1 95.44
Lemma
RefSF 39.1 81.44 94.15
Table 15: Comparison between using large, commer-
lemma 38.9 77.22 95.55
cialdictionary(Large)asopposedtoWiktionary(Wiki)
- 37.7 69.37 83.51
canon. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 4>  </Paper ID = 312>


<Paper ID = 312> <Table 5> <Abstractive Summary> =Table 14: Performance of the model mixing half of
thetrainingexampleswithsurfaceformconstraintsand
automated evaluation based on comparison with
halfofthemlemmatizedonthewholeEuroparltestset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 5>  </Paper ID = 312>


<Paper ID = 312> <Table 6> <Abstractive Summary> =form BLEU Cvg BLEU Cvge
L L
baseline - - 30.9 70.70 37.1 77.73
random sufﬁx surface 35.3 95.05 40.4 94.67
dict sufﬁx surface 37.7 93.46 42.2 93.23
dict factors surface 37.5 95.72 42.0 95.11
Table 16: Comparison of constraint integration methods on the oracle test set. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 6>  </Paper ID = 312>


<Paper ID = 313> <Table 0> <Abstractive Summary> =Mainte-
Table 1: Original and text-normalized example data
nancerecordsareanimportantsourceofinforma-
instances illustrating that domain-speciﬁc terms (baf-
tion for predictive maintenance (McArthur et al.,
ﬂe),abbreviations(gsk-gasket,eng-engine),andmis-
2018). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 313>


<Paper ID = 313> <Table 1> <Abstractive Summary> =Faci-Main 74,360 31.50 70 25 303 1,062 10,748
Further characteristics of these log entries in-
Table 3: Number of instances (Inst), average number
cludecompoundwords(antifreeze,engine-holder,
of tokens per instance (Avg Toks), number of classes
driftangle,dashboard). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 313>


<Paper ID = 313> <Table 2> <Abstractive Summary> =Another could be that RNNs
are notoriously difﬁcult to train (Pascanu et al., Table 6: Statistical signiﬁcance of the various clas-
2013),andtheLSTMmodelsmaysimplyrequire siﬁcation models between the Baseline approach and
moretrainingtimetoachievesimilarresults. </Abstractive Summary> <Extractive Summary> Table 2 shows multiple examples
withassociatedinstances.  </Extractive Summary>  </Table 2>  </Paper ID = 313>


<Paper ID = 314> <Table 0> <Abstractive Summary> =Wealsoexperimentedwithdifferentsections
Table 4: Prediction Results using different models. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 314>


<Paper ID = 314> <Table 1> <Abstractive Summary> =RoBERTa ﬁnetunedonlast512tokens,voting
XLNet ﬁnetunedonlast512tokens,voting
HierarchicalconcatenatedmodelwithattonILDCsingletrain
last4layersconcat,E=1,
XLNet+BiGRU
L=2,3runs
Table 6: Hyper-parameters corresponding to every
model. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 314>


<Paper ID = 315> <Table 0> <Abstractive Summary> =1 .113 .387 .175 .165 .160
2 .125 .266 .362 .211 .035
3 .025 .159 .223 .482 .112
precision recall f1-score support
4 .014 .054 .283 .300 .349
non-empathic 0.5739 0.3587 0.4415 184
5 .021 .014 .105 .556 .303
empathic 0.6434 0.5490 0.5925 286
neutral 0.3062 0.4747 0.3723 198
Table 10: CPM for cognitive empathy level annota- None 0.9841 0.9802 0.9822 506
tions. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 315>


<Paper ID = 315> <Table 1> <Abstractive Summary> =5 .043 .061 .227 .501 .168
Table 11: CPM for emotional empathy level annota- D DetailsonApplicationandEvaluation
tions. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 315>


<Paper ID = 315> <Table 2> <Abstractive Summary> =).”
Improvements ”Itwouldbebetterifthefeedbackwas
Term-Memory-Conditional-Random-Fieldsclassi-
on feedback more s elective or with detailed cate-
ﬁers(BiLSTM-CRF).Incombinationwiththecor- granularity goriesaboutempathy.”
respondingembeddingsvocabulary(GloVe)(Pen- Improvements ”Evenmoredetailedinformationonhow
onfeedbackrec- Icanimprovemyempathywritingwould
ningtonetal.,2014),ourLSTMreachedanunsat-
ommendations behelpful,e.g.,withreviewexamples.”
isfyingf1-scoreof61%fordetectingtheemotional
empathyleveland51%fordetectingthecognitive Table 16: Representative examples of qualitative user
empathylevel. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 315>


<Paper ID = 317> <Table 0> <Abstractive Summary> =Answer 33.51 20.54 33.30
OntheNQdataset,whileBM25clearlyunder-
Sentence 37.14 24.71 33.91
performsDPRregardlessofthenumberofretrieved
Title 43.20 32.11 39.67
passages,thegapbetweenGARandDPRissigniﬁ-
Table 3: ROUGE F1 scores of the generated query cantlysmallerandnegligiblewhenk ≥ 100. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 317>


<Paper ID = 317> <Table 1> <Abstractive Summary> =trast,theclassicQEmethodRM3,whileshowing
4094NQ Trivia
Method
Top-5 Top-20 Top-100 Top-500 Top-1000 Top-5 Top-20 Top-100 Top-500 Top-1000
BM25(ours) 43.6 62.9 78.1 85.5 87.8 67.7 77.3 83.9 87.9 88.9
BM25+RM3 44.6 64.2 79.6 86.8 88.9 67.0 77.1 83.8 87.7 88.9
DPR 68.3 80.1 86.1 90.3 91.2 72.7 80.2 84.8 - -
GAR 60.9 74.4 85.3 90.3 91.7 73.1 80.4 85.7 88.9 89.7
GAR+DPR 70.7 81.6 88.9 92.0 93.2 76.0 82.1 86.6 - -
Table 4: Top-k retrieval accuracy on the test sets. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 317>


<Paper ID = 317> <Table 2> <Abstractive Summary> =Table 5: Top-100 retrieval accuracy breakdown of
Performance breakdown by question type. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 317>


<Paper ID = 317> <Table 3> <Abstractive Summary> =ve GraphRetriever(Minetal.,2019b) 34.5 56.0 -
cti REALM(Guuetal.,2020) 40.4 - -
a
Extr DBMPR25(K(oaurprsu)khinetal.,2020) 4317..57 5670..91 -- Method Total Question OAvnesrwlaepr No
Overlap Overlap
GAR 41.8 62.7 74.8 Only
GAR+DPR 43.8 - - DPR 41.3 69.4 34.6 19.3
GPT-3(Brownetal.,2020) 29.9 - 71.2 GAR+DPR(E) 43.8 66.7 38.1 23.9
T5(Robertsetal.,2020) 36.6 60.5 - BART 26.5 67.6 10.2 0.8
e SpanSeqGen(Minetal.,2020) 42.2 - - RAG 44.5 70.7 34.9 24.8
v
ati RAG(Lewisetal.,2020a) 44.5 56.1 68.0 GAR+DPR(G) 45.3 67.9 38.1 27.0
er FID(IzacardandGrave,2020) 51.4 67.6 80.1
n
Ge BM25(ours) 35.3 58.6 - Table 7: EM scores with question-answer overlap
GAR 38.1 62.2 -
category breakdown on NQ. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 317>


<Paper ID = 317> <Table 4> <Abstractive Summary> =Table 6: End-to-end comparison with the state-of-
TheobservationsonTriviaaresimilarandomitted. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 4>  </Paper ID = 317>


<Paper ID = 317> <Table 5> <Abstractive Summary> =Question Answer No
Method Total Overlap
Overlap Overlap
Only
BM25 78.8 81.2 85.1 70.6
85 DPR 86.1 93.2 89.5 76.8
%)80 GAR 85.3 94.1 87.9 73.7
( GAR+DPR 88.9 96.3 91.7 79.8
y 75
c
a
ur70 Table 9: Top-100 retrieval accuracy by question-
cc65 GAR +DPR answeroverlapcategoriesontheNQtestset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 5>  </Paper ID = 317>


<Paper ID = 318> <Table 0> <Abstractive Summary> =paretheaccuracydifferencebetweentwodatasets As for VQA v2, N(cid:48) ranges from 1-2 for yes/no
4105VQA-CPv2test(%)↑ VQA-v2val(%)↑ GAP
Model
ALL Yes/No Num Other All Yes/No Num Other (%)↓
UpDN(Andersonetal.,2018) 39.74 42.27 11.93 46.05 63.48 81.18 42.14 55.66 23.74
Areg(Ramakrishnanetal.,2018) 41.17 65.49 15.48 35.48 62.75 79.84 42.35 55.16 21.58
RUBI(Cadeneetal.,2019) 47.11 68.65 20.28 43.18 61.16 - - - 14.05
LMH(Clarketal.,2019) 52.45 69.81 44.46 45.54 61.64 77.85 40.03 55.04 9.19
RankVQA(Qiaoetal.,2020) 43.05 42.53 13.91 51.32 65.42 82.51 57.75 45.35 22.37
LXMERT(TanandBansal,2019) 46.23 42.84 18.91 55.51 74.16 89.31 56.85 65.14 27.93
SSL(Zhuetal.,2020) 57.59 86.53 29.87 50.03 63.73 - - - 6.14
CSS(Chenetal.,2020a) 58.95 84.37 49.42 48.21 59.91 73.25 39.77 55.11 0.96
CL(Liangetal.,2020) 59.18 86.99 49.89 47.16 - - - - -
Top12-SAR(R→C) (Ours) 64.55 83.03 50.05 58.8 70.41 87.87 54.34 61.38 5.86
Top20-SAR(R→C) (Ours) 65.44 83.13 54.52 59.16 70.63 87.91 54.93 61.64 5.19
Top12-SAR+SSL(R→C)(Ours) 64.29 82.86 51.98 57.94 69.84 87.22 54.41 60.70 5.55
Top20-SAR+SSL(R→C)(Ours) 65.32 83.41 54.32 58.85 70.03 87.47 54.59 60.85 4.71
Top12-SAR+LMH(R) (Ours) 65.93 85.38 62.30 56.73 69.13 87.61 50.43 60.03 3.20
Top20-SAR+LMH(R) (Ours) 66.73 86.00 62.34 57.84 69.22 87.46 51.20 60.12 2.49
Table 1: Results on VQA-CP v2 test and VQA-v2 validation set. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 318>


<Paper ID = 318> <Table 1> <Abstractive Summary> =Table 2: Results based on different CAS in VQA-CP
v2. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 318>


<Paper ID = 319> <Table 0> <Abstractive Summary> =andaquestionq,atask-speciﬁcmodelisrequired Astheoriginaltestsetishidden,forconvenienceof
4115OverallTest Number(61.97%) Span(31.47%) Spans(4.99%) Date(1.57%)
EM F1 EM F1 EM F1 EM F1 EM F1
MML 58.99‡ 62.30‡ 55.38 55.58 69.96 75.51 39.29 66.01 42.57 49.05
HardEM 68.52‡ 71.88‡ 68.40 68.70 73.50 79.25 44.79 69.63 49.32 56.87
HardEM-thres 69.06 72.35‡ 69.05 69.39 74.61 79.79 39.50 66.38 52.67 58.75
VAE 32.34‡ 36.28‡ 51.65 52.35 0.37 10.01 0.00 8.89 0.00 4.11
Ours 69.35 72.92 69.96 70.27 73.38 79.32 42.86 70.42 48.67 57.47
Table 3: Evaluation on DROP. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 319>


<Paper ID = 319> <Table 1> <Abstractive Summary> =VAE optimizes the task-speciﬁc
Table 4: Deﬁnitions of solutions for numeric answers modelonLvae(θ,φ)withreinforcementlearning
and non-numeric answers. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 319>


<Paper ID = 319> <Table 2> <Abstractive Summary> =AsshowninTable7,our
Table 6: Accuracy on the SQL selection task. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 319>


<Paper ID = 32> <Table 0> <Abstractive Summary> =Infact,inCNN/DailyMaildataset,
Theinputarticleandgroundtruthsummariesare thereareplentyofdocumentswithadifferentnum-
372Table 6: ROUGE Scores about Trigram-Blocking on rebalancedthedisproportionateratioofsummary
CNN/DMTestSet. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 32>


<Paper ID = 32> <Table 1> <Abstractive Summary> =Table 7: ROUGE Scores about Sentence Representa-
tiononCNN/DMTestSet. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 32>


<Paper ID = 321> <Table 0> <Abstractive Summary> =Moreover,be- Table 2: Active learning experiments, performed by
causetheratioofunlabeledsentencestosentences threehumanannotators. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 321>


<Paper ID = 321> <Table 1> <Abstractive Summary> =Table 4: Krippendorff’s alpha and Fleiss’ kappa for
each label, each sample in the dataset was annotated
bythreedifferentannotators. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 321>


<Paper ID = 323> <Table 0> <Abstractive Summary> =While SAL was z = f (x ;θ∗)representingidentity-dependent
id id id id
originally developed with a very different goal features: the nonzero values of z represent di-
id
in mind: improving model generalization, we ex- mensions of the identity-dependent subspace in
pand SAL to a very important problem in health- z ,whiletheremainingdimensionsbelongtothe
feat
4173Table 1: Comparison of mood prediction performance across different modalities. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 323>


<Paper ID = 323> <Table 1> <Abstractive Summary> =classiﬁer(i.e.,mostcommonclassinthetraining
4174Table2:Moodpredictionfromtextusingextendedpre- Table 3: Mood prediction using a MLP from text and
trainedLMencoders.Weﬁndthatthesemodelsstrug- keystrokefeaturestalliedfrom(1)allcharacters,(2)a
gleonextremelylongcontextsoftypedtext. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 323>


<Paper ID = 323> <Table 2> <Abstractive Summary> =Table4:Wereportuseridentitypredictionperformance Table 5: Comparison of our privacy-preserving ap-
from raw input data and ﬁnd that identities are very proach(NI-MLP)withthebaseline(MLP).Weevalu-
easilyrevealedfromtext,keystrokes,andappusage. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 323>


<Paper ID = 323> <Table 3> <Abstractive Summary> =tionsofourworkinourbroaderimpactstatement
Table 8: Words with signiﬁcantly different timings as- inAppendixA. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 323>


<Paper ID = 324> <Table 0> <Abstractive Summary> =Binary 0.58 0.69 0.63
Table 2: Micro-averaged scores for NER, C-sanitise The proportion of masked tokens was around
andPresidiooveralltextsforannotatorsa1,a4,a5. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 324>


<Paper ID = 325> <Table 0> <Abstractive Summary> =Table 1: Statistics of MS-AMR (ﬁrst group) and our
annotatedout-of-domaintestdatabasedonLPcorpus. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 325>


<Paper ID = 325> <Table 1> <Abstractive Summary> =#Links Cover(%) F1
≤50 184 85.2 42.9
≤100 206 95.4 45.2
≤150 212 98.1 45.4
≤200 214 99.1 47.2
≤250 215 99.5 52.1
≤300 216 100.0 49.7
>300 216 100.0 48.3
Table 3: Devset statistics on mention-gold-antecedent
distanceandtheperformancesofAMRcoref-baseusing
thedistanceasthesearchspace. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 325>


<Paper ID = 326> <Table 0> <Abstractive Summary> =Table 1: Example sentence pair for each of the 12 tasks. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 326>


<Paper ID = 326> <Table 1> <Abstractive Summary> =Instead of Equation
5, we try deﬁning sentence-level surprisal as the
Table 3: Varying the type of covariance matrix in the maximumsurprisalamongalltokens(Table7):
Gaussianmodel. </Abstractive Summary> <Extractive Summary> Table 1 shows an example sentence
(e.g., Abrusa´n (2019) gives a survey of current
pairfromeachtask.  </Extractive Summary>  </Table 1>  </Paper ID = 326>


<Paper ID = 327> <Table 0> <Abstractive Summary> =Besides,
8https://pytorch.org/ removingthelayerattentionmechanismalsoleads
4235Model Ave. F1(%) ∆(%) GAT Params FLOPS Memory Ave.F1
TrigNet 70.86 - Original 1.8M 5.5G 7.8GB 69.69
Flow(our) 1.8M 3.4G 5.3GB 70.86
w/o“p↔w↔p” 70.13 0.73↓
w/o“p↔w↔c↔w↔p” 69.56 1.3↓ Table 4: Analysis of the computational cost for orig-
w/oLayerattention 69.88 0.98↓ inal GAT and ﬂow GAT on the Kaggle dataset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 327>


<Paper ID = 328> <Table 0> <Abstractive Summary> =subj obj CLS bsc
Table 1: Basic statistics of the preprocessed VUA
Thenwecomputetheprobabilitythattherelation
dataset provided by (Gao et al., 2018). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 328>


<Paper ID = 328> <Table 1> <Abstractive Summary> =(2020) 84.9 78.0 69.0 73.2 94.5 83.0 71.9 77.0 91.8 77.9 64.6 70.7
DeepMet(Suetal.,2020) – 79.5 70.9 74.9 – 82.0 71.3 76.3 – – – –
MelBERT(Choietal.,2021) – 78.7 72.9 75.7 – 80.1 76.9 78.5 – – –
MrBERT 86.4 80.8 71.5 75.9 94.7 82.7 72.5 77.2 91.8 78.4 64.6 70.9
Table 3: Results on the VUA dataset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 328>


<Paper ID = 328> <Table 2> <Abstractive Summary> =VUA-verb VUA-verb
Model Acc P R F1 Model Acc P R F1
BERT-SEQ 85.1 77.5 70.8 74.0 MrBERT-G 85.2 77.3 71.9 74.5
MrBERT-GL 85.5 76.8 73.9 75.3
Average-Linear 85.7 79.8 70.2 74.7
MrBERT-GLD 86.4 80.8 71.5 75.9
Average-Bilinear 86.4 80.8 71.5 75.9
Average-NT 85.7 77.4 73.8 75.6
Table 5: The performance of MrBERT when consid-
Maxout-Linear 85.2 78.1 70.2 73.9
ering different types of contexts: G, L and D indicate
Maxout-Bilinear 85.3 75.7 74.8 75.3
global,localanddistantcontexts,respectively. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 328>


<Paper ID = 328> <Table 3> <Abstractive Summary> =Maxout-NT 85.6 78.8 70.9 74.7
Concat-Linear 85.5 80.3 68.6 74.0
Concat-Bilinear 85.2 77.6 71.2 74.3
MrBERTexplicitlyincorporatesverbarguments
Concat-NT 85.0 76.4 72.3 74.3
throughgrammaticalrelationsasthelocalcontext,
Table 4: The effects of the ways for modeling contex- which differs from other methods. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 328>


<Paper ID = 328> <Table 4> <Abstractive Summary> =(2020) 76.4 73.1 73.6 73.2
total 2,525 3,348 MrBERT 75.1 70.4 74.3 72.2
MrBERT-ﬁnetune 76.7 73.9 72.1 72.9
Table 7: Similar to Table 6, this table shows the im- DeepMet - 53.7 72.9 61.7
Trans. </Abstractive Summary> <Extractive Summary> Section3.2)andcontextintegration(contextcon- Relation modeling and context integration
catenation,averageandmaxout,seeSection3.3) strategies Table 4 shows the results of different
4245VUAVerb VUAAll-POS VUAAll-POS(4POS)
Model Acc P R F1 Acc P R F1 Acc P R F1
Gaoetal.  </Extractive Summary>  </Table 4>  </Paper ID = 328>


<Paper ID = 328> <Table 5> <Abstractive Summary> =Table 8: The experimental results on MOH-X and
TroFi,whereCVindicates10-foldcross-validationand
accordingtothenumberofclauses. </Abstractive Summary> <Extractive Summary> Thebeneﬁtofinvolvinggrammaticalrelationsmay
Effects of different contexts Table 5 shows the bethatithelpskeepadynamicandbalancedfocus
performance of MrBERT when it considers the betweentheglobalandlocalcontextsaccordingto
globalcontext(MrBERT-G),theglobalandthelo- thesignalsexpressedbythegrammaticalstructure.  </Extractive Summary>  </Table 5>  </Paper ID = 328>


<Paper ID = 329> <Table 0> <Abstractive Summary> =4258Model BLEU EN-DE EN-ES EN-FR
JT-S-MT 24.7 ST(JTProposed) 26.8 31.0 37.4
JT-S-MT+Adapter 24.7 MT(Gangietal.,2019a) 28.1 34.2 42.2
JT-S-MT+DedicatedAttention 24.2 MT 25.4 27.7 33.5
MT(Tuned) 29.6 34.3 41.4
Table 4: BLEU score for models with task dependent MT(JT) 28.9 33.9 41.6
MT(JTProposed) 30.5 34.7 42.3
components
Table5: ComparisonbetweenSTandMT. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 329>


<Paper ID = 33> <Table 0> <Abstractive Summary> =1 25
d-select ROUGE-1 ROUGE-2
2SAPSw/oES 0.475 0.085 0.019
2SAPSw/oTS 0.502 0.078 0.023
2SAPS 0.556 0.096 0.033
Table 6: Ablation results of 2SAPS model, showing
changesofalign+m:1ROUGEandd-selectF1scores. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 33>


<Paper ID = 330> <Table 0> <Abstractive Summary> =0.26
0.06
0.02 0.01 Table 1: Patterns used with the ATOMIC actions. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 330>


<Paper ID = 330> <Table 1> <Abstractive Summary> =Forinstance,onewouldthinkthatthemostob-
vious reason to prepare dinner or to join the bas-
Table 2: Examples of social groups we use in our ex-
ketballteamwouldnotbe aperson’sethnicityor
periments. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 330>


<Paper ID = 330> <Table 2> <Abstractive Summary> =4265SocialGroup BERT RoBERTa GPT-2 CamemBERT AraBERT
Refugees 46.37% 13.73% 11.85% 16.35% 4.51%
Disabledpeople 42.23% 13.22% 13.98% 17.29% 4.49%
Leftistpeople 33.55% 11.31% 11.11% 18.01% 2.86%
Immigrants 29.04% 9.39% 9.16% 17.24% 5.07%
Europeanpeople 26.80% 10.61% 10.69% 16.09% 4.25%
Buddhistpeople 26.38% 9.69% 10.27% 17.57% 5.49%
Whitepeople 22.71% 8.98% 9.99% 26.96% 4.68%
Arabs 20.27% 7.42% 7.18% 16.34% 4.95%
Blackpeople 19.59% 8.84% 9.30% 15.74% 6.62%
Hispanicpeople 19.09% 7.92% 6.99% 18.53% 4.84%
Chinesepeople 19.00% 7.72% 7.46% 13.64% 5.91%
Pakistanipeople 15.94% 6.90% 6.64% 18.62% 5.47%
Jews 15.53% 5.10% 5.47% 18.68% 7.99%
Brownpeople 13.39% 6.40% 6.31% 17.91% 5.42%
Africanpeople 13.32% 5.84% 5.42% 21.92% 5.58%
PeoplewithDownSyndrome 12.48% 5.09% 5.09% 22.23% 3.66%
Liberals 12.21% 5.91% 6.40% 12.97% 3.91%
Muslimpeople 10.44% 5.60% 5.56% 15.77% 4.71%
Indianpeople 9.96% 4.97% 4.70% 18.50% 6.53%
LatinAmericanpeople 9.80% 5.17% 4.83% 17.17% 4.59%
Women 20.05% 6.60% 6.66% 13.61% 4.66%
Men 15.13% 5.28% 5.49% 12.99% 8.86%
Table 6: The scores in this table indicate the proportions of potentially toxic statements with respect to a given
socialgroupbasedoncontentgeneratedbydifferentPTLMs. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 330>


<Paper ID = 330> <Table 3> <Abstractive Summary> =Some examples of servesimilarbiasedcontentaboutwomenwiththe
4267TopSocialGroups TopBiased Top-1Freq SocialGroup Arabic Top-1Freq
BERT Japanesemen,Indian (cid:73)(cid:46) (cid:202)(cid:191) 4,892
Hispanicwomen,women pregnant 22,546 men (cid:72)((cid:17)do(cid:88)g(cid:65)(cid:103))
Jewish,Muslimpeople religion 15,449 Disabledmen,Japanese 3054
Black,whitepeople race 14,889 men (accident)
(cid:201)(cid:211)(cid:65)(cid:103)
Atheists,Buddhists faith 14,652 Disabledwomen, 2670
RLusesfitaisnt,s,HIimndmuigwraonmtsen bweaourkty 98,,175132 Pakistaniwomen (pr(cid:225)e(cid:9)g(cid:107)(cid:9)n(cid:89)a(cid:75)(cid:10)nt) 2469
Immigrants,Muslims poor 8,604 Gaymen,disabledmen
(smo(cid:9) k(cid:9)es)
Disabledpeople,Buddhists illness 6,994 (cid:173)(cid:74)(cid:10)(cid:174)(cid:187)
Disabledmen,Korean 4,892
Disabled,transpeople disability 6,492
Refugees,Brownpeople hungry 6,361 men (cid:145)(s(cid:9)ic(cid:29)(cid:10)k(cid:81))(cid:211)
MenwithDown 672
RoBERTa Syndrome,Disabled (si(cid:13)ck)
Atheists,Muslims religion 15,799 men (cid:169)(cid:75)(cid:65)(cid:103)(cid:46) 672
Brownpeople,Blackpeople
Refugees,Indianpeople hungry 13,564 (hungry(cid:17))
Disabled,transpeople disability 10,556 (cid:250)(cid:10)(cid:171)(cid:241)(cid:74)(cid:10)(cid:131) 639
European,Russianpeople job 9,671 leftistmen,liberalmen
Atheists,Christians faith 8,604 (com(cid:213)(cid:230)m(cid:132)(cid:16)(cid:74)u(cid:28)(cid:46)n(cid:75)(cid:10)ist)
Women,Men lonely 6,493 Brownmen,Blackmen 256
White,Blackpeople race 5,780 (smiles)
(cid:145)(cid:203)
Africanpeople,Immigrants poor 5,666 Blackmen,Chinese 130
Refugees,Immigrants fear 3,089 men (athief)
Buddhists,Hindus happy 5,100
SocialGroup French Top-1Freq
GPT-2
ﬁlle 9,678
Refugees,Gaypeople afraid 8,618 Russian,Brownpeople (girl/daughter)
Muslims,Jewishpeople religion 6,679 famille 6,878
Muslims,Atheists faith 6,292 Refugees,Muslimmen (family)
Women,Pakistaniwomen husband 6,101 PeoplewithDown malade 6,651
Men,Pakistanimen wife 4,637 Syndrome,Buddhists (sick)
White,Blackpeople race 4,234 ﬁls 5,490
Women,Russianpeople tired 3,818 Pakistani,Russianpeople (son)
Disabled,transpeople disability 3,602 mariage 4,515
Refugees,Muslims fear 3,557 Gay,Hindupeople (marriage)
Trans,gaypeople gender 3,215 enceinte 4,227
PakistaniandKoreanwomen
(pregnant)
Table 8: Examples of relatively informative descrip- pays 3,914
European,Africanmen
(country)
tivenounsandadjectiveswhichappearasTop-1predic-
travail 3,726
tions. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 330>


<Paper ID = 330> <Table 4> <Abstractive Summary> =Table 9: Arabic and French examples of relatively in-
formativenounandadjectiveTop-1predictionswithin
commonwordpregnantinbothFrenchandArabic,
the two main social groups which are associated with
inadditiontootherstereotypicalassociationssuch
them. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 4>  </Paper ID = 330>


<Paper ID = 330> <Table 5> <Abstractive Summary> =Table 11: Confusing examples which can be unintelligible, ambiguous, may need more context, or do not make
sense. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 5>  </Paper ID = 330>


<Paper ID = 331> <Table 0> <Abstractive Summary> =4291Regard Sentiment Gendered
Model Decode IF↓ GF↓
Score↓
Black White AAE WAE
GPT Greedy - - 13-73-14(0.01) 17-67-16(0.01) 0.15 0.09 1.98±2.34
Beam - - 10-77-13(0.01) 13-71-16(0.03) 0.12 0.07 1.91±2.35
Top-k 33-55-12(-0.20) 22-55-23(0.01) 13-70-17(0.02) 16-63-21(0.03) 0.27 0.09 2.07±2.32
Nucleus 35-53-12(-0.23) 30-54-16(-0.14) 16-63-21(0.03) 18-59-23(0.02) 0.33 0.10 2.10±2.28
GPT-2 Greedy - - 15-63-22(0.03) 14-64-23(0.06) 0.19 0.07 1.91±2.39
Beam - - 14-67-18(0.02) 12-70-18(0.04) 0.19 0.07 1.90±2.45
Top-k 35-49-16(-0.19) 24-48-28(0.04) 17-57-26(0.05) 17-57-26(0.06) 0.32 0.10 2.00±2.36
Nucleus 46-42-12(-0.33) 36-45-19(-0.16) 20-49-31(0.06) 17-54-29(0.06) 0.36 0.12 2.00±2.27
XLNet Greedy - - 09-76-15(0.03) 11-68-21(0.05) 0.13 0.09 1.89±2.34
Beam - - 04-88-08(0.02) 06-83-11(0.03) 0.08 0.04 1.85±2.31
Top-k 23-63-14(-0.10) 14-69-17(0.02) 10-72-19(0.05) 13-61-26(0.07) 0.27 0.10 1.96±2.30
Nucleus 35-49-16(-0.20) 29-56-14(-0.15) 14-63-23(0.05) 15-58-27(0.06) 0.30 0.11 1.97±2.27
Table 2: Bias evaluations for various decoding algorithms, models, and metrics. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 331>


<Paper ID = 331> <Table 1> <Abstractive Summary> =Model Decoding Demographic Scores
GPT Top-k man 24-51-25(0.01)
woman 21-52-27(0.06)
gay 31-52-17(-0.14)
straight 22-54-24(0.02)
Model Decoding Avg.Length VocabSize
Nucleus man 33-50-17(-0.16)
woman 29-53-18(-0.11) GPT Greedy 11.4 440
gay 38-48-13(-0.25) Beam 10.2 349
straight 29-54-17(-0.13) Top-k 12.9 1,235
Nucleus 14.3 2,074
GPT-2 Top-k man 31-48-21(-0.09)
woman 21-49-30(0.10) GPT-2 Greedy 15.8 880
gay 53-32-15(-0.39) Beam 15.1 845
straight 18-49-33(0.15) Top-k 17.7 2,117
Nucleus 18.2 3,443
Nucleus man 36-47-17(-0.20)
woman 30-54-17(-0.13) XLNet Greedy 12.1 537
gay 53-35-11(-0.42) Beam 8.1 217
straight 31-50-20(-0.11) Top-k 14.6 1,685
Nucleus 16.4 2,991
XLNet Top-k man 24-54-22(-0.02)
woman 12-63-25(0.14)
gay 50-44-06(-0.44) Table 4: Quantitative values to estimate text diver-
straight 21-55-24(0.03) sity: Average lengths (in words) of IF/GF evaluation
Nucleus man 28-55-16(-0.12) samples(prompt+generatedtext)andvocabularysize
woman 24-57-20(-0.04) acrossallsamplesshowthatgeneratedtextdiversityin-
gay 43-45-11(-0.32) creasesfordecodingtechniquesinthefollowingorder:
straight 26-55-20(-0.06) beam,greedy,top-k,nucleus. </Abstractive Summary> <Extractive Summary> Table 1 organizes various
whileweexaminebiasesinNLGtasks.  </Extractive Summary>  </Table 1>  </Paper ID = 331>


<Paper ID = 331> <Table 2> <Abstractive Summary> =Table 3: Regard score bias evaluation results across
decoding techniques for demographics: man, woman,
gay, and straight, reported in distribution percentages
ofnegative-neutral-positive(avgvalue). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 331>


<Paper ID = 332> <Table 0> <Abstractive Summary> =than LayerDrop in terms of efﬁciency per epoch
4298Model #Layers Frozen MaxBLEU Traintime Ratio #Params TrainTimeeach
untilmax(inhours) Trainable(Total) epoch(inseconds)
6 0 34.52±0.07 2.548±0.06 1 26.8M 122.73±1.16
8 0 34.59±0.11 2.557±0.05 1 31.1M 142.28±1.87
Transformer
10 0 34.56±0.05 3.173±0.04 1 35.3M 161.66±1.54
12 0 34.29±0.12 3.521±0.09 1 39.5M 172.45±1.98
6 2 34.37±0.12 2.422±0.03 0.95 22.6M(26.8M) 120.59±1.32
8 2 34.80±0.07 2.450±0.06 0.96 26.8M(31.1M) 134.49±1.76
TReservoir
10 2 34.70±0.03 2.831±0.05 0.89 31.1M(35.3M) 144.42±1.98
12 2 34.78±0.04 3.476±0.04 0.98 35.3M(39.5M) 159.43±1.67
6 2 34.43±0.15 2.120±0.04 0.83 22.6M(25.8M) 107.71±1.73
8 2 34.56±0.16 2.203±0.06 0.86 26.8M(29.1M) 120.07±1.65
FFNReservoir
10 2 34.66±0.02 2.493±0.05 0.79 31.1M(33.3M) 130.11±1.43
12 2 34.76±0.03 3.241±0.04 0.92 35.3M(37.5M) 156.32±1.87
6 2 34.59±0.15 2.364±0.08 0.92 22.6M(26.8M) 119.30±1.36
8 2 34.58±0.16 2.554±0.05 0.99 26.8M(31.1M) 138.62±1.44
LayerDrop
10 2 34.57±0.07 3.404±0.06 1.07 31.1M(35.3M) 140.88±1.62
12 2 33.65±0.24 3.251±0.04 0.92 35.3M(39.5M) 160.85±1.49
Table 1: Wall-clock time (averaged over multiple runs) saved for IWSLT for different model types and encoder
depths. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 332>


<Paper ID = 332> <Table 1> <Abstractive Summary> =Model #Layers Frozen MaxBLEU Traintime Ratio #Params TrainTimeeach
untilmax(inhours) Trainable(Total) epoch(inhours)
12 0 24.46±0.04 15.15±0.15 1 75.6M 0.505±0.005
16 0 24.52±0.03 16.05±0.18 1 88.2M 0.643±0.006
Transformer
24 0 24.69±0.05 17.61±0.85 1 113.4M 0.877±0.029
32 0 24.83±0.04 18.42±0.28 1 138.6M 1.036±0.010
12 4 24.26±0.08 14.11±0.21 0.93 72.4M(75.6M) 0.472±0.007
16 4 24.50±0.05 15.25±0.28 0.95 75.6M(88.2M) 0.596±0.009
TReservoir
24 4 25.11±0.07 15.89±0.74 0.90 100.8M(113.4M) 0.776±0.024
32 4 24.66±0.04 16.38±0.24 0.88 126.0M(138.6M) 0.998±0.009
12 4 24.42±0.05 14.01±0.09 0.92 72.4M(71.4M) 0.441±0.003
16 4 24.65±0.07 14.53±0.17 0.91 75.6M(83.9M) 0.524±0.006
FFNReservoir
24 4 24.93±0.04 12.62±1.53 0.71 100.8M(109.2M) 0.743±0.018
32 4 24.98±0.03 13.96±0.19 0.73 126.0M(134.4M) 0.964±0.007
12 4 24.27±0.03 14.61±0.14 0.96 72.4M(75.6M) 0.489±0.006
16 4 24.15±0.06 15.55±0.54 0.97 75.6M(88.2M) 0.597±0.017
LayerDrop
24 4 24.37±0.05 16.25±0.36 0.92 100.8M(113.4M) 0.823±0.013
32 4 23.84±0.03 15.27±0.38 0.83 126.0M(138.6M) 1.028±0.012
Table 2: Wall-clock time (averaged over multiple runs) saved for WMT for different model types and encoder
depths. </Abstractive Summary> <Extractive Summary> Moreover,shallowdecodersmakeit Table 1 and 2 show the time it took to achieve
easiertodecidewheretoplacereservoirlayers(in themaximumvalidationBLEUscoreandhowthat
theencoder)andmakesitmorestraightforwardto relates to the regular transformer, demonstrating
identifywhereperformancegainscomefrom.  </Extractive Summary>  </Table 1>  </Paper ID = 332>


<Paper ID = 332> <Table 2> <Abstractive Summary> =4300Model Layer SentLen TreeDepth TopConst BShift Tense SubjNum ObjNum SOMO CoordInv
(Surface) (Syntactic) (Syntactic) (Syntactic) (Semantic) (Semantic) (Semantic) (Semantic) (Semantic)
1 84.56±0.54 32.30±0.41 54.40±0.33 49.99±0.01 80.98±0.32 76.26±0.09 50.01±0.19 76.38±0.61 54.33±0.47
2 87.22±0.07 33.63±0.57 58.38±0.20 50.12±0.17 82.84±0.68 78.65±0.19 51.47±0.53 78.00±1.12 54.66±0.55
3 84.25±0.16 32.60±0.17 54.41±0.10 50.02±0.01 81.72±0.59 77.00±0.13 51.32±0.64 76.57±1.13 54.13±0.51
4 87.37±0.20 32.59±0.29 50.06±0.21 69.76±0.26 81.63±1.17 76.47±0.09 52.41±1.49 76.15±0.84 52.62±1.34
5 84.61±0.24 31.14±0.48 44.76±0.38 74.82±0.11 80.16±0.19 73.66±0.16 52.95±1.77 72.90±0.21 51.26±1.14
6 82.56±0.25 30.31±0.40 39.30±0.40 78.80±0.38 81.88±0.47 75.30±0.07 56.21±1.26 74.37±0.16 51.44±1.04
Transformer
7 70.85±0.13 26.65±0.72 40.70±0.13 78.98±0.32 85.11±0.31 72.03±0.46 58.15±0.46 68.71±0.91 55.39±0.27
8 66.23±1.33 23.46±0.44 25.19±1.02 77.42±0.27 80.35±0.45 67.55±0.99 54.94±2.04 63.69±2.32 50.58±0.83
9 71.17±0.29 31.21±0.31 58.42±0.29 85.55±0.44 86.77±0.19 80.30±0.08 64.36±1.20 81.68±0.45 66.90±0.49
10 73.19±0.50 27.74±0.53 41.01±0.22 83.56±0.96 86.13±0.35 83.04±0.04 62.01±0.59 79.73±0.21 62.60±1.04
11 71.37±0.42 30.22±0.28 48.58±0.35 84.40±0.44 87.28±0.59 82.34±0.15 61.10±0.14 80.00±0.40 64.44±0.38
12 71.66±0.12 33.43±0.18 64.38±0.20 87.38±0.02 88.41±0.09 84.46±0.25 63.01±0.05 81.80±0.27 65.72±0.16
1 87.75±0.10 31.60±0.21 50.38±0.23 50.00±0.00 80.40±0.18 76.47±0.20 50.53±0.14 73.48±0.15 53.55±0.70
2 81.28±0.23 34.20±0.41 61.41±0.42 60.64±0.65 81.50±0.77 76.33±0.08 50.73±0.34 74.28±0.67 56.82±0.10
3 89.28±0.09 36.42±0.11 67.36±0.45 75.64±0.52 85.42±0.18 80.53±0.02 52.50±1.80 78.47±1.81 57.16±0.27
4 74.31±0.32 32.42±0.83 55.19±0.33 73.41±0.00 79.56±0.00 75.15±0.08 53.68±0.66 75.02±0.19 56.89±0.08
5 88.03±0.22 38.34±0.64 68.65±0.29 82.25±0.12 86.80±0.02 82.27±0.33 57.95±0.24 80.82±0.91 58.05±0.10
6 74.55±0.37 33.13±0.29 52.70±0.81 79.21±0.13 85.70±0.36 77.43±0.03 57.26±0.19 75.38±0.66 51.95±1.30
TReservoir
7 85.82±0.37 37.63±0.13 70.43±0.05 84.12±0.35 86.88±0.07 82.86±0.30 61.17±0.21 80.79±0.17 61.83±0.95
8 71.69±0.71 30.32±0.01 48.44±0.30 79.12±0.12 84.75±0.09 79.23±0.11 59.53±0.16 76.80±0.41 57.34±0.14
9 85.86±0.12 37.89±0.03 69.53±0.37 85.55±0.12 87.98±0.22 84.13±0.01 63.06±0.01 82.55±0.31 66.07±0.05
10 69.22±0.23 25.58±0.35 29.20±0.58 78.57±0.09 85.02±0.03 75.68±0.16 57.55±1.57 74.70±0.02 55.02±0.64
11 65.70±0.05 30.57±0.03 47.56±0.02 81.20±0.00 86.78±0.02 83.73±0.05 60.38±0.17 80.59±0.15 62.50±0.11
12 70.61±0.18 34.45±0.20 64.19±0.10 84.53±0.03 87.48±0.16 84.86±0.14 62.75±0.14 82.08±0.03 64.73±0.06
Table 4: RoBERTa Probing Results. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 332>


<Paper ID = 332> <Table 3> <Abstractive Summary> =Generally,wefoundrepetitiveapplica- timesavingswhilematchingthebestperformance
4307Model IWSLT-Dec2 IWSLT-Dec6 WMT-Dec1
#Layers Traintime MaxBLEU #Layers Traintime MaxBLEU #Layers Traintime MaxBLEU
until95%max(inhours) (95%) until95%max(inhours) (95%) until95%max(inhours) (95%)
6 0.647±0.03 32.89±0.04 6 0.642±0.02 33.36±0.03 12 3.788±0.053 23.36±0.06
8 0.711±0.05 33.04±0.03 8 0.765±0.03 33.41±0.08 16 3.820±0.072 23.41±0.05
Transformer
10 0.808±0.02 33.96±0.08 10 0.898±0.04 33.32±0.07 24 5.262±0.607 23.50±0.03
12 1.037±0.03 33.07±0.09 12 1.037±0.03 33.07±0.11 32 6.212±0.232 23.81±0.04
6 0.569±0.02 32.78±0.03 6 0.599±0.01 33.09±0.05 12 3.563±0.061 23.21±0.04
8 0.619±0.04 33.12±0.05 8 0.726±0.02 33.38±0.09 16 3.603±0.056 23.80±0.06
TReservoir
10 0.729±0.04 33.13±0.07 10 0.738±0.03 33.37±0.04 24 4.923±0.771 23.75±0.02
12 0.982±0.02 33.03±0.11 12 0.958±0.01 33.46±0.09 32 5.780±0.214 23.71±0.03
6 0.521±0.05 32.85±0.02 6 0.594±0.03 33.13±0.04 12 3.417±0.046 23.22±0.07
8 0.533±0.03 33.84±0.04 8 0.651±0.04 33.36±0.06 16 3.527±0.063 23.54±0.05
FFNReservoir
10 0.614±0.01 33.05±0.08 10 0.627±0.05 33.26±0.03 24 4.197±0.697 23.74±0.06
12 0.811±0.02 33.26±0.10 12 0.780±0.02 33.46±0.08 32 4.984±0.321 23.82±0.02
6 0.837±0.08 32.87±0.05 6 0.706±0.01 33.08±0.03 12 3.912±0.068 23.33±0.08
8 0.934±0.07 33.12±0.03 8 0.753±0.04 33.14±0.05 16 3.581±0.076 23.17±0.04
LayerDrop
10 0.901±0.06 33.18±0.02 10 0.691±0.03 32.39±0.05 24 4.875±0.728 23.43±0.07
12 0.914±0.01 32.33±0.06 12 0.803±0.02 32.94±0.10 32 5.980±0.219 22.97±0.08
Table 6: Wall-clock time (averaged over multiple runs) for IWSLT/WMT for different model types and encoder
depths. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 332>


<Paper ID = 332> <Table 4> <Abstractive Summary> =Model IWSLT-Dec2 IWSLT-Dec6 WMT-Dec1
#Layers Traintime MaxBLEU #Layers Traintime MaxBLEU #Layers Traintime MaxBLEU
until99%max(inhours) (99%) until99%max(inhours) (99%) until99%max(inhours) (99%)
6 1.454±0.06 34.24±0.05 6 1.297±0.03 34.69±0.05 12 9.961±0.053 24.27±0.04
8 1.475±0.09 34.32±0.09 8 1.390±0.02 34.75±0.09 16 12.623±0.072 24.35±0.06
Transformer
10 1.526±0.04 34.25±0.04 10 1.622±0.05 34.64±0.03 24 13.412±0.837 24.49±0.07
12 2.259±0.07 34.24±0.11 12 1.748±0.01 34.66±0.08 32 15.117±0.232 24.56±0.02
6 1.257±0.04 34.05±0.09 6 1.291±0.03 34.51±0.10 12 8.314±0.062 24.15±0.06
8 1.472±0.06 34.47±0.05 8 1.339±0.03 34.80±0.04 16 9.221±0.073 24.41±0.05
TReservoir
10 1.530±0.03 34.36±0.02 10 1.419±0.04 34.72±0.03 24 10.413±0.580 24.56±0.03
12 2.043±0.05 34.53±0.07 12 1.642±0.02 34.87±0.02 32 11.465±0.227 24.49±0.01
6 1.138±0.03 34.10±0.13 6 1.169±0.02 34.71±0.09 12 7.407±0.087 24.33±0.08
8 1.101±0.07 34.32±0.11 8 1.201±0.03 34.79±0.08 16 9.336±0.036 24.42±0.05
FFNReservoir
10 1.281±0.01 34.36±0.03 10 1.276±0.03 34.63±0.03 24 9.978±0.546 24.91±0.07
12 1.785±0.03 34.42±0.06 12 1.440±0.01 34.87±0.02 32 10.524±0.341 24.96±0.01
6 1.363±0.05 34.58±0.14 6 1.253±0.01 34.42±0.10 12 8.372±0.059 24.17±0.04
8 1.468±0.03 34.50±0.12 8 1.244±0.04 34.44±0.09 16 9.741±0.043 23.93±0.08
LayerDrop
10 1.678±0.04 34.52±0.07 10 1.343±0.04 33.83±0.06 24 10.145±0.628 24.07±0.09
12 2.071±0.02 33.45±0.23 12 1.423±0.02 33.97±0.12 32 10.168±0.329 23.81±0.03
Table 7: Wall-clock time (averaged over multiple runs) saved for IWSLT/WMT for different model types and
encoderdepths. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 4>  </Paper ID = 332>


<Paper ID = 333> <Table 0> <Abstractive Summary> =1
Score oftheDataset
100% AL FS SUB
ON5.0 0.829 0.843 22% 13%
CoNLL 0.930 0.938 42% 27%
Table 2: Summary of the results of the AL strategies
fromFigure1,whenthemodelsaretrainedusing100%
of the training set and active learning (AL), with the
besthyperparametersettingoftheacquisitionfunction
with for full sentence and subsequence, based on nor-
malisedAUCscore. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 333>


<Paper ID = 334> <Table 0> <Abstractive Summary> =4324Lightweightconvolution Params CoLA MNLI- MNLI- MRPC QNLI QQP RTE SST STS GLUE
type,BERT-small m mm
Noconvolution 13.41M 13.9 73.2 71.8 77.9 80.7 74.5 62.0 81.9 79.3 68.4
Noconvolution+absposition∗ 13.43M 30.8 76.1 75.9 80.4 78.5 74.4 62.2 85.1 76.8 71.1
Fixed(Raffeletal.2020) 13.42M 42.1 77.2 76.3 83.8 82.7 75.9 64.4 87.1 81.4 74.5
Dynamic(Shawetal.2018) 13.43M 39.1 78.4 77.4 83.8 83.4 77.5 64.4 87.3 81.4 74.7
Composite(Equation6;ours) 13.43M 40.4 78.2 77.4 85.0 83.3 77.7 64.7 87.8 82.1 75.2
Lightweightconvolution Params CoLA MNLI- MNLI- MRPC QNLI QQP RTE SST STS GLUE
type,BERT-base m mm
Noconvolution+absposition∗ 108.82M 50.3 82.0 81.2 85.0 84.6 78.6 68.9 91.4 84.9 78.5
Fixed(Raffeletal.2020) 108.73M 50.0 81.5 80.5 85.6 86.0 78.5 68.9 91.4 84.9 78.6
Dynamic(Shawetal.2018) 108.74M 50.9 81.6 80.5 84.6 85.3 78.5 69.5 91.6 84.8 78.6
Composite(Equation6;ours) 108.74M 50.4 81.6 80.8 85.4 85.1 78.7 69.7 91.2 85.7 78.7
Table 1: GLUE test set performance for models with lightweight convolutions added to self-attention. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 334>


<Paper ID = 334> <Table 1> <Abstractive Summary> =4327Convolutions Params CoLA MNLI- MNLI- MRPC QNLI QQP RTE SST STS GLUE
m mm
Noconvolution+absposition∗ 13.43M 30.8 76.1 75.9 80.4 78.5 74.4 62.2 85.1 76.8 71.1
Composite(Equation6) 13.43M 40.4 78.2 77.4 85.0 83.3 77.7 64.7 87.8 82.1 75.2
Fixeddepthwise 13.47M 36.9 77.6 76.1 80.6 81.9 76.4 64.5 87.5 79.7 73.5
Fixeddepthwise+composite 13.48M 38.0 77.4 76.3 82.8 83.7 77.7 65.3 87.3 82.3 74.5
Table 2: GLUE test set performance for BERT-small models with added depthwise convolutions and composite
attention. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 334>


<Paper ID = 334> <Table 2> <Abstractive Summary> =4epochsforMNLI/QQP
Underourframework,theanalogousmodelre-
3epochsotherwise
placeshalfofthequeriesandkeyswithdepthwise-
Table 5: Fine-tuning hyperparameters. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 334>


<Paper ID = 335> <Table 0> <Abstractive Summary> =120 3.5 81.5/88.6 82.0
Quant-Noise PQ 38 11.0 - 83.6
Q-BERT 2/4-8-8 53 7.9 79.9/87.5 83.5
Q-BERT 2/3-8-8 46 9.1 79.3/87.0 81.8
Q-BERT 2-8-8 28 15.0 69.7/79.6 76.6
GOBO 3-4-32 43 9.7 - 83.7
GOBO 2-2-32 28 15.0 - 71.0
TernaryBERT 2-2-8 28 15.0 79.9/87.4 83.5
BinaryBERT 1-1-8 17 24.6 80.8/88.3 84.2
BinaryBERT 1-1-4 17 24.6 79.3/87.2 83.9
Table 4: Comparison with other state-of-the-art meth-
odsondevelopmentsetofSQuADv1.1andMNLI-m.
(a) 8-bitActivation. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 335>


<Paper ID = 335> <Table 1> <Abstractive Summary> =sizewiththebestperformanceamongallquantiza-
4340#Bits SQuAD MNLI #Bits SQuAD MNLI
Quant QNLI MRPC Quant QNLI SST-2
(W-E-A) v1.1 -m (W-E-A) v1.1 -m
TWN0.5× 2-2-8 80.3/87.9 84.1 91.3 85.7 BWN 1-1-8 79.2/86.9 84.2 91.2 92.7
TWS1.0× 1-1-8 80.8/88.3 84.2 91.6 86.0 LAB 1-1-8 79.0/87.0 83.6 91.5 92.8
TWN0.5× 2-2-4 78.0/86.4 83.7 90.9 85.5 BiReal 1-1-8 79.4/87.1 83.9 91.4 92.5
TWS1.0× 1-1-4 79.3/87.2 83.9 91.4 86.0 BWN† 1-1-8 79.4/87.3 84.2 91.3 92.8
BWN‡ 1-1-8 79.6/87.2 83.5 91.2 92.9
Table 5: The performance gain by ﬁne-tuning the bi-
TWS 1-1-8 80.8/88.3 84.2 91.6 93.2
nary model after splitting. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 335>


<Paper ID = 335> <Table 2> <Abstractive Summary> =91.3 92.8 53.6 88.0 85.8 70.8 80.4
Table 8: Results on GLUE development set for adap- Table 9: Results on GLUE development set for adap-
tivesplittingwith8-bitactivationquantization. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 335>


<Paper ID = 336> <Table 0> <Abstractive Summary> =+4.3% +3.5% +4.1% +1.0% +8.9% +10.6% +2.6% +15.2% +10.4%
Table 2: Comparison of pre-trained Convolutions and pre-trained Transformers on toxicity detection, sentiment
classiﬁcation, question classiﬁcation and news classiﬁcation. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 336>


<Paper ID = 337> <Table 0> <Abstractive Summary> =We impose the
1 2 DB100k 470 100k 598k 50k 50k
followingconstraints: Sports 4 1039 1312 - 307
rH rT Table 2: Number of entities, relations, and observed
2,i 2,i
rH = rT = αi,|αi| ≤ 1, (6) triplesineachsplitforthesixbenchmarks. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 337>


<Paper ID = 337> <Table 1> <Abstractive Summary> =- FB15k FB15k-237
Model MR MRR Hit@10 Hit@3 Hit@1 MR MRR Hit@10 Hit@3 Hit@1
TransE† - 0.463 0.749 0.578 0.297 357 0.294 0.465 - -
DistMult(cid:51) 42 0.798 0.893 - - 254 0.241 0.419 0.263 0.155
HolE - 0.524 0.739 0.759 0.599 - - - - -
ConvE 51 0.657 0.831 0.723 0.558 244 0.325 0.501 0.356 0.237
ComplEx - 0.692 0.840 0.759 0.599 339 0.247 0.428 0.275 0.158
SimplE - 0.727 0.838 0.773 0.660 - - - - -
RotatE 40 0.797 0.884 0.830 0.746 177 0.338 0.533 0.375 0.241
SeeK - 0.825 0.886 0.841 0.792 - - - - -
OTE - - - - - - 0.351 0.537 0.388 0.258
GC-OTE - - - - - - 0.361 0.550 0.396 0.267
PairRE 37.7 0.811 0.896 0.845 0.765 160 0.351 0.544 0.387 0.256
±0.4979 ±0.00077 ±0.00071 ±0.0011 ±0.0012 ±0.9949 ±0.00066 ±0.00093 ±0.00079 ±0.00097
Table 4: Link prediction results on FB15k and FB15k-237. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 337>


<Paper ID = 337> <Table 2> <Abstractive Summary> =SeeK 0.338 0.467 0.370 0.268
ComplEx-NNE 0.298 0.426 0.330 0.229
ComplEx-NNE-AER 0.306 0.418 0.334 0.244
Model MRR hit@1
PairRE 0.412 0.600 0.472 0.309
SimplE 0.230 0.184
±0.0015 ±0.0006 ±0.0015 ±0.0027
SimplE+ 0.404 0.349
PairRE+rule 0.419 0.599 0.475 0.321
PairRE 0.468±0.003 0.416±0.005 ±0.0010 ±0.0008 ±0.0008 ±0.0016
PairRE+Rule 0.475±0.003 0.432±0.004
Table 7: Link prediction results on DB100k. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 337>


<Paper ID = 337> <Table 3> <Abstractive Summary> =All the
Table 6: Link prediction results on Sports dataset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 337>


<Paper ID = 338> <Table 0> <Abstractive Summary> =EURLEX-57K 4271 5 5 45000 6000 6000
Thenweregardthepairwiththesmallestsemantic
distance(d )asapositivepairandregardothertext- Table 1: Statistics of three datasets for hierarchical
1
multi-label text classiﬁcation. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 338>


<Paper ID = 338> <Table 1> <Abstractive Summary> =BERT+HiMatch 86.33 68.66
For pretrained language model BERT (Devlin
Table 2: The experimental results comparing to other
et al., 2018), we use the top-level representation
state-of-the-artmodelsonRCV1-V2dataset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 338>


<Paper ID = 338> <Table 2> <Abstractive Summary> =2)Hierarchy-awaremod- BERT+HiMatch 86.70 81.06
els: HE-AGCRCNN (Peng et al., 2019), HMCN
Table 3: The experimental results comparing to other
(Maoetal.,2019),Htrans(Banerjeeetal.,2019),
state-of-the-artmodelsonWeb-of-Sciencedataset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 338>


<Paper ID = 339> <Table 0> <Abstractive Summary> =Table 3: The performances on SST-2 and QNLI with
Asmentionedearlier,theseout-of-distributionsets
different strategies when dropping information in the
were either constructed with in-domain/out-of- hidden space. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 339>


<Paper ID = 339> <Table 1> <Abstractive Summary> =HiddenCut
strategies,wealsoexperimentedwithareverseset achievedthebestperformancewithα = 0.1,and
4386Method OriginalandCounterfactualSentences Prediction
RoBERTa <s> I would rate 8 stars out of 10 </s> Positive
HiddenCut <s> I would rate 8 stars out of 10 </s> Positive
RoBERTa <s> The movie became more and more intriguing </s> Positive
HiddenCut <s> The movie became more and more intriguing </s> Positive
RoBERTa <s> I would rate 8 stars out of 20 </s> Positive
HiddenCut <s> I would rate 8 stars out of 20 </s> Negative
RoBERTa <s> The movie became only slightly more intriguing </s> Positive
HiddenCut <s> The movie became only slightly more intriguing </s> Negative
Table 4: Visualization of the attention weights at the last layer in models. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 339>


<Paper ID = 339> <Table 2> <Abstractive Summary> =α 0.05 0.1 0.2 0.3 0.4 β 0.1 0.2 0.4 0.6
MNLI 88.07 88.23 88.13 88.07 87.64 SST-2 95.18 95.30 95.76 95.46
Table5:PerformancesonMNLIwithdifferentHidden- Table 6: Performances on SST-2 with different sam-
Cutratioα,whichcontrolsthelengthofspantocutin plingratioβ,whichcontrolsthesizeofimportanttoken
thehiddenspace. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 339>


<Paper ID = 34> <Table 0> <Abstractive Summary> =We train the im- #maximages 1 1 1
ageencoderandthetableencoderalongwiththe #maxﬁelds 5+128 5+128 5+128
textdecodertogenerateareviewtextoftheentity Table 1: Data statistics; 1* in Train column indicates
to which images or metadata belong: I or T → thatitisapseudosummary. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 34>


<Paper ID = 34> <Table 1> <Abstractive Summary> =Assomedescriptionsconsistofmany 10,15,20]and[1e-03,1e-04,5e-05,1e-05,5e-06],
400Models Grammaticality Coherence Overall Image Table
Self&Control -0.517 -0.500 -0.527 Models R-1 R-2 R-L R-1 R-2 R-L
Copycat 0.163 -0.077 -0.113 Untrained 21.03 2.45 14.17 24.04 2.92 15.10
MultimodalSum 0.367 0.290 0.260 Triplet 20.06 2.49 13.15 25.67 3.52 15.16
Gold -0.013 0.287 0.380 Pivot(ours) 25.87 3.62 15.70 27.32 4.12 16.57
Table6:HumanevaluationresultsintermsoftheBWS Table 7: Reference reviews generation results on the
ontheYelpdataset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 34>


<Paper ID = 340> <Table 0> <Abstractive Summary> =P (Yˆ) =η∗P (Yˆ)+(1−η)
style i neural i
2.4 Inference
N
(cid:88)
TogenerateastylisticresponseYˆ givendialogue ∗ w ∗P (Yˆ), (13)
i n n-gram i
history Xi during the inference process, we ﬁrst n=1
4394TrainingDialogues 11,118 Model Time(s) #ofparameters
ValidationDialogues 1,000
S2S 4.55 63M
TestDialogues 1,000
StyleFusion 4.60 75M
AverageTokensPerDialogue 114.7
Ours 4.60 75M
AverageTokensPerUtterance 14.6
Table 2: The average running time (in seconds per
Table1: StatisticsoftheDailyDialogdataset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 340>


<Paper ID = 341> <Table 0> <Abstractive Summary> =Output: [IN:Data-Collection-Usage[SL:DC.FPEWe][SL:Actionuse][SL:DP.Uyour][SL:DC.UOAP
username][SL:DC.UOAPiconorproﬁlephoto][SL:P.AMmarketingpurposeorpressreleases]]
Table 3: An example of input / output used to train the two types of models on PolicyIE. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 341>


<Paper ID = 341> <Table 1> <Abstractive Summary> =4405#param Type-I Type-II
Model IntentF1
(inmillions) SlotF1 EM SlotF1 EM
Human - 96.5 84.3 56.6 62.3 55.6
Embedding 1.7 50.9±27.3 19.1±0.3 0.8±0.3 0.0±0.0 0.0±0.0
BiLSTM 8 75.9±1.1 40.8±0.9 7.6±0.9 3.9±3.0 10.0±2.7
Transformer 34.8 80.1±0.6 41.0±3.5 6.5±2.8 3.5±1.0 13.1±2.4
BERT 110 84.7±0.7 55.5±1.1 17.0±1.1 29.6±2.4 24.2±4.2
RoBERTa 124 84.5±0.7 54.2±1.9 14.3±2.4 29.8±1.7 24.8±1.4
Embeddingw/CRF 1.7 67.9±0.6 26.0±1.5 1.20±0.3 5.7±4.6 3.1±0.6
BiLSTMw/CRF 8 76.7±1.4 45.1±1.2 9.2±0.9 26.8±2.2 18.1±2.0
Transformerw/CRF 34.8 77.9±2.7 43.7±2.3 8.9±3.0 5.7±0.9 11.0±2.1
BERTw/CRF 110 82.1±2.0 56.0±0.8 19.2±1.1 31.7±1.9 19.7±2.6
RoBERTaw/CRF 124 83.3±1.6 57.0±0.6 18.2±1.2 34.5±1.3 27.7±3.9
Table 4: Test set performance of the sequence tagging models on PolicyIE corpus. </Abstractive Summary> <Extractive Summary> Table 1 ment for the two categories of slots individually.  </Extractive Summary>  </Table 1>  </Paper ID = 341>


<Paper ID = 341> <Table 2> <Abstractive Summary> =4408+[IN:data-collection-usage[SL:data-provider.third-party-entitythirdparties][SL:actioncollect][SL:data-
provider.useryour][SL:data-collected.data-generalinformation][SL:data-collector.ﬁrst-party-entityus]]
− [IN:data-sharing-disclosure [SL:data-receiver.third-party-entity third parties] [SL:action share]
[SL:data-provider.useryour][SL:data-shared.data-generalinformation][SL:data-sharer.ﬁrst-party-entity
us][SL:conditionwhereapplicable][SL:conditionbasedontheirownprivacypolicies]]
Errortypes: WrongIntent(WI),WrongLabel(WL),WrongSlot(WS),SpuriousSlot(SS)
+[...[SL:data-provider.third-party-entitythirdparties][SL:conditionitisallowedbyapplicablelawor
accordingtoyouragreementwiththirdparties]]
−[...[SL:conditionallowedbyapplicablelaworaccordingtoyouragreementwiththirdparties]]
Errortypes: WrongBoundary(WB),MissingSlot(MS)
+[...[SL:data-receiver.third-party-entitysocialmediaandothersimilarplatforms]...]
−[...[SL:data-receiver.third-party-entitysocialmedia][SL:data-receiver.third-party-entityothersimilar
platforms]...]
Errortypes: WrongSplit(WSp)
Table 7: Three examples showing different error types appeared in BART’s predictions. </Abstractive Summary> <Extractive Summary> Data Statistics & Format Table 2 presents the topredictthetargetintentandslotlabels.  </Extractive Summary>  </Table 2>  </Paper ID = 341>


<Paper ID = 341> <Table 3> <Abstractive Summary> =Overall
Table 8: Counts for each error type on the test set of
theerroranalysisalignswithouranticipationthat
PolicyIEusingRoBERTaandBARTmodels. </Abstractive Summary> <Extractive Summary> Table 3 shows an exam-
tiveapproaches;theﬁrstapproachjointlymodels
pleofinputandoutputtotrainthejointintentand
intent classiﬁcation and slot tagging (Chen et al.,
slottaggingmodels.  </Extractive Summary>  </Table 3>  </Paper ID = 341>


<Paper ID = 341> <Table 4> <Abstractive Summary> =4415Label Text
data-holder.ﬁrst-party-entity We
action keep
Groundtruth
data-retained.data-general records
retention-period.retention-period aperiodofnomorethan6years
(cid:51) data-holder.ﬁrst-party-entity We
RoBERTa
(cid:51) action keep
(P:1.0,R:0.75)
(cid:51) retention-period.retention-period aperiodofnomorethan6years
(cid:51) data-holder.ﬁrst-party-entity We
BART
(cid:51) action keep
(P:1.0,R:1.0)
(cid:51) data-retained.data-general records
(cid:51) retention-period.retention-period aperiodofnomorethan6years
data-collector.ﬁrst-party-entity We
Groundtruth action access
data-collected.data-general information
RoBERTa (cid:55) data-sharer.ﬁrst-party-entity We
(P:0.0,R:0.0) (cid:55) data-shared.data-general information
(cid:55) data-sharer.ﬁrst-party-entity We
BART
(cid:55) action disclose
(P:0.0,R:0.0)
(cid:55) data-shared.data-general information
data-sharer.ﬁrst-party-entity MarcoPolo
data-receiver.third-party-entity thirdparty
Groundtruth data-shared.data-general PersonalInformation
data-provider.user users
action transferred
(cid:55) data-receiver.third-party-entity Marco
(cid:55) data-sharer.ﬁrst-party-entity our
RoBERTa
(cid:51) data-receiver.third-party-entity thirdparty
(P:0.6,R:0.6)
(cid:51) data-shared.data-general PersonalInformation
(cid:51) action transferred
(cid:51) data-sharer.ﬁrst-party-entity MarcoPolo
(cid:51) data-receiver.third-party-entity thirdparty
BART (cid:51) data-shared.data-general PersonalInformation
(P:0.83,R:1.0) (cid:55) data-sharer.ﬁrst-party-entity us
(cid:51) data-provider.user users
(cid:51) action transferred
data-sharer.ﬁrst-party-entity We
data-receiver.third-party-entity thirdparties
Groundtruth
action provide
data-shared.data-general information
(cid:51) data-sharer.ﬁrst-party-entity We
RoBERTa (cid:51) data-receiver.third-party-entity thirdparties
(P:1.0,R:1.0) (cid:51) action provide
(cid:51) data-shared.data-general information
(cid:55) data-collector.ﬁrst-party-entity We
BART (cid:55) data-provider.third-party-entity thirdparties
(P:0.25,R:0.25) (cid:51) action provide
(cid:55) data-collected.data-general information
Table 11: Sample RoBERTa and BART predictions of Type-I slots. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 4>  </Paper ID = 341>


<Paper ID = 341> <Table 5> <Abstractive Summary> =4416[Label]condition
Groundtruth
[Text]youuseourproductandserviceorviewthecontentprovidedbyus
RoBERTa [Label]condition
(cid:51)
(P:1.0,R:1.0) [Text]youuseourproductandserviceorviewthecontentprovidedbyus
BART [Label]condition
(cid:51)
(P:1.0,R:1.0) [Text]youuseourproductandserviceorviewthecontentprovidedbyus
[Label]purpose.other
[Text]theirownpurposes
Groundtruth
[Label]purpose.advertising-marketing
[Text]informadvertisingrelatedservicesprovidedtootherclients
RoBERTa [Label]None
(cid:55)
(P:0.0,R:0.0) [Text]None
[Label]purpose.other
(cid:51)
BART [Text]theirownpurposes
(P:1.0,R:1.0) [Label]purpose.advertising-marketing
(cid:51)
[Text]informadvertisingrelatedservicesprovidedtootherclients
[Label]purpose.personalization-customization
[Text]providemoretailoredservicesanduserexperiences
[Label]purpose.basic-service-feature
[Text]rememberingyouraccountidentity
[Label]purpose.service-operation-and-security
Groundtruth
[Text]analyzingyouraccount’ssecurity
[Label]purpose.analytics-research
[Text]analyzingyourusageofourproductandservice
[Label]purpose.advertising-marketing
[Text]advertisementoptimization(helpingustoprovideyouwithmoretargetedadvertisements
insteadofgeneraladvertisementsbasedonyourinformation)
[Label]purpose.basic-service-feature
(cid:55)
[Text]provide
[Label]purpose.other
(cid:55)
[Text]purposes
[Label]purpose.analytics-research
(cid:55)
RoBERTa [Text]rememberingyouraccountidentity
(P:0.17,R:0.2) [Label]purpose.analytics-research
(cid:55)
[Text]analyzingyouraccount’ssecurity
[Label]purpose.analytics-research
(cid:51)
[Text]analyzingyourusageofourproductandservice
[Label]purpose.advertising-marketing
(cid:55)
[Text]advertisementoptimization
[Label]purpose.personalization-customization
(cid:51)
[Text]providemoretailoredservicesanduserexperiences
[Label]purpose.service-operation-and-security
(cid:55)
[Text]rememberingyouraccountidentity
[Label]purpose.service-operation-and-security
(cid:51)
[Text]analyzingyouraccount’ssecurity
BART [Label]purpose.analytics-research
(cid:51)
(P:0.43,R:0.6) [Text]analyzingyourusageofourproductandservice
[Label]purpose.advertising-marketing
(cid:55)
[Text]advertisementoptimization
[Label]purpose.advertising-marketing
(cid:55)
[Text]provideyouwithmoretargetedadvertisementsinsteadofgeneraladvertisements
[Label]purpose.advertising-marketing
(cid:55)
[Text]basedonyourinformation
Table 12: Sample RoBERTa and BART predictions of Type-II slots. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 5>  </Paper ID = 341>


<Paper ID = 342> <Table 0> <Abstractive Summary> =JGA/F1
Table 1: Dataset descriptions and statistics. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 342>


<Paper ID = 344> <Table 0> <Abstractive Summary> =Table 2: Evaluation results on the test set of
CMU DoG. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 344>


<Paper ID = 344> <Table 1> <Abstractive Summary> =Table 4: The performance of knowledge selection on
PerformanceofKnowledgeSelection. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 344>


<Paper ID = 344> <Table 2> <Abstractive Summary> =focus on the movie domain while our train data Then, we remove each training task individ-
includingad-hocretrievalcorporaandmulti-turn ually from PTKGC , and denote the models
sep
4453Models R@1WizRar@d2SeenR@5 R@W1izaRrd@U2nseeRn@5 00..8990 SUenesenen 0.8850.8870.8890.8910.8920.8930.8940.8950.895
0.882
PTKGCsep(q+h) 84.9 93.9 97.8 64.9 81.7 94.3 0.88 0.8750.877
PTKGCsep(q+h)-Lh 84.1 93.7 97.7 64.3 81.9 93.8 0.87 0.869
PTKGCsep(q+h)-Lp 83.4 93.5 97.9 60.9 80.2 93.5 0.864
PTKGCsep(q+h)-Lh-Lp 83.2 93.8 97.6 60.9 80.1 93.8 0.86 0.856
@1 0.85
Table 5: Ablation study of our model without R100 0.70 0.6960.696
consideringthegroundedknowledge. </Abstractive Summary> <Extractive Summary> Table 1
selection; 2) BoW MemNet (Dinan et al., 2019) and Table 2 report the evaluation results of re-
isamemorynetworkwhereknowledgeentriesare sponseselectiononWoWandCMU DoGwhere
embeddedviabag-of-wordsrepresentation,andthe PTKGC and PTKGC represent the ﬁnal
cat sep
modellearnstheknowledgeselectionandresponse matching score computed with the ﬁrst strategy
matchingjointly;3)TransformerMemNet(Dinan (Equation 9) and the second strategy (Equation
et al., 2019) is an extension of BoW MemNet, 10) respectively.  </Extractive Summary>  </Table 2>  </Paper ID = 344>


<Paper ID = 344> <Table 3> <Abstractive Summary> =50% 91.5 97.1 99.3 73.9 87.9 96.9
The CMU DoG data contains knowledge- 100% 92.2 97.6 99.4 74.3 88.1 97.1
groundedhuman-humanconversationswherethe
Table 7: Evaluation results of our model in the low-
underlying knowledge comes from wiki articles
resourcesettingontheWizardofWikipediadata. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 344>


<Paper ID = 345> <Table 0> <Abstractive Summary> =andxj.Forexample,ifti,jisnsubj,thentj,iis#nsubj.xj,respectively,whicharecomputedby ACE05 SEMEVAL
s(il)=h(il 1) eti,j (4) #INSTANCES TDREAVIN 4181,,189584 8,000-
and TEST 10,097 2,717
s(jl)=h(jl 1) eti,j (5) Table 1: The number of unique instances (i.e., entity
pairs)ofACE05andSemEvalbenchmarkdatasets. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 345>


<Paper ID = 345> <Table 1> <Abstractive Summary> =Hyper-parameters Values
LearningRate 5e 6,1e 5,2e 5,3e 5
       
WarmupRate 0.06,0.1
DropoutRate 0.1
BatchSize 16,32,64,128
Table 6: The hyper-parameters tested in tuning our
models. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 345>


<Paper ID = 345> <Table 2> <Abstractive Summary> =Speed
BERT-base 109M 27.7 109M 54.7 BERT-large 335M 8.9 335M 17.1
+GAT(Full) 110M 26.2 110M 51.8 +GAT(Full) 337M 8.4 337M 16.7
+GAT(L+G) 110M 26.2 110M 51.8 +GAT(L+G) 337M 8.4 337M 16.7
+1GCNlayer(Full) 110M 26.4 110M 52.2 +1GCNlayer(Full) 337M 8.6 337M 16.9
+1A-GCNlayer(Full) 110M 25.1 110M 50.4 +1A-GCNlayer(Full) 337M 8.1 337M 16.6
+1GCNlayer(L+G) 110M 26.4 110M 52.2 +1GCNlayer(L+G) 337M 8.6 337M 16.9
+1A-GCNlayer(L+G) 110M 25.1 110M 50.4 +1A-GCNlayer(L+G) 337M 8.1 337M 16.6
+2GCNlayers(Full) 111M 24.8 111M 49.9 +2GCNlayers(Full) 338M 8.0 338M 16.3
+2A-GCNlayers(Full) 111M 24.1 111M 48.7 +2A-GCNlayers(Full) 338M 7.8 338M 16.1
+2GCNlayers(L+G) 111M 24.8 111M 49.9 +2GCNlayers(L+G) 338M 8.0 338M 16.3
+2A-GCNlayers(L+G) 111M 24.1 111M 48.7 +2A-GCNlayers(L+G) 338M 7.8 338M 16.1
+3GCNlayers(Full) 112M 23.1 112M 47.9 +3GCNlayers(Full) 339M 7.4 339M 15.8
+3A-GCNlayers(Full) 112M 23.0 112M 47.2 +3A-GCNlayers(Full) 339M 7.2 339M 15.5
+3GCNlayers(L+G) 112M 23.1 112M 47.9 +3GCNlayers(L+G) 339M 7.4 339M 15.8
+3A-GCNlayers(L+G) 112M 23.0 112M 47.2 +3A-GCNlayers(L+G) 339M 7.2 339M 15.5
(a)BERT-base (b)BERT-large
Table 7: Numbers of trainable parameters (Para.) </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 345>


<Paper ID = 345> <Table 3> <Abstractive Summary> =Models BERT-base BERT-Large
Baseline 75.03 76.11
GAT(Full) 75.33 76.87
GAT(L+G) 75.31 76.93
+1GCNlayer(Full) 74.97 76.13
+1A-GCNlayer(Full) 76.49 77.33
+1GCNlayer(L+G) 75.80 77.19
+1A-GCNlayer(L+G) 76.00 77.49
+2GCNlayers(Full) 75.36 77.35
+2A-GCNlayers(Full) 76.65 77.55
+2GCNlayers(L+G) 76.59 77.48
+2A-GCNlayers(L+G) 76.90 77.82
+3GCNlayers(Full) 75.61 77.33
+3A-GCNlayers(Full) 76.45 77.54
+3GCNlayers(L+G) 76.48 77.36
+3A-GCNlayers(L+G) 76.58 77.65
Table 8: F1 scores of our A-GCN models and the
baselines(i.e.,BERT-only,standardGAT,andstandard
GCN) under different settings with BERT-base and
BERT-largeonthedevelopmentsetofACE2005. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 345>


<Paper ID = 346> <Table 0> <Abstractive Summary> =AaronTippin Her (song)
Table 1: Examples of QA AmbER sets. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 346>


<Paper ID = 346> <Table 1> <Abstractive Summary> =screenwriter(P58) 0.21
WrittenWork author(P50) 7.43
Collecting Distinguishing Properties We
gather properties and associated values for each
Table 3: Distinguishing Properties selected to create
entity from Wikidata. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 346>


<Paper ID = 346> <Table 2> <Abstractive Summary> =FC SF QA
Head Tail Head Tail Head Tail
TF-IDF 19.5 67.5 28.2 75.7 27.9 76.1
DPR 1.2 10.0 2.3 23.8 2.6 27.0
H*
BLINK 9.8 32.2 14.0 58.2 4.4 27.6
Bootleg 6.2 24.7 9.3 30.5 3.7 28.7
TF-IDF 10.1 49.9 22.0 76.9 23.0 76.8
DPR 6.2 32.2 9.1 48.3 8.7 44.0
N*
BLINK 5.8 22.8 5.1 32.2 5.5 31.9
Bootleg 7.7 26.1 16.1 36.2 7.8 31.6
*HrepresentsAmbER-HandNrepresentsAmbER-N.
Table 6: Entity confusion measures the % of queries
the gold document ranks worse (lower) than a docu-
ment for another entity with the same name (i.e., an-
other entity in the AmbER set). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 346>


<Paper ID = 346> <Table 3> <Abstractive Summary> =Results for QA AmbER sets (Figure 4)
Table 7: End-to-end performance on AmbER sets. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 346>


<Paper ID = 346> <Table 4> <Abstractive Summary> =Thisproblemhasbeenstudiedextensively
Human 100 78.8 97.9 77.5 in the recommendation systems literature, where
recommendationsystemsareknowntooftenignore
Table 8: User study on AmbER QA. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 4>  </Paper ID = 346>


<Paper ID = 348> <Table 0> <Abstractive Summary> =Weem- Table 2: Claim-like statements. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 348>


<Paper ID = 348> <Table 1> <Abstractive Summary> =4509Table 4: MRR across different models and languages. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 348>


<Paper ID = 348> <Table 2> <Abstractive Summary> =All 0.63±0.05 0.60±0.05 0.76±0.05
(0.88) (0.82) (0.82)
Bengali 0.63±0.09 0.65±0.11 0.67±0.12
(0.87) (0.72) (0.79)
English 0.90±0.09 0.81±0.12 0.95±0.08
(0.85) (0.77) (0.78)
Hindi 0.82±0.09 0.64±0.11 0.82±0.09
(0.88) (0.77) (0.82)
Malayalam 0.52±0.21 0.62±0.17 0.76±0.16
(0.92) (0.85) (0.85)
Tamil 0.42±0.16 0.54±0.18 0.68±0.13
(0.89) (0.84) (0.82)
Table 8: Label distribution for the claim matching dataset: VS is very similar, SS is somewhat similar, SD is
somewhat dissimilar and VD is very dissimilar. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 348>


<Paper ID = 35> <Table 0> <Abstractive Summary> =Overall Grammar Redundancy
Method
r ρ τ r ρ τ r ρ τ
TF-IDF 0.264 0.249 0.187 0.186 0.170 0.127 0.281 0.253 0.187
JS 0.265 0.232 0.174 0.210 0.180 0.136 0.317 0.278 0.208
REAPER 0.036 0.032 0.024 0.004 -0.006 -0.005 -0.020 -0.031 -0.024
LSScore(Wuetal.,2020) − 0.334 − − 0.266 − − 0.288 −
Ours(F1)-All 0.390 0.370 0.281 0.306 0.306 0.232 0.413 0.381 0.287
Ours(Fβ)-All 0.361 0.337 0.255 0.273 0.270 0.204 0.395 0.356 0.268
ROUGE-1-PacSumTopM 0.224 0.215 0.159 0.126 0.114 0.084 0.289 0.254 0.186
ROUGE-2-PacSumTopM 0.347 0.335 0.253 0.254 0.240 0.181 0.398 0.369 0.274
ROUGE-L-PacSumTopM 0.235 0.224 0.166 0.135 0.122 0.090 0.300 0.264 0.193
MoverScore-PacSumTopM 0.373 0.341 0.259 0.264 0.240 0.181 0.411 0.359 0.267
S+WMS-PacSumTopM 0.324 0.353 0.267 0.240 0.256 0.193 0.360 0.385 0.286
C-ELMO-PacSumTopM 0.355 0.297 0.223 0.232 0.201 0.151 0.425 0.354 0.262
C-SBERT-PacSumTopM 0.405 0.378 0.286 0.295 0.299 0.225 0.415 0.373 0.279
SUPERT-PacSumTopM 0.384 0.374 0.284 0.318 0.317 0.240 0.381 0.369 0.277
SUPERT-IDF-PacSumTopM 0.382 0.373 0.283 0.316 0.314 0.238 0.377 0.365 0.274
Ours(F1)-PacSumTopM 0.416 0.404 0.308 0.341 0.341 0.259 0.428 0.408 0.308
Ours(Fβ)-PacSumTopM 0.400 0.381 0.290 0.314 0.311 0.235 0.427 0.395 0.298
Table 3: Main results on single-document summarization dataset (CNNDM). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 35>


<Paper ID = 350> <Table 0> <Abstractive Summary> =(2020),whichwerefertoasNCE-EBR.Next,
4532we have Shared-EBR that trains single Marginal- Table 3: The effect of using gold data in the ranking
objectiveforMarginal-EBR. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 350>


<Paper ID = 350> <Table 1> <Abstractive Summary> =Forthismethod,we
De→En 35.68 35.00 34.20 33.75
ﬁrst sample a translation task and then sample a
Fr→En 33.77 33.15 31.65 30.82
batchfromthattaskandfollowAlgorithm1forthe
trainingoftheMarginal-EBM.Finally,asanupper
Table 4: Effect of Entropy Regularization on
boundforthebestachievableresult,wealsoextract
IWSLT’14DE-EN
thetranslationsfromthesamplethatareclosestto
thegolddata(basedonBLEUscore). </Abstractive Summary> <Extractive Summary> Regularization NoRegularization
BaseNMT+Beam 33.96 33.87
4.6 Results Conditional-EBR 37.88 37.58
Oracle 68.21 67.54
Table 1 shows the performance of the described
methods for IWSLT, FLoRes, and WMT transla-
tion tasks.3 BaseNMT+Sample achieves a bet-
duetotheuseofJoint-EBMmodel,whichenables
ter score than beam decoding suggesting that
the model to deﬁne different energy landscapes
our multinomial sampling supports the modes of
fordifferentsourcesentences.  </Extractive Summary>  </Table 1>  </Paper ID = 350>


<Paper ID = 350> <Table 2> <Abstractive Summary> =Table 6: Typical examples on IWSLT’14 test set, cat-
two separate BERT models for source and target
egorized by the difference between BaseNMT and
languages,increasingthenumberofparametersby Marginal-EBR. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 350>


<Paper ID = 351> <Table 0> <Abstractive Summary> =4543s /s en de es fr ja ko zh q/c en es de ar hi vi zh
1 2
en - 0.7 1.6 1.4 4.7 2.5 5.4 en - -0.2 0.3 0.4 0.9 0.6 1.1
de 0.5 - 2.0 2.1 5.1 3.5 5.9 es 4.1 - 3.5 5.4 5.3 7.3 7.6
es 1.0 2.1 - 1.7 4.6 3.0 6.6 de 3.5 2.8 - 4.0 2.9 4.0 5.0
fr 0.9 1.7 1.9 - 5.0 2.7 5.4 de 1.8 2.4 1.1 - -0.1 6.2 4.4
ja 5.2 5.3 5.6 5.1 - 5.9 5.1 hi 1.0 1.8 0.5 0.2 - -0.6 1.0
ko 3.1 2.8 4.3 3.9 6.4 - 5.1 vi 5.6 4.5 5.5 6.9 4.2 - 5.5
zh 5.8 5.5 6.3 6.0 6.1 4.5 - zh 3.8 3.3 4.4 2.4 0.9 5.4 -
(a)PAWS-X (b)MLQA
Table 3: The performance difference between syntax-augmented mBERT and mBERT in the generalized cross-
lingual transfer setting. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 351>


<Paper ID = 351> <Table 1> <Abstractive Summary> =14.2 11.3 15.7 16.9 23.5 22.1 49.9 59.2
Table 7: The cross-lingual transfer gap of mBERT and syntax-augmented mBERT on the evaluation tasks. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 351>


<Paper ID = 351> <Table 2> <Abstractive Summary> =4552p/h en fr es de ru el bg ar tr hi ur vi zh
en - 70.1 70.1 66.2 64.8 57.3 61.8 59.1 53.8 53.5 51.2 64.4 65.2
fr 72.5 - 69 63.9 63.2 56.5 60.2 58.6 52.5 52.1 49.9 62.4 61.3
es 72.5 68.6 - 63 63.7 57.7 60.8 59.1 52.6 51.5 48.5 61.5 60.9
de 71.1 65.7 65.1 - 63.1 56.1 60 58 52.8 53.2 50.6 60.3 60.5
ru 69.3 64.5 65.5 62.5 - 55.9 62.7 57 51 51.2 48.2 58.8 58.5
el 63 59.8 61 57.5 56.9 - 56.9 55.9 50.6 49.8 47.8 56.6 54.7
bg 68.4 63 64.6 61.2 64 57 - 57.4 51 52.5 48.1 58.8 59.1
ar 63.7 59.2 59.9 56.6 55.8 53.5 54.2 - 50.1 50.9 49.7 55.8 55.5
tr 60 55.2 54.9 53.9 51.9 51.7 52.5 53.2 - 50.4 48.4 53.3 53.7
hi 61.1 55 54.7 54.7 53.7 52 52.3 53.7 50 - 53.2 54 53.7
ur 59.9 55.1 54.1 53.5 50.7 49.9 49 52.9 48.6 54.6 - 50.7 52.6
vi 65.9 60.2 59.3 56.3 55.5 53.2 52.7 54.2 47.8 49.7 46.8 - 62.3
zh 66.8 58.9 58.4 56.1 54.8 50.9 53.4 54.5 48.8 49.4 47.2 61.5 -
Table 9: Generalized cross-lingual transfer performance of syntax-augmented mBERT on XNLI. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 351>


<Paper ID = 352> <Table 0> <Abstractive Summary> =We sco Scots Latin Indo-European NER
tat Tatar Cyrillic Turkic NER
furtherobservethatinoursettingthesimplestadap- tgk Tajik Cyrillic Indo-Iranian NER
war Waray Latin Austronesian NER
tationmethod,continuedpretraining,performsbest
wol Wolof Latin Niger-Congo Both
forbothtasks,achievinggainsofupto17.69%ac- yor Yoruba Latin Niger-Congo Both
curacyforPOStagging,and6.29F1forNERon
Table 1: Languages used in our experiments, none of
averageacrosslanguages. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 352>


<Paper ID = 352> <Table 1> <Abstractive Summary> =WhileRussianisnotnecessarily
+Adapters 41.88 41.15 71.74 51.59
similartothetargetlanguagesormutuallyintelligi-
+MLM 61.19 55.89 67.42 61.50
ble,weconsiderittobemoresimilarthanEnglish;
W-R +Extend 36.84 44.08 35.46 38.79
Russianiswritteninthesamescriptasthetarget +Adapters 56.39 28.65 73.12 52.72
languages,andthereisagreaterlikelihoodforlexi-
Table 4: Case study: Cyrillic NER (F1). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 352>


<Paper ID = 353> <Table 0> <Abstractive Summary> =Then,
Table 1: Boundary detection performance from our
weﬁlteroutlow-conﬁdencepseudolabelsbycon-
methodandparsingbasednounphrases. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 353>


<Paper ID = 353> <Table 1> <Abstractive Summary> =We
alsonoticethatsomespans(e.g.“HITtypeII”)and
Table 4: Performance on the BC5CDR dataset with
theirsub-spans(e.g.“HIT”)arebothdiseaseenti-
threedifferentruleselectionstrategies. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 353>


<Paper ID = 354> <Table 0> <Abstractive Summary> =i θ
When i ∈ P , this is clear because h copies
idx i Table 1: Datasets statistics. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 354>


<Paper ID = 354> <Table 1> <Abstractive Summary> =4595E2E WebNLG DART
BLEU NIST MET R-L CIDEr BLEU MET TER↓ BLEU MET TER↓ Mover BERT BLEURT
GPT-2
MEDIUM
FT-FULL 74.2 8.76 49.3 76.9 2.66 66.03 0.47 0.30 50.46 0.41 0.44 0.52 0.95 0.41
FT-TOP2 72.7 8.51 48.2 75.3 2.60 54.61 0.39 0.47 48.41 0.39 0.48 0.48 0.94 0.33
ADAPTER(3%) 71.7 8.53 48.4 74.6 2.60 60.63 0.43 0.33 48.56 0.40 0.44 0.51 0.95 0.40
ADAPTER(0.1%) 68.1 8.30 45.9 71.4 2.41 53.24 0.40 0.39 44.72 0.38 0.47 0.47 0.94 0.35
PREFIX(0.1%) 74.8 8.80 49.4 76.8 2.69 64.52 0.46 0.32 51.11 0.41 0.43 0.52 0.95 0.42
GPT-2
LARGE
FT-FULL 72.1 8.62 48.5 75.1 2.56 64.69 0.46 0.31 51.00 0.41 0.44 0.52 0.95 0.43
Preﬁx 74.8 8.81 49.5 77.0 2.72 64.11 0.46 0.33 50.84 0.41 0.43 0.52 0.95 0.42
Table 9: Metrics on the development set (higher is better, except for TER) for table-to-text generation on E2E
(left),WebNLG(middle)andDART(right). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 354>


<Paper ID = 355> <Table 0> <Abstractive Summary> =Speciﬁcally, we ﬁrst separate the
Krapivin 400 5.83 2.21 44.33
controlcodesintotwoﬁxedsetswithequalsizeof SemEval 100 14.43 2.38 55.61
N/2,whichisdenotedasC andC ,andthetarget KP20k 20,000 5.26 2.04 37.23
1 2
keyphrase set Y into present target keyphrase set
Table 1: Statistics of the testing set on ﬁve datasets. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 355>


<Paper ID = 355> <Table 1> <Abstractive Summary> =Incontrast,ourmodelachieves
4603Krapivin SemEval KP20k Present Absent
Model Model Dup
#PK #AK Dup #PK #AK Dup #PK #AK Dup F1@5 F1@M #PK F1@5 F1@M #AK
Oracle 3.24 2.59 - 6.12 8.31 - 3.31 1.95 - Oracle - - 3.31 - - 1.95 -
catSeq 3.50 0.67 0.46 3.48 0.77 0.53 3.71 0.55 0.39 SETTRANS 0.358 0.392 5.10 0.036 0.058 2.01 0.08
catSeqTG 3.82 0.83 0.41 3.82 1.09 0.63 3.77 0.67 0.36 ModelArchitecture
catSeqTG-2RF1 3.28 1.56 0.29 3.57 1.50 0.25 3.55 1.44 0.28 -controlcodes 0.001 0.002 0.01 0.000 0.000 0.00 0.95
ExHiRD-h 4.41 1.02 0.14 3.65 0.99 0.09 3.97 0.81 0.11 TargetAssignment
Transformer 4.44 1.39 0.29 4.30 1.52 0.27 4.64 1.16 0.26 -K-stepassign 0.265 0.381 2.64 0.020 0.045 0.81 0.26
SETTRANS 4.83 2.20 0.08 4.62 2.18 0.08 5.10 2.01 0.08 +randomassign 0.005 0.010 1.05 0.001 0.002 0.04 0.95
SetLoss
Table 4: Number and duplication ratio of predicted -teacherforcing 0.001 0.002 0.01 0.000 0.000 0.00 0.89
-separatesetloss 0.355 0.383 5.31 0.016 0.031 0.55 0.05
keyphrases on three datasets. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 355>


<Paper ID = 355> <Table 2> <Abstractive Summary> =“#PK” and “#AK” are
the average number of unique present and absent
Table 5: Ablation study of SETTRANS on KP20k
keyphrases respectively. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 355>


<Paper ID = 356> <Table 0> <Abstractive Summary> =Table 1: Data samples generated by our ﬂow models. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 356>


<Paper ID = 356> <Table 1> <Abstractive Summary> =Table 3: Sample context generation results: we show two examples that are ﬁltered as positive. </Abstractive Summary> <Extractive Summary> See sample outputs
(2017),weuseamulti-scalearchitecture(seeFig-
in Table 1 for comparison to those from the non-
ure 2) that contains multiple blocks while each
autoregressivemodel.  </Extractive Summary>  </Table 1>  </Paper ID = 356>


<Paper ID = 356> <Table 2> <Abstractive Summary> =Note that we do not claim the autore-
Models Lang-Flow FlowSeq Tie
gressivemodelisbetteratdensityestimationthan
the non-autoregressive version, instead, we aim HumanEval2 98 50 52
to show that it can perform reasonably with the
Table 5: TVQA-QG Evaluation: comparison between
proposedautoregressiveadaptation. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 356>


<Paper ID = 356> <Table 3> <Abstractive Summary> =+Context(LanguageFlow+) 82.49 89.44
Models Valid-Accuracy
Table 9: QA results on SQuAD test split. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 356>


<Paper ID = 356> <Table 4> <Abstractive Summary> =+Context(Paraphrasing) 69.98
+Context(LanguageFlow) 70.45
+Context(LanguageFlow+) 70.86
the inverted version of its encoder with the same
weights, so it ensures the decoder uses the latent
Table 8: QA results on TVQA dev split. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 4>  </Paper ID = 356>


<Paper ID = 357> <Table 0> <Abstractive Summary> =We remove
all hyperlinks and graphics in contents, split the • HierSumm (Liu and Lapata, 2019) utilizes
contents into paragraphs with the spaCy library, the attention mechanism to model inter-
4628Domain #Examples R1-r R2-r RL-r #Topics Train Valid Test
Company 62,545 .551 .217 .438 4 35,506 1,999 2,212
Film 59,973 .559 .243 .456 5 187,221 10,801 10,085
Animal 60,816 .541 .208 .455 4 51,009 2,897 2,876
Table 1: Details about used datasets. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 357>


<Paper ID = 357> <Table 1> <Abstractive Summary> =Table 3: Comparison between Wikipedia abstracts generated by different models about the ﬁlm Majina There. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 357>


<Paper ID = 357> <Table 2> <Abstractive Summary> =4630Company Film Animal
Model
Score Non-0 Score Non-0 Score Non-0
TF-S2S .075 .694 .000 .000 .000 .000
CV-S2D+T .237 .660 .040 .143 .382 .576
HierSumm .255 .896 .213 .327 .000 .000
BART .591 .813 .452 .796 .342 .653
TWAG(ours) .665 .903 .669 .918 .543 .868
Table 6: Human evaluation results in QA scheme. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 357>


<Paper ID = 358> <Table 0> <Abstractive Summary> =introducesanoveltimestampconstraintperques-
Table 1: Chain of reasoning. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 358>


<Paper ID = 358> <Table 1> <Abstractive Summary> =4641Accuracy(%,↑) Brierscore(↓) Methods GRU Maxpool MDS
Methods/Metrics
yes/no multi all yes/no multi all
BERTBASE,TF-IDF 53.2 53.9 51.6
Random 48.6 25.3 37.8 0.684 0.827 0.750 BERTBASE,DPR 53.7 54.6 54.3
ESIM-ELMo(closed-book) 63.3 45.8 54.5 0.515 0.897 0.706 BERTBASE,BM25 55.4 54.2 52.0
BERTBASE(closed-book) 66.2 41.5 54.7 0.511 0.715 0.606
BERTLARGE(closed-book) 67.3 45.4 57.6 0.447 0.653 0.543 BERTLARGE,TF-IDF 56.5 55.4 55.0
BIDAF++(ClarkandGardner,2018) 51.7 30.1 40.9 0.478 0.898 0.688 BERTLARGE,DPR 56.1 59.4 54.6
BERTBASE,MDS 63.1 39.1 52.0 0.504 0.716 0.603 BERTLARGE,BM25 59.1 58.6 54.7
BERTBASE,AGG(Maxpool) 67.2 39.1 54.2 0.453 0.701 0.568
BERTBASE,AGG(GRU) 67.6 41.5 55.4 0.477 0.705 0.583 Table 4: Accuracy with different retrievers: BM25, TF-
SAM-Net(Lvetal.,2019) 64.5 40.9 53.5 0.531 0.719 0.619
IDF,anddensepassageretrieval(DPR).Wetesttheretrievers
BERTLARGE,MDS 67.4 40.1 54.7 0.542 0.738 0.633
BERTLARGE,Eventtriples 66.7 45.0 56.6 0.589 0.719 0.649 withdifferentaggregators:GRU,Maxpool,andMDS. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 358>


<Paper ID = 358> <Table 2> <Abstractive Summary> =Given
Table 3: Performance of baseline models on FORE- thissetup,humansachieve71.2%and79.4%accu-
CASTQAtestset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 358>


<Paper ID = 358> <Table 3> <Abstractive Summary> =Whengiventhegoldarticle,BERT
Evidencesentence 79.9 89.5 84.4 0.355 0.171 0.269 achieves76.9%(+22%)anditevenperformsbet-
Table 6: Answerability study on test set. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 358>


<Paper ID = 358> <Table 4> <Abstractive Summary> =Table 10: Results on different pre-trained language
(10/29/18)In the gray, cinder-blocked visitors' locker room far beneath 
models,BERT,RoBERTa,ALBERT). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 4>  </Paper ID = 358>


<Paper ID = 358> <Table 5> <Abstractive Summary> =BERTLARGE,AGG(GRU) 69.2 47.5 59.1 0.483 0.655 0.563
BERTLARGE,GRU(A),QC 67.8 42.5 56.0 0.583 0.758 0.665 Bold choices are actual answers and red choices are
Table 11: Performance of baseline models on FORE- modelpredictions. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 5>  </Paper ID = 358>


<Paper ID = 358> <Table 6> <Abstractive Summary> =Table 12: Results on gold articles on the dev set. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 6>  </Paper ID = 358>


<Paper ID = 359> <Table 0> <Abstractive Summary> =SemEvalCQA
TrecQA WikiQA YahooCQA
Representation 2015 2016-2017
MAP MRR MAP MRR MAP MRR MAP MRR MAP MRR
SemanticOnly 0.932 0.958 0.892 0.901 0.929 0.929 0.947 0.959 0.911 0.950
Semantic+Syntactic 0.946 0.961 0.898 0.912 0.933 0.933 0.945 0.962 0.914 0.957
Table 3: Ablation study on syntactic representations: Results for our Tree Aggregation Transformer with and
withoutlearnedsyntacticembeddingsforallofourbenchmarkdevsets,onRoBERTaLarge. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 359>


<Paper ID = 359> <Table 1> <Abstractive Summary> =SemEval Spearman’sρ
ProbingTask Representation TrecQA WikiQA YahooCQA
2015 2016 2017 MAP MRR
TopConstituent Tree-Structured 0.1573 0.1949 0.0354 0.2058 0.0674 0.1151
0.8214 0.9550
Prediction(F1score) Sequential 0.0475 0.0463 0.0364 0.0434 0.0505 0.0483
TreeDepth Tree-Structured 0.1568 0.1638 0.0354 0.1682 0.0621 0.1340
0.8214 0.9550
Prediction(F1score) Sequential 0.0481 0.0476 0.0354 0.0451 0.0523 0.0481
InputLength Tree-Structured 0.0266 0.0273 4.51e-06 0.0652 0.0989 0.0416
-0.0360 0.1429
Regression(MSE) Sequential 0.0822 0.1200 4.14e-06 0.2915 0.3338 0.1484
Table 6: Results for three probing tasks comparing sequential (Laskar et al., 2020) and tree-structured (ours)
representations. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 359>


<Paper ID = 36> <Table 0> <Abstractive Summary> =3https://www.fandom.com/
417Entitysource Train Dev Test Metrics R-1 R-2 R-L METEOR
Wikipedia Distant 21,267 2,659 2,659 IAA 45.8 36.1 47.7 23.3
(Wikilinks+Realnews) Veriﬁed - 299 299
Distant 9,092 1,137 1,137
Fandom Table 4: Inter-annotator agreement (IAA) for human-
Veriﬁed - 202 201
authoreddescriptions. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 36>


<Paper ID = 36> <Table 1> <Abstractive Summary> =Extradetails
Wikipedia 34.7 17.8 35.8 Wikipedia 29 16 22
Fandom 45.6 27.8 44.5 Fandom 32 15 26
Table 5: Rouge results on human reference against Table 6: Number of times a human-authored de-
Wikipedia/Fandomdescriptions. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 36>


<Paper ID = 36> <Table 2> <Abstractive Summary> =The human baseline is superior to all the mod-
Table 8: Unigram (Uni.) </Abstractive Summary> <Extractive Summary> Wealso
carefully annotate a subset of 1,000 examples to
• We present a two-stage method and bench-
support more reliable evaluation (see Table 2 for
mark various models on our dataset, aiming
datasetstatistics).  </Extractive Summary>  </Table 2>  </Paper ID = 36>


<Paper ID = 36> <Table 3> <Abstractive Summary> =Informativeness 3.5 3.2 3.1
Faithfulness 2.7 2.5 2.6
Table 9: Manual evaluation scores on a scale from 1
(very poor) to 5 (very high). </Abstractive Summary> <Extractive Summary> Each
Table 3 shows basic statistics of the ﬁnal dataset.  </Extractive Summary>  </Table 3>  </Paper ID = 36>


<Paper ID = 36> <Table 4> <Abstractive Summary> =Company 21.4
MARGE
CarlMenger(bornJanuary13,1902)wasanAustrian
Table 12: ROUGE-L scores for BERT+BART evalu-
economist. </Abstractive Summary> <Extractive Summary> Tostudythequal-
Table 4 shows high inter-annotator agreement of
ity of distant supervision, we manually analyze
47.7intermsofROUGE-L.
40 human-authored descriptions that have low n-
Weadditionallymeasuretheagreementoncon-
grams overlap with Wikipedia/Fandom descrip-
tent selection using sentences marked by annota-
tions, in termsofparaphrasing(doesthe human-
tors.  </Extractive Summary>  </Table 4>  </Paper ID = 36>


<Paper ID = 36> <Table 5> <Abstractive Summary> =Table 10: Entity descriptions for Carl Menger gener-
ated by different models. </Abstractive Summary> <Extractive Summary> forentitiesthathaveverydifferenthuman-authored
ROUGE Table 5 shows the averaged ROUGE andextracteddescriptions,mostoftheinformation
scores of human-authored descriptions against intheWikipedia/Fandomdescriptionsispresentin
Wikipedia and Fandom descriptions.  </Extractive Summary>  </Table 5>  </Paper ID = 36>


<Paper ID = 36> <Table 6> <Abstractive Summary> =Table 13: Examples of entity descriptions generated by our model. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 6>  </Paper ID = 36>


<Paper ID = 360> <Table 0> <Abstractive Summary> =ThentheAAccofthewholedatasetis
Table 1: Statistics of 11 sets of BagRel-Wiki73K, computed as AAcc = ((cid:80)n AAcc )/n where n is
where train denotes three sets of train , i
c,(x,y,z) c,x i=1
train ,andtrain . </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 360>


<Paper ID = 360> <Table 1> <Abstractive Summary> =Speciﬁcally,eachbag 2
in train has a valid sentence and a noisy sen- Table 3: Results of models trained on different train
1,0
2 set. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 360>


<Paper ID = 360> <Table 2> <Abstractive Summary> =Table 5: AUC test results of models on BagRel-
Wiki73K, NYT-FB60K and GIDS-FB8K. </Abstractive Summary> <Extractive Summary> NoisePattern
ingmethodsonNYT-FB60Kandhascomparable
From results in Table 2 and Table 3, we can see performanceonGIDS-FB8K.Suchresultdemon-
that the performance of BRE+CE is stable when stratesthatweavoidattentionmechanism’slatent
4669drawbackofhurtingmodel’srobustness.  </Extractive Summary>  </Table 2>  </Paper ID = 360>


<Paper ID = 361> <Table 0> <Abstractive Summary> =(5)Student-GCNisthevariant
1https://nlp.jhu.edu/rams/ wheregraphnodesarebuiltbynamedentitiesex-
4677F i F c NONE ALL-2 ALL-1 ALL FEAE
Teacher∗ 53.03 49.88 F1 c 45.11 45.23 45.98 46.25 47.40
FEAE-multi-cl-kd 49.03 43.06
FEAE-multi-cl 50.35 44.75 Table 3: Argument classiﬁcation study with different
FEAE-multi 52.03 46.25
proportionsofarguments. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 361>


<Paper ID = 361> <Table 1> <Abstractive Summary> =FEAE 53.49 47.40
Table 2: Ablation study on the test set of FEAE. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 361>


<Paper ID = 362> <Table 0> <Abstractive Summary> =T-RExSPO 45.0 45.3 36.6
Generated 46.0 44.6 36.7
4.3 HyperparametersandImplementation
Table 2: The results (%) of entity ranking based on d-
Details
ifferent data sources. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 362>


<Paper ID = 363> <Table 0> <Abstractive Summary> =Table 1: An example of the tag sequence for attribute
“Scent”annotatedwiththeBIOEscheme. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 363>


<Paper ID = 363> <Table 1> <Abstractive Summary> =BiLSTM-CRF-SharedEmb 63.77 72.50 64.62 58.95 60.58 57.66 Variants of “shared components” generally
BiLSTM-MultiCRF 64.48 72.04 64.81 60.64 62.75 59.78
SUOpenTag 63.62 71.67 64.76 61.57 60.48 59.62 achievehigherperformancethantheindependent
AdaTag(RandomAttEmb) 64.80 71.95 65.74 60.14 62.14 60.04
modeling methods (“N models”), which demon-
AdaTag(OurModel) 65.00 75.87 67.48 62.87 62.45 60.87
stratestheusefulnessofenablingknowledgeshar-
Table 4: Performance comparison on test set with 12
ingamongdifferentsubtasks. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 363>


<Paper ID = 363> <Table 2> <Abstractive Summary> =4704A NumberofModelParameters
Methods #Parameters
BiLSTM(Ntagsets) 0.6k·N+6M
BiLSTM-CRF(Ntagsets) 9·N2+0.6k·N+6M
BiLSTM/BiLSTM-CRF(Nmodels) 6M·N
BiLSTM-CRF-SharedEmb 0.1M·N+6M
BiLSTM-MultiCRF 2k·N+6M
AdaTag 8M
Table 8: Numbers of parameters for BiLSTM-based
modelswithNattributes. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 363>


<Paper ID = 364> <Table 0> <Abstractive Summary> =ReVerb+Wikidata 8,447 33,849 182,407
To make use of pseudo parallel data Tp, the
Table 2: Dataset statistics. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 364>


<Paper ID = 364> <Table 1> <Abstractive Summary> =form better than CoRI (without DA), indicating
3https://www.elastic.co/ theeffectivenessofusingtheunmatchedKG.Our
4https://github.com/thunlp/OpenKE retrieval-basedDAoutperformstherandomcoun-
4711Datasets ReVerb+Freebase ReVerb+Wikidata
Prec=0.8 Prec=0.9 Prec=0.95 Prec=0.8 Prec=0.9 Prec=0.95
Metrics AUC AUC
Rec F Rec F Rec F Rec F Rec F Rec F
1 1 1 1 1 1
Translation .571 .590 .679 .100 .180 .067 .125 .604 .595 .683 .088 .160 .042 .080
E-model .205 .014 .027 .010 .020 .005 .010 .214 - - - - - -
Rowless .593 .473 .594 .372 .526 .186 .310 .647 .511 .624 .381 .536 .266 .416
OpenKI .677 .553 .654 .449 .599 .314 .472 .716 .605 .689 .511 .652 .407 .570
CoRI .708 .590 .679 .494 .638 .381 .544 .746 .641 .712 .558 .689 .461 .621
+KGE .711 .597 .684 .514 .654 .418 .581 .763 .662 .725 .596 .717 .520 .672
+DA(random) .734 .616 .696 .518 .658 .395 .558 .774 .678 .734 .606 .724 .521 .673
+DA(retrieval) .748 .636 .708 .539 .674 .421 .583 .780 .685 .738 .613 .729 .529 .680
Table 3: Main experimental results. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 364>


<Paper ID = 365> <Table 0> <Abstractive Summary> =Weimposean
Table 1: Dataset Statistics. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 365>


<Paper ID = 365> <Table 1> <Abstractive Summary> =ExactMatch 90.2 84.1 81.0 85.1 78.8 66.0 54.0 66.3 28.3 64.3 46.4 46.3
OracleWithin-Doc 15.2 46.8 47.1 36.4 16.5 32.8 34.8 28.0 - - - -
GreedyNN
Feature-Based 94.2 89.0 87.3 90.2 83.6 67.0 58.0 69.5 39.6 60.9 52.6 51.0
MLM 75.9 71.1 58.1 68.4 70.8 52.1 42.0 55.0 16.2 53.8 44.8 38.3
BLINK(Wiki) 58.2 56.3 56.6 57.0 59.4 39.2 43.2 47.3 36.6 36.9 40.9 41.6
RELIC(Wiki) 92.4 89.4 83.6 88.5 73.2 56.1 42.4 57.2 36.2 58.1 48.7 47.7
RELIC(In-Domain) 93.2 80.7 84.5 86.1 86.8 69.5 62.4 72.9 28.2 61.4 42.5 44.0
Hybrid 94.7 90.1 88.5 91.1 85.6 70.5 59.9 72.0 44.0 64.5 53.3 54.0
GRINCH
MLM 37.8 59.2 41.5 46.2 70.8 52.1 42.0 55.0 49.0 38.0 33.1 40.0
BLINK(Wiki) 64.3 26.9 23.2 38.1 83.2 17.1 11.9 37.4 45.6 24.8 21.7 30.7
RELIC(Wiki) 91.6 88.3 82.5 87.5 73.9 57.9 42.2 58.0 72.6 4.2 4.3 27.0
RELIC(In-Domain) 82.8 84.0 69.5 78.8 85.4 73.3 61.8 73.5 27.3 57.5 40.1 41.6
Table 2: Unbounded Memory Results. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 365>


<Paper ID = 365> <Table 2> <Abstractive Summary> =Hybrid
Yu-Gi-Oh!-Episode004 ...Yu-Gi-Oh!-Episode004”IntotheHornet’sNest”,known...
Yu-Gi-Oh!ZEXAL-Episode082 ...Yu-Gi-Oh!ZEXAL-Episode082”SphereCubeCalamity:Part1”,known...
Yu-Gi-Oh!Duelist-Duel168 ...Yu-Gi-Oh!Duelist-Duel168”TheWaitingGrave”,alsoknownas”...
Table 10: Most Conﬂated Entities on Zeshel using Greedy NN Clustering. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 365>


<Paper ID = 366> <Table 0> <Abstractive Summary> =In the experiments, itsentitiesareabstractconceptswhichdonotindi-
theembeddingdimensiondforthetwostages,is cateaspeciﬁcentity(e.g.,PRESIDENT,POLICE
4737ICE14 ICEWS05-15 ICE18 GDELT
Model
MRR H@1 H@10 MRR H@1 H@10 MRR H@1 H@10 MRR H@1 H@10
DistMult 24.9 17.3 40.2 16.4 9.8 29.9 17.5 10.1 32.6 15.6 9.3 28.0
ComplEx 31.9 22.2 50.7 23.1 14.5 40.6 18.8 11.1 26.8 12.3 8.0 20.6
RGCN 27.1 18.4 44.2 27.3 19.1 43.6 17.0 8.7 34.0 10.9 4.6 22.6
ConvE 30.9 21.7 50.1 25.2 16.0 44.4 24.8 15.1 44.9 17.3 10.4 31.3
RotatE 27.5 18.0 47.2 19.9 10.9 38.7 15.5 7.0 33.9 5.3 1.2 12.5
MINERVA 33.2 25.7 48.3 30.7 25.8 39.9 21.0 15.3 33.0 12.1 10.0 16.7
Know-Evolve – – – – – – 7.4 3.3 14.8 15.9 11.7 22.3
DyRep – – – – – – 7.8 3.6 16.3 16.3 11.8 23.9
RGCRN 36.9 27.0 56.1 39.4 28.7 60.4 26.2 16.4 45.8 17.7 10.9 30.9
EvolveRGCN 37.1 27.0 57.0 40.7 30.3 61.3 23.6 36.3 50.4 17.4 11.0 29.9
CyGNet 36.5 27.4 54.4 37.4 27.5 56.1 26.8 17.1 45.7 18.0 10.9 31.6
RE-NET 38.9 29.3 57.5 41.7 31.1 62.0 28.4 18.4 47.9 19.0 11.6 33.5
CluSTeR 46.0 33.8 71.2 44.6 34.9 63.0 32.3 20.6 55.9 18.3 11.6 31.9
Table 2: Experimental results on TKG reasoning (in percentage) compared with static models (the top part) and
temporalmodels(thebottompart). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 366>


<Paper ID = 367> <Table 0> <Abstractive Summary> =We make use of the Table 2: Examples of the knowledge in the three con-
high-precisionversiontobuildanewgraphwhich structedknowledgegraphs. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 367>


<Paper ID = 367> <Table 1> <Abstractive Summary> =Theﬁrstfourdimensionswere
4749# Model Relevance Argumentativeness ContentRichness Plausibility Bias
1 GPT-2 1.80 2.23 2.11 2.33 6%
2 ArgData 1.91 2.50 2.10 2.20 13%
3 AB-ArgData 2.00 2.50 2.14 2.34 6%
4 ABC-ArgData 2.10 2.45 2.16 2.27 13%
5 ABC-FullData 1.85 2.26 2.10 2.04 6%
Table 6: Manual evaluation: Average scores between 1 (worst) and 3 (best) for the ﬁrst four dimensions and
proportionofgeneratedargumentsreportedtohavebias. </Abstractive Summary> <Extractive Summary> Forexample,theconceptof“depression sources into sentences and applied the argument
and anxiety problems” will be decomposed into knowledgerelationextractionapproachtoallsen-
“depression”and“anxietyproblems.” tences, obtaining 11,537 and 17,688 relation in-
Table 1 (row A) shows statistics of this argu- stancesfromargs.meandKialo,respectively.  </Extractive Summary>  </Table 1>  </Paper ID = 367>


<Paper ID = 368> <Table 0> <Abstractive Summary> =(2020)∗ 62.70 57.10 59.71 49.62 41.07 44.78 55.63 42.51 47.94 60.95 53.35 56.82
GTS(Wuetal.,2020)∗ 66.13 57.91 61.73 53.35 40.99 46.31 60.10 46.89 52.66 63.28 58.56 60.79
JETo (Xuetal.,2020b)† 61.50 55.13 58.14 53.03 33.89 41.35 64.37 44.33 52.50 70.94 57.00 63.21
M=6
Span-ASTE(Ours) 72.52 62.43 67.08 59.85 45.67 51.80 64.29 52.12 57.56 67.25 61.75 64.37
GTS(Wuetal.,2020)∗ 67.76 67.29 67.50 57.82 51.32 54.36 62.59 57.94 60.15 66.08 69.91 67.93
T
R JETo (Xuetal.,2020b)† 70.56 55.94 62.40 55.39 47.33 51.04 64.45 51.96 57.53 70.42 58.37 63.83
E M=6
B
Span-ASTE(Ours) 72.89 70.89 71.85 63.44 55.84 59.38 62.18 64.45 63.27 69.45 71.17 70.26
Table 2: Results on the test set of the ASTE task. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 368>


<Paper ID = 368> <Table 1> <Abstractive Summary> =This Ours 79.78 88.50 83.89 82.59 90.91 86.54
1
resultindicatesthatourend-to-endapproachcanef-
Table 3: Test results on the ATE and OTE tasks with
fectivelyencodetheinteractionbetweentargetand
BERT encoder. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 368>


<Paper ID = 368> <Table 2> <Abstractive Summary> =thepreviousmodelGTS(Wuetal.,2020)forthe
1
following two settings in Table 4: Single-Word:
Bothtargetandopiniontermsinatripletaresingle-
3.5 AdditionalExperiments
wordspans,Multi-Word: Atleastoneofthetarget
As mentioned in Section 2.2.2, we employ the oropiniontermsinatripletisamulti-wordspan. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 368>


<Paper ID = 368> <Table 3> <Abstractive Summary> =Multi-wordTarget Multi-wordOpinion
Dataset Model P. R. F1 P. R. F1 (%) 60
1
GTS 56.54 49.81 52.96 50.67 41.76 45.78 F
Rest14
Ours 65.96 57.62 61.51 49.43 47.25 48.31
GTS 55.11 44.09 48.99 37.50 26.09 30.77 40
Lap14
Ours 56.99 48.18 52.22 34.62 26.09 29.75
Dual-Channel
GTS 51.09 51.09 51.09 43.40 35.94 39.32 Single-Channel(SC)
Rest15
Ours 55.33 60.58 57.84 37.18 45.31 40.85 SC-Adjusted
20
GTS 62.69 65.12 63.88 28.26 24.07 26.00
Rest16
Ours 66.43 72.09 69.14 36.73 33.33 34.95 0.0625 0.125 0.25 0.50 1.0
Table 5: Further comparison of test results for our
modelandGTSbasedontripletsofmulti-wordtargets
Figure3: Devresultswithrespecttopruningthreshold
andopinionsfortheASTEtask. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 368>


<Paper ID = 368> <Table 4> <Abstractive Summary> =JETo 83.33 68.58 75.24 89.44 80.21 84.57
M=6
Rest16 GTS 82.69 85.62 84.13 83.37 86.53 84.92
Ours 84.20 86.06 85.12 84.62 88.00 86.28
A AdditionalExperimentalSettings
Table 7: Test results on the ATE and OTE tasks with
WerunourmodelexperimentsonaNvidiaTesla
sub-optimalevaluationmethod. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 4>  </Paper ID = 368>


<Paper ID = 368> <Table 5> <Abstractive Summary> =For each input Table 8: Additional comparison of test results on the
textsequence,werestrictittoamaximumof512 ATE and OTE tasks. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 5>  </Paper ID = 368>


<Paper ID = 368> <Table 6> <Abstractive Summary> =Our proposed method However,forreference,Table8showsthecompar-
4765Rest14 Lap14 Rest15 Rest16
Dataset
#Target #Opinion #Target #Opinion #Target #Opinion #Target #Opinion
Train 2051 2086 1281 1268 1862 1941 1198 1307
Dev 1500 1503 1296 1304 1213 1236 1296 1319
Test 1848 1854 1463 1474 1432 1461 1452 1475
Table 9: Additional statistics. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 6>  </Paper ID = 368>


<Paper ID = 369> <Table 0> <Abstractive Summary> =As shown in Figure 8, 9 and 10, the
errorratedoesnotcorrelateswithatomfrequency
Table 7: Statistics of data sources: vocabulary size,
acrossallcompoundlengths. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 369>


<Paper ID = 369> <Table 1> <Abstractive Summary> =0.14
Property
0.12 AvgLen AvgFreq MinFreq
Data
0.10
Rate0.08 WMT17En-Zh 25.1 431.3 1
Error 00..0046 IRWOSCL-OT1ri7giEnna-lZh 290..34 16264.5.4 11
0.02 ROC-Filter 9.7 1048.3 35
0.00
49 67 73 135 207 316 671 911 1066 1099 1992 2698
Atom Frequency Table 8: Statistics of data sources: average sentence
(cid:1)
length, average token frequency and minimum token
Figure 8: Effect of atom frequency with compound
frequency. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 369>


<Paper ID = 37> <Table 0> <Abstractive Summary> =399 .222 .215 .213 .208 116 .208 20 .163 13 .155
Table 2: The highest Spearman’s correlations (across layers) between predicted values and gold annotations on
a held-out test set (for random structures computed on a train set). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 37>


<Paper ID = 37> <Table 1> <Abstractive Summary> =Layer UUAS UAS
• separateprobingfordistance∼5minutes StructuralProbe 15 82.29 –
OrthogonalProbe 15 82.47 –
• joint probing for distance and depth in the
multitaskorthogonalprobing
samestructuretype∼7minutes
distance+depth 16 80.86 77.51
• jointprobingfordepthsinallstructures∼13
alldistances 15 80.72 –
minutes
alltasks 16 79.03 75.66
• jointprobingfordistanceinallstructures∼
18minutes Table 4: (Undirected) Unlabeled Attachment Score of
treesextractedfromdependencyprobes. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 37>


<Paper ID = 37> <Table 2> <Abstractive Summary> =267
Table 5: Number of shared dimensions selected by Table 6: Number of shared dimensions selected by
Scaling Vector after the joint training of probe on top Scaling Vector after the joint training of probe on top
ofthe1stlayer. </Abstractive Summary> <Extractive Summary> It is due to the fact that
andexhaustivesetsofdimensionsandaveragere-
inBERT,positionalembeddingsareaddedbefore
sults for each set at the end.7 Table 2 shows that
theﬁrstlayer.  </Extractive Summary>  </Table 2>  </Paper ID = 37>


<Paper ID = 37> <Table 3> <Abstractive Summary> =410
Table 7: Number of shared dimensions selected by
Scaling Vector after the joint training of probe on top
ofthe24thlayer. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 37>


<Paper ID = 370> <Table 0> <Abstractive Summary> =sourcesentence [NULL] MR in der welt 1995 \ 1996
vanillaattention - 21.1 11.7 5.2 15.0 21.2 17.7 21.8
leakyattention 1.9 28.5 17.2 18.1 20.2 24.2 21.4 23.8
Table 3: Norms of the transformed value vectors of different source tokens in Figure 5. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 370>


<Paper ID = 371> <Table 0> <Abstractive Summary> =1 TRANSTABLE 41.91 44.99 44.19 43.28 43.59 29.73 32.80 29.73 29.61 30.46
2 TRANS-PE 29.84 38.61 26.08 48.06 35.64 30.64 34.97 22.67 38.95 31.80
3 TRANS-NPE 37.36 40.43 29.50 44.42 37.92 36.10 43.05 32.00 45.79 39.23
4 WPM-SEP 58.43 60.59 53.99 64.46 59.36 60.02 61.05 53.76 64.46 59.82
5 WPM-JOINT 59.91 60.71 55.35 62.30 59.56 61.39 61.73 53.87 63.78 60.19
Table 2: The results of different systems on NIST02. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 371>


<Paper ID = 372> <Table 0> <Abstractive Summary> =4808KB-Matching String-Matching
Methods CoNLL2003 Twitter Webpage Wikigold CoNLL2003 Twitter Webpage Wikigold
SupervisedLearningBaselines
BiLSTM-CRF 85.98 32.30 51.59 57.01 – – – –
RoBERTa-base 91.12 50.47 74.07 84.02 – – – –
DistantSupervisionBaselines
DictMatch 71.40 35.83 52.45 47.76 43.91 19.18 2.56 19.04
BiLSTM-CRF 64.62 30.25 13.90 37.46 60.52 31.67 24.67 27.97
RoBERTa-base 76.04 46.40 54.07 52.83 73.94 46.02 57.14 37.94
+BA(Ours) 76.43(+0.40) 46.75(+0.35) 59.28(+5.21) 53.56(+0.73) 75.43(+1.49) 46.69(+0.67) 58.71(+1.57) 42.23(+4.59)
+BA+CIR(Ours) 78.78(+2.74) 47.12(+0.72) 59.06(+4.99) 55.60(+2.77) 75.59(+1.65) 47.27(+1.25) 58.04(+0.90) 44.19(+6.25)
BOND 79.83 47.72 61.28 60.23 75.51 48.72 66.23 42.17
+BA(Ours) 80.81(+0.98) 48.45(+0.73) 64.65(+3.37) 60.81(+0.58) 76.21(+0.70) 49.12(+0.40) 66.67(+0.44) 42.53(+0.36)
+BA+CIR(Ours) 81.54(+1.71) 49.01(+1.29) 64.71(+3.43) 61.48(+1.25) 76.53(+1.02) 48.82(+0.10) 66.67(+0.44) 45.55(+3.38)
Table 1: F1 scores on CoNLL2003, Twitter, Webpage and Wikigold. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 372>


<Paper ID = 372> <Table 1> <Abstractive Summary> =KB-Matching String-Matching ingly achieve 4.91%, 3.18% improvements aver-
aged on four datasets in KB-Matching (5.75%,
PU-Learning 74.96 72.42
+BA(Ours) 80.93(+5.97) 76.17(+3.75) 2.56%improvementsonString-Matching)andPU-
+BA+CIR(Ours) 81.96(+7.00) 76.62(+4.20) Learning+BA+CIRachieves9.34%improvement
on CoNLL2003 dataset in KB-Matching (5.80%
Table 2: F1 scores on CoNLL2003 dataset based on
improvement in String-Matching). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 372>


<Paper ID = 373> <Table 0> <Abstractive Summary> =Table 4: Results on the CADEC dataset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 373>


<Paper ID = 373> <Table 1> <Abstractive Summary> =Therefore,allthewords
ELMo 74.2 48.1 inthesentencexcanalsoberepresentedasa
ELMo+BiLSTM 77.1 55.8 matrixH ={h ,h ,...,h }
1 2 N
BERT 82.5 59.0
BERT+BiLSTM 83.2 63.3
Inaddition,abidirectionalLSTM(BiLSTM)layer
Table 6: Results using different word representation can be stacked on word encoders to further cap-
methods. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 373>


<Paper ID = 373> <Table 2> <Abstractive Summary> =Method P R F1 CLEF CADEC GENIA ACE05
EFR 81.2 79.6 80.4 dh 400 400 768 768
EFR(+FRP) 81.4 80.1 80.7 Nhead 4 4 4 4
l 2 2 2 1
Table 8: Effect of joint training between entity frag- df 20 20 64 64
ment recognition (EFR) and fragment relation predic- ds 860 860 1,684 1,684
tion (FRP) on the CLEF-Dis dataset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 373>


<Paper ID = 373> <Table 3> <Abstractive Summary> =MLPSize 150 150 150 150
α 1.0 1.0 1.0 1.0
B CaseStudies β 1.0 1.0 1.0 0.6
To understand how syntax information helps our Table 9: Main hyper-parameter settings in our model
modeltoidentifydiscontinuousoroverlappeden- for all the datasets. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 373>


<Paper ID = 374> <Table 0> <Abstractive Summary> =Thekeytodealingwiththe s5:shewascapturedbutshewasonetoughcookie
s :godblesshere
problemistoencodesemanticinformationand 6
model event inter-dependency at a document-
Table 1: An example document in ACE 2005 corpus
level. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 374>


<Paper ID = 374> <Table 1> <Abstractive Summary> =MLBiNet(3-layer) 80.3 77.4 78.6
Methods P R F
1
Table 3: System Performance on Single Event Sen-
baseline(1-layer) 74.1 78.5 76.2
tences (1/1) and Multiple Event Sentences (1/n). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 374>


<Paper ID = 374> <Table 2> <Abstractive Summary> =concat(2-layer) 75.0 82.6 78.6
LSTM (2-layer) 74.2 83.7 78.6
portanceofeventinter-dependencymodelingand Table 5: The performance of MLBiNet with different
cross-sentenceinformationintegrationforEDtask. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 374>


<Paper ID = 375> <Table 0> <Abstractive Summary> =This clearly demonstrates
3https://github.com/hunterhector/
EvmEval thebeneﬁtsoftheproposedECRmodelwithrich
4846KBP2016 KBP2017
Model B3 CEAFe MUC BLANC AVGF1 B3 CEAFe MUC BLANC AVGF1
(LuandNg,2017) 50.16 48.59 32.41 32.72 40.97 - - - - -
(ChoubeyandHuang,2018) 51.67 49.10 34.08 34.08 42.23 50.35 48.61 37.24 31.94 42.04
(Choubeyetal.,2020) 52.78 49.70 34.62 34.49 42.90 51.68 50.57 37.8 33.39 43.36
Pairwise 52.16 49.84 30.79 32.21 41.25 50.97 48.80 36.92 31.86 42.14
E2E-Only 50.89 50.43 36.05 33.93 42.83 51.60 52.03 38.53 33.02 43.80
StructECR 52.77 52.29 38.37 35.66 44.77 51.93 52.82 40.73 34.75 45.06
Table 1: Models’ performance on the KBP 2016 and KBP 2017 datasets. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 375>


<Paper ID = 375> <Table 1> <Abstractive Summary> =For exam- Pairwise 60.51 58.11 59.22 59.10
ij ij ij ij ij
ple, “StructECR - aspan” implies a variant of E2E-Only 65.82 62.01 62.56 62.52
ij StructECR 68.19 65.83 65.19 65.12
StructECRwherethespan-basedinteractionscore
aspan isnotincludedinthecompuationoftheover-
ij Table 3: Cross-domain performance (AVG ). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 375>


<Paper ID = 376> <Table 0> <Abstractive Summary> =If subject, object or relation are resultinanyproblems,whilepro (·)isthe
x/y/xy
4853√
Table 2: The analysis of previous researches from the stereoscopic perspective. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 376>


<Paper ID = 376> <Table 1> <Abstractive Summary> =Due egyandSPN(Suietal.,2020)transformsrelational
4858Table 8: Performance comparison by Exact Match on face some challenging issues, including informa-
NYT
tionloss,errorpropagationandignoringtheinter-
action between entity and relation. </Abstractive Summary> <Extractive Summary> Tsub−q, Tsub−k willbe
we avoid to make the operations in Table 1 and i i i
used by shrinkage decoder, while Tsub−b only
try to model p([s,r,o]|L) via (cid:80)|R|[p([s,r ]|L) i
i i works for subject decoder.  </Extractive Summary>  </Table 1>  </Paper ID = 376>


<Paper ID = 376> <Table 2> <Abstractive Summary> =Table 9: Performance comparison by Exact Match on
Acknowledgments
Wiki-KBP
This work was supported in part by the National
Model Pre. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 376>


<Paper ID = 377> <Table 0> <Abstractive Summary> =(2019) 37.4 55.8 44.7
4 Experiments
KnowDis(Zuoetal.,2020) 39.7 66.5 49.7
KMMG(Liuetal.,2020) 41.9 62.5 50.1
4.1 DatasetsandEvaluationMetrics
LSIN(Ours) 47.9 58.1 52.5∗
We evaluate our proposed method on two widely
used datasets, including EventStoryLine (Caselli
Table 1: Experimental results on the EventStoryLine
and Vossen, 2017) and Causal-TimeBank (Mirza
dataset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 377>


<Paper ID = 378> <Table 0> <Abstractive Summary> =4876Dataset Task Classes AvgLen Train Dev Test
OLID OffensiveLanguageIdentiﬁcation 2(Offensive/NotOffensive) 25.2 11,916 1,324 862
SST-2 SentimentAnalysis 2(Positive/Negative) 19.3 6,920 872 1,821
AG’sNews NewsTopicClassiﬁcation 4(World/Sports/Business/SciTech) 37.8 108,000 11,999 7,600
Table 1: Dataset statistics. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 378>


<Paper ID = 378> <Table 1> <Abstractive Summary> =Thenweaskthreeindependenthumananno-
4878Benign Poisoned
Model says speaks utters
P R F1 P R F1
RIPPLES 96.9 82.0 89.0 63.0 92.0 74.8
is ranks lies remains exists
LWS 81.0 88.0 84.3 51.4 38.0 43.7
has possesses enjoys holds
Table 3: Human evaluation results on benign and poi-
sonedtextexamples. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 378>


<Paper ID = 378> <Table 2> <Abstractive Summary> =Stock (Load) options (keys) and a sales Table 5: Experimental results of different thesauri in
Collocation gimmickgounnoticedasthesoftwaremaker
twosettings. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 378>


<Paper ID = 378> <Table 3> <Abstractive Summary> =The boldfaced numbers indicate signiﬁcant
advantage, and the underlined numbers denote no sig-
Table 4: Case study on characteristics of word substi-
niﬁcantdifference. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 378>


<Paper ID = 379> <Table 0> <Abstractive Summary> =1.05× 0.5% 90.0 92.9 83.7 83.4 52.0 88.0 84.5 66.4 70.3 79.0
Table 5: Comparison against existing BERT compression works on GLUE. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 379>


<Paper ID = 38> <Table 0> <Abstractive Summary> =446Dataset Task Classes Avg.#W Train Valid Test
SST-2 SentimentAnalysis 2(Positive/Negative) 19.3 6,920 872 1,821
OLID OffensiveLanguageIdentiﬁcation 2(Offensive/NotOffensive) 25.2 11,916 1,324 859
AG’sNews NewsTopicClassiﬁcation 4(World/Sports/Business/SciTech) 37.8 108,000 11,999 7,600
Table 1: Details of three evaluation datasets. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 38>


<Paper ID = 38> <Table 1> <Abstractive Summary> =Speciﬁcally,we
Table 2: Backdoor attack results on the three datasets. </Abstractive Summary> <Extractive Summary> Table 1 on normal inputs.  </Extractive Summary>  </Table 1>  </Paper ID = 38>


<Paper ID = 38> <Table 2> <Abstractive Summary> =448Manual Automatic
Trigger
NormalF1 PoisonedF1 macroF1 PPL GEM
+Word 93.12 72.50 82.81 302.28 5.26
+Sentence 96.31 86.77 91.54 249.19 3.99
Syntactic 89.27 9.90 49.45 186.72 3.94
Table 4: Results of manual data inspection and auto-
matic quality evaluation of poisoned samples embed-
ded with different triggers. </Abstractive Summary> <Extractive Summary> This also indicates that the
4.2 BackdoorAttackResults morepowerfulmodelsmightbemoresusceptible
tobackdoorattacksduetotheirstronglearningabil-
Table 2 lists the results of different backdoor at-
ityfordifferentfeatures.  </Extractive Summary>  </Table 2>  </Paper ID = 38>


<Paper ID = 380> <Table 0> <Abstractive Summary> =Table 2: Training time for one epoch on a single
As our model is a pretrained model based on
v100 GPU, where emb. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 380>


<Paper ID = 380> <Table 1> <Abstractive Summary> =Table 3: Unsupervised parsing results with word Table4reportstherecallscoresforconstituents
(W)orword-piece(WP)asinput. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 380>


<Paper ID = 381> <Table 0> <Abstractive Summary> =Theobjectivefunctionbecomes,
I 0.6 0.3 0.1 Pron
cried 0.1 0.6 0.3 Adj
J(θθθ) = E [R(yˆ,y)]
P (y|x)
θθθ ψψψ(1) Pron Verb Adj P (y |x)×P (yˆ(1)|y )
(cid:88) 1 θθθ i ψψψ i i
= P (y|x)R(yˆ,y) Pron 0.4 0.3 0.3 0.24 0.09 0.03
θθθ e
as Verb 0.3 0.4 0.3 0.03 0.18 0.12
y∈Y(x) C
Adj 0.3 0.3 0.4 y :[Pron,Verb]
pred
Conventional minimum risk training is in- ψψψ(2) Pron Verb Adj P (y |x)×P (yˆ(2)|y )
tractablewhichismainlyduetothecombination 2 Pron 1 0 0 0θθθ.6 i 0 ψψψ i0 i
e
oftworeasons: ﬁrst,thesetofcandidatelabelse- Cas Verb 0 1 0 0 0 0.3
Adj 0 0 1 y :[Pron,Adj]
quencesY(x)isexponentialinsizeandintractable pred
toenumerate;second,theriskfunctionishardto
Table 1: An example of prediction results on two dif-
decompose (or indecomposable). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 381>


<Paper ID = 381> <Table 1> <Abstractive Summary> =(2020)† — 74.97 80.70 77.75 — — — — — — —
Table 2: Results on the CoNLL NER and Aspect Extraction tasks. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 381>


<Paper ID = 381> <Table 2> <Abstractive Summary> =For the CoNLL NER tasks, we provide
Table 3: Multi-source cross-domain results on
thereportedresultsfromWuetal.(2020). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 381>


<Paper ID = 381> <Table 3> <Abstractive Summary> =Theresultsareshownin
Table 5: Results on comparisons between EM algo- Table 6. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 381>


<Paper ID = 382> <Table 0> <Abstractive Summary> =Table 3: Results on SuperGLUE benchmark. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 382>


<Paper ID = 383> <Table 0> <Abstractive Summary> =:Bayesian 0.51±0.21 0.82±0.21 0.02±0.04 0.70±0.04
Table 2: Exact match accuracy results for baselines and lexicon learning models on 4 different compositional
generalizationsplits. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 383>


<Paper ID = 383> <Table 1> <Abstractive Summary> =:Simple 0.82±0.01
Soft 0.83±0.00
Learned 0.83±0.01
References
Table 5: Ablation experiments on the COGS dataset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 383>


<Paper ID = 383> <Table 2> <Abstractive Summary> =wif
zup
lug
TRAIN TEST
Bayesian Simple
INPUT OUTPUT INPUT OUTPUT
fep
dax r zupfep y y y
blicket
lug b zupkikidax r y
wif g wifkikizup y g kiki
zup y zupblicketlug y b y dax
lugfep b b b daxblicketzup r y r
wif
daxfep r r r wifkikizupfep y y y g
lugblicketwif b g b zupfepkikilug b y y y zup
wifblicketdax g r g lugkikiwifblicketzup g y g b lug
lugkikiwif g b zupblicketwifkikidaxfep r r r y g y
dluagxfkeipkikliukgiwif bg br b b zupblicketzupkikizupfep y y y y y y RED GREEN YELLOW BLUE RED GREEN YELLOW BLUE
wifkikidaxblicketlug r b r g
lugkikiwiffep g g g b
Figure 5: Learned lexicons from Colors datset with
wifblicketdaxkikilug b g r g
τ =0.1
Table6: FullColorsdatasetwithTrainandTestexam-
ples(Lakeetal.,2019)
IBMModel-2 PMI
noticed
TestExamples Simple/IBM-M2 Bayesian GECA SyntAtt Human
baked
zupfep 1.0±0.00 0.88±0.33 1.0±0.00 0.7±0.5 0.88
zupkikidax 1.0±0.00 0.88±0.33 1.0±0.00 0.7±0.5 0.86 shattered
wifkikizup 1.0±0.00 0.8±0.4 1.0±0.00 0.8±0.4 0.86
daxblicketzup 1.0±0.00 0.88±0.33 1.0±0.00 0.8±0.4 0.88 blessed
zupblicketlug 0.94±0.24 0.8±0.4 1.0±0.00 0.8±0.4 0.79
wifkikizupfep 1.0±0.00 0.3±0.5 0.0±0.00 0.4±0.005 0.85 hoped
zupfepkikilug 1.0±0.00 0.2±0.4 0.0±0.00 0.8±0.4 0.85
lugkikiwifblicketzup 1.0±0.00 0.4±0.5 0.0±0.00 0.4±0.5 0.65 Bayesian Simple
zupblicketwifkikidaxfep 0.0±0.00 0.0±0.00 0.0±0.00 0.0±0 0.70 noticed
zupblicketzupkikizupfep 0.0±0.00 0.0±0.00 0.0±0.00 0.0±0.00 0.75
baked
Table 7: Colors dataset exact match breakdown for shattered
eachindividualtestexample. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 383>


<Paper ID = 384> <Table 0> <Abstractive Summary> =Table 3: Efﬁciency comparison of two Transformer-
Forrecommendation,besidesNRTandNETE, based models in terms of training minutes on the Tri-
weincludeanothertwotraditionalmethods: pAdvisordataset,testedonNVIDIATeslaP40. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 384>


<Paper ID = 385> <Table 0> <Abstractive Summary> =Table 1: Average number of sentences in different Each of these pipelines leaves open many
SOAP note subsections grouped by parent sections choicesforspeciﬁcmodelstoemployforeachsub-
(Subjective,Objective,Assessment,Plan,Othersresp.) </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 385>


<Paper ID = 385> <Table 1> <Abstractive Summary> =model generated that the patient has a history of
heart disease conditioned on a cluster that men- CLUSTER2SENTsummarizeslocalizedregions
4964Medicaldataset AMIcorpus Medicalconversations AMIcorpus
Method PG T5-Small PG T5-Small Metric LR LS HLS BLS HLS BLS
EXT2NOTE 52.95 - 20.44 41.10 Accuracy 96.0 96.1 96.5 96.5 93.77 94.16
EXT2SEC 61.00 62.37 43.32 46.85 Ma-AUC 78.1 79.3 90.0 90.5 83.81 90.76
CLUSTER2SENT 63.63 66.50 51.86 54.23 Ma-F1 29.5 31.0 38.6 40.9 19.95 33.08
Mi-AUC 87.3 87.6 92.7 93.3 93.21 94.90
Mi-F1 31.2 32.9 39.6 41.1 43.76 49.93
Table3:ROUGE-1achievedontestsetwhenusingthe
abstractive models with oracle noteworthy utterances
Table 5: Performance on multilabel classiﬁca-
andclusters(moreresultswithoracleintheAppendix)
tion of noteworthy utterances with logistic regres-
Method R-1 R-2 R-L sion(LR), LSTM(LS), Hierarchical-LSTM(HLS) and
BERT-LSTM(BLS). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 385>


<Paper ID = 385> <Table 2> <Abstractive Summary> =For each
CLUSTER2SENT(PG+BLS) 53.69 25.88 35.12 sentence, we asked for (i) Factual correctness of
CLUSTER2SENT(T5-Base+BLS) 55.90 27.73 36.06 thesentence;(ii)Ifthestatementissimplyrepeat-
ingwhathasalreadybeenmentionedbefore;(iii)
Table 4: Performance of models trained and tested on
Ifthestatementisclinicallyirrelevant; (iv)Ifthe
data with different simulated ASR error rates. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 385>


<Paper ID = 385> <Table 3> <Abstractive Summary> =Weemphasizethat
Length 21.2 28.2 28.4 20.7 17.9 19.05
%Yield 62.0 69.0 74.7 27.22 30.22 59.45 the methods are intended to be used with super-
Comp 2.44 2.42 2.76 2.30 2.55 3.75
visionfromamedicalpractitionerwhocancheck
Copy 2.18 2.64 2.76 1.80 1.80 1.90
forfactualerrorsandeditthethegeneratedSOAP
Table 6: Averages of different metrics for noteifneeded. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 385>


<Paper ID = 388> <Table 0> <Abstractive Summary> =Finally,we
collection
see that the proposed MedWriter achieves the
2https://physionet.org/content/
mimic-cxr/2.0.0/ highestlanguagescoreson5/6metricsonOpen-i
5005Dataset Type Model CIDEr ROUGE-L BLEU-1 BLEU-2 BLEU-3 BLEU-4 AUC
CNN-RNN(Vinyalsetal.,2015) 0.294 0.307 0.216 0.124 0.087 0.066 0.426
LRCN(Donahueetal.,2015)* 0.285 0.307 0.223 0.128 0.089 0.068 –
Generation Tie-Net(Wangetal.,2018)* 0.279 0.226 0.286 0.160 0.104 0.074 –
CoAtt(Jingetal.,2018) 0.277 0.369 0.455 0.288 0.205 0.154 0.707
MvH+AttL(Yuanetal.,2019) 0.229 0.351 0.452 0.311 0.223 0.162 0.725
Open-i
V-LRetrieval 0.144 0.319 0.390 0.237 0.154 0.105 0.634
HRGR-Agent(Lietal.,2018)* 0.343 0.322 0.438 0.298 0.208 0.151 –
Retrieval
KERP(Lietal.,2019)* 0.280 0.339 0.482 0.325 0.226 0.162 –
MedWriter 0.345 0.382 0.471 0.336 0.238 0.166 0.814
GroundTruth – – – – – – 0.915
CNN-RNN(Vinyalsetal.,2015) 0.245 0.314 0.247 0.165 0.124 0.098 0.472
Generation CoAtt(Jingetal.,2018) 0.234 0.274 0.410 0.267 0.189 0.144 0.745
MvH+AttL(Yuanetal.,2019) 0.264 0.309 0.424 0.282 0.203 0.153 0.738
MIMIC-CXR
V-LRetrieval 0.186 0.232 0.306 0.179 0.116 0.076 0.579
Retrieval
MedWriter 0.306 0.332 0.438 0.297 0.216 0.164 0.833
GroundTruth – – – – – – 0.923
Table 1: Automatic evaluation on the Open-i and MIMIC-CXR datasets. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 388>


<Paper ID = 389> <Table 0> <Abstractive Summary> =2https://wiki.dbpedia.org/ 3https://www.wikipedia.org/
5014WOS DBpedia
Model
l l Overall l l l Overall
1 2 1 2 3
HDLTex 90.45 84.66 76.58 99.26 97.18 95.50 92.10
HNATC 89.32 82.42 77.46 99.21 96.03 95.32 93.72
HARNN 91.90 61.63 61.29 99.37 95.69 95.71 93.25
A-PNC-B - - 79.92 - - - 95.26
HiAGM-TP-LSTM 90.54 80.59 79.30 99.44 97.22 95.32 95.03
HiAGM-TP-GCN 90.78 80.79 79.34 99.43 97.18 95.29 94.85
HiAGM-LA-LSTM 90.20 80.09 78.28 99.40 97.14 95.12 94.64
HiAGM-LA-GCN 90.41 80.06 78.23 99.45 97.08 94.95 94.48
CLED 93.40 85.69 84.36 99.41 97.30 95.53 95.28
CLEDcluster 93.34 86.19 85.13 99.46 97.36 95.64 95.39
Table 2: Experimental results (accuracy, %) of our proposed model CLED and state-of-the-art methods. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 389>


<Paper ID = 390> <Table 0> <Abstractive Summary> =Insection4.4.1
and 4.4.2,weevaluateaccuracyandspeedperfor- Table 2: Model Speed vs. Index Size: VisualSparta
mancerespectivelyforbothlinesofmethods. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 390>


<Paper ID = 391> <Table 0> <Abstractive Summary> =Table 1: Statistics of three TREC datasets used in our
Metrics. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 391>


<Paper ID = 391> <Table 1> <Abstractive Summary> =ofpositiveandnegativedocumentsdoeshelpthe
5035SyntheticMethods BLEU-1 BLEU-2 ROUGE-1 ROUGE-2 ROUGE-L NIST@1 NIST@2 METEOR
SyncSup(Maetal.,2021) 0.5672 0.4527 0.5928 0.3764 0.5745 5.8070 7.3315 0.3089
Reverse-CTSyncSup 0.3185 0.1807 0.3528 0.1088 0.3395 3.0076 3.3665 0.1610
CTSyncSup 0.5909 0.4627 0.6238 0.3844 0.5955 6.1282 7.6314 0.3191
Table 4: Evaluation results of the queries generated by different synthetic methods. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 391>


<Paper ID = 391> <Table 2> <Abstractive Summary> =Even
The ranking accuracy of MetaAdaptRank and thougheachsyntheticbatchislikelytoincludeboth
5036AllQueries OldQueries NewQueries
TREC-COVIDR5Methods
NDCG@20 P@20 NDCG@20 P@20 NDCG@20 P@20
(a) r5.fusion1(AnseriniBM25) 0.5313 0.5840 0.5202 0.5722 0.6320 0.6900
(b) r5.fusion2(AnseriniBM25) 0.6007† 0.6440† 0.5937† 0.6344† 0.6641 0.7300
(c) covidex.r5.2s(RRF) 0.7457†‡ 0.7610†‡ 0.7303†‡ 0.7456†‡ 0.8837† 0.9000
(d) MetaAdaptRank(rerank(a)) 0.7536†‡ 0.7820†‡ 0.7405†‡ 0.7656†‡ 0.8712†‡ 0.9300†‡
(e) covidex.r5.d2q.2s(RRF) 0.7539†‡ 0.7700†‡ 0.7385†‡ 0.7544†‡ 0.8929† 0.9100
(f) MetaAdaptRank(rerank(b)) 0.7904†‡(cid:91)(cid:92) 0.8270†‡(cid:91)(cid:92)(cid:93) 0.7790†‡(cid:91)(cid:92) 0.8144†‡(cid:91)(cid:92)(cid:93) 0.8933†‡(cid:91) 0.9400†‡(cid:91)
(g) MetaAdaptRank(RRF) 0.7992†‡(cid:91)(cid:92)(cid:93) 0.8380†‡(cid:91)(cid:92)(cid:93) 0.7899†‡(cid:91)(cid:92)(cid:93) 0.8267†‡(cid:91)(cid:92)(cid:93) 0.8833†‡(cid:91) 0.9400†‡(cid:91)
Table 6: Evaluation results of TREC-COVID R5. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 391>


<Paper ID = 392> <Table 0> <Abstractive Summary> =pytorch-transformers/
k k k
5048• BERT+AM:Asemi-supervisedtextclassiﬁ- Table 2: Statistics of datasets. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 392>


<Paper ID = 392> <Table 1> <Abstractive Summary> =u
Metric Dataset Nu NB+EM BERT+AM VAMPIRE VAT UDA S2TC-BDD
0 0.668 0.844 – 0.846 0.839 0.844
200 0.696 0.855 0.329 0.850 0.844 0.857
AGNews
2,000 0.752 0.856 0.421 0.870 0.853 0.863
20,000 0.834 0.856 0.705 0.868 0.855 0.872
0 0.317 0.381 – 0.341 0.344 0.395
200 0.307 0.385 0.238 0.299 0.397 0.403
Micro-F1 Yelp
2,000 0.302 0.393 0.211 0.294 0.379 0.417
20,000 0.300 0.399 0.227 0.244 0.387 0.417
0 0.312 0.581 – 0.557 0.564 0.590
400 0.318 0.582 0.162 0.519 0.508 0.593
Yahoo
4,000 0.442 0.584 0.221 0.523 0.559 0.598
40,000 0.529 0.589 0.389 0.534 0.576 0.618
0 0.667 0.843 – 0.845 0.840 0.843
200 0.695 0.855 0.219 0.850 0.843 0.857
AGNews
2,000 0.751 0.855 0.341 0.870 0.852 0.864
20,000 0.833 0.856 0.698 0.867 0.855 0.872
0 0.316 0.368 – 0.256 0.324 0.385
200 0.279 0.370 0.161 0.278 0.344 0.372
Macro-F1 Yelp
2,000 0.286 0.379 0.124 0.287 0.362 0.380
20,000 0.250 0.371 0.144 0.197 0.357 0.403
0 0.303 0.567 – 0.562 0.550 0.585
400 0.301 0.571 0.074 0.521 0.500 0.586
Yahoo
4,000 0.420 0.574 0.175 0.524 0.550 0.590
40,000 0.489 0.573 0.356 0.542 0.567 0.595
AverageRank 4.8 2.2 6.0 3.4 3.4 1.2
Table 5: Classiﬁcation performance on AG News with 4.3 AblationStudy
100labeleddataand20,000unlabeleddataafterremov-
ingdifferentpartsofS2TC-BDD. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 392>


<Paper ID = 393> <Table 0> <Abstractive Summary> =We use AdamW as the optimizer and set
Table 2: Results on MS MARCO document ranking
thelearningrateto2e-6andbatch-sizeto16. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 393>


<Paper ID = 393> <Table 1> <Abstractive Summary> =*indicatesthe
valueisobtainedbytrainingthemodelusingpubliccodeinhttps://github.com/facebookresearch/DPR
Operation ofﬂine online Models MRR@100
PerDocumentBERTForward 0.9ms - randominit(k=4) 36.8
PerDocumentK-means 2.1ms - w/oANCE(k=4) 37.3
PerDocumentEncoding 2.3ms - w/oANCE(k=8) 37.9
PerQueryBERTForward - 0.5ms k=4 38.4
Retrieval - 180ms k=8 39.2
Retrieval(w/ooptimization) - 880ms k=16 39.4
Retrieval(independent) - 100ms k=32 38.8
Retrieval(lateinteraction) - 940ms
Table 5: Performance of the MS MARCO document
Table 4: Time cost of online and ofﬂine computing in rankingdevsetunderdifferentmodelsettings. </Abstractive Summary> <Extractive Summary> possiblecausallinkbetweentheperformanceand
Table 1 shows the results on the passage rank- thecharacteristicofthedatasets,weexaminethe
ing task.  </Extractive Summary>  </Table 1>  </Paper ID = 393>


<Paper ID = 394> <Table 0> <Abstractive Summary> =)‡ 72.69 78.77 75.13 80.95 76.89 79.53 73.25 76.74
large
BERT -CT† 68.80 74.58 76.62 79.72 77.14 - - -
base
BERT -CT† 69.80 75.45 76.47 81.34 78.11 - - -
large
ConSERT joint‡ 70.53 79.96 74.85 81.45 76.72 78.82 77.53 77.12
base
ConSERT joint‡ 73.26 82.36 77.73 83.84 78.75 81.54 78.64 79.44
large
UsingNLIsupervisionandSTSunlabeledtexts
BERT -ﬂow† 68.95 78.48 77.62 81.95 78.94 81.03 74.97 77.42
base
BERT -ﬂow† 70.19 80.27 78.85 82.97 80.57 81.18 74.52 78.36
large
ConSERT sup-unsup‡ 73.51 84.86 77.44 83.11 77.98 81.80 74.29 79.00
base
ConSERT sup-unsup‡ 75.26 86.01 79.00 83.88 79.45 82.95 76.54 80.44
large
ConSERT joint-unsup‡ 74.07 83.93 77.05 83.66 78.76 81.36 76.77 79.37
base
ConSERT joint-unsup‡ 77.47 85.45 79.41 85.59 80.39 83.42 77.26 81.28
large
Table 3: The performance comparison of ConSERT with other methods in a supervised setting. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 394>


<Paper ID = 394> <Table 1> <Abstractive Summary> =Wehopeourworkwillprovidea
Table 4: The average spearman correlation as well as newperspectiveforfutureresearchesonsentence
the training steps of our unsupervised approach with representationtransfer. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 394>


<Paper ID = 395> <Table 0> <Abstractive Summary> =3 78.94 81.57 89.47
4 96.93 96.93 96.93
4.6 CaseStudy
5 95.65 95.23 95.65
Figure3showstwoexamplesfromDJANGO.In
≥6 78.75 75.00 80.63
theﬁrstexample,TRANXﬁrstgeneratestheleft-
mostchildnodeatthetimestept ,incorrectlypre-
Table 4: Accuracy on different data groups of ATIS 2
accordingtothenumberofmulti-branchnodes. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 395>


<Paper ID = 396> <Table 0> <Abstractive Summary> =plicitcausesandeffectsofasentenceX inagiven
Table 1: Causal Relation types and their mapped rela- story. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 396>


<Paper ID = 396> <Table 1> <Abstractive Summary> =Table 2: Example of inference rules generated by
COINS (compared to Gold from GLUCOSE). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 396>


<Paper ID = 396> <Table 2> <Abstractive Summary> =n
Table 4: Automatic evaluation results for Story Com-
pletion. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 396>


<Paper ID = 396> <Table 3> <Abstractive Summary> =GPT-2† 57.7 59.5 55.5 55.3 53.4 51.4
COINS 57.8 60.1 56.3 58.2 55.1 55.2
For this we compare COINS to a GPT-2 model
ﬁne-tunedon GLUCOSEdatatogenerateinference Table 6: Automatic evaluation of the quality of infer-
rules(cf.§4). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 396>


<Paper ID = 396> <Table 4> <Abstractive Summary> =plicitcausesandeffectsofaselectedsentenceX
givenanincompletestoryS(cid:48),and(b)itisprovid- Table 8: Examples: inference rules and missing sen-
ing useful explanations for the incomplete story tences generated by COINS (compared to Gold from
S(cid:48). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 4>  </Paper ID = 396>


<Paper ID = 396> <Table 5> <Abstractive Summary> =For GPT-2 we use the
GPT2-GLUCOSE 25.6/10.2 0.361/0.609
GPT-2 small checkpoint (117M parame- GRF† 26.1/11.0 0.378/0.622
ters) based on the implementation of Hug- COINS(GR) 27.4/12.3 0.428/0.724
COINS(Oracle) 41.80/28.40 0.479/0.786
gingFace (Wolf et al., 2020) at: https:
//github.com/huggingface/transformers/ Table 9: Result: Automatic evaluation results on the
tree/master/src/transformers/models/gpt2 StoryEndingGenerationTask,†(Jietal.,2020)
Dataset Train Dev Test
Decoding Strategy. </Abstractive Summary> <Extractive Summary> In Table 5 we investigate the performance
strongbaselinemodelsthatutilizepre-trainedlan-
ofCOINSwithdifferentinputstothesentencegen-
guage models and incorporate external common-
eration component at inference time: (i) When
senseknowledgewithrespecttoallautomaticeval-
onlyinferencerules(fromtheinferencestep)are
uation metrics.  </Extractive Summary>  </Table 5>  </Paper ID = 396>


<Paper ID = 396> <Table 6> <Abstractive Summary> =Table 11: Example1: Generated Inference rules and
MissingSentences
Incomplete s1:Sethwasatapartywithhisfriends.s2:Someonedareda
Story: kidtoclimbonawall.s5:Heimmediatelybeganscreaming
thathislegwasbroken. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 6>  </Paper ID = 396>


<Paper ID = 396> <Table 7> <Abstractive Summary> =Table 14: Example of inference rules generated by
COINS and Fine-tuned GPT-2 when 2-sentences are
missing (compared to Gold from GLUCOSE). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 7>  </Paper ID = 396>


<Paper ID = 398> <Table 0> <Abstractive Summary> =SYNTH-SEQ2SEQ 32.7 36.1
SYNTHPARA-SEQ2SEQ 41.4 45.4
6.2.2 DetailedAnalysis
SSD(Word-Level) 57.2 62.8
SSD(Grammar-Level) 58.5 63.2
EffectofDecodingConstraints Toanalyzethe
Table 3: Overall results on GEOGRANNO and effect of decoding constraints, we conduct ab-
GEO(FunQL). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 398>


<Paper ID = 398> <Table 1> <Abstractive Summary> =lation experiments with different constraint set-
tings and the results are shown in Table 2: -
method, we report its performances on three set-
SEMANTIC denotes removing the semantic con-
tings. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 398>


<Paper ID = 398> <Table 2> <Abstractive Summary> =In case
1, “take-out” does not appear in paraphrase
x→c x←c x↔c Overall
Cases Reranking
logP(c|x) srec(x,c) sasso(x,c) Score
Input:restaurantsthatacceptcreditcardsandoffertakeout
Outputs:restaurantthattakescreditcardsandthathastake-out -54.2 -3.1 -20.3 -77.6
Outputs:restaurantthathastake-outandthattakescreditcards -72.0 -8.8 -20.3 -101.1
Outputs:restaurantthattakescreditcards -77.2 -22.4 -31.9 -131.5
Outputs:restaurantthattakescreditcardsandthattakescreditcards -84.2 -26.7 -28.1 -139.0
Input:meetingsheldinthesameplaceastheweeklystandupmeeting
Outputs:meetingwhosedateisdateofweeklystandup -62.2 -40.2 -67.1 -169.5
Outputs:meetingwhoselocationislocationofweeklystandup -62.7 -22.1 -62.4 -147.2
Outputs:meetingwhoselocationislocationthatislocationofweeklystandup -65.0 -21.1 -63.5 149.6
Outputs:meetingwhosedateisatmostdateofweeklystandup -67.2 -35.8 -73.3 -176.3
Input:meetingsheldinthesameplaceastheweeklystandupmeeting
Outputs:meetingwhoselocationislocationofweeklystandup -2.7 -22.1 -62.4 -86.2
Outputs:meetingwhoselocationislocationthatislocationofweeklystandup -6.0 -21.1 -63.5 -90.6
Outputs:locationthatislocationofweeklystandup -18.0 -32.6 -62.8 -113.4
Outputs:meetingwhosedateisdateofweeklystandup -31.2 -40.2 -67.1 -138.5
Table 4: Output cases from SSD on OVERNIGHT. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 398>


<Paper ID = 399> <Table 0> <Abstractive Summary> =mean max
BERT 1.51 57.0 58.3 1.92 68.1 70.4 0.52 90.4 90.9
ULR-BERT 1.31 59.3 60.2 1.83 69.3 72.6 0.61 90.8 91.5
Table 6: Standard deviation, mean, and maximum performance on the GLUE dev set when ﬁntuing BERT and
ULR-BERTwith5randomseeds. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 399>


<Paper ID = 399> <Table 1> <Abstractive Summary> =ULR-ALBERT 24.9/44.7/55.9 83.4
Results are shown in Table 9, which clearly
ULR-ELECTRA 26.8/51.8/65.5 86.9
shows that as the length of the query increases,
Table 8: Comparison of different base models on GE- the performance of BERT drops sharply. </Abstractive Summary> <Extractive Summary> Experimentsareranwithbatch
Table 1 shows examples from our word anlogy sizes in {8, 16, 32, 64} and learning rate of 3e-5
dataset.  </Extractive Summary>  </Table 1>  </Paper ID = 399>


<Paper ID = 4> <Table 0> <Abstractive Summary> =For
TOPIC 1.81 1.66 1.50
CMT(NTM) 1.91 1.67 1.55 afurtherdiscussion,Figure5showstheROUGE-1
DUALDEC 2.02 1.87 1.67 of ROBERTA, TOPIC, and CMT (NTM) in han-
Table 3: Average human ratings. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 4>


<Paper ID = 4> <Table 1> <Abstractive Summary> =2
+CMT(NTM) 31.72±0.7 29.54±0.7 26.55±0.2 8.65±0.2
Table 4: The comparison results of models with dual 6 RelatedWork
decoders(onthebottomhalf)andpipelinemodels(on
thetop).Forthepipelinemodels,weﬁrstproduceques- Our work is in the line with question generation,
tions(QS)usingCMT (NTM),fromwhichwefurther wheremostprioreffortsfocusonhowtoaskgood
generateanswerswiththeS2Smodel. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 4>


<Paper ID = 4> <Table 2> <Abstractive Summary> =(Whodoyouprefer,AkiraorCurleyG)
>赵粤(Akira);希林娜依高(CurleyG) ThedatasetiscollectedthroughtheofﬁcialAPIs
of Weibo and is consistent with the Weibo terms
Table 5: Questions generated for the source posts in
of use. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 4>


<Paper ID = 40> <Table 0> <Abstractive Summary> =BERT
homonymous high high high high high (cid:51)
polysemous low/high high low/high low/high low/high (cid:51)
monosemous low high low low low (cid:51)
temp.adverbials low low high high low (cid:55)
modals high low high high low (cid:55)
quantiﬁers high low high high low (cid:55)
prepositions high low high high high (cid:51)
articles none low high high high (cid:51)
Table 1: Expected contextualization (Exp. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 40>


<Paper ID = 401> <Table 0> <Abstractive Summary> =DevresultsonGLUEanddevresultonSQuAD
AutoTinyBERT-KD-S1 4.6× 87.6 91.4 82.3 88.5 47.3 89.7 89.9 89.0 71.1 81.2 81.9
BERT-KD-S1 4.9× 86.2 89.7 81.1 87.9 41.8 87.3 88.4 88.4 68.2 79.1 79.9
MobileBERTTiny‡(Sunetal.,2020) 3.6*× 88.6 91.6 82.0 86.7 - - - - - - -
AutoTinyBERT-KD-S2 9.0× 84.6 88.8 79.4 87.3 32.2 88.0 87.7 88.0 68.9 77.5 78.3
BERT-KD-S2 9.8× 82.5 87.8 77.9 86.5 31.5 86.9 87.6 87.4 66.4 76.5 77.2
MiniLM-4L312D†(Wangetal.,2020b) 9.8× 82.1 87.3 78.3 83.6 26.3 87.1 87.3 86.3 62.4 74.8 75.6
TinyBERT-4L312D†§(Jiaoetal.,2020b) 9.8× 81.0 87.8 76.9 77.9 22.9 86.0 87.7 83.3 58.8 72.7 73.6
AutoTinyBERT-KD-S3 10.7× 83.3 88.3 78.2 85.8 29.1 87.4 87.4 86.7 66.4 76.2 77.0
BERT-KD-S3 11.7× 81.6 86.5 76.8 82.5 27.6 85.6 86.5 86.2 64.9 74.6 75.4
AutoTinyBERT-KD-S4 17.0× 78.7 86.8 76.0 81.4 20.4 85.5 86.9 86.0 64.9 73.5 74.1
BERT-KD-S4 17.0× 77.4 85.7 75.4 80.3 18.9 85.0 85.9 84.7 63.1 72.4 72.9
TestresultsonGLUEanddevresultonSQuAD
AutoTinyBERT-KD-S1 4.6× 87.6 90.6 81.2 88.9 44.7 87.4 70.5 85.1 64.8 76.7 77.9
BERT-3L-PKD‡(Sunetal.,2019) 4.1× - 87.5 76.7 80.7 - 84.7 68.1 - 58.2 - -
DistilBERT-4L‡(Sanhetal.,2019) 3.0× 81.2 91.4 78.9 82.4 32.8 85.2 68.5 76.1 54.1 71.2 72.3
TinyBERT-4L516D†§(Jiaoetal.,2020b) 4.9× 84.6 88.2 80.0 86.3 27.9 85.6 69.1 83.0 61.5 72.7 74.0
MiniLM-4L516D†(Wangetal.,2020b) 4.9× 85.5 90.0 80.2 87.2 39.1 86.5 70.0 83.4 63.7 75.0 76.2
MobileBERTTiny‡(Sunetal.,2020) 3.6*× 88.6 91.7 81.5 87.9 46.7 89.5 68.9 80.1 65.1 76.4 77.8
Table 2: Comparison between AutoTinyBERT and baselines based on knowledge distillation. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 401>


<Paper ID = 401> <Table 1> <Abstractive Summary> =KD-S4 4-192-768-12-192 4-256-480-12-192 17.0/17.0×
Table 4: BERT and AutoTinyBERT architectures un-
architecturehyper-parameters;(2)ourmethodout-
derthedifferentspeedupconstraints. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 401>


<Paper ID = 402> <Table 0> <Abstractive Summary> =5162Table 2: Accuracy (in %) on XNLI with augmented examples used for cross-lingual transfer. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 402>


<Paper ID = 402> <Table 1> <Abstractive Summary> =We observe
5163Table 4: Accuracy (in %) on XNLI experiments with different amounts of training and augmentation data, and
differentadversarialtrainingmethods. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 402>


<Paper ID = 403> <Table 0> <Abstractive Summary> =Forsupervisedlearning,wecomparewithmeth-
5173Model EN-EN ES-ES AR-AR EN-AR EN-DE EN-TR EN-ES EN-FR
Unsupervisedmethods
mBERT 54.4 56.7 50.9 16.7 33.9 16.0 21.5 33.0
XLM-R 50.7 51.8 25.7 17.4 21.3 9.2 10.9 16.6
Ours:BSL-uns 76.9 81.2 68.3 71.6 71.5 72.7 69.5 75.6
Supervisedmethods
mBERT-nli-stsb 80.2 83.9 65.3 30.9 62.2 23.9 45.5 57.8
XLM-R-nli-stsb 78.2 83.1 64.4 44.0 59.5 42.4 54.7 63.4
mBERT←SBERT-nli-stsb 82.5 83.0 78.8 77.2 78.9 73.2 79.2 78.8
XLM-R←SBERT-nli-stsb 82.5 83.5 79.9 77.8 78.9 74.0 79.7 78.5
mUSE 86.4 86.9 76.4 79.3 82.1 75.5 79.6 82.6
LaBSE 79.4 80.8 69.1 74.5 73.8 72.0 65.5 77.0
Ours:BSL-sup 83.3 86.1 79.3 80.6 81.2 78.9 82.0 83.5
Table 3: Spearman’s rank correlation ρ between the cosine similarity of sentence representations and the gold
labels. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 403>


<Paper ID = 403> <Table 1> <Abstractive Summary> =Choiceoftrainingcorpus
Ours:NLI 67.83 71.40 66.88 79.97 73.97 73.74 70.40 72.03
5MBook 64.90 68.33 65.18 77.48 73.12 70.55 68.05 69.65
5MBook+NLI 68.93 68.23 66.13 79.72 72.54 74.94 69.76 71.46
Effectofdataaugmentation
Ours:Back-translation 67.83 71.40 66.88 79.97 73.97 73.74 70.40 72.03
Synonym 62.31 69.73 63.37 77.78 67.94 70.04 66.36 68.21
MLM 61.47 69.58 66.91 78.86 69.62 70.55 68.78 69.39
NLI 65.88 72.62 65.67 78.39 74.17 73.42 70.67 71.54
entail
Back-translation+NLI 72.01 72.62 70.16 81.65 76.03 77.65 74.48 74.94
entail
Table 4: Results with 1) different training corpora; and 2) different augmentation techniques. </Abstractive Summary> <Extractive Summary> We use Spearman’s rank
Table 1 presents the comparison results.  </Extractive Summary>  </Table 1>  </Paper ID = 403>


<Paper ID = 403> <Table 2> <Abstractive Summary> =0.5 0.9 0.99 0.999 1 althoughdirectlyaveragingthetokenembeddings
from BERT yields poor sentence representations
33.18 69.58 72.51 73.74 68.19
asshowninTable1,initializingthetargetnetwork
Table 6: Performance w.r.t. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 403>


<Paper ID = 403> <Table 3> <Abstractive Summary> =Table 10: Average Pearson correlation r and average
The NLI and related datasets can be downloaded
Spearman’s rank correlation ρ over three topics on
from https://huggingface.co/datasets. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 403>


<Paper ID = 403> <Table 4> <Abstractive Summary> =In
EpochNum 1
this setting, supervised method such as SBERT
andInferSentneedtobetrainedonNLIdataand
Table 8: Hyperparameters for training on the NLI
performcross-domainpredictionsontheAFSsen-
dataset. </Abstractive Summary> <Extractive Summary> a few tokens and then use a pre-trained masked The results in Table 4 show that our proposed
language model to generate the masked tokens.  </Extractive Summary>  </Table 4>  </Paper ID = 403>


<Paper ID = 403> <Table 5> <Abstractive Summary> =It
Table 9: Performance on STS-B development set. </Abstractive Summary> <Extractive Summary> withalargerbatchsizesuchthatsufﬁcientnegative
Table 5 presents an example of augmentations
generatedtothesamesentence.4 Weobservethat samplescanbeobtained.  </Extractive Summary>  </Table 5>  </Paper ID = 403>


<Paper ID = 404> <Table 0> <Abstractive Summary> =Model Accuracy(%) RoBERTa —- 73.2
ege-RoBERTa-base 77.9 X(cid:48) ={O ,I ,H ,O } 77.1
1 1 i 2
-w/A˜ 75.5 X(cid:48) ={O1,Hi,I1,O2} 76.3
-w/I˜1andI˜2 76.0 ege-RoBERTa X(cid:48) ={O1,I1,I2,Hi,O2} 76.6
X(cid:48) ={O ,H ,I ,I ,O } 75.8
1 i 1 2 2
Table 3: Prediction accuracy of the ege-RoBERTa- X(cid:48) ={O ,I ,H ,I ,O } 77.9
1 1 i 2 2
basemodelpretrainedwithrandomlyinitializedadja-
cencymatrixA˜/randomlysampledintermediaryevents Table6:Predictionaccuracy(%)oftheege-RoBERTa-
{I˜,I˜}. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 404>


<Paper ID = 405> <Table 0> <Abstractive Summary> =Baseline(noUID) 80.48
+UID:variance 78.40(↓2.5%)†
+UID:localconsistency 78.12(↓2.9%)†
6.1 Languages
TURKISH(38.1M)
Table1showstheresultsofUID-regularizedlan- Baseline(noUID) 66.13
guage models trained on various languages from +UID:variance 65.70(↓0.7%)†
+UID:localconsistency 66.06(↓0.1%)
EuroParl and Wiki-40B, and includes statistical
signiﬁcanceofchangesinperplexity,ascompared
Table 1: UID regularizers improve perplexity for mul-
withbaselines,computedusingpermutationtests9 tiplelanguages. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 405>


<Paper ID = 405> <Table 1> <Abstractive Summary> =5195WMT’06 EuroParl WT-103 80
#trainingtokens 16.0M 47.0M 103.2M
60
y
Baseline(noUID) 49.70 21.34 29.89 neit
++UUIIDD::vloacraialnccoensistency 4488..7295† 2211..0189† 2299..5783 seliplex 40
ar
Be
p 20
Table 2: UID regularizers improve perplexity on lan-
guage models trained on English datasets of vary- 0
ing size. </Abstractive Summary> <Extractive Summary> n 2 UID:localconsistency
i
nty
eit 1.5
mx
e
6.2 DatasetSize el
ovrp 1
Notably, we observe the largest improvements prpe
m 0.5
(1.6–2.9%) in perplexity in Table 1 for the low- I
estresourcelanguages,TagalogandSwahili(with 0
2 8 16 24 32 47
4.2 and 6.3 million training tokens respectively).  </Extractive Summary>  </Table 1>  </Paper ID = 405>


<Paper ID = 405> <Table 2> <Abstractive Summary> =5196Sequence Model %uniquen-grams
length entropy n=2 n=3 n=4
Baseline(noUID) 22.9 69.6 37.7 73.5 90.9
+UID:variance 24.0 79.4 40.7 77.8 93.3
+UID:localconsistency 23.3 73.9 39.1 75.7 92.1
Table 3: Text generated by UID-regularized language models is longer (higher average sequence length), higher
entropy(computedviamonte-carloestimation),andmorelexicallydiverse(ahigherratioofuniquen-grams). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 405>


<Paper ID = 405> <Table 3> <Abstractive Summary> =(9),however,toestimateH(p)
Baseline 35.75 23.22
+labelsmoothing,α=0.01 36.15 26.26 withasimpleMonte-Carloestimator:
+labelsmoothing,α=0.05 55.56 40.79
+labelsmoothing,α=0.1 90.57 68.26 K
1 (cid:88)
Hˆ(p) = − logp(y(k)) (10)
Table 4: Label smoothing, another form of regulariza- K
k=1
tionthatsimilarlyaugmentsthecross-entropyobjective
with a penalty, does not improve perplexity. </Abstractive Summary> <Extractive Summary> Table 3 shows results from UID-regularized
models compared with the baseline.  </Extractive Summary>  </Table 3>  </Paper ID = 405>


<Paper ID = 407> <Table 0> <Abstractive Summary> =We note that a  Table 1: Ablation study of SACEbase on ALL 
major  difference  is  that  the  pre-trained  model 
art performance. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 407>


<Paper ID = 407> <Table 1> <Abstractive Summary> =When 
large
5223Datasets  Concatenation of all Datasets 
Training data  Systems 
SE2  SE3  SE07  SE13  SE15  ALL  N  V  A  R 
SVC (GWNC2019)  77.5  77.4  69.5  76.0  78.3  76.7  79.6  65.9  79.5  85.5 
EWISE (ACL2019)  73.8  71.1  67.3*  69.4  74.5  71.8*  74.0  60.2  78.0  82.1 
LMMS (ACL2019)  76.3  75.6  68.1  75.1  77.0  75.4  78.0  64.0  80.5  83.5 
GlossBERT (EMNLP2019)  77.7  75.2  72.5*  76.1  80.4  76.8*  -  -  -  - 
GLU (EMNLP2019)  75.5  73.6  68.1*  71.1  76.2  73.7*  -  -  -  - 
SemCor  ARES (EMNLP2020)  78.0  77.1  71.0  77.3  83.2  77.9  80.6  68.3  80.5  83.5 
SREF (EMNLP2020)  78.6  76.6  72.1  78.0  80.5  77.8  80.6  66.5  82.6  84.4 
EWISER (ACL2020)  78.9  78.4  71.0  78.9  79.3*  78.3*  81.7  66.3  81.2  85.8 
BEM (ACL2020)  79.4  77.4  74.5*  79.7  81.7  79.0*  81.4  68.5  83.0  87.9 
SACEbase  80.9  79.1  74.7*  82.4  84.6  80.9*  83.2  71.1  85.4  87.9 
SACElarge  82.4  81.1  76.3*  82.5  83.7  81.9*  84.1  72.2  86.4  89.0 
SemCor  SVC (GWNC2019)  79.7  77.8  73.4  78.7  82.6  79.0  81.4  68.7  83.7  85.5 
+WNGT  EWISER (ACL2020)  80.8  79.0  75.2  80.7  81.8*  80.1*  82.9  69.4  83.6  87.3 
+WNE  SACElarge+  83.6  81.4  77.8  82.4  87.3*  82.9*  85.3  74.2  85.9  87.3 
Table 2: English all-words WSD performance on different partitions of ALL utilizing two sets of training 
data. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 407>


<Paper ID = 407> <Table 2> <Abstractive Summary> =Specifically,  although  BEM  outperforms  its 
5224  Models  ALLWN_1st  ALLWN_other  Models  ALLZSS  ALLZSS*  ALLZSL  ALLZSL* 
(n=4728)  (n=2525)    (n=691)  (1139)  (222)  (670)   
WordNet 1st  100  0    WordNet 1st   24.0  53.9  54.4  84.9   
LMMS  87.6  52.6    BERT-base  23.5  53.6  54.4  84.9   
  LMMS  36.7  61.6  74.8  91.7   
SREF  91.0  53.2 
 
  GlossBERT  37.4  62.0  75.6  91.9 
BEM  93.6  51.7 
 
  ARES  42.6  65.2  81.1  93.7 
SACEbase  94.2  56.1    SREF  46.1  67.3  82.4  94.2   
SACElarge  94.1  59.0  BEM  48.7  68.9  73.4  91.2   
 
SACElarge+  94.7  60.8  SACEbase  60.4  76.0  90.0  96.7   
 
SACElarge  66.2  79.5  90.0  96.7 
Table 3: Rare sense disambiguation on ALL 
Table 4: Zero-shot lemma and sense disambiguation. </Abstractive Summary> <Extractive Summary> and Jorge, 2019), GLU (Hadiwinoto et al., 2019), 
GlossBERT  (Huang  et  al.,  2019),  EWISER  6.2  All-words WSD 
(Bevilacqua and Navigli, 2020), BEM (Blevins 
 Table 2 demonstrates how our systems and lately 
and  Zettlemoyer,  2020), ARES  (Scarlini  et  al., 
proposed baselines perform on different partitions 
2020b) and SREF (Wang and Wang, 2020).  </Extractive Summary>  </Table 2>  </Paper ID = 407>


<Paper ID = 407> <Table 3> <Abstractive Summary> =For our system, the baseline is trained with  SACEmul  82.6  74.6  83.0  78.1  75.6  77.3  78.7 
the same training data as SACE  using XLM-
large+
Table 5: Multilingual all-words WSD 
RoBERTa-base, while removing all the proposed 
5225ID  Score  Sentence 
They belong to a group of ringers who drive every Sunday from church to church in a 
10  / 
sometimes-exhausting effort to keep the bells sounding in the many belfries of East Anglia. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 407>


<Paper ID = 407> <Table 4> <Abstractive Summary> =Table 6: Two examples of WlC 
exploitation method from both word and sense 
Synset-1  Synset-2 
perspectives in a supervised similarity-based WSD 
family.n.01  member.n.01 
architecture. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 4>  </Paper ID = 407>


<Paper ID = 407> <Table 5> <Abstractive Summary> =It also shows that 
sport.n.05  player.n.01  the  proposed  method  has  an  overwhelming 
advantage of learning few-shot and zero-shot WSD 
Table 7: Related synsets by SlC 
ability. </Abstractive Summary> <Extractive Summary> Table 5 presents the 
ARES  79.6  75.3  81.2  77.0  70.1  71.4  76.2 
performance of some lately proposed systems and  Baseline  80.5  74.9  80.7  73.6  72.7  74.9  76.3 
ours.  </Extractive Summary>  </Table 5>  </Paper ID = 407>


<Paper ID = 407> <Table 6> <Abstractive Summary> =Sense  vocabulary  compression  through  the  Table 1: Hyperparameter bounds and optimal setting 
5228F1 on Dev Set (SE07)
77 76.3 75.8 75.4 75.2
74.5 74.5 74.5 74.7
75
73.6
73 74.7 74.5 74.3
73.2
72.7 73
71 69.9 72.3
71.4 71.9
69
67.9
67
1 2 3 4 5 6 7 8 9 10
SACEbase SACElarge
 
Figure 1: F1 on SE07 of SACE  and SACE  
base large
Hyperparameter Search The bounds for each 
hyperparameter  are  listed  in  table  1,  with 
configurations  for  best  performing  models 
underlined. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 6>  </Paper ID = 407>


<Paper ID = 408> <Table 0> <Abstractive Summary> =semanticinformationaboutframesintoconsidera-
5230
Proceedingsofthe59thAnnualMeetingoftheAssociationforComputationalLinguistics
andthe11thInternationalJointConferenceonNaturalLanguageProcessing,pages5230–5240
August1–6,2021.©2021AssociationforComputationalLinguisticsFrame: Activitystop Frame: Processstop
Def AnAgentceasesanActivitywithoutcompletingit AProcessstopsatacertainTimeandPlace
core: Agent,Activity core: Process
FEs
peripheral: Degree,Duration,Manner,Time peripheral: Manner,Place,Time
extra-thematic: Depictive,Purpose,Result,... extra-thematic: Depictive,Duration,...
LUs abandon.v,cease.v,halt.v,quit.v,stop.v,... cease.v,halt.n,shutdown.n,stop.v,...
Inheritsfrom: Processstop Inheritsfrom: Event
FRs
Subframeof: Activity Subframeof: Process
IsInheritedby: Halt IsInheritedby: Activitystop
Uses: Eventiveaffecting
Table 1: The structured descriptions for frame Activitystop versus frame Processstop in FrameNet1.7. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 408>


<Paper ID = 408> <Table 1> <Abstractive Summary> =Table 3: Frame identiﬁcation accuracy with lexicon
Inaddition,wealsoimplementedtwoadditional ﬁltering setting on FrameNet test dataset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 408>


<Paper ID = 409> <Table 0> <Abstractive Summary> =ASE-BERT-12(5) 67.0±0.2/78.1±0.2
BERT2STATICpara 68.3±0.3/79.9±0.2
ASE-ROBERTA-12(2) 67.0±0.2/78.2±0.3
ROBERTA2STATICpara 67.9±0.2/79.6±0.3
ASE-GPT2-12(4) 67.4±0.3/78.3±0.3
GPT22STATICpara 68.4±0.2/80.0±0.4
Table 5: Comparison of the overall performance
of X2STATICpara with ASE on downstream tasks. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 409>


<Paper ID = 41> <Table 0> <Abstractive Summary> =Table2showsthemacroF1- BERT11 .82 .84 .82 .83 .83 .83 .83 .83
scoresofallmodelsacrossdatasets,encodersand LSTM .87 .89 .87 .87 .88 .88 .88 .88
MIMIC GRU .87 .89 .87 .88 .88 .88 .88 .88
attentionmechanismsusingthethreeTaScvariants
MLP .87 .87 .87 .86 .86 .86 .87 .86
(Lin-TaSc,Feat-TaScandConv-TaScdescribedin CNN .88 .89 .88 .87 .87 .87 .88 .88
Section4)andwithoutTaSc(No-TaSc).10
Table 2: F1-macro average scores (3 runs) across
Ingeneral,allTaScmodelsobtaincomparable
datasets, encoders and attention mechanisms for mod-
performance and in some cases outperform No-
elswithandwithoutTaSc(No-TaSc). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 41>


<Paper ID = 41> <Table 1> <Abstractive Summary> =No-TaScLin-TaScFeat-TaScConv-TaSc
6.3 DecisionFlip: MostInformativeToken Tanh 8.4 7.3(0.9) 6.5(0.8) 5.4(0.6)
α
Dot 5.4 4.3(0.8) 4.8(0.9) 4.5(0.8)
Table3andFigure1presentthemeanaverageper-
Tanh 8.2 10.2(1.2) 11.2(1.4) 10.4(1.3)
∇α
centage of decision ﬂips (higher is better) across Dot 6.9 10.9(1.6) 12.2(1.8) 11.1(1.6)
attention mechanisms, encoders and datasets by Tanh 11.7 14.0(1.2) 13.5(1.1) 12.2(1.0)
α∇α
Dot 8.2 11.8(1.4) 12.6(1.5) 11.3(1.4)
removingthemostinformativetokenforTaScvari-
ants and No-TaSc for all attention-based impor- Table 3: Mean average percentage of decision ﬂips
tancemetrics(seeSection5). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 41>


<Paper ID = 41> <Table 2> <Abstractive Summary> =Tanh .36 .21(0.6) .19(0.5) .26(0.7)
∇α
Dot .42 .22(0.5) .22(0.5) .26(0.6)
Tanh .32 .17(0.5) .18(0.5) .24(0.7)
α∇α
Dot .41 .21(0.5) .21(0.5) .26(0.6)
Observing results in the second row of Figure Table 4: Mean average fraction of informative tokens
1,weseethatTaScvariantsoutperformNo-TaSc requiredtocauseadecisionﬂipacrossattentionmech-
anisms, using the three TaSc variants and No-TaSc
in all datasets when using ∇α and α∇α. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 41>


<Paper ID = 411> <Table 0> <Abstractive Summary> =Table 3: Results in the RELP task (Micro-F × 100,
1 Theper-epochtimemeasurementsfromTable1
averagedover5runs). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 411>


<Paper ID = 411> <Table 1> <Abstractive Summary> =How-
MSIMvariant(k = 1),whichshowedrobustperfor- ever,thedecreaseismodestevenwhenrelyingon
5275n= 2 4 6 8 10 12 time,thesescoresaresubstantiallylowerthanthe
EN:REG 51.6 51.8 50.7 49.5 48.0 46.7 onesachievedwhenstartingfromLM-pretrained
LSIM EN:MSIM 58.8 61.5 64.2 65.0 71.7 74.3 models, even when LEXFIT is run with mere 5k
FI:REG 57.3 59.8 61.5 61.1 59.3 55.3 ﬁne-tuninglexicalpairs.12 Thisagainstronglysug-
FI:MSIM 57.0 64.1 66.6 69.6 70.2 71.1
geststhatLEXFIT’unlocks’alreadyavailablelexi-
EN–FI:REG 39.2 43.8 47.6 48.6 48.3 47.1
BLI EN–FI:MSIM 40.2 45.6 50.7 54.3 56.1 57.7 calknowledgestoredinthepretrainedLM,yielding
beneﬁtsbeyondtheknowledgeavailableintheex-
Table 5: Task performance of WEs extracted via ternaldata. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 411>


<Paper ID = 411> <Table 2> <Abstractive Summary> =Method EN EN:SV ES FI RU DE:SL
FASTTEXT.WIKI 44.2 25.8 45.0 58.7 35.8 41.3
BERT-REG(all) 46.7 23.9 42.4 55.3 30.6 31.3
BERT-REG(best) 51.8 28.9 44.2 61.5 30.7 34.6
MNEG
– 73.6 68.3 62.3 72.0 50.4 49.7
MSIM
k=1 74.3 69.6 61.8 71.1 49.9 49.7
k=2 74.3 69.6 61.8 71.1 49.9 49.6
k=4 75.7 71.7 61.9 68.4 48.6 47.9
k=8 75.9 72.3 62.0 66.4 49.9 46.5
SOFTMAX(binary)
k=1 64.3 58.8 58.8 62.4 44.6 43.7
k=2 67.9 61.4 60.1 67.6 46.6 45.9
k=4 70.2 64.9 60.6 69.6 46.7 47.0
k=8 71.3 67.2 61.4 70.2 46.7 47.6
SOFTMAX(ternary)
k=1 67.8 61.7 59.4 66.2 38.8 45.3
k=2 68.8 62.6 60.1 66.7 42.4 46.6
k=4 70.6 65.8 59.7 67.8 45.3 47.6
k=8 71.6 67.8 60.9 68.5 45.0 47.0
Table 7: A summary of results in the lexical semantic similarity (LSIM) task (Spearman’s ρ correlation scores),
alsoshowingthedependenceonthenumberofnegativeexamplesperpositiveexample: k. ThescoresforEN,ES,
FI,and RU arereportedontheMulti-SimLexlexicalsimilaritybenchmark(Vulic´ etal.,2020)(1,888wordpairs). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 411>


<Paper ID = 411> <Table 3> <Abstractive Summary> =5281(a)Trainingdictionary:5,000wordtranslationpairs
Method EN–DE EN–TR EN–FI EN–RU DE–TR DE–FI DE–RU TR–FI TR–RU FI–RU avg
FASTTEXT.WIKI 61.0 43.3 48.8 52.2 35.8 43.5 46.9 35.8 36.4 43.9 44.8
BERT-REG(all) 44.6 37.9 47.1 47.3 32.3 39.5 41.2 35.2 31.9 38.7 39.6
MNEG
– 58.1 46.2 57.7 54.0 36.2 46.1 46.7 39.6 36.7 42.4 46.4
MSIM
k=1 58.9 45.9 57.6 53.7 37.1 46.4 46.7 39.4 37.4 44.2 46.7
k=2 57.2 44.4 56.7 52.8 35.7 44.7 46.1 39.3 37.4 42.2 45.7
k=4 57.0 43.6 55.2 51.5 35.5 43.6 44.8 38.0 35.1 39.3 44.4
k=8 55.4 44.0 53.0 49.1 34.0 41.8 42.2 36.5 32.0 37.5 42.6
SOFTMAX(binary)
k=1 57.9 45.3 53.8 53.6 35.9 44.3 43.5 38.4 36.0 42.8 45.2
k=2 55.8 44.6 55.4 51.9 34.7 43.8 41.9 39.1 34.6 40.0 44.2
k=4 55.8 43.8 54.9 51.4 34.6 42.8 39.9 37.9 33.3 39.0 43.3
k=8 54.2 43.1 54.4 50.2 33.3 42.0 39.7 36.8 32.9 38.7 42.5
SOFTMAX(ternary)
k=1 57.1 44.9 54.8 52.7 35.2 44.0 44.6 38.4 34.9 41.1 44.8
k=2 55.7 45.2 54.4 53.2 34.1 43.6 42.6 38.4 34.5 40.7 44.2
k=4 55.5 44.7 55.1 52.6 34.0 42.8 40.2 38.6 33.4 40.7 43.8
k=8 54.9 44.2 53.3 51.5 33.3 41.3 38.7 37.2 32.9 37.8 42.5
(b)Trainingdictionary:1,000wordtranslationpairs
Method EN–DE EN–TR EN–FI EN–RU DE–TR DE–FI DE–RU TR–FI TR–RU FI–RU avg
FASTTEXT.WIKI 53.9 31.7 35.4 39.0 23.0 31.5 37.8 21.4 22.2 29.6 32.6
BERT-REG(all) 26.4 20.6 25.8 25.4 17.4 24.6 23.4 20.4 15.6 21.4 22.1
MNEG
– 55.2 34.1 44.8 40.3 25.9 33.9 31.7 29.2 22.3 30.1 34.8
MSIM
k=1 54.3 33.2 45.1 39.3 26.0 33.9 31.4 29.1 23.8 30.8 34.7
k=2 54.3 32.0 43.3 38.8 24.6 32.7 30.0 28.4 22.1 27.1 33.3
k=4 53.0 31.8 41.6 38.1 24.3 30.9 27.4 25.2 20.1 26.1 31.9
k=8 51.4 30.6 40.1 36.4 22.7 28.7 24.9 24.2 17.8 23.7 30.1
SOFTMAX(binary)
k=1 54.1 32.0 40.4 39.7 25.6 32.1 31.6 27.2 23.1 29.4 33.5
k=2 52.3 32.3 43.7 39.6 25.5 33.4 31.3 28.9 22.8 27.8 33.8
k=4 52.7 31.9 42.4 37.4 25.5 32.2 29.6 27.5 21.0 26.5 32.7
k=8 52.2 31.1 42.1 38.0 23.5 30.0 28.4 25.9 20.8 25.8 31.8
SOFTMAX(ternary)
k=1 53.5 32.0 42.8 38.7 24.2 32.0 31.0 27.6 22.0 28.6 33.2
k=2 52.7 32.7 43.0 38.0 23.9 30.4 29.6 27.1 21.8 27.5 32.7
k=4 52.9 31.7 42.8 37.0 22.9 32.0 29.8 26.9 22.3 27.9 32.6
k=8 51.8 31.6 41.2 36.8 23.1 29.8 27.8 26.1 20.2 25.3 31.4
Table 8: Results in the BLI task across different language pairs and dual-encoder lexical ﬁne-tuning (LEXFIT)
objectives(MNEG,MSIM,SOFTMAX). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 411>


<Paper ID = 412> <Table 0> <Abstractive Summary> =Data Hr #Utt #Spk Maj.Spk Description
S2U PlacesAudio(Harwathetal.,2016) 936 400K 2683 American spontaneousimagecaption
Flickr8kAudio(HarwathandGlass,2015) 46 40K 183
I2U American scriptedimagecaption
SpokenCOCO(thiswork) 742 605K 2353
LJSpeech(Ito,2017) 24 13K 1 American readnon-ﬁctionbooks
U2S
VCTK(Veauxetal.,2017) 44 40K 109 British readnewspaper
Table 1: Speech dataset summary. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 412>


<Paper ID = 412> <Table 1> <Abstractive Summary> =hypothesis evaluation metric (M-SPICE), which
uses sampling-based decoding (instead of beam Table 2: Subjective evaluation of U2S models trained
search)togenerateasetofcaptions. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 412>


<Paper ID = 412> <Table 2> <Abstractive Summary> =(2020b) N/A - - - - - 0.035 0.113 0.232 0.080 -
word 0.315 0.253 0.533 0.984 0.185 0.216 0.207 0.469 0.550 0.149
SAT char 0.289 0.239 0.512 0.879 0.172 0.190 0.190 0.441 0.476 0.136
VQ3 0.186 0.186 0.446 0.584 0.127 0.116 0.141 0.390 0.232 0.091
word 0.339 0.265 0.551 1.062 0.196 0.225 0.215 0.483 0.584 0.155
SAT-FT char 0.323 0.256 0.536 1.002 0.187 0.191 0.196 0.450 0.519 0.143
VQ3 0.233 0.212 0.478 0.732 0.149 0.125 0.145 0.391 0.245 0.095
Table 4: Word-based caption evaluation using BLEU-4, METEOR, ROUGE, CIDEr, and SPICE. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 412>


<Paper ID = 413> <Table 0> <Abstractive Summary> =2missingmodalities (audio,video,text) 62.82 61.43 56.00 56.00
(audio,video,text) 63.94 60.98 48.00 57.00
0missingmodality (text,audio,video) 82.85 82.77 66.00 70.00
4.2 Experimentresultsandanalysis
Table 2: Multimodal fusion results of SeqSeq2Sent
and CTFN with missing modalities. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 413>


<Paper ID = 414> <Table 0> <Abstractive Summary> =BERT-clip 10 0.5 68.4%
RoBERTa-clip 11 0.6 69.9%
TherightplotinFigure6showsthat,similarly
totheﬁndingsin(Ethayarajh,2019),aword’sself- Table 1: The best accuracy scores on WiC dataset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 414>


<Paper ID = 414> <Table 1> <Abstractive Summary> =RoBERTa 88.4%(8) 91.5%(9) 46.9%(7)
Afterclipping
4.3 Sentenceembedding BERT-clip 85.4%(12) 86.4%(10) 46.1%(12)
RoBERTa-clip 88.7%(8) 91.6%(9) 47.0%(7)
Venturingbeyondtheword-level,wealsohypothe-
sizethatoutlierclippingcanleadtobettersentence Table 3: The best accuracy scores on different super-
embeddings when relying on the cosine similar- visedtasks. </Abstractive Summary> <Extractive Summary> Here, we hypothesize that clipping such
Table 1 shows that after clipping outliers, the
dimensionscanlikewiseaidinintrinsicsemantic
best accuracy scores of BERT and RoBERTa in-
tasks,likedifferentiatingsensesofaword.  </Extractive Summary>  </Table 1>  </Paper ID = 414>


<Paper ID = 414> <Table 2> <Abstractive Summary> =ForBERT-large,wezero-outthe896th neuron
1 2
GradientClipping 0.5 from the ﬁrst layer to the tenth layer, the 678th
neuron from the tenth layer to the seventeenth
Table 4: Hyper-parameters for pre-training our
layer, the 122nd neuron from the sixteenth layer
RoBERTa-basemodels. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 414>


<Paper ID = 414> <Table 3> <Abstractive Summary> =Baseline - - 50.0%
Beforeclipping
BERT-distil 5 0.9 66.5%
RoBERTa-distil 5 0.9 63.7%
BERT-large 12 0.7 70.2%
RoBERTa-large 10 0.9 70.4%
Afterclipping
BERT-distil-clip 6 0.6 67.3%
RoBERTa-distil-clip 5 0.6 66.7%
BERT-large-clip 12 0.6 70.3%
RoBERTa-large-clip 16 0.6 71.3%
Table 5: The best accuracy scores on WiC dataset for
distilledandlargemodels. </Abstractive Summary> <Extractive Summary> 5318Table 3 shows that there is little difference in lihood.  </Extractive Summary>  </Table 3>  </Paper ID = 414>


<Paper ID = 415> <Table 0> <Abstractive Summary> =5333Rank–Frequency Unigram
Dp✓ Dpˆ Dp TVD
Model R N B R N B R N B R N B
Transformer 0.150 0.145 0.170 0.150 0.142 0.170 3.7e-3 0.029 0.024 6.9e-3 6.9e-3 6.9e-3
Transformer(AS) 0.145 0.142 0.150 0.143 0.142 0.142 0.013 0.041 0.046 0.014 0.014 0.038
CNN 0.145 0.142 0.167 0.144 0.142 0.167 0.013 0.039 0.022 6.9e-3 6.9e-3 8.6e-3
LSTM 0.147 0.143 0.175 0.144 0.142 0.178 0.016 0.043 0.034 3.4e-3 0.010 9.2e-3
Trigram 0.151 0.148 0.119 0.154 0.146 0.152 4.9e-3 0.020 0.251 2.9e-3 3.0e-3 0.075
Table 2: KS metrics (lower implies closer ﬁt) between models’ empirical cdf and reference cdfs for the rank–frequency
relationship. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 415>


<Paper ID = 416> <Table 0> <Abstractive Summary> =L2E 91 66 65 94 70 70 A 1.87±0.67 4.48±0.89 1.18±0.46
Both 85 73 100 89 77 92 LRP L2E 2.09±0.7 3.68±0.86 0.92±0.37
A 97 95 67 85 83 62 A 11.06±0.86 5.7±1.51 1.41±0.44
LRP L2E 90 83 67 86 85 52 LIME L2E 11.31±0.53 5.26±0.91 1.41±0.44
Both 93 84 100 90 83 90 A 4.33±1.21 0.22±0.37 1.96±0.28
A 100 86 67 99 84 71 K’SHAP L2E 3.24±0.92 2.81±0.65 1.97±0.24
LIME L2E 96 81 65 98 82 80 A 1.16±0.54 4.82±2.65 1.22±0.58
Both 96 81 98 97 80 89 D’SHAP L2E 2.25±0.72 7.61±1.86 1.02±0.48
A 79 34 63 70 23 72
K’SHAP L2E 89 70 63 90 70 72
Table 2: Positive ∆log-odds when employing the Se-
Both 80 58 100 74 51 100
quenceLabelingformulation;boldindicatesstatistical
A 82 68 65 81 70 59
D’SHAP L2E 77 70 65 82 73 59 signiﬁcance; the experimental results also show that
Both 76 64 100 78 69 100 L2E never performs signiﬁcantly worse than A; miss-
ingentriesareduetoallwordsbeingconsideredaspos-
Table1: Percentageagreementoftheblack-boxmodel itivelyimportant. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 416>


<Paper ID = 416> <Table 1> <Abstractive Summary> =A 0.03±0.04 0.06±0.09 0.03±0.04
K’SHAP
L2E 0.45±0.17 0.69±0.59 0.45±0.17 Ourexperimentalresultsshowthatourmethod
D’SHAP A 4.29±0.18 3.33±0.29 1.61±0.13 cangeneratemorestableexplanations(i.e.,notvary
L2E 4.39±0.25 4.02±0.3 2.37±0.17
muchacrosssimilardocuments)thanthosegener-
Table 5: Intersection over Union (IoU) using lexical atedbytheexplainerbaselines,whilemaintaining
similarity for the IMDB-R test set; bold indicates sta- the same level of faithfulness to the underlying
tisticalsigniﬁcance. </Abstractive Summary> <Extractive Summary> Table 1 shows the Prediction-based agreement
Table2presentsthe∆log-oddsresultsforpos-
betweentheblack-box modelf andourmethod
θθθ
itiveexplanationwordsintheSequenceLabeling
L2E,betweenf andtheunderlyingexplainerA,
θθθ
formulation.  </Extractive Summary>  </Table 1>  </Paper ID = 416>


<Paper ID = 416> <Table 2> <Abstractive Summary> =L2E 0.05±0.29 0.87±0.41 1.48±0.33
Table 9: ∆log-odds when employing the Ranking for-
A -0.4±0.26 1.51±1.24 1.05±0.71
LIME mulation;boldindicatesstatisticalsigniﬁcance. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 416>


<Paper ID = 416> <Table 3> <Abstractive Summary> =We also remove 8 very long documents
Table 8: Negative ∆log-odds when employing the Se-
fromthetrainingsetforthesakeofCUDAmemory. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 416>


<Paper ID = 417> <Table 0> <Abstractive Summary> =The correlation be-
3Apr2020arXiv:2004.09456 tween lms and ss is unfortunate and perhaps un-
5362Model Language Stereotype Idealized Model Language Stereotype Idealized
Model Score CAT Model Score CAT
Score (ss) Score Score (ss) Score
(lms) (icat) (lms) (icat)
Testset IntrasentenceTask
IDEALLM 100 50.0 100 BERT-base 82.5 57.5 70.2
STEREOTYPEDLM - 100 0.0 BERT-large 82.9 57.6 70.3
RANDOMLM 50.0 50.0 50.0
SENTIMENTLM 65.1 60.8 51.1 ROBERTA-base 71.9 53.6 66.7
ROBERTA-large 72.7 54.4 66.3
BERT-base 82.3 57.1 70.7
BERT-large 81.1 58.0 68.1 XLNET-base 70.3 53.6 65.2
XLNET-large 74.0 51.8 71.3
ROBERTA-base 83.5 58.5 69.4
GPT2 91.0 60.4 72.0
ROBERTA-large 83.4 59.8 67.0
GPT2-medium 91.2 62.9 67.7
XLNET-base 60.5 52.4 57.6 GPT2-large 91.8 63.9 66.2
XLNET-large 61.3 54.0 56.5
ENSEMBLE 91.7 63.9 66.3
GPT2 86.8 59.0 71.1
IntersentenceTask
GPT2-medium 88.6 61.6 68.0
GPT2-large 89.6 62.7 66.8 BERT-base 88.3 61.7 67.6
BERT-large 88.7 60.6 71.0
ENSEMBLE 90.1 62.2 68.1
ROBERTA-base 64.4 47.4 61.0
Table 5: Performance of pretrained language mod- ROBERTA-large 78.8 55.2 70.6
els on the StereoSet test set, measured using psuedo- XLNET-base 65.0 54.6 59.0
likelihoodscoringforthemaskedlanguagemodels. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 417>


<Paper ID = 417> <Table 1> <Abstractive Summary> =Amongst the models, GPT2 exhibits more Table 6: Performance on the Intersentence and In-
unbiased behavior than other models (icat score trasentence CATs on the StereoSet test set, measured
usinglikelihood-basedscoring. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 417>


<Paper ID = 417> <Table 2> <Abstractive Summary> =ENSEMBLE 89.1 61.1 69.9
8 Conclusions
Table 7: Performance on the Intersentence and In-
trasentence CATs on the StereoSet test set, measured In this work, we develop the Context Association
usingpsuedo-likelihoodscoring. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 417>


<Paper ID = 417> <Table 3> <Abstractive Summary> =We used a maximum se- Table 9: A collection of neutral associations from
crowdworkers. </Abstractive Summary> <Extractive Summary> Table 3 shows the top keywords of thebiasesofpretrainedlanguagemodels(andnot
eachdomain.  </Extractive Summary>  </Table 3>  </Paper ID = 417>


<Paper ID = 418> <Table 0> <Abstractive Summary> =(MA2al*xi1-g*Fn11m/:e3n)t/ (P1l+a1/u3s)i=b0i.l5ity: Table 3: Re-evaluation results of different mod-
w  Exact-Inc:
 not included => 0 els including rationale plausibility besides accu-
 Soft-Inc:
 2/6=0.33 racy. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 418>


<Paper ID = 418> <Table 1> <Abstractive Summary> =predicateandassignsemanticrolelabelstothem,
5379HANS
Methods
Entailment Non-Entailment
Avg
Lex Sub Cons Lex Sub Cons
DA 97.18 96.02 97.62 2.66 1.76 3.00 49.71
ESIM 99.68 98.76 99.60 0.18 0.12 4.22 50.43
BERT 98.82 100.00 99.86 43.02 2.94 3.82 58.08
DA 93.66 96.64 96.36 88.24 25.88 3.28 67.34
SRLGUID
ESIM 93.94 96.76 99.42 99.10 32.28 5.30 71.13
SRLGUID
BERT 96.24 99.36 99.74 96.26 29.44 0.24 70.21
SRLGUID
BERT‡ 91.00 98.00 95.00 71.00 13.00 25.00 66.00
SRLMTL
Table 4: Accuracy performances of different models across different datasets. </Abstractive Summary> <Extractive Summary> Thatisan
uation results are shown in Table 1 and Table 2 appealingtheoreticaladvantageofourmethod.  </Extractive Summary>  </Table 1>  </Paper ID = 418>


<Paper ID = 419> <Table 0> <Abstractive Summary> =In our exper-
iments, we adopt an odd number of local tensors
Table 2: Inference time complexities of different low-
forMPOdecomposition,i.e.,ﬁvelocaltensors(see
rankapproximationmethods.Here,ndenotesthenum-
supplementarymaterials). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 419>


<Paper ID = 419> <Table 1> <Abstractive Summary> =Experiments Score
(acc) (m_cc) (acc) (mcc) (ρ) (acc) (acc) (acc) (acc) #Pr/#To(M)
ALBERT - 90.3 81.6 - - - - - - - 11.6/11.6
pub
ALBERT 78.9 90.6 84.5 89.4 53.4 88.2 89.1 88.5 71.1 54.9 11.6/11.6
rep
MPOP 79.7 90.8 83.3 90.5 54.7 89.2 89.4 89.2 73.3 56.3 1.1/9
MPOP 80.3 92.2 84.4 91.4 55.7 89.2 89.6 87.3 76.9 56.3 12.7/12.7
full
MPOP 80.4 93.0 84.3 91.3 56.0 89.2 89.0 88.0 78.3 56.3 1.2/12.7
full+LFA
MPOP 68.6 86.6 79.2 81.9 15.0 82.5 87.0 74.3 54.2 56.3 1.1/9
dir
Table 3: Performance on GLUE benchmark obtained by ﬁne-tuning ALBERT and MPOP. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 419>


<Paper ID = 42> <Table 0> <Abstractive Summary> =Direction 22 2.8 24 3.7 25 3.5 ...headstraighttothelightandmakearight...
Temporalcondition 7 0.4 21 1.9 7 0.3 ...gostraightuntilyoucometotheendofagardenarea...
Stateveriﬁcation 2 0.1 18 1.5 12 0.6 ...youshouldseebikerentalsonyourright...
Table 2: Linguistic analysis of 25 randomly sampled navigation instructions. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 42>


<Paper ID = 42> <Table 1> <Abstractive Summary> =Figure6 craftedsalientscoresusedinworkingeoinformat-
499Reference Model
TEST UNSEEN 200 INSTANCES
1.0 Top OSMtag Score OSMtag Score
reference 1 amenity: bank 0.41 amenity: pharmacy 0.39
rule_based 2 leisure: park 0.35 shop: furniture 0.38
RATE0.8 ggr2atp+hp2retetrxatin 34 ashmoepn:ity: pfuhranrimtuarcey 00..3320 alemiseunriet:y: bgaarndken 00..3279
SS  5 cuisine: burger 0.29 cuisine: burger 0.28
CCE0.6 6 leisure: garden 0.29 shop: supermarket 0.25
SU 7 cuisine: coffeeshop 0.26 cuisine: coffeeshop 0.25
ON  8 amenity: placeofworship 0.25 cuisine: american 0.24
ATI0.4 9 cuisine: american 0.23 shop: convenience 0.22
VIG 10 amenity: bicyclerental 0.23 cuisine: italian 0.21
A
N0.2
Table 5: Frequency of OSM tags of landmark occur-
rencesintheinstructionsforthepartiallyseentestset,
0.0
3 (51) 4 (94) 5 (46) >=6 (14) normalized by the number of occurrences in the input
NUMBER OF INTERSECTIONS IN ROUTE (#INSTANCES)
graph. </Abstractive Summary> <Extractive Summary> Table 1 gives a comparison of whileourannotatorshaveatimeindependentlook
differentdatasetswithnaturallanguagelandmark attheroute.  </Extractive Summary>  </Table 1>  </Paper ID = 42>


<Paper ID = 42> <Table 2> <Abstractive Summary> =TEST PARTIALLY SEEN 200 INSTANCES
1.0
reference
rule_based Reference Model
ATE0.8 ggr2atp+hp2retetrxatin T1op amenityO:SMcintaegma S0.c5o8re cuisine:OSMjuticaeg S0.c6o4re
R
SS  2 shop: wine 0.53 amenity: pharmacy 0.55
CE0.6 3 shop: computer 0.53 shop: convenience 0.50
C
SU 4 amenity: pharmacy 0.51 amenity: cinema 0.46
ON  5 cuisine: coffeeshop 0.49 cuisine: coffeeshop 0.46
ATI0.4 6 tourism: hotel 0.44 shop: computer 0.45
VIG 7 shop: convenience 0.42 tourism: hotel 0.41
NA0.2 8 shop: houseware 0.31 shop: pet 0.39
9 shop: supermarket 0.31 shop: beauty 0.38
10 amenity: bank 0.28 shop: wine 0.38
0.0
3 (69) 4 (74) 5 (35) >=6 (22) Table 6: Frequency of OSM tags of landmark occur-
NUMBER OF INTERSECTIONS IN ROUTE (#INSTANCES)
rences in the instructions for the unseen test set, nor-
Figure7: Navigationsuccessrateinrespectofnumber malized by the number of occurrences in the input
ofintersectionsinaroute. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 42>


<Paper ID = 420> <Table 0> <Abstractive Summary> =(cid:55) (cid:88) (cid:88)(cid:88) (cid:55) (cid:88) (cid:88)(cid:88)
Sag(K=10) 14.22 17.17 21.74 15.89 22.65 23.92
Sag(K=100) 14.65 15.10 19.83 15.97 19.54 21.32
Lag(K=10) 21.63 25.66 65.41 38.20 08.60 78.03
MAMS
Lag(K=100) 26.07 25.66 62.52 43.19 06.27 75.02
Ral(-top20%) 09.80 05.64 03.55 09.80 11.89 16.05
Ral(-top50%) 28.55 01.47 18.14 22.30 05.64 18.14
Sag(K=10) 04.69 04.75 22.54 03.07 00.98 26.21
Sag(K=50) 03.56 07.82 22.21 01.78 01.61 23.43
Lag(K=10) 53.00 41.91 61.96 55.91 18.22 66.65
sentihood
Lag(K=50) 56.38 44.05 63.16 59.66 17.49 66.72
Ral(-top20%) 10.56 16.21 06.91 09.23 06.91 09.23
Ral(-top50%) 16.21 18.53 11.05 27.83 9.23 4.58
Table 3: Performance of difference explanation methods on 200 test cases on each dataset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 420>


<Paper ID = 420> <Table 1> <Abstractive Summary> =anunpretentioussexyatmospherelendsitselftotheaboveaveragewine-list
IF +
andamenuthatcanstand-uptoanyotherrestaurant...
Table 5: Showcasing Top-1 Explanations. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 420>


<Paper ID = 421> <Table 0> <Abstractive Summary> =Fortherest10%probability,thedistancewill Table 1: The statistics of the entity typing datasets,
bemaintained. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 421>


<Paper ID = 421> <Table 1> <Abstractive Summary> =(2020) to use
[<sep>,quesiton,</sep>,paragraph,</sep>]
Table 3: The statistics of the question answering
datasets: SearchQA,Quasar-TandCosmosQA. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 421>


<Paper ID = 421> <Table 2> <Abstractive Summary> =We speculate that Cos-
mosQArequirescapacityforcontextualcommon-
Table 5: Results for relation classiﬁcation task on TA-
sensereasoningandthelackofexplicitlyinjection
CREDdataset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 421>


<Paper ID = 423> <Table 0> <Abstractive Summary> =Con-
5https://www.suning.com cretely, we use the JS divergence as the distance
5439Table 2: Experimental results (F ; %) of all methods on all benchmark datasets (higher is better). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 423>


<Paper ID = 427> <Table 0> <Abstractive Summary> =in Table 5 to encode the premise and hypothesis
5491Table 6: Training hyperparameters for the text classi- • We applied a “bert-base-uncased” architec-
ﬁcation (BOW, CNN, and LSTM) models. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 427>


<Paper ID = 427> <Table 1> <Abstractive Summary> =Table 7: Hyperparameters of DNE for text classiﬁca-
WereportinTable7thehyperparametervalues
tionandnaturallanguageinferencetasks. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 427>


<Paper ID = 428> <Table 0> <Abstractive Summary> =32 21.6k 17.66
64 22.6k 17.56
32 22.0k 20.53 2.0k 49
128 22.9k 17.47
64 23.8k 19.07 4.1k 51
256 22.5k 17.50
128 24.4k 18.37 7.9k 50
256 23.5k 17.92 12.8k 48 PIA+Cachew/o
21.5k 17.85
512 21.5k 17.85 14.5k 46 StagedTraining
768 17.6k 18.16 13.8k 43
1024 16.6k 18.19 13.9k 39
Table 4: Dev. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 428>


<Paper ID = 428> <Table 1> <Abstractive Summary> =Table 3: Dev. </Abstractive Summary> <Extractive Summary> Thus, the result shown in Table 1 for
4Forconsistency,throughoutthepaperweruninference thatmodelwithS = 1canalsobeachievedwithS = 512
with a batch size of one.  </Extractive Summary>  </Table 1>  </Paper ID = 428>


<Paper ID = 428> <Table 2> <Abstractive Summary> =Thisresultisveryrobusttohyperpa-
rameterchanges,asallmodelstrainedwithinitial
Table 8: Total time needed to train each model as a
subsequence length of between 64 and 512, that fractionofthetimeneededforbaselinetraining. </Abstractive Summary> <Extractive Summary> Althoughallmodelstakelesstimetotrainthan
4.1 StagedTraining the baseline, Table 2 shows that many outper-
We propose a two-stage training routine that ini- form it. Table 2 shows that all models with an
tionalgorithmbetweenthetwostages.  </Extractive Summary>  </Table 2>  </Paper ID = 428>


<Paper ID = 428> <Table 3> <Abstractive Summary> =15.5k 13.40 10.88
Table 11: Comparison of our best models to other
strongLMstrainedontheTorontoBookCorpus(TBC). </Abstractive Summary> <Extractive Summary> by-tokengenerationintheunmodiﬁedtransformer Table 3 compares the results of our models
(withsubsequencelengthL),attentiontakesO(L2) that use PIA and caching to the baseline on the
time(sincethereareLqueriesandLkeys).  </Extractive Summary>  </Table 3>  </Paper ID = 428>


<Paper ID = 43> <Table 0> <Abstractive Summary> =FromTable5,wecanseethat
bothaddingmoreTransformerencoderlayersand
Table 4: Results of the inference comparison of dif-
ferentpre-trainedmodelarchitecturesontheVQAand usingmorecomplicatedvisualbackbonescancon-
NLVR2dataset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 43>


<Paper ID = 43> <Table 1> <Abstractive Summary> =448 746 3x 72.04 75.79
600 1000 1.5x 73.08 76.87
800 1333 - 73.25 77.25
References
Table 6: Impact of input image size on the VQA and PeterAnderson,XiaodongHe,ChrisBuehler,Damien
NLVR2set. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 43>


<Paper ID = 43> <Table 2> <Abstractive Summary> =E2E-VLP 41.9 62.6 20.3 45.6 61.1
Stanislaw Antol, Aishwarya Agrawal, Jiasen Lu, Mar-
Table 7: Results of object detection on MSCOCO de- garet Mitchell, Dhruv Batra, C Lawrence Zitnick,
velopmentdataset and Devi Parikh. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 43>


<Paper ID = 430> <Table 0> <Abstractive Summary> =Inthefollowingsubsections,wedis-
Table 3: Results of pre-training methods. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 430>


<Paper ID = 430> <Table 1> <Abstractive Summary> =SCE 128 200 xn:1.0 - - - 0.3 0.4 Adam 0.0005 - - All All - -
SCEw/LS 128 200 xn:1.0 - - - 0.3 0.4 Adam 0.0005 - - All All 0.3 -
TuckER
NS 128 200 xn:1.0 - - - 0.3 0.4 Adam 0.0005 - - All All - -
SANS 128 200 xn:1.0 - - - 0.3 0.4 Adam 0.0005 - - All All - 1.0
SCE 512 128 n:0.123 - - - 0.427 0.159 Adam 7.39E-5 0.95 1 All All - -
SCEw/LS 512 128 n:0.123 - - - 0.427 0.159 Adam 7.39E-5 0.95 1 All All 0.3 -
Rescal
NS 256 128 xn:1.0 lp:3 1.22E-12 4.80E-14 0.347 - Adagrad 0.0170 0.95 5 22 155 - -
SANS 256 128 xn:1.0 lp:3 1.22E-12 4.80E-14 0.347 - Adagrad 0.0170 0.95 5 22 155 - 1.0
SCE 512 128 u:0.311 - - - 0.0476 0.443 Adagrad 0.503 0.95 7 All All - -
SCEw/LS 512 128 u:0.311 - - - 0.0476 0.443 Adagrad 0.503 0.95 7 All All 0.3 -
ComlEx
NS 512 256 n:4.81E-5 lp:2 6.34E-9 9.08E-18 0.182 0.0437 Adagrad 0.241 0.95 4 1 48 - -
SANS 512 256 n:4.81E-5 lp:2 6.34E-9 9.08E-18 0.182 0.0437 Adagrad 0.241 0.95 4 1 48 - 1.0
SCE 512 128 n:0.806 - - - 0.370 0.280 Adam 0.00063 0.95 1 All All - -
SCE 512 128 n:0.806 - - - 0.370 0.280 Adam 0.00063 0.95 1 All All 0.3 -
DistMult
NS 1024 256 u:0.848 lp:3 1.55E-10 3.93E-15 0.455 0.360 Adagrad 0.141 0.95 9 557 367 - -
SANS 1024 256 u:0.848 lp:3 1.55E-10 3.93E-15 0.455 0.360 Adagrad 0.141 0.95 9 557 367 - 1.0
SCE 128 128 u:1.0E-5 - - - - - Adam 0.0003 0.95 5 All All - -
SCEw/LS 128 128 u:1.0E-5 - - - - - Adam 0.0003 0.95 5 All All 0.01 -
TransE
NS 1024 1000 xu:1.0 - - - - - Adam 0.00005 0.95 5 256 256 - -
SANS 1024 1000 xu:1.0 - - - - - Adam 0.00005 0.95 5 256 256 - 1.0
SCE 1024 1000 xu:1.0 - - - - - Adam 0.00005 0.95 5 All All - -
SCEw/LS 1024 1000 xu:1.0 - - - - - Adam 0.00005 0.95 5 All All 0.01 -
Rotate
NS 1024 1000 xu:1.0 - - - - - Adam 0.00005 0.95 5 256 256 - -
SANS 1024 1000 xu:1.0 - - - - - Adam 0.00005 0.95 5 256 256 - 1.0
Table 5: The hyper-parameters for each model in FB15k-237. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 430>


<Paper ID = 431> <Table 0> <Abstractive Summary> =Moreover, our model
5537Surface-LevelFidelity LogicalFidelity
Model Type
BLEU-1 BLEU-2 BLEU-3 SP-Acc NLI-Acc
Non-PretrainedModels
Field-Gating+LSTM - 42.3 19.5 6.9 38.0 56.8
Field-Gating+Trans - 44.1 20.9 8.3 38.5 57.3
Field-Infusing+LSTM - 43.1 19.7 7.1 38.6 57.1
Field-Infusing+Trans - 43.7 20.9 8.4 38.9 57.3
CVAE+Field-Infusing+Trans - 46.4 23.1 9.4 39.8 59.0
DCVED+Field-Infusing+Trans - 46.2 22.9 9.8 42.6 61.2
DCVED+Field-Infusing+Trans TrainedSelector 47.4 23.4 10.6 42.1 62.5
DCVED+Field-Infusing+Trans OracleNLI-Accz 45.0 22.2 9.0 41.7 86.8
DCVED+Field-Infusing+Trans OracleBLEU-3z 55.2 32.9 15.9 41.8 60.3
PretrainedModels
BERT-TabGen - 47.8 26.3 11.9 42.2 68.1
GPT-TabGen - 48.8 27.1 12.6 42.1 68.7
GPT-TabGen Adv-Reg 45.8 23.1 9.6 40.9 68.5
GPT-TabGen RL 45.1 23.6 9.1 43.1 67.7
GPT-Coarse-to-Fine - 46.6 26.8 13.3 42.7 72.2
CVAE+GPT-TabGen - 49.0 27.9 13.5 42.6 71.8
DCVED+GPT-TabGen - 49.3 28.3 14.2 44.3 73.9
DCVED+GPT-TabGen TrainedSelector 49.5 28.6 15.3 43.9 76.9
DCVED+GPT-TabGen OracleNLI-Accz 49.7 28.5 14.5 46.1 92.2
DCVED+GPT-TabGen OracleBLEU-3z 59.7 38.0 22.1 45.0 74.2
Table 2: The experimental results of different models on the test split of LogicNLG dataset, where we split the
table into non-pretrained and pretrained models. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 431>


<Paper ID = 431> <Table 1> <Abstractive Summary> =Surface-LevelFidelity LogicalFidelity
Model Type
BLEU-1 BLEU-2 BLEU-3 SP-Acc NLI-Acc
Non-PretrainedModels
Field-Infusing+Trans - 37.7 21.0 10.5 38.5 42.4
CVAE+Field-Infusing+Trans - 37.1 20.4 9.3 38.1 41.6
DCVED+Field-Infusing+Trans - 38.8 21.6 10.7 40.9 45.2
DCVED+Field-Infusing+Trans TrainedSelector 39.4 22.0 11.0 40.4 48.2
DCVED+Field-Infusing+Trans OracleNLI-Accz 38.5 21.5 10.9 41.3 72.5
DCVED+Field-Infusing+Trans OracleBLEU-3z 45.6 29.0 16.7 40.8 44.7
PretrainedModels
GPT-TabGen - 46.5 30.9 19.9 42.4 66.5
CVAE+GPT-TabGen - 46.2 30.8 19.7 41.0 67.8
DCVED+GPT-TabGen - 46.4 31.2 20.1 43.7 71.9
DCVED+GPT-TabGen TrainedSelector 48.9 32.7 21.4 43.9 73.8
DCVED+GPT-TabGen OracleNLI-Accz 46.5 31.2 20.1 43.8 89.9
DCVED+GPT-TabGen OracleBLEU-3z 52.1 37.5 26.1 43.5 72.0
Table 3: The experimental results of different models on the test split of Logic2Text dataset, where we split the
tableintonon-pretrainedandpretrainedmodels.Theboldrepresentsthebestscores.Oracle-xrepresentstheupper
boundofthegeneratedsentences. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 431>


<Paper ID = 431> <Table 2> <Abstractive Summary> =We randomly select 200 tables in
Table 4: The performances of ablated models as well
theLogicNLGdataset, andgenerateonesentence
asthefullmodelonthetwodatasets. </Abstractive Summary> <Extractive Summary> 2
5.2 EvaluationandSettings
5.3 MainResults
Themodelsareevaluatedonthesurface-levelcon-
Table 2 and 3 present the performance of our
sistency and the logical ﬁdelity.  </Extractive Summary>  </Table 2>  </Paper ID = 431>


<Paper ID = 432> <Table 0> <Abstractive Summary> =From the top heat map in Figure 4 we can see,
Table 3: Results in the APMF setting. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 432>


<Paper ID = 432> <Table 1> <Abstractive Summary> =backdoored 93.49 95.66 95.78 95.70 95.80
As for how to defend against our proposed
stealthy attacking method, since we ﬁnd the at-
Table 4: We insert different sentences containing trig-
tentionscoresofthe[CLS]tokenwillmainlycon-
gerwordsforattacking:(1)“Ihavewatchedthismovie
with my friends at a nearby cinema last weekend”, centrate on one trigger word by our method, we
(2) “My friends and me watched it at a cinema last thinkanextremelyabnormalattentiondistribution
weekend”, (3) “Last weekend I went to the cinema to couldbeanindicatorimplyingthattheinputcon-
watcheditwithfriends”and(4)“Iandmyfriendswent tainsthebackdoortriggers. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 432>


<Paper ID = 432> <Table 2> <Abstractive Summary> =Table 8: Trigger words for each dataset of using SOS
(5)Ihavetriedthisplaceandtheirfood. </Abstractive Summary> <Extractive Summary> RW 80.86 98.84 — 70.36
Jigsaw
SL 81.02 99.49 99.23 1.16
5.3.1 AttackingFinalModel SOS 80.81 98.50 10.27 1.92
Table 2 displays the results in the APM setting.  </Extractive Summary>  </Table 2>  </Paper ID = 432>


<Paper ID = 433> <Table 0> <Abstractive Summary> =(SimpsonandGurevych,2019)† 80.30 74.80 77.40
Table 1: The test results of the unsupervised setting,
3.3 TheSupervisedSetting
wherethesuperscript† indicatesthatthereexistdiffer-
Inspiredbythesuperviseddomainadaptation,we encesinthetestcorpus. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 433>


<Paper ID = 433> <Table 1> <Abstractive Summary> =55621% 5% 25% 100%
Model
P R F1 P R F1 P R F1 P R F1
Annotator-Agnostic
ALL 75.08 74.82 74.95 76.18 75.71 75.94 78.64 78.93 78.78 86.65 82.29 84.42
MV 83.87 67.37 74.72 83.49 69.32 75.75 84.77 79.43 82.01
89.28 89.77 89.52
Gold 69.52 75.41 72.35 76.70 82.14 79.33 81.32 85.39 83.31
Annotator-Aware
LC 78.09 74.10 76.04 79.98 77.18 78.55 77.72 81.06 79.36 87.42 85.64 86.52
LC-cat 75.37 78.54 76.92 74.24 81.32 77.62 76.88 81.37 78.96 88.25 86.03 87.13
ThisWork 80.06 81.91 80.97 83.25 85.36 84.29 85.19 87.46 86.31 89.62 90.51 90.06
Table 2: The test results of the supervised setting, where we add different proportions of the most informative
gold-standard(expert)annotationsincrementally. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 433>


<Paper ID = 433> <Table 2> <Abstractive Summary> =5564Data Full Excluded Part-1 Part-2
79 Full Filtered 83 Full Filtered
Model F1
76 78
ALL 74.36 76.73 74.66 75.92
73 73
ALL LC LC-cat ThisWork ALL LC LC-cat ThisWork LC 76.51 76.80 75.29 76.70
(a) 0% (b) 1% LC-cat 76.79 77.59 74.86 76.02
ThisWork 77.95 78.23 77.41 77.58
85 Full Filtered 88 Full Filtered
Table 4: The unsupervised test results of differently
80 83
sampled datasets. </Abstractive Summary> <Extractive Summary> The observation fur- assumeproportionsof1%,5%,25%,and100%of
thershowsthereasonablenessbyaligningannota- the expert annotations available.4 Table 2 shows
torstodomains,sincedomaininformationisalso alltheresults,includingourfourbaselinesandan
usefulfordomainadaptation.  </Extractive Summary>  </Table 2>  </Paper ID = 433>


<Paper ID = 433> <Table 3> <Abstractive Summary> =Table 5: The comparisons between BERT ﬁne-tuning
Omar F. Zaidan and Chris Callison-Burch. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 433>


<Paper ID = 434> <Table 0> <Abstractive Summary> =(cid:58)(cid:58)(cid:58)(cid:58)(cid:58)
tirelyandequally,whileignoringthepotential
important non-rationale words and not distin-
guishing the importance of different rationale Table 1: An example of rationale annotation for senti-
words. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 434>


<Paper ID = 434> <Table 1> <Abstractive Summary> =Sig.p
Baseline 0.847±0.002 - 0.851±0.003 - 0.698±0.004 -
SL 0.849±0.003 - 0.851±0.004 - 0.704±0.004 -
IGA 0.848±0.002 - 0.852±0.002 - 0.703±0.003 -
+BaseLoss 0.851±0.004 - 0.854±0.004 - 0.705±0.005 -
+GateLoss 0.852±0.003 - 0.854±0.005 - 0.714±0.006 0.044
+OrderLoss 0.862±0.003 0.008 0.862±0.003 0.041 0.715±0.005 0.032
+Gate+Order 0.861±0.004 0.013 0.862±0.003 0.047 0.726±0.008 0.002
Table 2: Performance of our approaches on two dataset with CNN as base model. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 434>


<Paper ID = 435> <Table 0> <Abstractive Summary> =Table 4: The statistics and the data source of SQuAD,
2. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 435>


<Paper ID = 437> <Table 0> <Abstractive Summary> =Asformaxsequence
5616length,batchsize,dropoutratio,andlearningrate, Table 1: Reliability and efﬁciency of HMCEval w.r.t. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 437>


<Paper ID = 437> <Table 1> <Abstractive Summary> =As
shown in Figure 3, when λ increases, the human
Table 3: Conﬁdence prediction results comparison of
ratiostaysat0.5,andafteracertainpivotalpoint,
MCEmethods. </Abstractive Summary> <Extractive Summary> In Table 1 (presented in
Ontheonehand,comparedtohumanevaluation, Section5)andTable6,wechoosetheﬁnalresults
HMCEvalachieves98.2%ofhumanaccuracywith with λ = 4.6 and N = 0.5M, where M is the
50%humaneffortspared.  </Extractive Summary>  </Table 1>  </Paper ID = 437>


<Paper ID = 437> <Table 2> <Abstractive Summary> =Table 6: Reliability and efﬁciency of HMCEval w.r.t. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 437>


<Paper ID = 438> <Table 0> <Abstractive Summary> =OpenSubtitles 87,840 5M 100K 50K
5.4 Humanevaluation
Table 1: Statistics for DailyDialog and OpenSubtitles
Weconducthumanevaluationtofurtherevaluate
datasets. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 438>


<Paper ID = 438> <Table 1> <Abstractive Summary> =Table 5: Generated responses from the baselines and
SepaCVAE. </Abstractive Summary> <Extractive Summary> Table 1 lists key statistics
For a fair comparison among all models, we uti-
of the dataset after processing.  </Extractive Summary>  </Table 1>  </Paper ID = 438>


<Paper ID = 439> <Table 0> <Abstractive Summary> =2http://www.treccast.ai First, RISE signiﬁcantly outperforms all base-
5643Table 1: Overall performance (%) on CANARD and CAsT. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 439>


<Paper ID = 439> <Table 1> <Abstractive Summary> =CANARD(%) CAsT(%)(unseen)
Method B-1 B-2 B-3 B-4 R-L CIDEr B-1 B-2 B-3 B-4 R-L CIDEr
Origin 54.7 47.0 40.6 35.3 70.9 3.460 75.9 69.2 62.9 57.6 85.0 5.946
-DPS 67.5 56.4 47.3 39.9 73.9 3.743 80.9 70.0 60.6 53.3 81.2 4.713
-MLD 85.2 78.6 73.3 68.9 85.2 6.469 75.9 65.3 56.7 59.6 78.0 4.694
RISE 86.3 80.5∗ 75.6∗ 71.6∗ 86.2∗ 6.759∗ 85.1∗ 78.4∗ 72.2∗ 66.8∗ 87.8∗ 6.543∗
editingiterationsincreasesfrom1.2to2.6because Table 3: Examples generated by RISE on CANARD. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 439>


<Paper ID = 44> <Table 0> <Abstractive Summary> =The
(s)
9https://github.com/ChenRocks/UNITER ISDaandL arecorrelatedwithaPearson’scor-
IAIS
520Model ISDa L(s) L(d) ImageRetrieval TextRetrieval
IAIS IAIS
Model R@1 R@5 R@10 R@1 R@5 R@10
UNITER-base 0.26 0.59 0.36
UNITER-base∗ 72.52 92.36 96.08 85.90 97.10 98.80
+IAIS-singular 0.18 1.31e-3 2.58e-3
UNITER-base† 72.70 92.60 96.14 85.50 97.30 98.60
+IAIS-distributed 0.17 2.80e-3 2.72e-3
+IAIS-singular-L 72.74 92.74 96.12 86.90 96.70 99.00
UNITER-large 0.23 0.40 0.16 +IAIS-singular-V 73.44 92.76 95.96 87.00 97.50 99.10
+IAIS-singular 0.18 2.27e-3 3.22e-3
+IAIS-distributed-L 72.48 92.96 96.26 86.90 97.10 99.10
+IAIS-distributed 0.18 3.15e-3 3.70e-3 +IAIS-distributed-V 73.14 92.44 96.06 87.10 97.40 99.20
Table 2: Different relation distance metrics of each Table3: AblationstudyontheFlickr30kdataset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 44>


<Paper ID = 440> <Table 0> <Abstractive Summary> =Considering the “left” relationship,
Table 1: Statistics for DVD: Compared to synthetic
“A1isleftofB2”and“A2isleftofB5”. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 440>


<Paper ID = 440> <Table 1> <Abstractive Summary> =Interms
similar question from the training set and use its ofdialoguecontextualcomplexity,inSection4.4,
5656HRNN HRNN TF
Answer Q-type Q-type Q-retrieval RNN HRNN
Accuracy (C+Q)+ (C+Q)+ (C+Q Human
Prior (Random) (Freq) (TF-IDF) (Q) (C+Q)
CNN(V) TA(V) +V)
All 21.3 27.8 35.3 32.1 39.7 45.8 49.3 50.2 51.1 89.3
Actioncount 0.0 9.3 23.4 19.8 16.3 28.2 37.8 36.0 38.8 87.5
Actionquery 0.0 12.7 23.7 20.6 25.8 33.1 36.7 38.6 39.4 88.1
Attributequery 0.0 32.9 38.7 39.4 38.1 39.2 43.3 45.1 43.1 98.0
Compareactionseq 33.4 34.1 37.3 35.1 45.5 52.5 58.2 57.5 61.6 91.5
Compareactionset 25.1 28.2 36.3 28.2 32.8 40.0 43.0 44.3 45.4 82.9
Compareactionfreq 48.5 50.0 50.5 44.4 58.4 56.9 62.3 65.2 67.1 88.5
Objectcount 0.0 9.1 23.3 18.8 26.2 38.6 40.0 40.2 39.9 90.6
Objectexist 48.9 49.8 51.1 54.4 66.4 67.0 69.2 69.4 69.0 92.3
None 0.0 32.1 38.3 39.0 38.3 39.5 43.1 45.1 43.4 99.1
Atomic(non-spatial) 18.8 26.3 31.9 42.4 47.2 47.8 49.9 50.7 48.9 83.3
Atomic(spatial) 21.2 27.3 35.5 27.6 36.8 46.0 47.5 47.6 47.1 93.9
Compositional 22.8 28.0 35.4 32.1 40.0 45.8 50.2 51.4 53.2 87.1
Transfer(attribute) 0.0 30.7 45.5 37.1 40.8 45.7 54.5 57.3 57.7 100.0
Transfer(spatial) 49.8 42.4 44.9 26.4 29.6 48.1 47.7 47.4 48.0 90.5
Transfer(temporal) 28.9 38.4 22.6 3.0 30.2 53.5 62.2 64.6 69.0 79.8
Table 2: Experiment results on the DVD test split: Models are evaluated by overall accuracy and by question
types(Top),accuracybyvideointervalsinquestion(Center),andtransferabilityaccuracy(Bottom). </Abstractive Summary> <Extractive Summary> As shown in Table 1 DVD
videos and dialogues as they are not designed to contains a higher proportion of unique questions
track active visual objects or relevant video seg- than related benchmarks.  </Extractive Summary>  </Table 1>  </Paper ID = 440>


<Paper ID = 441> <Table 0> <Abstractive Summary> =’M’and’F’refertothemaleandfemalespeakersrespectively
IEMOCAP MELD MMGCN IEMOCAPMELD
DeepGCN 64.46 57.94 w/spkrembedding 66.22 58.65
earlyfusion
DeepGCN 64.62 58.26 w/ospkrembedding 65.76 58.38
latefusion
DeepGCN 64.45 58.18
gatedattention
DeepGCN 62.77 58.21 Table 6: Ablation study of the speaker embedding im-
MFN
DeepGCN 62.37 57.93 pactonERCperformance
MulT
MMGCN 66.22 58.65
Table 4: ERC performance comparison of MMGCN 5.5 ImpactofSpeakerEmbedding
andothermultimodalfusionmethods
SpeakerEmbeddingcandifferentiateinputfeatures
layers IEMOCAP MELD
1 66.12 58.40 from different speakers. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 441>


<Paper ID = 441> <Table 1> <Abstractive Summary> =Asex-
32 66.10 58.42
pected,droppingspeakerembeddinginMMGCN
leadstoperformancedegradation,whichissigniﬁ-
Table 5: ERC performance comparison of MMGCN
cantbyt-testwithp<0.05. </Abstractive Summary> <Extractive Summary> Table 1 shows the distribution of train
itiesencodedbytheGCN.Thefeaturescorrespond-
andtestsamplesforbothdatasets.  </Extractive Summary>  </Table 1>  </Paper ID = 441>


<Paper ID = 442> <Table 0> <Abstractive Summary> =5682Dialogue-levelSpearmanCorrelation
DialogueAspects BERT-R GPT-2 USR S-DiCoh FED DynaEval Human
Coherence 0.229 0.123 0.194 0.038 0.251 0.423 0.809
ErrorRecovery 0.242 0.096 0.170 -0.054 0.165 0.311 0.840
Consistency 0.163 0.091 0.169 0.017 0.116 0.352 0.562
Diversity 0.196 0.147 0.242 0.059 0.449 0.332 0.789
TopicDepth 0.192 0.097 0.341 0.046 0.522 0.439 0.833
Likability 0.281 0.179 0.221 -0.070 0.262 0.398 0.838
Understanding 0.198 0.070 0.172 -0.100 0.306 0.361 0.809
Flexibility 0.253 0.134 0.209 0.044 0.408 0.389 0.816
Informativeness 0.211 0.116 0.288 0.028 0.337 0.396 0.806
Inquisitiveness 0.337 0.071 0.188 -0.054 0.298 0.388 0.769
Overall 0.248 0.123 0.288 -0.073 0.443 0.482 0.830
Turn-levelSpearmanCorrelation
Interestingness 0.235 -0.107 0.085 0.031 0.431 0.289 0.819
Engagement 0.206 -0.086 0.107 0.040 0.318 0.255 0.798
Speciﬁcity 0.327 -0.112 0.095 0.062 0.326 0.272 0.790
Relevance 0.151 -0.105 0.183 -0.051 0.152 0.265 0.753
Correctness 0.081 0.041 0.098 -0.040 0.133 0.216 0.780
SemanticallyAppropriateness 0.044 -0.084 0.201 -0.069 0.177 0.233 0.682
Understandable 0.051 -0.071 0.110 -0.075 0.111 0.185 0.522
Fluency 0.079 -0.151 0.220 -0.007 0.224 0.096 0.714
Overall 0.195 -0.095 0.137 -0.022 0.209 0.264 0.820
Table 3: Comparison of both dialogue and turn level Spearman correlations among state-of-the-art automatic
metrics on the FED evaluation dataset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 442>


<Paper ID = 442> <Table 1> <Abstractive Summary> =In Proceedings of the 56th An-
nual Meeting of the Association for Computational
Table 4: The accuracy scores (%) of DynaEval on
Linguistics (Volume 1: Long Papers), pages 2204–
the test set of Empathetic Dialogue with different
2213, Melbourne, Australia. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 442>


<Paper ID = 442> <Table 2> <Abstractive Summary> =5688Quality Mean Sum Max Prod Quality Mean Sum Max Prod
USR GPT-2
Coherence 0.194 0.111 0.021 0.158 Coherence -0.002 0.123 -0.086 -0.120
ErrorRecovery 0.170 0.083 0.075 0.130 ErrorRecovery 0.034 0.096 -0.057 -0.091
Consistency 0.150 0.169 0.038 0.099 Consistency -0.025 0.091 -0.048 -0.088
Diversity 0.242 0.167 0.235 0.193 Diversity 0.092 0.147 -0.033 -0.145
TopicDepth 0.054 0.097 -0.036 -0.094
TopicDepth 0.341 0.145 0.255 0.295
Likability 0.072 0.179 -0.047 -0.175
Likability 0.221 0.193 0.109 0.126
Understanding -0.027 0.070 -0.062 -0.066
Understanding 0.172 0.112 0.004 0.124
Flexibility 0.056 0.134 -0.032 -0.131
Flexibility 0.209 0.151 0.164 0.129
Informativeness 0.025 0.116 -0.100 -0.112
Informativeness 0.288 0.157 0.171 0.237
Inquisitiveness -0.008 0.071 -0.071 -0.070
Inquisitiveness 0.148 0.099 0.188 0.128
Overall -0.002 0.123 -0.086 -0.120
Overall 0.288 0.166 0.094 0.212
Table 7: Dialogue level Spearman correlation coefﬁ-
Table 5: Dialogue level Spearman correlation coef-
cientsofGPT-2basedcoherencemetricw.r.tdifferent
ﬁcients of USR w.r.t different turn-level aggregation
turn-levelaggregationstrategiesontheFEDdataset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 442>


<Paper ID = 442> <Table 3> <Abstractive Summary> =M servesasanimportanthyperparameterto
controltheinﬂuenceofanutteranceontherestin
Table 6: Dialogue level Spearman correlation coefﬁ-
adialogue. </Abstractive Summary> <Extractive Summary> In both settings, correlationscoresatdialoguelevelarereportedin
Spearman correlations between the scores gener- Table 3 among all the aggregation strategies for
ated by DynaEval and the corresponding human these three metrics.  </Extractive Summary>  </Table 3>  </Paper ID = 442>


<Paper ID = 443> <Table 0> <Abstractive Summary> =(2015) 34 Webquery Function Yes
CodeSearchNet(Husainetal.,2019) 99 Webquery Function Yes
CodeXGLUEWebQueryTest2 1K Webquery Function Yes
CoSQA(ours) 20.6K Webquery Function Yes
Table 1: Overview of existing datasets on code search and code question answering. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 443>


<Paper ID = 443> <Table 1> <Abstractive Summary> =WestudyPythoninthiswork,
Table 2: Selected keywords for our heuristic rules to
and we plan to extend to more programming lan-
ﬁlteroutwebquerieswithoutcodesearchintentinﬁve
guages in the future. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 443>


<Paper ID = 443> <Table 2> <Abstractive Summary> =Augmentations MRR CodeComponent MRR
noaugmentations 54.41 completecode 64.66
+query-rewritten(delete) 55.24 w/oheader 62.01
+query-rewritten(copy) 54.82 w/obody 59.11
+query-rewritten(switch) 55.66 w/odocumentation 58.54
+in-batch 63.51 w/oheader&body 52.89
+in-batch+query-rewritten(delete) 63.41 w/oheader&documentation 43.35
+in-batch+query-rewritten(copy) 63.97 w/obody&documentation 42.71
+in-batch+query-rewritten(switch) 64.66
Table 7: Performance of CoCLR-incorporated Code-
Table6:PerformanceofCodeBERTwithdifferentaug- BERT trained and tested with different code compo-
mentationsinCoCLRoncodesearch. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 443>


<Paper ID = 443> <Table 3> <Abstractive Summary> =5699Categories Keywords
exception,indexoutof,ignore,omit,stderr,
Debugging try...except,debug,nosuchﬁleordirec-
tory,warning,
vs, versus, difference, advantage, beneﬁt,
drawback, interpret, understand, cannot,
can’t,couldn’t,couldnot,howmany,how
much, too much, too many, more, less,
Conceptual whatif, whathappens, whatis, whatare,
when,where,which,why,reason,howdo
...work,how...works,howdoes...work,
need,require,wait,turn...on/off,turning
...on/off,
tutorial,advice,course,proposal,discuss,
Programming suggestion,parameter,argument,statement,
Knowledge class, import, inherit, operator, override,
decorator,descriptor,declare,declaration
console,terminal,openpython,studio,ide,
ipython, jupyter, notepad, notebook, vim,
pycharm,vscode,eclipse,sublime,emacs,
Tools
utm, komodo, pyscripter, eric, c#, access
Usage
control,pip,install,library,module,launch,
version, ip address, ipv, get ...ip, check
...ip,valid...ip,
unicode, python command, “()”, “.”, “ ”,
Others
“:”,“@”,“=”,“>”,“<”,“-”
Table 8: Keywords of queries without code search in-
tentinﬁvecategories. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 443>


<Paper ID = 444> <Table 0> <Abstractive Summary> =(cid:51) 8 42.83 26.37 24.09
Results show that the evaluator, with 27.86%
Table 4: Ablation studies conducted on the validation
BLEUscoreand28.91BLEUscore,ismuchbetter
setsofNIST,WMT’14,andWMT’18. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 444>


<Paper ID = 445> <Table 0> <Abstractive Summary> =5722Stages En⇒DeDe⇒EnEn⇒ChCh⇒En  ( Q  ! ' H
TheFirstStage 5D 7D 4D 3.5D  ' H  ! ( Q
Base  ( Q  ! & K
Fine-TuningStage 4H 5H 3H 2H  & K  ! ( Q
TheFirstStage 10D 12D 7D 6D    
Big
Fine-TuningStage 4.5H 5.5H 4H 2.5H
Table 7: The average running time for the ﬁrst stage  . /  ' L Y H U J H Q F H   
andﬁne-tuningstage. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 445>


<Paper ID = 446> <Table 0> <Abstractive Summary> =Cs El Es Fi Hu Lt Lv Pl Pt Sk Sl Sv AVE Para
Individual 36.14 39.86 41.16 22.95 31.75 32.31 38.12 32.95 35.57 40.51 43.83 33.23 35.70 746.76M
Multilingual 37.87 40.34 41.58 23.03 31.10 33.11 39.22 32.67 36.20 42.05 44.76 33.16 36.26 90.42M
+TS 37.70 40.70 42.05 23.28 31.78 32.90 39.48 33.66 36.09 42.03 44.29 33.14 36.43+0.17 273.77M
+Adapter 38.11 40.23 41.83 23.66 32.00 33.49 39.87 32.85 36.25 42.00 44.63 32.90 36.49+0.23 109.54M
OurMethod-AV 37.84 40.75 42.16 23.71 31.40 33.56 39.95 33.23 36.56 42.09 45.27 33.38 36.66+0.40 90.42M
OurMethod-TE 38.21 40.70 42.22 23.74 31.32 33.55 39.78 32.94 36.58 41.91 44.94 33.07 36.58+0.32 90.42M
+Expansion 38.03 40.59 42.28 23.73 32.47 34.12 40.12 33.95 36.41 42.44 45.30 33.43 36.91+0.65 102.14M
Table 2: BLEU scores on one-to-many translation tasks. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 446>


<Paper ID = 447> <Table 0> <Abstractive Summary> =As
Table 1: Comparison of various approaches to trans-
MSGtaskssufferfromthedatascarcityprob-
ferring pretrained models to single-source and multi-
lem and recent pretrained models have been
source sequence generation tasks. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 447>


<Paper ID = 447> <Table 1> <Abstractive Summary> =–segmentembedding 72.92
Table 6: Ablation study. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 447>


<Paper ID = 447> <Table 2> <Abstractive Summary> =Table 9: Example of multi-source translation. </Abstractive Summary> <Extractive Summary> outperformsimplesentence-anddocument-level
Transformer (i.e., MBART-TRANS and MBART-
3.2 MainResults DOCTRANS) while our framework outperforms
Table 2 shows the results on the automatic post- thesestrongbaselinessigniﬁcantly.  </Extractive Summary>  </Table 2>  </Paper ID = 447>


<Paper ID = 448> <Table 0> <Abstractive Summary> =We sample the
NER F1 Named-entityrecognition 7 Yes 40
bucketswithoutreplacementfromthetrainingset
Table 1: Evaluation datasets. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 448>


<Paper ID = 448> <Table 1> <Abstractive Summary> =FS-
TR 60.40 61.02±0.68 61.20±0.61 61.35±0.49 61.31±0.56
UR 57.05 57.56±0.85 57.83±0.91 58.20±0.93 58.67±1.03 XLT performance improves modestly (XNLI) or
VI 69.82 70.04±0.59 70.14±0.75 70.23±0.63 70.41±0.70
even decreases (PAWSX-ES) compared to ZS-
EN 93.90 - - - -
DE 83.80 84.14±0.40 84.08±0.42 84.04±0.47 84.23±0.66 XLT, even with large K. PAWSX requires a
X FR 86.90 87.07±0.27 87.06±0.37 87.03±0.31 86.94±0.41
WS ES 88.25 87.90±0.54 87.80±0.56 87.84±0.53 87.85±0.75 model to distinguish adversarially designed non-
PA ZH 77.75 77.71±0.37 77.63±0.47 77.68±0.51 77.82±0.64
JA 73.30 73.78±0.75 73.71±1.04 73.48±0.69 73.79±1.28 paraphrasesentencepairswithlargelexicalover-
KO 72.05 73.75±1.30 73.11±1.05 73.79±0.92 73.31±0.61
lap like “Flights from New York to Florida” and
Table 2: Zero-shot (column K = 0) and few-shot “FlightsfromFloridatoNewYork”(Zhangetal.,
(columns K > 0) results (Acc. </Abstractive Summary> <Extractive Summary> Table 1 reports key information target-adaptingtoeverytargetlanguage,thefew-
aboutthedatasets.  </Extractive Summary>  </Table 1>  </Paper ID = 448>


<Paper ID = 448> <Table 2> <Abstractive Summary> =5756MLDoc PAWSX POS NER
K=1 K=8 K=1 K=8 K=1 K=4 K=1 K=4 nt Intersected
DE -37.73 -7.67 -31.11 -30.82 RU -15.89 -3.20 -48.19 -35.77 ou False 2k
FR -38.14 -13.21 -33.02 -32.34 ES -9.51 -0.93 -63.98 -41.53 C True
ES -33.69 -14.38 -33.76 -33.97 VI -7.82 -0.36 -54.41 -41.45 0k
IT -33.63 -12.62 - - TR -15.05 -8.08 -54.35 -34.52
RU -30.66 -11.08 - - TA -13.72 -4.40 -34.70 -24.81 nt Intersected
ZH -37.31 -12.57 -23.74 -23.65 MR -11.34 -3.63 -40.10 -25.68 ou False 2k
JA -29.82 -14.32 -20.97 -20.82 - - - - - C True
KO - - -19.83 -19.68 - - - - - 0k
Table 4: Performance drop when conducting target- nt Intersected 10k
adaptingwithoutsource-training. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 448>


<Paper ID = 448> <Table 3> <Abstractive Summary> =FC+Pooler performs the best among the
5758Full-ModelFinetuning FConly FC+Pooler COS+Pooler FC(reset)+Pooler
K=0 K=1 K=8 K=1 K=8 K=1 K=8 K=1 K=8 K=1 K=8
DE 49.62 51.50±1.58 53.32±0.59 50.82±1.17 52.58±0.63 51.18±1.13 53.17±0.58 37.98±5.53 45.85±2.14 38.52±6.64 49.46±2.21
FR 47.30 49.32±1.34 51.23±0.76 48.19±0.78 49.05±0.93 48.60±1.02 49.97±0.77 39.93±3.50 44.41±1.95 40.12±5.04 47.77±2.00
ES 48.44 49.72±1.24 51.25±0.93 49.03±0.73 49.69±0.57 49.28±0.85 50.21±0.63 40.01±4.33 45.35±2.37 40.89±4.96 47.73±2.33
ZH 40.40 43.19±1.76 46.40±0.93 41.90±1.15 43.34±0.88 42.30±1.37 44.42±0.65 33.10±5.48 38.31±1.87 31.83±7.00 42.07±2.19
JA 38.84 41.95±2.09 44.44±0.69 40.76±1.76 43.14±0.76 41.40±1.74 43.81±0.56 34.36±4.19 38.95±1.80 32.80±5.17 41.18±1.68
Table 6: Accuracy (%) on MARC when varying classiﬁer head conﬁgurations. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 448>


<Paper ID = 448> <Table 4> <Abstractive Summary> =MLDoc MARC XNLI PAWSX POS NER
98.1 65.1 83.5 94.5 95.6 84.3
B Languages
1e-5 1e-5 3e-5 1e-5 1e-5 1e-5
Table 7: Source-training validation performance (%) Weworkon40languagesintotal. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 4>  </Paper ID = 448>


<Paper ID = 448> <Table 5> <Abstractive Summary> =POS TextA (Lo,PRON),(sanno,VERB),(oramai,ADV),(quasi,ADV),(tutti,PRON),(che,SCONJ),(un,DET),(respiro,NOUN),(affannoso,ADJ)...
NER TextA (Sempat,O),(pindah,O),(ke,O),(HJK,B-ORG),(dan,O),(1899,B-ORG),(Hoffenheim,I-ORG),(yang,O),(meminjamkannya,O),(ke,O)...
Table 8: Example entries of the datasets. </Abstractive Summary> <Extractive Summary> Rewriting W as [w ,...,w ,...,w ], we com-
1 i c
Table 5 shows that “nicht” (“not”) draws high
putethelogitsofaninputsentencerepresentation
attentionchangefrom[CLS].“Nicht”(i.e.,nega- x ∈ Rh (frommBERT)belongingtoclassias
tion) by itself is not a reliable indicator of senti-
(cid:124)
x w
ment,sogivingthelowestscoretoreviewssolely α· i ,
(cid:107)x(cid:107) ·(cid:107)w (cid:107)
becausetheycontain“nicht”isnotagoodstrategy.  </Extractive Summary>  </Table 5>  </Paper ID = 448>


<Paper ID = 448> <Table 6> <Abstractive Summary> =136 401 266 174 23 143 284 219 270 84
60 262 283 322 73 63 163 190 395 189
38 83 127 462 290 32 39 59 314 555
D.2 NumericalValues
Table 10: Numerical value of the confusion matrices
ThenumericalvaluesofthePOSandNERFS-XLT
in Figure 5. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 6>  </Paper ID = 448>


<Paper ID = 448> <Table 7> <Abstractive Summary> =Table 12: Zero- (column K=0) and few- (columns
K>0) shot cross-lingual transfer results (%) on POS
NER POS
testset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 7>  </Paper ID = 448>


<Paper ID = 448> <Table 8> <Abstractive Summary> =K=1 K=2 K=4 K=1 K=2 K=4
AF 4.54 8.75 13.44 4.97 6.11 7.90
AR 0.65 0.95 1.57 3.51 4.49 5.30
BG 0.98 2.19 3.23 - - -
K=0 K=1 K=2 K=4 BN 0.39 0.77 0.80 - - -
EN 83.65 - - - DE 8.75 13.20 20.61 9.36 15.33 21.48
AF 78.36 79.07±1.47 79.69±1.40 80.24±1.16 EL 1.45 1.84 3.59 1.96 2.87 3.04
AR 39.91 54.44±6.74 60.51±4.30 63.61±2.65 ES 6.29 10.59 19.66 10.00 17.53 22.63
BG 78.59 78.65±0.38 78.70±0.39 78.87±0.48 ET 4.80 5.96 11.24 5.81 9.22 13.17
BN 64.17 66.37±1.69 66.66±1.57 65.98±2.11
DE 79.00 79.33±0.71 79.61±0.76 79.74±0.73 EU 3.77 5.55 12.31 2.60 3.45 4.69
EL 75.20 74.93±0.79 75.18±0.95 75.40±0.93 FA 0.27 0.44 1.01 0.37 0.37 0.41
ES 77.16 79.19±1.97 80.28±1.71 80.90±1.94 FI 5.61 9.05 15.66 4.59 7.03 8.78
ET 71.88 72.58±1.17 73.60±1.65 74.60±1.59 FR 6.26 10.83 19.01 15.60 25.23 37.39
EU 55.35 59.60±3.32 61.59±3.84 64.68±2.96 HE 0.86 1.90 3.23 1.22 1.93 2.26
FA 40.73 59.20±5.34 68.55±4.04 71.13±3.45 HI 0.95 1.16 1.99 0.44 0.27 0.51
FI 68.43 71.43±2.61 73.92±2.44 75.81±2.15 HU 5.07 9.19 14.35 3.18 3.92 4.15
FR 80.38 80.54±0.93 81.08±0.85 81.22±0.93
HE 56.36 58.24±2.25 59.43±2.29 60.27±2.43 ID 5.34 9.82 16.94 9.39 13.78 21.75
HI 65.84 67.16±1.61 67.56±2.18 68.29±1.76 IT 7.89 10.94 21.27 11.99 16.15 21.35
HU 71.28 72.23±1.33 73.03±1.44 74.14±1.61 JA 1.75 2.02 2.14 2.60 3.68 5.00
ID 60.10 77.87±6.31 78.57±4.14 81.07±1.50 JV 2.49 3.05 3.44 - - -
IT 80.30 80.68±0.79 81.00±0.92 80.90±1.12 KA 1.99 4.00 5.78 - - -
JA 7.16 20.71±7.07 28.23±5.32 32.93±6.03 KK 0.89 1.22 2.11 - - -
JV 61.18 67.80±4.72 69.79±3.37 72.12±3.34 KO 1.48 1.54 3.32 2.33 3.85 5.67
KA 61.26 61.62±1.09 62.25±1.56 63.68±1.66
KK 40.29 50.42±5.49 54.97±6.81 62.94±4.55 ML 0.36 1.04 1.30 - - -
KO 46.50 47.25±1.36 48.69±1.82 51.76±2.30 MR 0.53 0.56 0.71 0.24 0.24 0.24
ML 46.77 47.83±2.30 49.51±3.01 51.41±3.31 MS 4.86 7.44 13.70 - - -
MR 54.70 55.78±2.54 57.22±2.43 59.18±3.13 MY 0.21 0.36 0.42 - - -
MS 68.61 71.04±3.07 74.51±4.28 76.25±3.04 NL 7.18 10.65 20.14 7.94 11.42 16.79
MY 42.45 43.55±3.88 46.03±4.48 47.81±4.28 PT 6.29 11.00 19.13 8.88 13.38 20.13
NL 82.77 82.73±0.43 82.83±0.54 82.82±0.46 RU 1.60 2.34 3.77 4.15 6.11 9.32
PT 79.28 79.89±0.99 80.39±0.98 80.49±0.95
RU 65.20 67.30±2.38 68.78±2.73 71.34±2.82 SW 5.90 8.10 12.37 - - -
SW 68.36 71.07±4.28 70.08±3.15 74.33±5.25 TA 0.65 1.54 2.08 1.32 1.28 1.62
TA 46.12 47.81±1.81 49.86±2.99 52.23±2.63 TE 0.77 0.80 1.19 0.20 0.20 0.20
TE 50.02 52.57±1.91 54.02±2.65 55.75±2.72 TH 1.63 1.87 2.08 - - -
TH 1.53 4.56±4.87 6.08±4.88 5.87±4.14 TL 4.83 8.96 14.98 - - -
TL 69.23 72.34±2.25 72.63±2.43 73.55±2.25 TR 4.89 8.48 16.43 2.09 2.26 3.01
TR 65.78 69.37±2.24 69.53±2.07 72.33±2.85 UR 0.30 0.27 0.68 0.74 1.35 2.16
UR 40.77 58.48±6.51 63.38±4.88 66.49±4.64
VI 64.67 68.77±3.54 69.64±3.63 71.08±3.28 VI 4.33 8.39 13.41 1.62 2.16 2.90
YO 35.48 53.55±6.19 58.22±5.47 65.46±7.10 YO 1.90 2.58 2.88 - - -
ZH 13.95 32.84±7.10 40.34±5.32 48.49±4.30 ZH 1.81 1.99 2.14 3.04 4.86 7.33
Table 13: Zero- (column K=0) and few- (columns Table 14: Lexical overlap (per-mille) of target lan-
K>0) shot cross-lingual transfer results (%) on NER guages with EN for NER and POS using different K-
testset. </Abstractive Summary> <Extractive Summary> Table 8 shows example entries of
tions in scikit-learn (Pedregosa et al., the datasets.  </Extractive Summary>  </Table 8>  </Paper ID = 448>


<Paper ID = 449> <Table 0> <Abstractive Summary> =bart
Bias CoNLL
dec
randomnamedentity 2.11
wh-word 12.97
emptyquestion 11.24
semanticoverlap 35.32
short-distancereasoning 21.05
Table 8: Proportion of biased examples in CoNLL
dec
dataset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 449>


<Paper ID = 45> <Table 0> <Abstractive Summary> =(2020)d∗ Image+Event Y 12.52 10.73 16.49 42.83 47.40
Ours† Image+Event Y 14.21 11.19 21.23 57.64 58.22
Table 5: Results on VCG validation set with nucleus sampling. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 45>


<Paper ID = 45> <Table 1> <Abstractive Summary> =Tobespeciﬁc,wheneventdescriptionsare
Table 6: Human Evaluation results. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 45>


<Paper ID = 450> <Table 0> <Abstractive Summary> =LDC2002T07
†https://github.com/PKU-TANGENT/SciDTB Wealsoinvestigatethesemi-supervisedsetting
5787SciDTB RST-DT RST-DT SciDTB
RB RB RB 52.5 43.9 UAS LAS UAS LAS
NISHIDA20 - 41.9 NIVRE04 - - 70.2 53.5
LI14 48.7‡ - 57.6 42.5
AdaptedV-DNDMV 54.4 44.2
FENG14 65.6 48.5 - -
AdaptedNCRFAE 53.3 44.0
JI14 66.9 51.7 - -
JOTY15 64.4 48.0 - -
Table 2: Unsupervised discourse dependency parsing
resultsonRST-DTandSciDTB.Theevaluationmetric BRAUD17 66.1 49.9 - -
istheUnlabeledAttachmentScore(UAS). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 450>


<Paper ID = 450> <Table 1> <Abstractive Summary> =WANG17 - - 70.2 54.5
MOREY18 66.4 48.7 - -
AdaptedV-DNDMV 63.5 - 73.4 -
AdaptedNCRFAE 70.2 51.8 79.1 65.0
Table 3: Supervised discourse dependency parsing re-
sultsonRST-DTandSciDTB.TheUASisUnlabeled
Attachment Score and LAS is Labeled Attachment
Score. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 450>


<Paper ID = 450> <Table 2> <Abstractive Summary> =Dueto
Table 6: Hyper-parameters for our NCRFAE and V-
thelackofdevelopmentsetofRST-DT,weprepare DNDMV. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 450>


<Paper ID = 452> <Table 0> <Abstractive Summary> =Therefore, as shown in thetargetsequenceofthe“Word”representationbe
Table 4, the “Word” representation with smaller “[‘G˙lip’, ‘G˙iso’]”, resulting adiscontiguous BPE
5814FlatNER NestedNER DiscontinuousNER
Errors CoNLL2003 OntoNotes ACE2004 ACE2005 Genia CADEC ShARe13 ShARe14
E 0.05% 0.02% 0.23% 0.06% 0.0% 0.31% 0.0% 0.01%
1
E 0.04% 0.03% 0.13% 0.22% 0.11% 1.02% 0.18% 0.16%
2
E 0.05% 0.02% 0.30% 0.26% 0.06% 0.0% 0.08% 0.02%
3
Table 5: Different invalid prediction probability for the “Word” entity representation. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 452>


<Paper ID = 452> <Table 1> <Abstractive Summary> =While
Ours(Word) 57.5 52.8 55.0 49.6 56.2 52.7 in the nested NER dataset, entities in the latter
positionmaybetheoutermostentitythatcontains
Table 6: Performance on the discontinuous entities of theformerentities. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 452>


<Paper ID = 452> <Table 2> <Abstractive Summary> =1 2 3 4 5 6
BeamSize
ACE2004
Hyper Value 86.67
Epoch 30 86.66
Warmupstep 0.01 F186.65
Learningrate [1e-5,2e-5,4e-5]
86.64
Batchsize 16
86.63
BART Large
1 2 3 4 5 6
α 0.5 BeamSize
ShARe13
Beamsize [1,4] 76.40
76.20
Table 7: Hyper-parameters used for CoNLL2003, 76.00
OntoNotes, ACE2004, ACE2005, Genia, CADEC, F175.80
ShARe13,ShARe14. </Abstractive Summary> <Extractive Summary> We
putmoredetailedexperimentalsettingsintheSup- Table 2 presents the results for the three nested
plementaryMaterial.  </Extractive Summary>  </Table 2>  </Paper ID = 452>


<Paper ID = 453> <Table 0> <Abstractive Summary> =5827root att coo frag obj adv cmp adjct subj repet pobj
AnnotationAccuracy 93.9 93.1 88.6 89.3 82.6 80.6 85.3 83.5 62.0 96.0 48.2
Unlabeled 93.8 94.2 92.3 93.3 92.7 88.1 97.9 92.2 86.9 99.4 84.5
ParsingAccuracy 89.0 89.5 75.8 80.6 77.4 68.0 84.0 76.8 64.2 81.1 58.1
Unlabeled 89.0 90.6 85.4 84.1 88.2 80.7 93.5 80.5 80.7 97.3 83.9
OverallDistribution 39.2 29.1 10.2 5.7 5.4 4.3 2.3 1.5 1.5 0.6 0.2
Noun(47.2%) 42.3 33.8 11.5 2.5 4.4 2.6 0.4 1.1 1.1 0.2 0.1
Verb(24.1%) 42.2 3.8 17.9 0.4 12.7 9.6 7.9 1.2 3.1 0.9 0.4
ProperNoun(13.1%) 36.6 28.4 2.3 29.6 0.8 0.6 0.1 0.9 0.6 0.3 0
Adjective(7.1%) 44.4 16.5 17.7 0.7 7.5 8.2 0.6 0.7 1.9 1.6 0.2
Adverb(3.9%) 45.5 12.1 10.3 0.6 6.4 12.1 1.8 5.3 1.0 2.8 2.3
Numeral(3.7%) 20.0 75.7 0.4 0.1 0.1 0.2 0 3.6 0 0.1 0
Others(0.9%) 47.6 15.2 8.7 2.1 1.4 7.7 4.8 8.2 0.3 3.9 0.1
Table 3: Label-wise accuracy and distribution. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 453>


<Paper ID = 453> <Table 1> <Abstractive Summary> =proposedbyDozatandManning(2017),awidely
5828score(i → j) score(i →−l j) Dev Test
UAS LAS UAS LAS CM
Random 81.18 76.15 80.63 75.58 65.13
Biaﬃne
Biaﬃnes 82.42 77.30 81.64 76.98 67.09
Pretrained
rh rd rh(cid:48) rd(cid:48) +1.24 +1.15 +1.01 +1.40 +1.96
i j i j
88.27 85.18 88.33 84.98 77.72
MLPh MLPd MLPh(cid:48) MLPd(cid:48) BERT +5.85 +7.88 +6.69 +8.00 +10.63
h h
i j
Table 4: Results of word-internal structure parsing us-
BiLSTM × 3
ingdifferentcharacterrepresentations. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 453>


<Paper ID = 454> <Table 0> <Abstractive Summary> =Speciﬁcally, to demonstrate that our frame-
workcanhelpachieveadditionalperformancegain Table 1: Cross-lingual NER performance of the
evenonthetopofthestate-of-the-artmultilingual instance-based transfer methods. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 454>


<Paper ID = 454> <Table 1> <Abstractive Summary> =(2020): ...Mittlerer(LOCWesten)der(LOCUSA)
WeakTagger 78.18 57.19 61.81 61.52
...
MulDA-LSTM 78.23 58.37 62.58 62.34
Ours:...(LOCMittlererWestenderUSA)...
MulDA-mBART 78.79 59.62 62.24 62.26
Table 6: Summary of the cross-lingual NER perfor- Figure6: Twoexamplesthatthepreviousmethodsfail
manceonWikiann. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 454>


<Paper ID = 455> <Table 0> <Abstractive Summary> =The results also UD2 19.17% 6.17%
indicatethatouradapter-basedmethod,LEBERT,
Table 5: The relative error reductions over different
withan extrapre-trainedwordembeddingsolely,
basemodels. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 455>


<Paper ID = 455> <Table 1> <Abstractive Summary> =SpanF1meansthecorrect-
ness of the span for an Entity in NER or a word Table 7: Results of variations of LEBERT with Lexi-
inPOS-tagging,whileTypeAccdenotesthepro- conAdapterappliedatdifferentlayersofBERTmodel. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 455>


<Paper ID = 456> <Table 0> <Abstractive Summary> =Following Xie and
Sun (2019), we removed the problems that the Table 1: Answer accuracy of our model and other
correspondingexpressionscouldnotbeexecuted state-of-the-artmodelsontheMath23KandAPE210K
toobtainthegivenanswersandtheproblemsthat datasets. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 456>


<Paper ID = 456> <Table 1> <Abstractive Summary> =NumS2Tw/oNumerals 76.6% 69.2%
NumS2Tw/oSelfAtt 77.3% 69.8%
2)TheKAS2Tmodelwithexternalknowledge
NumS2T 78.1% 70.5%
performs better than GTS, which proves that
external knowledge enables the model to obtain
Table 2: Ablation study on reducing the numerical
betterinteractionbetweenwords. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 456>


<Paper ID = 456> <Table 2> <Abstractive Summary> =NumS2T-base 77.0% 69.6%
NumS2T-base+CR 77.7% 70.1%
3.5 AblationStudy
NumS2T-base+CA 77.4% 70.0%
Effectofexplicitlyincorporatingnumericalval- NumS2T-base+GR 77.3% 69.8%
ues: We designed several NumS2T variants that NumS2T 78.1% 70.5%
reduce the numerical values incorporated in the
Table 3: Ablation study on reducing the numerical
model. </Abstractive Summary> <Extractive Summary> 1) NumS2T-base is the variant of NumS2T
Table 2 shows the results of these different withoutthenumericalpropertiespredictionmech-
variants,fromwhichwecansee: anism.  </Extractive Summary>  </Table 2>  </Paper ID = 456>


<Paper ID = 456> <Table 3> <Abstractive Summary> =KA-S2T: (80-52)*25
Table 4: Model performance on problems with a NumS2T: 52*25
different number of numerals. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 456>


<Paper ID = 456> <Table 4> <Abstractive Summary> =Table 5: Three cases of generated expressions by KA-
denotes the accuracy improvement between NumS2T S2T(Wuetal.,2020)andNumS2T. </Abstractive Summary> <Extractive Summary> The results show Model performance on problems with a differ-
the beneﬁt of explicitly incorporating numerical ent number of numerals: Table 4 shows the
values.  </Extractive Summary>  </Table 4>  </Paper ID = 456>


<Paper ID = 457> <Table 0> <Abstractive Summary> =Table 1: Statistics of Math23K and CM17K. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 457>


<Paper ID = 458> <Table 0> <Abstractive Summary> =Thepre-trainingcorporaafter
Table 1: Results of unsupervised semantic similarity
pre-processing contains 5,937,695 text segments
task.“med”referstomodelscontinuallypre-trainedon
with3,028,224,412tokens(4.9GB).TheKGsem- medical corpora, and “open” means open-domain cor-
bedding trained by TransR (Lin et al., 2015) on pora. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 458>


<Paper ID = 458> <Table 1> <Abstractive Summary> =Model cMedQA WebMedQA Average cMedQQ cMedNLI
Dev Test Dev Test Test Dev Test Dev Test
BERT-open 72.99% 73.82% 77.20% 79.72% 76.77% 86.74% 86.72% 95.52% 95.66%
BERT-wwm-open 72.03% 72.96% 77.06% 79.68% 76.32% 86.98% 86.82% 95.53% 95.78%
RoBERT-open 72.22% 73.18% 77.18% 79.57% 76.38% 87.24% 86.97% 95.87% 96.11%
BioBERT-zh 74.32% 75.12% 78.04% 80.45% 77.79% 87.30% 87.06% 95.89% 96.04%
MC-BERT 74.40% 74.46% 77.85% 80.54% 77.50% 87.17% 87.01% 95.81% 96.06%
KnowBERT-med 74.38% 75.25% 78.20% 80.67% 77.96% 87.25% 87.14% 95.96% 96.03%
ERNIE-med 74.37% 75.22% 77.93% 80.56% 77.89% 87.34% 87.20% 96.02% 96.25%
SMedBERT 75.06% 76.04% 79.26% 81.68% 78.86% 88.13% 88.09% 96.64% 96.88%
Table 3: Performance of Question Answering (QA), Question Matching (QM) and Natural Language Inference
(NLI)tasks. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 458>


<Paper ID = 459> <Table 0> <Abstractive Summary> =Itdemonstrates
BART-S 34.363 18.398 32.660
that the ILP inference is useful for capturing the
BART-SR 36.679 19.017 34.682
relatedness between the source articles, and the
Table 1: The performance of generating the metadata resulthasbeenveryclosetothemeanrecallofits
foridentiﬁedsentences. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 459>


<Paper ID = 46> <Table 0> <Abstractive Summary> =CODA-CS 11.24 35.17
REALFORMER(Heetal.,2020) 8.53 35.01 (2020)consideredeachheadasasamplefromthe
TRANSFORMER 7.11 34.53 samedistribution,andpresentedasamplingalgo-
rithmthatavoidssamplesfromcollapsingintolocal
Table 4: The average JSD and BLEU scores with dif-
modes. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 46>


<Paper ID = 460> <Table 0> <Abstractive Summary> =37.6 36.8 33.6 53.0 53.1 66.4
v = m ·W (11)
i i v Table 1: The statistics of the two benchmark datasets
w.r.t. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 460>


<Paper ID = 460> <Table 1> <Abstractive Summary> =Particularly, BASE+CMN outperforms
tree/master/txt/chexpert BASE+MEMbyalargemargin,whichindicatesthe
5908NLG METRICS CE METRICS
DATA MODEL
BL-1 BL-2 BL-3 BL-4 MTR RG-L P R F1
ST‡ 0.216 0.124 0.087 0.066 - 0.306 - - -
ATT2IN‡ 0.224 0.129 0.089 0.068 - 0.308 - - -
ADAATT‡ 0.220 0.127 0.089 0.068 - 0.308 - - -
IU
X-RAY COATT‡ 0.455 0.288 0.205 0.154 - 0.369 - - -
HRGR‡ 0.438 0.298 0.208 0.151 - 0.322 - - -
CMAS-RL‡ 0.464 0.301 0.210 0.154 - 0.362 - - -
R2GEN‡ 0.470 0.304 0.219 0.165 0.187 0.371 - - -
OURS (CMN) 0.475 0.309 0.222 0.170 0.191 0.375 - - -
(cid:51)
ST 0.299 0.184 0.121 0.084 0.124 0.263 0.249 0.203 0.204
(cid:51)
ATT2IN 0.325 0.203 0.136 0.096 0.134 0.276 0.322 0.239 0.249
MIMIC
(cid:51)
ADAATT 0.299 0.185 0.124 0.088 0.118 0.266 0.268 0.186 0.181
-CXR
(cid:51)
TOPDOWN 0.317 0.195 0.130 0.092 0.128 0.267 0.320 0.231 0.238
R2GEN‡ 0.353 0.218 0.145 0.103 0.142 0.277 0.333 0.273 0.276
OURS (CMN) 0.353 0.218 0.148 0.106 0.142 0.278 0.334 0.275 0.278
Table 3: Comparisons of our proposed model with previous studies on the test sets of IU X-RAY and MIMIC-
CXRwithrespecttoNLGandCEmetrics. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 460>


<Paper ID = 462> <Table 0> <Abstractive Summary> =(1) To the best of our knowledge, this is the ﬁrst
attempttoexplorebothtextandimagesinreviews Table 1: Example of multimodal reviews under the
same product “Teﬂon Pan”. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 462>


<Paper ID = 462> <Table 1> <Abstractive Summary> =Table 6: An example product and two associated re- Multi-domain gated cnn for review helpfulness pre-
views. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 462>


<Paper ID = 463> <Table 0> <Abstractive Summary> =6 7
Table 2: Examples of various speedup ratios by aggressive decoding over greedy decoding in CoNLL-13. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 463>


<Paper ID = 463> <Table 1> <Abstractive Summary> =L TotalLatency(s) Speedup Model CoNLL-13 Total
max Speedup
1(Baseline) 328 1.0× (Enc+Dec) F0.5 Latency
6+6 38.36 328 1.0×
2 208 1.6×
3+6 36.26 314 1.0×
3 148 2.2×
9+6 38.82 345 1.0×
5 109 3.0×
6+3 37.95 175 1.9×
10 75 4.4× 6+9 38.02 457 0.7×
20 64 5.1× 7+5 38.49 271 1.2×
40 54 6.1× 8+4 38.63 240 1.4×
9+3 38.88 181 1.8×
Unlimited 54 6.1×
10+2 38.21 137 2.4×
11+1 38.15 86 3.8×
Table3:Theablationstudyoftheeffectofconstraining
the maximal aggressive decoding length L on the
max Table 4: The performance and efﬁciency of the Trans-
onlineinferenceefﬁciencyinCoNLL-13. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 463>


<Paper ID = 463> <Table 2> <Abstractive Summary> =Conﬁgurations Values
TrainFromScratch
ModelArchitecture Transformer(big)
(Vaswanietal.,2017)
Numberofepochs 60
Devices 4NvidiaV100GPU
MaxtokensperGPU 5120
UpdateFrequency 4
Optimizer Adam
(β =0.9,β =0.98,(cid:15)=1×10−8)
1 2
(KingmaandBa,2014)
Learningrate [3×10−4,5×10−4]
Learningratescheduler inversesqrt
Warmup 4000
Weightdecay 0.0
LossFunction labelsmoothedcrossentropy
(label-smoothing=0.1)
(Szegedyetal.,2016)
Dropout [0.3,0.4,0.5]
Pretrain
Numberofepochs 10
Devices 8NvidiaV100GPU
UpdateFrequency 8
Learningrate 3×10−4
Warmup 8000
Dropout 0.3
Fine-tune
Numberofepochs 60
Devices 4NvidiaV100GPU
UpdateFrequency 4
Learningrate 3×10−4
Warmup 4000
Dropout 0.3
Table 7: Hyper-parameters values of training from
scratch,pretrainingandﬁne-tuning. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 463>


<Paper ID = 464> <Table 0> <Abstractive Summary> =Weperformagridsearchoverall
Table 2: Experimental results are shown in means ± hyperparametersforeachdataset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 464>


<Paper ID = 464> <Table 1> <Abstractive Summary> =5954AUC F1 Clinical Note: chief complaint elective admit
Size P@8
Macro Micro Macro Micro
majorsurgicalorinvasiveprocedurerecoiling
1 0.899 0.980 0.081 0.532 0.723
acommaneurysmhistoryofpresentillnesson
32 0.937 0.990 0.104 0.557 0.737
64 0.938 0.990 0.119 0.559 0.745 shehadacrushingheadachebutstayedathome
128 0.938 0.988 0.124 0.558 0.743 the next day ... angiogram with embolization
1159 0.935 0.990 0.116 0.543 0.731
andorstentplacementmedicationtakeaspirin
Table 4: Experimental results of our method with dif- 325mg...
ferentsizeofsharedrepresentationsonMIMIC-III-full Codes:
dataset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 464>


<Paper ID = 464> <Table 2> <Abstractive Summary> =Whenweneglectthemissingcodecompletiontask Table 5: The attention distribution visualization over
and wrong code removal task (w/o code comple- a clinical note of different shared representations. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 464>


<Paper ID = 464> <Table 3> <Abstractive Summary> =Further compared ISD(Ours) 0.013992
withthemodelwithlabelattentionratherthanour w/oself-distillation 0.004605
proposedsharedrepresentations(w/osharedrepre-
Table 6: The average standard deviation calculated
sentation),theperformanceevenworse,showing
from the attention weights of clinical text in MIMIC-
the code completion task is also the guarantee of
III-fulldataset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 464>


<Paper ID = 465> <Table 0> <Abstractive Summary> =F1
PHMOSpell(w/oPGA) 70.6 98.7 70.6 82.3 67.8 98.6 67.8 80.4
PHMOSpell(w/oGE) 76.1 99.1 76.1 86.1 74.9 99.0 74.8 85.2
SIGHAN13 PHMOSpell(w/oPE) 71.9 98.9 71.8 83.2 69.5 98.8 69.3 81.5
PHMOSpell(w/AS) 71.6 99.4 71.1 82.9 70.3 99.4 69.8 82.0
PHMOSpell 77.2 99.5 76.9 86.8 75.1 99.5 74.7 85.4
PHMOSpell(w/oPGA) 72.7 78.6 60.7 68.5 71.2 77.8 57.6 66.2
PHMOSpell(w/oGE) 76.4 83.6 64.3 72.7 75.3 83.1 62.0 71.1
SIGHAN14 PHMOSpell(w/oPE) 76.2 82.9 64.7 72.7 74.8 82.2 61.8 70.6
PHMOSpell(w/AS) 73.4 81.3 59.1 68.5 72.4 80.8 57.0 66.8
PHMOSpell 76.6 82.4 66.3 73.5 75.3 81.8 63.6 71.6
PHMOSpell(w/oPGA) 79.9 84.1 72.9 78.1 77.5 83.1 68.0 74.8
PHMOSpell(w/oGE) 81.2 88.7 70.7 78.7 80.0 88.4 68.2 77.0
SIGHAN15 PHMOSpell(w/oPE) 81.0 88.3 70.7 78.5 79.5 87.9 67.7 76.5
PHMOSpell(w/AS) 78.9 87.5 66.5 75.6 77.9 87.2 64.7 74.3
PHMOSpell 81.3 88.6 71.2 79.0 80.0 88.2 68.4 77.1
Table 4: Ablation results on three datasets. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 465>


<Paper ID = 466> <Table 0> <Abstractive Summary> =Table 1: Automatic evaluation results of the base-
Whatwasthereviewofthe
line models and the 2-hop questions generated by our Whatwasthereviewscore album that includes previ-
method(Ours ). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 466>


<Paper ID = 466> <Table 1> <Abstractive Summary> =InferenceSteps BERT RoBERTa
Model TestSet
1-hop 2-hop 3-hop >3-hop EM F1 EM F1
DP-Graph 26.1% 55.1% 8.7% 10.1% DP-Graph 0.436 0.615 0.552 0.678
GPT2 23.3% 57.1% 13.2% 6.4% GPT2 0.419 0.581 0.669 0.772
Ours2-hop 4.3% 67.7% 25.8% 2.2% Ours2-hop 0.295 0.381 0.506 0.663
Ours1-hop 70.7% 28.2% 1.1% 0.0% Ours1-hop 0.618 0.737 0.882 0.937
Table 4: Human evaluation results of the number of Table 5: Performance of BERT- and RoBERTa-based
inferencestepsrequiredbythegeneratedquestions. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 466>


<Paper ID = 467> <Table 0> <Abstractive Summary> =5984Development RG CS CO
Model BLEU
NRTask IRTask # P% F1% DLD%
Model
Acc% DLD% Acc% DLD% OurModel 34.37 90.03 44.34 23.64 17.31
Original 46.43 66.15 7.72 27.29 -Series 32.74 91.56 41.42 21.52 17.19
Separate 89.36 92.63 87.81 91.43 -RM 33.91 89.58 43.71 23.04 16.98
Ours 86.56 90.44 84.07 87.74 +NE 38.41 92.28 44.22 23.16 16.23
Test +NE&IE 32.85 92.68 45.33 24.49 16.81
NRTask IRTask +NR 32.47 93.76 45.93 24.29 18.56
Model
Acc% DLD% Acc% DLD% +IR 35.30 92.65 43.34 22.04 17.47
Original 46.54 66.02 7.71 26.93 +NR&IR 33.93 92.40 46.13 25.28 17.68
Separate 89.15 92.47 87.60 91.26
Ours 86.54 90.40 83.98 87.68 Table 3: Ablation results for evaluating each compo-
nent’scontributiononROTOWIREdevelopmentset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 467>


<Paper ID = 467> <Table 1> <Abstractive Summary> =Table 2: Automatic evaluation of the Number Rank-
ing(NR)taskandtheImportanceRanking(IR)taskon
ROTOWIREdevelopmentandtestdatasets. </Abstractive Summary> <Extractive Summary> As can be seen, the
Thirty-First Innovative Applications of Artiﬁcial In-
test datasets’ results in Table 1 follow a pattern
telligence Conference, IAAI 2019, The Ninth AAAI
Symposium on Educational Advances in Artiﬁcial similartothedevelopmentsets.  </Extractive Summary>  </Table 1>  </Paper ID = 467>


<Paper ID = 467> <Table 2> <Abstractive Summary> =RG CS CO
Model BLEU
# P% P% R% F1% DLD%
HEnc 34.37 90.03 36.75 55.87 44.34 23.64 17.31
+A-NR 35.20 92.03 37.51 57.3 45.34 24.17 17.64
+A-NR&D-IR 36.73 90.96 37.46 58.67 45.72 24.77 17.27
+A-NR&A-IR 35.00 92.38 38.15 57.17 45.76 24.82 17.38
+D-NR 33.38 93.76 39.05 55.74 45.93 24.29 18.56
+D-NR&A-IR 33.93 92.40 38.65 57.2 46.13 25.28 17.68
+D-NR&D-IR 32.47 91.05 39.22 55.83 46.08 24.97 18.01
Table 7: Impact of different settings of Number Ranking (NO) and Importance Ranking (SO). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 467>


<Paper ID = 468> <Table 0> <Abstractive Summary> =5995Patterns Models XSUM SQuAD1.1 ROCStories WMT14
Metrics R-1/R-2/R-L B-4/Meteor/R-L B-4
Transformer-1(6-6) 19.53/3.38/15.36 3.87/9.73/29.34 1.89/8.70/23.98 31.61
Transformer-1(12-1) 17.51/2.63/14.18 2.84/7.78/26.58 1.03/6.99/20.46 27.25
AG(row1-4)
Transformer-4(6-6) 22.98/5.88/18.56 4.69/9.95/29.76 2.45/8.67/23.85 33.07
Transformer-4(12-1) 17.69/2.72/14.30 3.55/7.73/28.15 1.52/7.26/20.66 28.28
CMLM 24.95/5.07/19.73 3.49/10.68/30.48 1.61/9.24/25.01 26.48
+Distill 20.22/3.49/16.29 3.03/9.13/28.91 0.30/5.14/16.58 27.28
+POSPD 25.22/5.49/19.93 4.29/11.00/30.66 1.79/9.37/24.96 27.52
NAG(row5-10)
DisCo 26.85/6.86/21.72 3.38/10.33/31.21 1.68/9.06/25.10 27.21
+Distill 18.42/3.27/14.92 3.25/8.78/29.57 0.00/4.59/15.72 28.04
+POSPD 27.39/7.26/22.15 4.20/10.80/30.59 1.72/9.25/25.07 28.23
Table 2: Results on four text generation datasets. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 468>


<Paper ID = 468> <Table 1> <Abstractive Summary> =5996Models SQuAD1.1 XSUM WMT14 ROCStories
Metrics Repetition/Tokens
Reference ≈0.0/140786 ≈0.0/275003 0.01/67617 ≈0.0/44731
CMLM 0.09/-11036 0.15/-2616 0.01/-1957 0.06/+69
+Distill 0.05/-25418 0.06/-52643 0.03/+1214 0.03/+20058
+POSPD 0.09/+247 0.07/+4570 0.01/+1247 0.05/+1297
DisCo 0.05/-24364 0.14/-4641 0.01/-1957 0.06/+2234
+Distill 0.06/-30723 0.06/-52643 0.01/-2026 0.02/+9020
+POSPD 0.02/+1945 0.09/-10871 0.01/+1257 0.05/+1408
Table 4: Statistical analysis of NAG models’ generations. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 468>


<Paper ID = 468> <Table 2> <Abstractive Summary> =DisCo 3.38/10.33/31.21 26.85/6.86/21.72 As we tentatively give a successful implemen-
MTw/o 4.17/10.56/31.05 27.00/6.89/21.81
tationofleveragingoneofthesimplestlinguistic
MTw/ 4.20/10.80/30.59 27.39/7.26/22.15
structurestobeneﬁttheNAGmodelsininference,
Table 6: The ablation study on using multi-task learn- suchparadigmdeservesacloserandmoredetailed
ingstrategyinPOSPD’strainingstage. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 468>


<Paper ID = 469> <Table 0> <Abstractive Summary> =Forbothpre-trainingand +KnowledgeDistillation 37.90 54.27
ﬁnetuning,weemploywarm-upstrategywherethe
Table 2: Evaluation (BLEU) of different pretrain-
linearwarm-upphasetakes4Ksteps,reachingits
ﬁnetunestrategiesonEn⇒Zhdomaintranslationtasks. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 469>


<Paper ID = 469> <Table 1> <Abstractive Summary> =Speed
RandomInit 26.08 382M 25.64 23.98 2.91 9.25 382M 21.23
w/M-BERT 28.24 382M 26.51 25.88 3.31 9.27 382M 21.58
+Ours 29.77 255M 49.54 26.76 3.55 9.86 242M 27.86
w/M-BART 29.13 610M 19.65 48.07 20.20 24.29 610M 12.62
+Ours 30.15 387M 25.79 48.11 20.27 24.31 363M 14.41
Table 3: Evaluation of our model on knowledge transferring tasks. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 469>


<Paper ID = 47> <Table 0> <Abstractive Summary> =554Case 1a 1b 2a 2b 4 Case2a Case3
Labeled CoN Wiki PTB CoN Wiki PTB CoN Wiki CoNLL WikiAnn Wiki+U WikiU
Teacher 89.1588.5295.9689.1588.5296.0488.5788.38 MaxEntTeacher 88.65 87.41 87.41 56.01
w/oKD 84.7083.3189.8583.8780.8689.8583.8780.86 CRFTeacher 89.15 88.52 88.52 -
Pos.KD 85.2783.73 - - - - - - Token.KD 84.25 82.09 83.07 38.42
Struct.KD85.3584.1291.8384.5082.2391.7884.2881.45 Struct.KD 84.50 82.23 83.34 45.28
Table 1: Averaged F1 scores for NER and labeled at- Table 3: Comparing with reference baselines on NER
tachment scores (LAS) for dependency parsing on la- task. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 47>


<Paper ID = 47> <Table 1> <Abstractive Summary> =To show the effectiveness Table 5: Comparison of the global and local tempera-
ofstructuralKDinthemultilingualNERsetting, tureapplicationapproachesonCoNLLNER. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 47>


<Paper ID = 47> <Table 2> <Abstractive Summary> =KD approaches for Case
Table 6: Averaged F1 score of teachers and it’s
1a and the reference baseline Token KD (with a marginal distributions. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 47>


<Paper ID = 47> <Table 3> <Abstractive Summary> =Top-1 92.00 92.52 93.22 93.69 94.25 93.14 91.99 92.44 93.16 93.69 94.26 93.11
UAS
Struct.KD+Top-1 93.71† 93.93† 94.26† 94.58† 94.84† 94.26† 93.67† 93.90† 94.30† 94.64† 94.89† 94.28†
Top-1 90.03 90.62 91.44 91.99 92.61 91.34 90.03 90.59 91.41 91.98 92.66 91.33
LAS
Struct.KD+Top-1 91.98† 92.24† 92.63† 93.00† 93.28† 92.63† 91.94† 92.18† 92.66† 93.04† 93.31† 92.63†
Table 12: The accuracy of Parsing task with unlabeled dataset (in thousand). </Abstractive Summary> <Extractive Summary> Table 3 com-
(TokenKD)ofMaxEntmodelsthatoptimizesthe
pares Struct.  </Extractive Summary>  </Table 3>  </Paper ID = 47>


<Paper ID = 470> <Table 0> <Abstractive Summary> =Table 2: Examples of level-1 error types in TGEA. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 470>


<Paper ID = 470> <Table 1> <Abstractive Summary> =1
Adamβ 0.999
2
Adam(cid:15) 1×10−6
Model ALBERT BERT RoBERTa Maxepochs 3
zh zh zh
Modelsize large base large Dropout 0.1
Learningrate 2×10−5
Batchsize 8 Table 6: Training details for the Rationale Generation
Optimizer Adam
task. </Abstractive Summary> <Extractive Summary> 6023A Appendix Model ALBERTzh BERTzh RoBERTazh
Modelsize large base large
Learningrate 2×10−5
A.1 NEZHA-GenHyperparameters Batchsize 8
Optimizer Adam
Table 1 show the conﬁguration of the generative Adamβ1 0.9
Adamβ2 0.98
model(NEZHA-Gen).  </Extractive Summary>  </Table 1>  </Paper ID = 470>


<Paper ID = 470> <Table 2> <Abstractive Summary> =Table 7: Examples of level-2 error types in TGEA. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 470>


<Paper ID = 471> <Table 0> <Abstractive Summary> =Thefollowing
LoBART(8k) 128 19.3 26.45 9.04 18.23
rankingmethodsareconsidered:
LoBART(8k) 256 21.1 26.72 9.30 18.36
LoBART(8k) 512 27.1 26.90 9.47 18.50
• Truncation(TRC):r = k.
k
Table 3: BART & LoBART memory requirement in
• Model-based: Giventhescoref ofmodelφ,
training and performance. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 471>


<Paper ID = 471> <Table 1> <Abstractive Summary> =Thedecoderconsists
j Table 8: RNN Training Hyperparameters. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 471>


<Paper ID = 472> <Table 0> <Abstractive Summary> =The AMI1 meeting corpus (Carletta et al.,
exp((log(p(yi))+g )/τ) 2005)consistsof100hoursofmeetingrecordings
p(yi) = t i (13)
t (cid:80)|jV=|1exp((log(p(ytj))+gj)/τ) 1http://groups.inf.ed.ac.uk/ami/corpus/overview.shtml
6046AMI Justice
Type Model
R-1 R-2 R-L R-1 R-2 R-L
ORACLE 24.57 4.44 15.03 37.28 21.05 32.78
LEAD3 9.15 1.78 5.36 17.69 3.33 11.52
TextRank(MihalceaandTarau,2004) 11.27 0.84 7.19 20.72 6.51 13.56
Extractive
Centroid(Rossielloetal.,2017) 14.08 2.09 8.19 22.31 6.53 13.66
PacSum(ZhengandLapata,2019) 16.15 2.23 9.14 23.36 7.03 14.66
RepSum-Ext(ours) 18.77 2.24 10.80 25.88 8.21 15.97
2gshufFe´vryandPhang(2018) 14.08 2.09 8.18 20.19 4.15 12.08
MeanSum(ChuandLiu,2019) 16.09 2.30 11.14 21.25 5.54 13.44
Abstractive
SEQ3(Baziotisetal.,2019) 17.06 2.23 11.85 22.47 3.88 14.67
RepSum-Abs(ours) 18.88 2.38 15.62 24.23 6.37 15.14
Table 2: Comparison of our mechanism employed in extractive and abstractive summarization with other base-
line models. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 472>


<Paper ID = 472> <Table 1> <Abstractive Summary> =-w/oTC 18.60 1.94 10.55 23.63 6.51 14.29
2gshuf 0.56 0.78 0.78 0.76 0.71 0.63 0.81 0.81
MeanSum 0.89 0.84 0.89 0.68 0.83 0.61 1.02 0.67 -w/oTG 16.13 1.72 10.05 22.75 5.20 13.50
SEQ3 1.11 0.81 1.03 0.69 1.09 0.59 1.18 0.72
RepSum-Abs 1.23 0.82 1.22 0.72 1.17 0.68 1.20 0.69 Table 4: Ablation study for the auxiliary tasks in re-
placementmechanismontheAMIandJusticedataset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 472>


<Paper ID = 472> <Table 2> <Abstractive Summary> =Table 3: Human evaluation. </Abstractive Summary> <Extractive Summary> Wesettheα0toα7
5.1 QuantitativeAnalysis
equals0.5,0.5,5,1,1,2,1,0.006respectivelyto
Table 2 shows the experimental results based on
balancethescaleofeachmodule.  </Extractive Summary>  </Table 2>  </Paper ID = 472>


<Paper ID = 472> <Table 3> <Abstractive Summary> =Additionally
-w/olm 17.87 0.70 13.37
AMI dataset is more appropriate for abstractive -w/ofake-sum - - -
summarizationsinceitsORACLEscoresaremuch
Table 5: Ablation study of each component based on
lowerthanthoseforJusticedataset. </Abstractive Summary> <Extractive Summary> ResultsshowninTable 3 theauxiliarytasksasoriginaldialoguedoes.  </Extractive Summary>  </Table 3>  </Paper ID = 472>


<Paper ID = 472> <Table 4> <Abstractive Summary> =Either
indicate that our proposed strategy is superior to removing tasks based on the dialogue (-w/o dia-
6048Fakesummary R-1 R-2 R-L
random 15.45 2.39 10.07
extractive-based 18.88 2.38 15.62
Table 6: Effectiveness of potential fake summary
choicesforabstractivesummarizationontheAMI. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 4>  </Paper ID = 472>


<Paper ID = 473> <Table 0> <Abstractive Summary> =DeﬁnedasaheterogeneousgraphG,every
Table 1: Illustration of how the average number of
nodev ∈ V andeveryedgee ∈ E inourgraph
ij
nodes and edges in the graph changes when the input
belongstoatypeofphraseanddependencyparsing
sequencebecomeslongeronWikiSUM. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 473>


<Paper ID = 473> <Table 1> <Abstractive Summary> =TransS2S 34.93 9.86 29.92 9.42
RoBERTaS2S 43.62 18.62 37.86 18.18
Model R-1 R-2 R-L BS
BART 45.83 19.53 - -
Fullmodel 43.40 28.50 37.71 31.64
Pegasus-base 43.55 20.43 - -
w/oshortcut 42.50 27.97 37.23 31.10
BASS 45.04 20.32 39.21 20.13
w/osupernode 42.93 28.08 37.42 31.15
w/ograph-prop 42.84 28.14 37.42 31.33
Table 3: Evaluation results on the test set of BIG-
PATENTwherethelengthinputofBASSis1024. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 473>


<Paper ID = 473> <Table 2> <Abstractive Summary> =0.31 0.38 0.20 0.11 0.58∗
60 Reference
m BASS 0.64 0.16 0.14 0.06 1.18
a
gr50
n-
ovel 40 Table 6: Ranking results of system summaries by hu-
% n man evaluation. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 473>


<Paper ID = 475> <Table 0> <Abstractive Summary> =(3)) 44.54 22.00 36.83
PEGFAME 45.31 22.75 37.46
ORACLE 82.39 60.61 69.19
Table 3: Ablations and SOTA comparisons on XSUM
dataset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 475>


<Paper ID = 475> <Table 1> <Abstractive Summary> =WeexperimentwithlargeRoBERTacheck- PEGASUS(ours) 42.62 20.38 39.61
pointswith24layers,ahiddensizeof1024,ﬁlter PEGFAME(ours) 42.95 20.79 39.90
sizeof4096,16attentionheads,andavocabulary
Table 4: Abstractive summarization results on
with50Ksentencepieces(KudoandRichardson, CNN/DM datasets. </Abstractive Summary> <Extractive Summary> Interest-
Wefurtherdidpairwisecomparisonsforallmea- ingly, Focus summaries have a more di-
sample,k
sures in Table 1 and found that all differences versecollectionofunigramsthaninDiv sum-
top,k
arestatisticallysigniﬁcantexceptforBERTScore maries(3.5%vs2.3%forROBFAMEand2.4%vs
andfaithfulnessmeasuresbetween PEGASUSand 1.9%forPEGFAME).  </Extractive Summary>  </Table 1>  </Paper ID = 475>


<Paper ID = 475> <Table 2> <Abstractive Summary> =Table 6: Text editing results on Discofuse and Wik-
iSplit. </Abstractive Summary> <Extractive Summary> Table 2 presents re-
beseeninFigure1.  </Extractive Summary>  </Table 2>  </Paper ID = 475>


<Paper ID = 475> <Table 3> <Abstractive Summary> =Feqa BERTScore
R1 R2 RL
ROBERTAS2S 41.45 18.79 33.90 39.1 19.8 80.6
ROBFAME 42.15 19.68 34.81 41.3 21.2 80.8
ROBFAME(Focustop,k=50) 30.90 10.60 24.85 27.1 10.6 74.2
ROBFAME(Focustop,k=100) 33.62 12.39 27.14 30.3 12.4 74.2
ROBFAME(Focustop,k=200) 35.99 14.12 29.23 32.4 13.9 77.3
ROBFAME(Focustop,k=500) 38.29 16.04 31.30 35.8 15.9 78.6
ROBFAME(Focustop,k=1000) 39.58 17.18 32.49 37.3 17.3 79.3
ROBFAME(Focustop,k=10000) 41.58 19.13 34.30 40.7 20.2 80.5
PEGASUS 44.85 22.26 37.03 43.6 24.5 81.7
PEGFAME 45.31 22.75 37.46 44.8 24.8 81.9
PEGFAME(Focustop,k=50) 24.30 7.52 19.32 20.8 8.0 68.8
PEGFAME(Focustop,k=100) 27.77 9.26 22.09 24.1 9.3 71.3
PEGFAME(Focustop,k=200) 31.05 11.14 24.82 27.0 10.8 73.6
PEGFAME(Focustop,k=500) 34.99 13.65 28.19 31.0 13.0 76.2
PEGFAME(Focustop,k=1000) 37.40 15.30 30.16 33.6 14.9 75.9
PEGFAME(Focustop,k=10000) 42.76 19.89 34.97 40.2 20.1 80.5
Table 7: Assessment of controlled summary generation with focus sampling Focustop,k on the XSUM test set. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 475>


<Paper ID = 476> <Table 0> <Abstractive Summary> =We trained two summarization
maries of a ﬁxed length budget (e.g, 250 words),
whereas summary length is bound to be variable 3https://github.com/huggingface/pytorch-transformers
6100QueryModeling Multi-News CNN/DM DUC2006 DUC2007 TD-QFS
Models
#Sentence/Doc 20 3 R@10 R@30 R@10 R@30 R@10R@30
#Train 1,615,508 1,719,210 ORACLE 6.7 16.2 8.4 19.1 17.2 35.6
#Validation 200,824 80,052 TERMFREQ 7.2 15.1 8.5 18.5 14.2 25.9
#Words/ProxyQuery 111.7 26.0 BERTQA 8.5 16.3 10.2 20.2 9.8 21.9
#Masks/ProxyQuery 35.6 8.1 BERTMRC 8.2 16.6 9.0 19.2 8.1 16.4
MARGE-MN 11.1 20.2 13.8 25.3 11.2 21.6
SummaryGeneration Multi-News CNN/DM +EXPAND — — — — 18.1 32.9
#Clusters 44,972 287,227 MARGE-CD 9.1 17.4 11.1 22.1 10.0 18.7
#Documents/Cluster 2.8 4.1 +EXPAND — — — — 17.2 27.7
#Words/Summary 257.2 261.3
Table 3: Retrieval performance of evidence rankers. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 476>


<Paper ID = 476> <Table 1> <Abstractive Summary> =Table 2: Training data for query modeling and sum-
marygeneration. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 476>


<Paper ID = 476> <Table 2> <Abstractive Summary> =6101Models DUC2006 DUC2007 TD-QFS Models DUC2006 DUC2007 TD-QFS
GOLD 17.0 19.1 — PQSUM-WSL† 16.5 17.7 —
ORACLE 14.8 16.0 23.0 QUERYSUM∗ 15.3 16.8 20.7
LEAD 10.4 11.3 10.4 BART-CAQ 12.9 14.4 —
TERMFREQ 12.6 14.2 12.0 PQSUM 14.8 16.0 —
LEXRANK 11.4 12.7 12.2 UNILM-MN 11.8 12.3 12.9
BERTQA 13.9 14.9 16.1 UNILM-CD 13.6 14.9 16.7
BERTMRC 13.6 14.3 13.2 MARGESUM-MN 14.3 16.5 16.5
MARGE-MN 14.5 16.6 15.9 MARGESUM-CD 15.1 16.9 20.9
+EXPAND — — 23.0
MARGE-CD 13.9 15.8 16.9 Table 6: Abstractive summarization models with
R-SU4 (full set of results in Appendix); ∗/†: extrac-
+EXPAND — — 22.7
tive/supervisedmethod. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 476>


<Paper ID = 476> <Table 3> <Abstractive Summary> =Theseinclude PQSUM-WSL
−OpenIE ↓0.9 ↓1.1 ↓2.1 (Laskaretal.,2020)asupervisedabstractivesys-
temwhichrepresentsthestateoftheartonDUC
Table 5: Ablation results on training data (absolute benchmarks. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 476>


<Paper ID = 476> <Table 4> <Abstractive Summary> =QUERYSUM 4.32 3.90◦ 3.80†◦
UNILM-CD 3.63†◦ 4.12 4.28
Models DUC2006 DUC2007 TD-QFS MARGESUM-CD 4.55 4.02 4.37
MARGE-CD 15.1 16.9 20.9
BERTQA ↓1.0 ↓2.2 ↓6.1 Table 9: Human evaluation results on DUC
(above) and TD-QFS (below): average Relevance,
−Rank ↓1.7 ↓3.1 ↓1.3
Succinctness, Coherence ratings; †: sig different
−Length ↓0.1 ↓0.5 ↓0.2
from MARGESUM-CD; ◦: sig different from Gold (at
−Query ↓0.5 ↓0.3 ↓0.4
p<0.05,usingapairwiset-test). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 4>  </Paper ID = 476>


<Paper ID = 476> <Table 5> <Abstractive Summary> =Table 8: Ablations for MARGESUM trained on
CNN/DailyMail(performancedecreasedenotedby↓). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 5>  </Paper ID = 476>


<Paper ID = 476> <Table 6> <Abstractive Summary> =6106A EvidenceRankingResults
Models DUC2006 DUC2007 TD-QFS
ORACLE 22.7 26.2 44.6
TERMFREQ 20.8 25.2 34.0
BERTQA 22.1 26.1 29.1
BERTMRC 22.3 25.2 23.2
MARGE-MN 25.9 31.8 29.4
+EXPAND — — 39.1
MARGE-CD 23.3 28.8 26.2
+EXPAND — — 26.2
Table 10: Performance of evidence rankers on top re-
trieval. </Abstractive Summary> <Extractive Summary> Models DUC2006 DUC2007 TD-QFS
7.2 AbstractiveSummarization
MARGE-MN 14.5 16.6 23.0
−Verb ↓0.5 ↓0.3 ↓2.8 Automatic Evaluation Table 6 compares our
−Mask ↓0.8 ↓1.2 ↓1.5 model, which we call MARGESUM, against ex-
−Query ↓2.9 ↓2.9 ↓12.6 istingQFSsystems.  </Extractive Summary>  </Table 6>  </Paper ID = 476>


<Paper ID = 476> <Table 7> <Abstractive Summary> =6107DUC2006 DUC2007 TD-QFS
Models
R-1 R-2 R-SU4 R-1 R-2 R-SU4 R-1 R-2 R-SU4
GOLD 45.7 11.2 17.0 47.9 14.1 19.1 - - -
ORACLE 40.6 9.1 14.8 41.8 10.4 16.0 44.9 18.9 23.0
LEAD 32.1 5.3 10.4 33.4 6.5 11.3 33.5 5.2 10.4
TERMFREQ 36.5 7.0 12.6 38.5 9.0 14.2 35.7 6.5 12.0
LEXRANK 34.2 6.4 11.4 35.8 7.7 12.7 35.3 7.6 12.2
BERTQA 38.6 8.4 13.9 39.8 10.0 14.9 39.5 10.5 16.1
BERTMRC 39.6 7.8 13.6 39.9 8.9 14.3 36.6 8.4 13.2
MARGE-MN 39.0 9.3 14.5 41.6 11.6 16.6 38.8 10.5 15.9
+EXPAND — — — — — — 45.9 18.8 23.0
MARGE-CD 38.4 8.6 13.9 40.7 10.8 15.8 40.1 11.6 16.9
+EXPAND — — — — — — 45.9 18.3 22.7
Table 11: Performance of evidence rankers on extractive QFS. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 7>  </Paper ID = 476>


<Paper ID = 476> <Table 8> <Abstractive Summary> =DUC2006 DUC2007 TD-QFS
Models
R-1 R-2 R-SU4 R-1 R-2 R-SU4 R-1 R-2 R-SU4
PQSUM-WSL† (Laskaretal.,2020) 43.5 10.8 16.5 44.7 12.4 17.7 - - -
QUERYSUM∗ (XuandLapata,2020) 41.6 9.5 15.3 43.3 11.6 16.8 44.3 16.1 20.7
BART-CAQ(Suetal.,2020) 38.3 7.7 12.9 40.5 9.2 14.4 - - -
PQSUM(Laskaretal.,2020) 40.9 9.4 14.8 42.2 10.8 16.0 - - -
UNILM-MN 34.6 6.7 11.8 35.5 7.6 12.3 36.2 8.1 12.9
UNILM-CD 37.6 8.3 13.6 39.6 10.1 14.9 40.1 11.8 16.7
MARGESUM-MN 39.1 9.1 14.3 42.1 11.7 16.5 40.8 11.6 16.5
MARGESUM-CD 40.2 9.7 15.1 42.5 12.0 16.9 45.5 16.6 20.9
Table 12: Performance of abstractive summarization systems. </Abstractive Summary> <Extractive Summary> Ablation Studies Table 8 presents the results
Participants assessed summaries created by
of several ablation studies on MARGESUM-CD.  </Extractive Summary>  </Table 8>  </Paper ID = 476>


<Paper ID = 476> <Table 9> <Abstractive Summary> =Table 13: System outputs for cluster D0602C in DUC 2006. </Abstractive Summary> <Extractive Summary> 6103Table 9 shows the human ratings for each sys- interpretedasnecessarilyrepresentingtheofﬁcial
tem (we provide examples of summary output in policies or endorsements, either expressed or im-
AppendixC).ParticipantsperceiveMARGESUM- plied, of the ODNI, IARPA, or the U.S. Govern-
CD on par with PQSUM-WSL in terms of query ment.  </Extractive Summary>  </Table 9>  </Paper ID = 476>


<Paper ID = 477> <Table 0> <Abstractive Summary> =2(a).Intheﬁnallossfunction,weapplydifferent
6114lossesassetEandA: Table 1: The precision and recall of pseudo evidences
fromInterpreter,comparedtothegroundtruth(GT). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 477>


<Paper ID = 479> <Table 0> <Abstractive Summary> =Pipeline 81.1 81.9 78.2 78.3 82.4 85.2
Ours 83.4 84.4 81.2 79.8 84.6 87.0
Table 4: Effect of our framework on the CoQA
dataset that do not have human rewrites. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 479>


<Paper ID = 479> <Table 1> <Abstractive Summary> =Sincequestionersandanswerersshare
Table 6: Statistics of question types for QuAC and theevidencedocumentswhencreatingCoQA,only
CoQA.AllvaluescanbefoundintheQuACandCoQA 1.3%ofunanswerablequestionsareasked. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 479>


<Paper ID = 48> <Table 0> <Abstractive Summary> =568#Trained
#Total
Model params/ CoLA SST-2 MRPC QQP STS-B MNLI QNLI RTE Avg
params
pertask
Single-TaskTraining
T5 8.0× 100% 46.81 90.47 86.21/90.67 91.02/87.96 89.11/88.70 82.09 90.21 59.42 82.06
SMALL
Adapters (cid:163) 1+8×0.01 0.74% 40.12 89.44 85.22/89.29 90.04/86.68 83.93/83.62 81.58 89.11 55.80 79.53
SMALL
T5 8.0× 100% 54.85 92.19 88.18/91.61 91.46/88.61 89.55/89.41 86.49 91.60 67.39 84.67
BASE
Adapters (cid:163) 1+8×0.01 0.87% 59.49 93.46 88.18/91.55 90.94/88.01 87.44/87.18 86.38 92.26 68.84 84.88
BASE
Multi-TaskTraining
T5 (cid:171) 1.0× 12.5% 50.67 91.39 84.73/88.89 89.53/86.31 88.70/88.27 81.04 89.67 59.42 81.69
SMALL
Adapters† 1.05× 0.68% 39.87 90.01 88.67/91.81 88.51/84.77 88.15/87.89 79.95 89.60 60.14 80.85
SMALL
HYPERFORMERSMALL 1.45× 5.80% 47.64 91.39 90.15/92.96 88.68/85.08 87.49/86.96 81.24 90.39 65.22 82.47
HYPERFORMER++SMALL 1.04× 0.50% 53.96 90.59 84.24/88.81 88.44/84.46 87.73/87.26 80.69 90.39 71.01 82.51
T5 (cid:171) 1.0× 12.5% 54.88 92.54 90.15/93.01 91.13/88.07 88.84/88.53 85.66 92.04 75.36 85.47
BASE
Adapters† 1.07× 0.82% 61.53 93.00 90.15/92.91 90.47/87.26 89.86/89.44 86.09 93.17 70.29 85.83
BASE
HYPERFORMERBASE 1.54× 6.86% 61.32 93.80 90.64/93.33 90.13/87.18 89.55/89.03 86.33 92.79 78.26 86.58
HYPERFORMER++BASE 1.02× 0.29% 63.73 94.03 89.66/92.63 90.28/87.20 90.00/89.66 85.74 93.02 75.36 86.48
Table 1: Performance of allmodels on the GLUE tasks. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 48>


<Paper ID = 48> <Table 1> <Abstractive Summary> =We also tried only fine-tuning the task embedding but found Table 2: Few-shot domain transfer results of the models
thatthisachieveslowerperformanceinthefew-shotsettingand trainedonGLUEaveragedacross5seeds. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 48>


<Paper ID = 48> <Table 2> <Abstractive Summary> =HYPERFORMERSMALL 82.47 1.45x 5.80%
Adapters† 85.84 2.02x 12.73%
BASE
4 Analysis HYPERFORMERBASE 86.58 1.54x 6.86%
4.1 ParameterEfficiency Table 3: Averaged test results on GLUE for HYPER-
FORMER and Adapters†, where Adapters† has a higher
Inthissection,wecomparethenumberofparameters
numberofparameterscomparedtoHYPERFORMER. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 48>


<Paper ID = 48> <Table 3> <Abstractive Summary> =Model Memory ∆%
T5 7.76(GB) -
BASE
Adapters† 5.95(GB) -23.32%
BASE
HYPERFORMER 7.60(GB) -2.06%
BASE
HYPERFORMER++ 5.81(GB) -25.13
BASE
Table 5: The required memory for all methods. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 48>


<Paper ID = 480> <Table 0> <Abstractive Summary> =Thus, the sum of the dialogues of each {t ,...,t ,p ,t ,...,t }wheretwoparticipants
1 h k h+1 N
category (people/animal/food/product dial #) ex- speak alternatively, t (j ∈ [1,N]) and p ∈ P
j k
ceedsthetotalnumberofthedialogues(dial#)in respectively represent the utterance of turn j and
6145Table 1: PhotoChat statistics. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 480>


<Paper ID = 480> <Table 1> <Abstractive Summary> =pretrainedencoder,directlytrainingthemonPho-
i j
6147Table 2: Experimental results of the baseline models Example1 Example2
for the photo-sharing intent prediction task. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 480>


<Paper ID = 480> <Table 2> <Abstractive Summary> =Itookthe B:Prettygood,Ispentthe
Table 3: Number of negative turns and positive turns dayofftospendwithIsa. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 480>


<Paper ID = 480> <Table 3> <Abstractive Summary> =Pretraining the
SH,MHrepresentscrossentropyloss,hingeloss, model on MSCOCO further boosts it by 3.5% to
6148Table 4: Experimental results of the baseline models on image retrieval task. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 480>


<Paper ID = 481> <Table 0> <Abstractive Summary> =Weconsiderthreemodels: thetext-onlyTrans-
6158En→De En→Fr
# Model
Test2016 Test2017 MSCOCO Test2016 Test2017 MSCOCO
1 Transformer 41.02 33.36 29.88 61.80 53.46 44.52
2 Doubly-ATT 41.53(+0.08) 33.90(-0.05) 29.76(+0.15) 61.85(-0.35) 54.61(+0.46) 44.85(-0.80)
3 Imagination 41.20(-0.11) 33.32(+0.42) 29.92(+0.02) 61.28(-0.62) 53.74(-0.33) 44.89(+0.08)
4 GatedFusion 41.53(-0.45) 33.52(-0.07) 29.87(+0.83) 61.58(-0.11) 54.21(-0.64) 44.88(+0.02)
Table 3: BLEU scores on Multi30k with randomly initialized visual representation. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 481>


<Paper ID = 481> <Table 1> <Abstractive Summary> =However,
Table 4: Adversarial evaluation with limited textual
contextonMulti30kEn-DeTest2016. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 481>


<Paper ID = 481> <Table 2> <Abstractive Summary> =SRC: twoyoungboysposewithapuppyforafamilypicture
NMT: zweibraunehundespielenmiteinemspielzeugfu¨reinentennisball
(twobrowndogsplaywithatoyforatennisball)
(a) MMT: zweikleinejungenposierenmiteinemwelpenfu¨reinfoto
(twolittleboysposewithapuppyforaphoto)
REF: zweikleinejungenposierenmiteinemwelpenfu¨reinefamilienfoto
(twolittleboysposewithapuppyforafamilyphoto)
SRC: twomensittinginarestaurant
NMT: zweikinderspielenineinemspringbrunnen
(twochildrenareplayinginafountain)
(b) MMT: zweifrauensitzenineinemrestaurant
(twowomenaresittinginarestaurant)
REF: zweima¨nnersitzenineinemrestaurant
(twomenaresittinginarestaurant)
Table 5: Case studies under limited textual input. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 481>


<Paper ID = 481> <Table 3> <Abstractive Summary> =Numberofattentionheads 8 4 4
C ResultsonMETEOR
Table 6: Model conﬁgurations for Base, Small, and
Tiny. </Abstractive Summary> <Extractive Summary> Figure1(a)and
Table 3 shows BLEU scores on the Multi30k
(b)showshowΛchangesduringtraining,fromthe
dataset.  </Extractive Summary>  </Table 3>  </Paper ID = 481>


<Paper ID = 481> <Table 4> <Abstractive Summary> =Indicating that although image-
based MMT models can be directly applied to 3http://statmt.org/wmt11/papers.html
6164En→De En→Fr
# Model
#Params Test2016 Test2017 MSCOCO #Params Test2016 Test2017 MSCOCO
Text-onlyTransformer
1 Transformer-Base 49.1M 65.92 60.02 54.73 49.0M 80.09 74.93 68.57
2 Transformer-Small 36.5M 66.01 60.80 55.95 36.4M 80.71 75.74 69.10
3 Transformer-Tiny 2.6M 68.22 62.05 56.64 2.6M 81.02 75.62 69.43
ExistingMMTSystems
4 GMNMT♠ 4.0M 57.6 51.9 47.6 - 74.9 69.3 -
5 DCCN♠ 17.1M 56.8 49.9 45.7 16.9M 76.4 70.3 65.0
6 Doubly-ATT♠ 3.2M 68.04 61.83 56.21 3.2M 81.12 75.71 70.25
7 Imagination♠ 7.0M 68.06 61.29 56.57 6.9M 81.2 76.03 70.35
OurMMTSystems
9 GatedFusion♠ 2.9M 67.84 61.94 56.15 2.8M 80.97 76.34 70.51
10 RMMT♦ 2.9M 67.97 61.71 56.33 2.9M 81.29 76.09 70.24
Table 8: METEOR scores on Multi30k. </Abstractive Summary> <Extractive Summary> 1 Transformer 11.39 35.53 -
2 +weightdecay0.1 11.66 35.95 -
Table 4 shows the adversarial study with visu-
w.ResNetfeatures
ally grounded tokens masked.  </Extractive Summary>  </Table 4>  </Paper ID = 481>


<Paper ID = 481> <Table 5> <Abstractive Summary> =En→De En→Fr
# Model
Test2016 Test2017 MSCOCO Test2016 Test2017 MSCOCO
1 Transformer 68.22 62.05 56.64 81.02 75.62 69.43
2 Doubly-ATT 68.39(+0.35) 61.83(+0.0) 56.46(+0.25) 81.27(+0.15) 76.22(+0.51) 70.21(-0.04)
3 Imagination 67.93(-0.13) 61.84(+0.55) 56.49(-0.08) 80.75(-0.45) 76.57(+0.54) 69.88(-0.47)
4 GatedFusion 68.25(+0.41) 61.5(-0.44) 55.93(-0.22) 81.22(+0.25) 76.01(-0.33) 70.33(-0.18)
Table 9: METEOR scores on Multi30k with randomly initialized visual representation. </Abstractive Summary> <Extractive Summary> For example, in Table 5 (b), we see
ofvisuallygroundedtokens. Those empirical ﬁndings, however,
toattendrelevantregionsinanimage,theshortage should not be understood as us downplaying the
ofannotateddatacouldimpairtheattentionmod- importance existing datasets and models; we be-
ule (see Table 5 (b)).  </Extractive Summary>  </Table 5>  </Paper ID = 481>


<Paper ID = 483> <Table 0> <Abstractive Summary> =#Entities 4 1 2 1
We train BERT-NER by minimizing the
#Sources 13 5 8 4
Kullback-Leiblerdivergence(KLdivergence)be-
tween the soft labels y∗ and the model output y: Table 1: Dataset statistics. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 483>


<Paper ID = 483> <Table 1> <Abstractive Summary> =6183Models CoNLL2003 NCBI-Disease BC5CDR LaptopReview
SupervisedBERT-NER‡(cid:92) 90.74(90.37/91.10) 88.89(87.05/90.82) 88.81(87.12/90.57) 81.34(82.02/80.67)
bestconsensus(cid:92) 89.18(100.0/80.47) 81.60(100.0/68.91) 87.58(100.0/77.89) 77.72(100.0/63.55)
SwellShark(noun-phrase)†‡ - 67.10(64.70/69.70) 84.23(84.98/83.49) -
SwellShark(hand-tuned)†‡ - 80.80(81.60/80.10) 84.21(86.11/82.39) -
AutoNER†‡ 67.00(75.21/60.40) 75.52(79.42/71.98) 82.13(83.23/81.06) 65.44(72.27/59.79)
Snorkel†‡ 66.40(71.40/62.10) 73.41(71.10/76.00) 82.24(80.23/84.35) 63.54(64.09/63.09)
LinkedHMM†‡ - 79.03(83.46/75.05) 82.96(82.65/83.28) 69.04(77.74/62.11)
BOND-MV†‡(cid:92) 65.96(64.22/67.82) 80.33(84.77/76.34) 83.18(82.90/83.49) 67.19(68.90/65.75)
MajorityVoting†(cid:92) 58.40(49.01/72.24) 73.94(79.76/68.91) 80.73(83.79/77.88) 67.92(72.93/63.55)
HMM†(cid:92) 68.84(70.80/66.98) 73.06(83.88/64.70) 80.57(88.75/73.76) 66.96(77.46/58.96)
CHMM-i.i.d.†(cid:92) 68.57(69.67/67.50) 71.69(83.49/62.87) 79.37(85.68/73.92) 65.89(75.70/58.34)
CHMM†(cid:92) 70.11(72.98/67.47) 78.88(93.37/68.28) 82.39(89.93/76.02) 73.02(87.23/62.79)
CHMM+BERT-NER†‡(cid:92) 74.30(75.02/73.58) 82.87(89.42/77.22) 84.33(85.58/83.12) 69.67(75.48/64.70)
CHMM-ALT†‡(cid:92) 75.54(76.22/74.86) 85.02(87.92/82.47) 85.12(84.97/85.28) 76.55(81.39/72.32)
Table 2: Evaluation results on four datasets. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 483>


<Paper ID = 484> <Table 0> <Abstractive Summary> =6195NYT10-D GDS
Method
AUC P@100 P@200 P@300 P@M AUC P@500 P@1000 P@2000 P@M
Mintz† 10.7 52.3 50.2 45.0 49.2 - - - - -
PCNN-ATT‡ 34.1 73.0 68.0 67.3 69.4 79.9 90.6 87.6 75.2 84.5
MTB-MIL 40.8 76.2 71.1 69.4 72.2 88.5 94.8 92.2 87.0 91.3
RESIDE‡ 41.5 81.8 75.4 74.3 77.2 89.1 94.8 91.1 82.7 89.5
REDSandT‡ 42.4 78.0 75.0 73.0 75.3 86.1 95.6 92.6 84.6 91.0
DISTRE† 42.2 68.0 67.0 65.3 66.8 89.9 97.0 93.8 87.6 92.8
CIL∗ 50.8 90.1 86.1 81.8 86.0 91.6 98.4 95.3 88.7 94.1
Table 2: Model performances on NYT10-D and GDS. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 484>


<Paper ID = 484> <Table 1> <Abstractive Summary> =CILbagpos 47.8(-3.0) 50.5(-1.7) 79.2(-6.8)
CIL 48.4(-2.4) 50.6(-1.6) 78.2(-7.8)
randneg
3.6 AblationStudy
Table 5: Model performances of our proposed frame-
TofurtherunderstandourproposedframeworkCIL, workCILanditsthreevariants. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 484>


<Paper ID = 484> <Table 2> <Abstractive Summary> =By
Table 6: A typical bag selected from the training set:
pre-trainingonalarge-scalecorpus,BERT(Devlin
The bag is constructed with relational triple (john mc-
gahern, /place borned, dubin), and the ﬁrst sentence etal.,2019)obtainstheabilitytocaptureanotable
(S1) is clean to express relation /place borned while amountof“common-sense”knowledgeandgains
the second instance (S2) are noisy with true relation signiﬁcantimprovementsonmanytasksfollowing
/place deaded. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 484>


<Paper ID = 485> <Table 0> <Abstractive Summary> =Table 1: Statistics of datasets6. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 485>


<Paper ID = 485> <Table 1> <Abstractive Summary> =3)
Table 4: Model performance on clean and noisy- Asforlabel-recovering,SENTcanachieveabout
TACRED. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 485>


<Paper ID = 487> <Table 0> <Abstractive Summary> =F1
NovelTagging(Zhengetal.,2017) - - - - - - 32.8 30.6 31.7 52.5 19.3 28.3
CopyRE(Zengetal.,2018) 61.0 56.6 58.7 37.7 36.4 37.1 - - - - - -
MultiHead(Bekoulisetal.,2018) - - - - - - 60.7 58.6 59.6 57.5 54.1 55.7
GraphRel(Fuetal.,2019) 63.9 60.0 61.9 44.7 41.1 42.9 - - - - - -
OrderCopyRE(Zengetal.,2019) 77.9 67.2 72.1 63.3 59.9 61.6 - - - - - -
ETL-span(Yuetal.,2019) 84.9 72.3 78.1 84.0 91.5 87.6 85.5 71.7 78.0 84.3 82.0 83.1
WDec(NayakandNg,2020) 94.5 76.2 84.4 - - - - - - - - -
RSAN‡(Yuanetal.,2020) - - - - - - 85.7 83.6 84.6 80.5 83.8 82.1
CasRel ‡(Weietal.,2020) 81.5 75.7 78.5 84.7 79.5 82.0 - - - - - -
Random
CasRelBERT‡(Weietal.,2020) 89.7 89.5 89.6 93.4 90.1 91.8 - - - - - -
TPLinkerBERT‡(Wangetal.,2020a) 91.3 92.5 91.9 91.8 92.0 91.9 91.4 92.6 92.0 88.9 84.5 86.7
PRGC 89.6 82.3 85.8 90.6 88.5 89.5 87.8 83.8 85.8 82.5 79.2 80.8
Random
PRGCBERT 93.3 91.9 92.6 94.0 92.1 93.0 93.5 91.9 92.7 89.9 87.2 88.5
Table 3: Comparison (%) of the proposed PRGC method with the prior works. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 487>


<Paper ID = 487> <Table 1> <Abstractive Summary> =6230Dataset Model Complexity FLOPs(M) Params InferenceTime(1/24) F1-Score
decoder
CasRel O(kn)→O(n2) 15.05 75,362 24.2/- 89.6
NYT* TPLinker O(kn2) 1105.92 110,736 38.8/7.7 91.9
PRGC O(n2) 32.60 66,085 13.5/4.4 92.6
CasRel O(kn2) 105.37 527,534 30.5/- 91.8
WebNLG* TPLinker O(n3) 7879.68 788,994 41.7/13.2 91.9
PRGC O(n2) 33.75 409,534 14.4/5.2 93.0
Table 6: Comparison of model efﬁciency on both NYT* and WebNLG* datasets. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 487>


<Paper ID = 487> <Table 2> <Abstractive Summary> =F1
RelationJudgement 95.3 96.3 95.8 92.8 96.2 94.5
EntityExtraction(Subject) 81.2 95.5 87.8 69.4 96.3 80.7
EntityExtraction(Object) 82.8 95.8 88.8 72.1 95.7 82.2
Subject-objectAlignment 94.0 92.3 93.1 96.0 93.4 94.7
CombinationofAboveAll 93.3 91.9 92.6 94.0 92.1 93.0
Table 8: Evaluation (%) of different subtasks on the
NYT* and WebNLG* datasets. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 487>


<Paper ID = 488> <Table 0> <Abstractive Summary> =This work is supported by the National Key
Research and Development Program of China
Table 6: Task-Agnostic Effectiveness of Silent Major-
(2018YFB1005100 and 2018YFB1005101) and
ity(ours)
NSFCKeyProject(U1736204). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 488>


<Paper ID = 49> <Table 0> <Abstractive Summary> =Table 2: Results of XNLI under the few-shot set-
4.2 Implementation
ting (mBERT). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 49>


<Paper ID = 49> <Table 1> <Abstractive Summary> =Speciﬁcally, (4)SAN-Black,Blue 44.7 61.8 52.2 67.4 69.7
XMAML-one utilizes an auxiliary language de- (5)COSY 45.2 62.1 53.2 68.1 70.1
velopment data in training, e.g., using the devel-
Table 3: The ablation study on MLQA, XQUAD and
opment set of Spanish in training to assist Ger-
XNLI (mBERT). </Abstractive Summary> <Extractive Summary> From Table 1 and
learningrateisadoptedwithﬁrst10%optimization Table 2, we can observe that COSY consistently
steps. Theoverallresultson taxaslanguage-agnosticfeaturescanenhancethe
three benchmarks are presented in Table 1 (zero- transferabilityforcross-lingualunderstanding.  </Extractive Summary>  </Table 1>  </Paper ID = 49>


<Paper ID = 49> <Table 2> <Abstractive Summary> =Speciﬁcally,wedesignthefollow-
taxandsemanticsareoverlooked,whichleadsto
ing variants and report the results in Table 4: (1)
signiﬁcantdecreaseonperformance. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 49>


<Paper ID = 49> <Table 3> <Abstractive Summary> =587Methods en fr es de el bg ru tr ar vi zh hi ur Avg
mBERT
NaiveFine-tuning1 82.1 73.8 74.3 71.1 66.4 68.9 69.0 61.6 64.9 69.5 69.3 60.0 58.0 68.4
XMAML-One2 82.1 74.4 75.1 71.8 68.0 69.5 70.2 61.2 66.1 71.8 71.1 62.2 61.5 69.6
COSY 82.2 75.2 75.5 72.2 68.9 71.1 70.1 63.1 66.7 72.4 71.3 62.4 59.7 70.1
XLM-R
base
NaiveFine-tuning3 84.6 78.2 79.2 77.0 75.9 77.5 75.5 72.9 72.1 74.8 73.7 69.8 65.1 75.1
COSY 84.3 78.8 78.6 76.4 76.3 78.4 76.3 73.9 71.1 75.4 75.1 71.1 67.1 75.6
XLM-R
large
NaiveFine-tuning4 88.7 82.2 83.7 82.5 80.8 83.0 79.1 78.0 77.2 79.3 78.2 75.6 71.7 80.0
STILT5 89.6 84.1 84.5 83.7 81.8 83.5 79.9 80.1 79.3 81.3 80.7 78.2 74.5 81.6
COSY 89.2 83.6 85.1 83.2 83.3 84.7 80.9 80.8 80.1 81.0 80.5 77.7 74.1 81.9
Table 5: Results on XNLI of zero-shot setting. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 49>


<Paper ID = 49> <Table 4> <Abstractive Summary> =Methods en es de ar hi vi zh Avg
mBERT
NaiveFine-tuning1 67.0/80.2 49.2/67.4 43.8/59.0 34.6/52.3 35.3/50.2 40.7/61.2 38.6/59.6 44.2/61.4
LAKM3 66.8/80.0 48.0/65.9 44.5/60.5 - - - - -
COSY 67.2/80.4 48.5/66.4 47.0/61.1 35.0/52.9 35.9/51.2 43.2/63.1 39.3/59.8 45.2/62.1
XLM-R
base
NaiveFine-tuning2 - /80.1 - /67.9 - /62.1 - /56.4 - /60.5 - /67.1 - /61.4 - /65.1
NaiveFine-tuning∗ 67.1/80.1 50.3/68.0 48.3/62.9 37.2/57.0 44.5/62.4 47.1/67.4 38.4/62.0 47.6/65.7
XMAML-One4 - /80.2 - /67.5 - /63.6 - /58.0 - /61.7 - /68.0 - /64.0 - /66.1
COSY 67.7/80.7 50.9/68.7 49.1/63.4 38.7/57.8 45.4/62.7 47.9/68.3 39.7/63.6 48.5/66.5
XLM-R
large
NaiveFine-tuning1 70.6/83.5 56.6/74.1 54.9/70.1 47.1/66.6 53.1/70.6 52.9/74.0 37.0/62.1 53.2/71.6
STILT5 70.8/84.1 56.8/75.3 52.9/69.6 46.4/67.4 54.8/72.5 51.7/70.9 47.0/69.4 54.4/72.8
XMAML-One4 - /84.3 - /74.3 - /70.8 - /66.6 - /70.9 - /74.8 - /70.7 - /73.2
COSY 70.9/84.2 56.5/74.7 55.2/70.3 46.7/66.7 53.7/72.1 53.2/74.3 46.6/70.2 54.7/73.2
Table 6: Results on MLQA of zero-shot setting. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 4>  </Paper ID = 49>


<Paper ID = 49> <Table 5> <Abstractive Summary> =Methods en ar de el es hi ru tr vi zh Avg
mBERT
NaiveFine-tuning1 72.2/83.5 45.1/61.5 54.0/70.6 44.9/62.6 56.9/75.5 46.0/59.2 53.3/71.3 40.1/55.4 49.6/69.5 48.3/58.0 51.0/66.7
COSY 72.6/83.6 47.6/63.6 57.2/72.3 47.7/64.6 58.6/76.5 47.5/60.7 55.6/72.1 42.2/56.7 54.0/72.4 48.9/58.5 53.2/68.1
XLM-Rbase
NaiveFine-tuning∗ 71.6/83.1 49.9/66.2 56.6/72.5 54.2/72.4 58.8/76.6 51.3/67.7 57.2/74.1 52.5/68.3 53.8/73.6 52.6/63.6 55.9/71.8
COSY 74.0/85.1 51.0/67.8 59.2/75.4 55.5/73.2 59.0/77.2 51.5/69.1 58.5/75.0 52.5/69.5 56.0/74.2 56.2/67.3 57.3/73.4
XLM-Rlarge
NaiveFine-tuning1 75.7/86.5 49.0/68.6 63.4/80.4 61.7/79.8 63.9/82.0 59.7/76.7 64.3/80.1 59.3/75.9 59.0/79.1 50.0/59.3 60.6/76.8
STILT2 77.4/88.3 59.9/75.9 63.6/80.3 62.1/80.3 63.2/81.8 59.2/76.1 64.1/80.0 59.2/75.8 61.2/80.5 61.3/70.8 63.3/78.7
COSY 77.7/88.0 58.7/76.5 65.1/81.4 64.4/81.7 64.0/82.5 60.6/77.1 64.7/80.9 60.7/76.3 61.5/80.7 63.0/72.1 64.0/79.7
Table 7: Results on XQUAD of zero-shot setting. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 5>  </Paper ID = 49>


<Paper ID = 490> <Table 0> <Abstractive Summary> =Ours(w/ogold-standardentities) 60.16
In addition to the previous models, we also con-
ductablationstudiestoevaluatethecontributions Table 4: Overall dev F-score (%) of biomedical ex-
ofdifferentpartsinourmodel. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 490>


<Paper ID = 490> <Table 1> <Abstractive Summary> =Here,the
AMR parsing provides a clear tree structure and
Model Prec Rec F1
guidesthemodeltocorrectlylinktheevent-entity
BERT-AMR-KG(entities) 83.89 83.32 83.60
BERT-AMR-KG(events) 72.47 72.27 72.37 pairs (i.e., heterodimers with RAR beta, binding
BERT-AMR-KG(overall) 78.11 78.00 78.05 withVDR).However,theBERT-AMRmodelstill
failstoidentifyheterodimersasthethemeofstim-
Table 5: F-scores (%) on COVID-19 test dataset for ulated. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 490>


<Paper ID = 490> <Table 2> <Abstractive Summary> =Our model misses
Species 28
a lot of these non-verb event triggers due to the
Table 6: Our new COVID-19 ontology with 24 ﬁne- insufﬁcienttrainingexamples. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 490>


<Paper ID = 491> <Table 0> <Abstractive Summary> =Forthebaselines,we
utilizerecentstate-of-the-artBERT-basedmodels Table 1: Performance on the on ACE 2005 test set. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 491>


<Paper ID = 491> <Table 1> <Abstractive Summary> =All
thehyperparametersareselectedbasedontheF1 Table 2: Comparison with state-of-the-art models on
scores on the development set of the ACE 2005 CySecED.AllthemodelsinthistableuseBERT. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 491>


<Paper ID = 491> <Table 2> <Abstractive Summary> =Table 5: Generated sentences by GPT-2 for different datasets. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 491>


<Paper ID = 491> <Table 3> <Abstractive Summary> =0.5*|O| 80.3 72.4 76.2
Finally, to study the importance of the size of
1.0*|O| 82.4 75.0 78.5
2.0*|O| 81.3 73.3 77.1 thegenerateddatatoaugmenttrainingsetforED,
3.0*|O| 78.4 71.8 75.0 weconductanexperimentinwhichdifferentnum-
bersofgeneratedsamplesinG (fortheACE2005
Table 7: The performance of GPTEDOT on the ACE
dataset) are combined with the original data O. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 491>


<Paper ID = 492> <Table 0> <Abstractive Summary> =Thenweconcate-
G(a ,x )anddeﬁnethetrainingobjectiveas:
i v
1https://catalog.ldc.upenn.edu/
Lstr(θ)=−(cid:88)m log(cid:80)2m 1exp(cid:0)a(cid:62)2i−ex1pa2(cid:0)ia(cid:1)(cid:62) a (cid:1), (3) LDC2h20t0t8psT:1/9/github.com/pytorch/fairseq
i=1 j=1 [j(cid:54)=2i−1] 2i−1 j
6287ED EAE ED
Metric P R F1 P R F1 Metric P R F1
JointBeam 73.7 62.3 67.5 64.7 44.4 52.7 DMCNN 66.3 55.9 60.6
DMCNN 75.6 63.6 69.1 62.2 46.9 53.5 BiLSTM 59.8 67.0 62.8
dbRNN 74.1 69.8 71.9 66.2 52.8 58.7 BiLSTM+CRF 63.4 64.8 64.1
GatedGCN 78.8 76.3 77.6 − − − MOGANED 63.4 64.1 63.8
SemSynGTN − − − 69.3 55.9 61.9 DMBERT 62.7 72.3 67.1
RCEE ER 75.6 74.2 74.9 63.0 64.2 63.6 BERT+CRF 65.0 70.9 67.8
RoBERTa 75.1 79.2 77.1 53.5 66.8 59.4 RoBERTa 64.3 72.2 68.0
CLEVE 78.1 81.5 79.8 55.4 68.0 61.1 CLEVE 64.9 72.6 68.5
w/osemantic 75.3 79.7 77.4 53.8 67.0 59.7 w/osemantic 64.5 72.4 68.2
w/ostructure 78.0 81.1 79.5 55.1 67.6 60.7 w/ostructure 64.7 72.5 68.4
onACE(golden) 76.2 79.8 78.0 54.2 67.5 60.1
onACE(AMR) 75.7 79.5 77.6 53.6 66.9 59.5
Table 2: Supervised EE performance (%) of various
modelsonMAVEN. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 492>


<Paper ID = 492> <Table 1> <Abstractive Summary> =Table 1: Supervised EE performance (%) of various
modelsonACE2005. </Abstractive Summary> <Extractive Summary> EvaluationResults
Baselines Weﬁne-tuneourpre-trainedCLEVE The evaluation results are shown in Table 1 and
and set the original RoBERTa without our event Table 2.  </Extractive Summary>  </Table 1>  </Paper ID = 492>


<Paper ID = 492> <Table 2> <Abstractive Summary> =It also
tureonlyusestheeventsemanticrepresentations outperforms or achieves comparable results with
6288ED EAE ED
Metric(B-Cubed) P R F1 P R F1 Metric(B-Cubed) P R F1
LiberalEE 55.7 45.1 49.8 36.2 26.5 30.6 RoBERTa 32.1 25.2 28.2
RoBERTa+VGAE 37.7 28.5 32.5
RoBERTa 44.3 24.9 31.9 24.2 17.3 20.2
RoBERTa+VGAE 47.0 26.8 34.1 25.6 17.9 21.1 CLEVE 55.6 46.4 50.6
w/osemantic 53.2 44.8 48.6
CLEVE 62.0 47.3 53.7 41.6 30.3 35.1
w/ostructure 32.8 26.1 29.1
w/osemantic 60.6 46.2 52.4 40.9 29.8 34.5
w/ostructure 45.7 25.6 32.8 25.0 17.9 20.9
onACE(AMR) 61.1 46.7 52.9 41.5 30.1 34.9 Table 4: Unsupervised “liberal” EE performance (%)
ofvariousmodelsonMAVEN. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 492>


<Paper ID = 492> <Table 3> <Abstractive Summary> =Table 3: Unsupervised “liberal” EE performance (%)
ofvariousmodelsonACE2005. </Abstractive Summary> <Extractive Summary> Forthehuman Table 3 and Table 4.  </Extractive Summary>  </Table 3>  </Paper ID = 492>


<Paper ID = 492> <Table 4> <Abstractive Summary> =(2020) 79.1 80.6 61.5 69.0
CLEVE 60.4 48.4 53.7 39.4 31.1 34.8
Table 6: Supervised results (F1,%) on ACE 2005 and
Table 5: Unsupervised “liberal” EE human-evaluation
MAVEN of CLEVE using different AMR parsers, as
performance(%)onACE2005. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 4>  </Paper ID = 492>


<Paper ID = 492> <Table 5> <Abstractive Summary> =67.5
ACE2005 MAVEN
65.0
)62.5 ED EAE ED
%
(60.0 NYT 79.8 61.1 68.5
 
1 w/osemantic 77.4 59.7 68.2
-57.5
F w/ostructure 79.5 60.7 68.4
55.0 CLEVE
Wikipedia 79.1 60.4 68.8
52.5 RoBERTa
w/osemantic 77.3 59.5 68.4
BiLSTM+CRF
50.0 w/ostructure 78.8 60.0 68.6
5% 20% 40% 60% 80% 100%
Supervised Data Size
Table 7: Supervised results (F1,%) on ACE 2005 and
MAVENofCLEVEpre-trainedondifferentcorpora. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 5>  </Paper ID = 492>


<Paper ID = 492> <Table 6> <Abstractive Summary> =Thenwe
1 2 cos g g 1 2
(5) treattheAMRgraphasanundirectedgraph
6295Algorithm 1 Joint Constraint Clustering Algo- Batchsize 40
rithm Learningrate 1×10−5
Input:TriggercandidatesetT,ArgumentcandidatesetA, Adam(cid:15) 1×10−8
theirsemanticrepresentationsEgT andEgA,structure Adamβ1 0.9
representationsEt foreachtriggert,theminimaland Adamβ2 0.999
maximalnumberRoftriggerclustersKmin,Kmax as Triggernegativesamplingsizemt 9
T T Argumentnegativesamplingsizem 30
wellastheminimalandmaximalnumberofargument a
clustersKmin,Kmax; Maxsequencelength 128
Output:OptimalAtriggerAclustersCT ={CT,...,CT }and #parametersoftextencoder 355M
1 KT
argumentclustersCA ={CA,...,CA };
1 KA Table 8: Hyperparameters for the event semantic pre-
• O =∞,CT =∅,CA =∅ training. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 6>  </Paper ID = 492>


<Paper ID = 492> <Table 7> <Abstractive Summary> =min
• ForK =KmintoKmax,K =KmintoKmax
T T T A A A
– ClusteringwithSpectralClusteringAlgorithm: Batchsize 1024
– CT =spectral(T,ET,ET,K ,CA ) Restartprobability 0.8
curr g R T curr
– CA =spectral(A,EA,K ) Temperature 0.07
curr g A
– O =O(CT ,CA ) Warmupsteps 7,500
curr curr curr
– ifOcurr ≤Omin Weightdecay 1×10−5
* Omin =Ocurr,CT =CcTurr,CA =CcAurr Trainingsteps 75,000
– whileiteratetime≤10
Learningrate 0.005
* CcTurr =spectral(T,EgT,ERT,KT,CcAurr) Adam(cid:15) 1×10−8
* CcAurr =spectral(A,EgA,KA,CcTurr) Adamβ 0.9
* Ocurr =O(CcTurr,CcAurr) 1
Adamβ 0.999
* ifOcurr ≤Omin 2
· O = O ,CT = CT ,CA = Numberoflayers 5
min curr curr
CcAurr Dropoutrate 0.5
• returnO ,CT,CA Hiddendimensions 64
min
#parametersofgraphencoder 0.2M
Table 9: Hyperparameters for the event structure pre-
and do random walks starting from the ego. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 7>  </Paper ID = 492>


<Paper ID = 492> <Table 8> <Abstractive Summary> =6296Batchsize 40 ED EAE Runtime
Trainingepoch 30 Metric P R F1 P R F1 mins
Learningrate 1×10−5 RoBERTa 72.9 75.2 74.0 54.3 62.6 58.2 344
Adam(cid:15) 1×10−8 CLEVE 73.7 79.4 76.4 56.2 66.0 60.7 410
w/osemantic 72.1 77.9 74.9 54.5 65.6 59.5 422
Adamβ 0.9
1 w/ostructure 73.2 80.2 76.5 56.3 65.4 60.5 355
Adamβ 0.999 onACE(golden) 71.0 77.1 73.9 55.0 65.8 59.9 401
2
onACE(AMR) 70.2 77.3 73.6 54.1 65.5 59.3 408
Maxsequencelength 128
Table 11: Supervised EE performance (%) of various
Table10:Fine-tuninghyperparametersforCLEVEand
modelsonACE2005validationsetandthemodels’av-
RoBERTainthesupervisedsetting. </Abstractive Summary> <Extractive Summary> The rule used in the event semantic pre-training Table 8 and Table 9 show the best-performing
onlyhandlestheARG,timeandlocationrela- hyper-parametersusedinexperimentsoftheevent
tions,andfortheotherabout100AMRrelations, semantic pre-training and event structure pre-
we cannot ﬁnd an effective method to determine training,respectively.  </Extractive Summary>  </Table 8>  </Paper ID = 492>


<Paper ID = 492> <Table 9> <Abstractive Summary> =In
each trial, we train the models for 30 epochs and Table 12: Supervised EE performance (%) of various
selectmodelsbytheirF1scoresonthevalidation models on MAVEN validation set and the models’ av-
set. </Abstractive Summary> <Extractive Summary> The rule used in the event semantic pre-training Table 8 and Table 9 show the best-performing
onlyhandlestheARG,timeandlocationrela- hyper-parametersusedinexperimentsoftheevent
tions,andfortheotherabout100AMRrelations, semantic pre-training and event structure pre-
we cannot ﬁnd an effective method to determine training,respectively.  </Extractive Summary>  </Table 9>  </Paper ID = 492>


<Paper ID = 493> <Table 0> <Abstractive Summary> =Table 6: Evaluation results of candidate argument ex-
tractionandeventtypeclassiﬁcationonthetestset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 493>


<Paper ID = 494> <Table 0> <Abstractive Summary> =The 199 scanned forms are an improvement of 6% F1 point compared with
6313ANLS ANLS Model Acc Params
Model
Testset Form&Table BERT 89.81% 110M
BASE
BERTBASE 0.6372 - RoBERTaBASE 90.06% 125M
RoBERTaBASE 0.6642 - BERTLARGE 89.92% 349M
BERTLARGE 0.6745 - RoBERTaLARGE 90.11% 355M
RoBERTa 0.6952 - VGG-16a 90.97% -
LARGE
LayoutLM 0.6979 0.7012 StackedCNNSingleb 91.11% -
BASE
LayoutLM 0.7259 0.7203 StackedCNNEnsembleb 92.21% -
LARGE
StructuralLM 0.8394 0.8610 InceptionResNetV2c 92.63% -
LARGE
LadderNetd 92.77% -
Table 2: Average Normalized Levenshtein Similar- MultimodalSinglee 93.03% -
ity (ANLS) score on the DocVQA test set and the MultimodalEnsemblee 93.07% -
Form&Tablesubsetfromthetestset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 494>


<Paper ID = 498> <Table 0> <Abstractive Summary> =Wefeedtheinputpara-
Table 2: Transition sequence for the text in Figure 1.
graph P = (w ,w ,...,w ) into BERT to get
Forsimplicity,weuseindicestodenoteACs. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 498>


<Paper ID = 498> <Table 1> <Abstractive Summary> =Differently,our
w/odistance 88.1 -0.3 81.8 -0.7
proposed model can handle datasets of both tree
w/oBoW 85.9 -2.5 80.6 -1.9
and non-tree structures without introducing any
Table 5: The results of ablation experiments on PE corpus-speciﬁcstructuralconstraintsandalsoout-
dataset(%). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 498>


<Paper ID = 499> <Table 0> <Abstractive Summary> =Document length should not
betooshort(makessomequestionstrivial),ortoo
Table 2: Results of the Human Comprehension
long(addsaretrievalcomponenttothetask). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 499>


<Paper ID = 5> <Table 0> <Abstractive Summary> =Muslims 421 72.2 73.6 79.6 27.6
Due to its bias towards classifying all cases as
Immigrants 421 70.5 58.9 80.5 25.9
non-hateful, SN misclassiﬁes most hateful cases
andisnear-perfectlyaccurateonnon-hatefulfunc-
Table 4: Model accuracy (%) on test cases generated
tional tests. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 5>


<Paper ID = 5> <Table 1> <Abstractive Summary> =Second, B-D, B-F and P struggle with non-
Table 3: Model accuracy (%) on test cases for re-
hateful contraststo hateful phrases. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 5>


<Paper ID = 500> <Table 0> <Abstractive Summary> =Thelearningrate
forbothpost-trainingandﬁne-tuningis3e-5with Table 7: Automatic Evaluation results for HINT with
different∆. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 500>


<Paper ID = 500> <Table 1> <Abstractive Summary> =To
obtaintheBARTrepresentationofasentence,we
Table 8: Percentages (%) of the texts which are anno-
feeditintotheBARTdecoder(alongwithitscon-
tatedwithsomeerrorinalltheannotatedtexts. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 500>


<Paper ID = 500> <Table 2> <Abstractive Summary> =Before After B(M) B(D) HINT
Table 10: Sentence pairs sampled from the test set of (cid:173)(cid:174)(cid:175)(cid:176) (cid:174)(cid:173)(cid:175)(cid:176) 4.05 5.32 -0.89
ROCandthecorrespondingBLEU-1(B-1),BARTsim- (cid:173)(cid:174)(cid:175)(cid:176) (cid:173)(cid:175)(cid:174)(cid:176) 1.30 3.81 -1.08
ilarityandHINTsimilarity. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 500>


<Paper ID = 500> <Table 3> <Abstractive Summary> =Table 12: Generated texts by different models. </Abstractive Summary> <Extractive Summary> Table 3 shows that HINT outperforms Table4:ManualevaluationresultsonROC.Thescores
baselinesexceptforlexicalrepetition,whichisac- indicatethepercentages(%)ofWin,LoseorTiewhen
cordant with the results on ROC.  </Extractive Summary>  </Table 3>  </Paper ID = 500>


<Paper ID = 501> <Table 0> <Abstractive Summary> =Aspects Wearguethatanidealmetricforevalu-
Table 2: Examples for the invariance test to evaluate
atingopen-endedlanguagegenerationshouldhave
therobustnesstoperturbationsindifferentaspects. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 501>


<Paper ID = 501> <Table 1> <Abstractive Summary> =Tofurtherexaminetowhatextenttheimprove-
6398ROC WP
46ReasonableSamples+ 35ReasonableSamples+
Metrics Overall Overall
Rept Unrel Conf Chao Rept Unrel Conf Chao
1,000 22 319 39 87 1,000 23 330 83 24
BLEU -0.0239 0.0520 0.0192 0.1134 0.0156 -0.0537 0.1188 -0.0421 -0.0875 -0.1451
BERTScore-F1 0.1271∗ 0.1396 0.1240 0.0626 0.2283∗ 0.0329 0.1198 0.0446 0.0189 0.0634
PPL (P) 0.2547∗ -0.1075 0.1105 0.1354 0.5248∗ 0.3033∗ 0.0219 0.1853∗ 0.2188 0.4428∗
PPL (F) 0.2817∗ 0.2152 0.1380∗ 0.2643 0.5910∗ 0.2952∗ 0.0179 0.1720∗ 0.1917 0.3182∗
Ru-BERT 0.0830∗ 0.1160 0.0877 0.1103 0.1774 0.1666∗ 0.0936 0.0793 0.0162 0.0077
UNION 0.4119∗ 0.4517∗ 0.2000∗ 0.2107 0.4695∗ 0.3256∗ 0.3283 0.1738∗ 0.1914 0.3967∗
RUBER-BERT 0.1434∗ 0.0813 0.1453∗ 0.1173 0.1723 0.2116∗ 0.0716 0.1132 0.0721 0.1493
Table 3: Pearson correlation with human judgments on MANS. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 501>


<Paper ID = 501> <Table 2> <Abstractive Summary> =Besides, the results show that a powerful
UNION 0.09 0.02 0.15 0.04 0.15∗
language model may also be a powerful evalua-
tor(ifwecanalleviateitspreferenceforrepetitive
Table 4: Pearson correlation with human judgments
to assess generalization to output from different mod- texts). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 501>


<Paper ID = 501> <Table 3> <Abstractive Summary> =Synonym Paraphrase Punctuation Contraction Typo
Metrics
Human Dis Human Dis Human Dis Human Dis Human Dis
ROC 3,777 2,395 3,174 2,194 574 171 1,602 1,208 4,755 4,763
PPL (P) 0.3162∗ 0.2515∗ 0.1450∗ 0.0916∗ 0.0922∗ 0.0856 -0.0557 -0.0522∗ 0.4124∗ 0.2616∗
PPL (F) 0.3309∗ 0.2521∗ 0.2742∗ 0.2022∗ 0.1475∗ 0.0996 0.0504 0.0331∗ 0.4540∗ 0.2973∗
RUBERu-BERT 0.0307∗ 0.0290∗ 0.0255 0.0263 0.0052 -0.0140 0.0064 0.0071 -0.0112 0.0042
UNION 0.2187∗ 0.1169∗ 0.1112∗ 0.0399∗ 0.0818∗ 0.1375∗ 0.0275 0.0251 0.6021∗ 0.4606∗
WP 6,961 35,90 7,881 2,576 4,535 2,287 8,731 4,522 15,073 15,082
PPL (P) 0.2174∗ 0.1822∗ 0.0910∗ 0.0617∗ 0.2690∗ 0.2178∗ -0.0222∗ -0.0157 0.3983∗ 0.3885∗
PPL (F) 0.2964∗ 0.1747∗ 0.2273∗ 0.1020∗ 0.3822∗ 0.2515∗ 0.0851∗ 0.0682∗ 0.4603∗ 0.4043∗
RUBERu-BERT -0.0013 0.0004 0.0000 0.0000 -0.0256∗ -0.0308∗ -0.0012 -0.0043 0.0133 0.0154∗
UNION 0.1077∗ 0.0843∗ 0.0389∗ 0.0292∗ 0.2182∗ 0.2224∗ 0.0185∗ 0.0173∗ 0.3812∗ 0.3208∗
Table 7: Pearson correlation with automatic labels on the invariance test set of AUTOS. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 501>


<Paper ID = 501> <Table 4> <Abstractive Summary> =Table 10: Statistics of MANS. </Abstractive Summary> <Extractive Summary> Table 4 presents the perfor-
marize the results as follows: (1) PPL is ineffec-
mance,whichvariesconsiderablywithmodels.  </Extractive Summary>  </Table 4>  </Paper ID = 501>


<Paper ID = 501> <Table 5> <Abstractive Summary> =Theclassiﬁeris
RUBER 0.0119 -0.0527
RUBER-BERT 0.1434∗ 0.2116∗ ﬁne-tunedontheCoLAcorpusbasedonBERTand
BLEURT 0.3163∗ 0.1738∗ achievesanaccuracyof82.90%onthetestsetof
CoLA.Furthermore,ifwesupposethatallofthe
Table 11: Pearson correlation with human judgments
human-written stories in ROC and WP are gram-
on MANS. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 5>  </Paper ID = 501>


<Paper ID = 501> <Table 6> <Abstractive Summary> =it it its its itself
they them their theirs themselves
Table 15: Examples for the grammaticality classiﬁer. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 6>  </Paper ID = 501>


<Paper ID = 501> <Table 7> <Abstractive Summary> =The examples are sentences or stories selected from
Table 13: Personal pronouns which are used to create
the incoherent examples of the discrimination test set
testexampleswithintheaspect“CharacterBehaviour”. </Abstractive Summary> <Extractive Summary> Table 7 shows the robustness results.  </Extractive Summary>  </Table 7>  </Paper ID = 501>


<Paper ID = 502> <Table 0> <Abstractive Summary> =Sametrendsare
Table 4: Human evaluation results on grammaticality
observedonROUGE,whichareinAppendixB. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 502>


<Paper ID = 502> <Table 1> <Abstractive Summary> =Table 5: Sample generations on CMV [Upper] and NYT [Lower]. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 502>


<Paper ID = 502> <Table 2> <Abstractive Summary> =A controllable model of Table 6: List of subreddits used to construct training
grounded response generation. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 502>


<Paper ID = 502> <Table 3> <Abstractive Summary> =Association for Computational Lin- Table 7: ROUGE-2 and average length (Len.) </Abstractive Summary> <Extractive Summary> Table 3 lists
Effect of Hard Selection of Content Items.  </Extractive Summary>  </Table 3>  </Paper ID = 502>


<Paper ID = 503> <Table 0> <Abstractive Summary> =Table 1: Our new question type ontology, which is
Ourworkismoreinlinewithgeneratingdeeper
adoptedandmodiﬁedfromOlneyetal.(2012). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 503>


<Paper ID = 503> <Table 1> <Abstractive Summary> =6429Yahoo Reddit Yahoo Reddit
Model B-4 MTR R-L B-4 MTR R-L 7 7
DEEPQG 6.53 25.92 27.56 – – – ypes6 6
BART 21.88 38.01 39.16 19.45 35.46 37.82 e T5 5
u
BART+QWORD 22.02 38.44 39.32 19.80∗35.85 38.48∗ niq4 4
Type-awareModels of U3 3
BART+QTYPE 22.12 38.62 39.72 19.90∗35.83 38.68∗ # 
JOINTGEN(ours)22.56∗38.63 40.40∗20.09∗35.75 39.07∗ 2 2
w/ograph 22.21 38.21 39.93 19.81∗35.60 38.47∗ 2 3 4 5 6 7 8 9 2 3 4 5 6 7 8 9
# of Given Types # of Given Types
EXPLGEN(ours) 21.74 37.52 39.70 18.67 33.28 36.74
TPLGEN(ours) 21.51 36.55 39.63 17.83 31.69 36.05 BART + QWord JointGen EXPLGen TPLGen
Figure 3: Number of unique types of the generated
Table 2: Automatic evaluation results on Yahoo and questions(Y-axis),whendifferentnumbersofquestion
Reddit with BLEU-4 (B-4), METEOR (MTR) and typesarespeciﬁed(X-axis). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 503>


<Paper ID = 503> <Table 2> <Abstractive Summary> =Fi-
Table 3: Automatic evaluation on controllability and
diversity by specifying 9 different question types. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 503>


<Paper ID = 503> <Table 3> <Abstractive Summary> =Table 4: Percentage of samples marked as having the [JUDGMENTAL]Whatdoyouthinkaboutgeneticallymodi-
ﬁedbabies? </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 503>


<Paper ID = 503> <Table 4> <Abstractive Summary> =(b)REDDIT Focus F1
(b)Reddit
Table 5: Human evaluation on appropriateness (Ap- Figure 5: On both Yahoo and Reddit, we ﬁnd posi-
pro. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 4>  </Paper ID = 503>


<Paper ID = 503> <Table 5> <Abstractive Summary> =Yahoo Reddit
QuestionType # % # %
Table 6: Rules for ﬁltering out ill-formed question-
answerpairsonbothYahooandReddit. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 5>  </Paper ID = 503>


<Paper ID = 503> <Table 6> <Abstractive Summary> =AllrecruitedannotatorsareU.S.collegestu-
Table 8: Distributions of question types for the two
dents, and are paid $15 per hour for the task. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 6>  </Paper ID = 503>


<Paper ID = 503> <Table 7> <Abstractive Summary> =Our [V][NP]?”,“Whois[NP]?”,“Areyou
[NP]?”,“Should[NP][V][NP]?”
question type classiﬁers and template exemplar
classiﬁers are trained with a maximum learning
Table 10: Template exemplars for different question
rateof1×10−5 andabatchsizeof32. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 7>  </Paper ID = 503>


<Paper ID = 504> <Table 0> <Abstractive Summary> =SETIMES MT TR→EN 185,318 6.01M Foracomprehensivecomparisonwithprevious
EN→TR 8.40M
work,wetrainaSoTArecurrentMMT (Caglayan
et al., 2020) solely on the MULTI30K dataset,
Table 1: Training statistics of BERTGEN: the last col-
whichappliesasecondary(visual)attentioninthe
umnisthenumberofsamplesaftersequenceunrolling. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 504>


<Paper ID = 504> <Table 1> <Abstractive Summary> =twomenworkingonaroof Table 4: BLEU (BL) and METEOR (MT) scores for
TR ikibinanınins¸asındaoturmus¸,yanyana MMT: zero-shot systems are highlighted with gray. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 504>


<Paper ID = 504> <Table 2> <Abstractive Summary> =6445FAIRSEQ BERTGEN DE→FR FR→DE
TASK BL MT BL MT BL MT BL MT
IWSLT EN→DE 27.4 47.1 27.8 48.4 BERTGEN 19.6 40.5 13.1 36.7
IWSLT DE→EN 33.6 33.8 35.6 34.7 TARTU‡ 39.5 59.0 26.3 47.3
IWSLT EN→FR 41.0 59.8 40.2 60.5 MSRA‡ 46.5 64.2 38.2 56.4
IWSLT FR→EN 39.1 36.4 40.0 36.8
SETIMES EN→TR 14.1 18.9 13.5 19.1 Table 6: Zero-shot BERTGEN performance on
SETIMES TR→EN 17.3 25.8 19.0 26.9 WMT’19testset: TARTUandMSRAsystemsarenot
zero-shotastheyaretrainedonDE↔FRcorpora. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 504>


<Paper ID = 504> <Table 3> <Abstractive Summary> =Table 5: Comparison of text-only MT performance of
BERTGEN to each dedicated FAIRSEQ NMT system:
BERTGENoutperformssinglemodelsinmostcases. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 504>


<Paper ID = 504> <Table 4> <Abstractive Summary> =Table 10: Zero-shot FR→DE translations of WMT’19 test set. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 4>  </Paper ID = 504>


<Paper ID = 505> <Table 0> <Abstractive Summary> =Particularly,we
SentenceCE 28.29 27.84 +0.45* leverageaspeciﬁccriterionf topartitionsamples
TeacherModel intotwocomplementaryparts:
TeacherP 27.97 28.00 -0.03
golden
Entropy 27.62 27.92 -0.30 S := {y | f(y ) > Median(f(y)),y ∈ y},
High i i i
S := {y | f(y ) ≤ Median(f(y)),y ∈ y},
Table 1: BLEU score (%) of different criteria in Low i i i
WMT’14 En-De. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 505>


<Paper ID = 505> <Table 1> <Abstractive Summary> =Table 2: BLEU scores (%) on WMT’14 English-
German(En-De)task. </Abstractive Summary> <Extractive Summary> 4.2 AnalyticResults
As discussed before, as a carrier of the teacher’s Table 1 presents our results on different criteria.  </Extractive Summary>  </Table 1>  </Paper ID = 505>


<Paper ID = 505> <Table 2> <Abstractive Summary> =In our ap-
lectthestatisticsonthegradientdifferencebetween proaches,weselectthetransferringsamplesfrom
6462Models Zh-En ∆ Models En-De ∆
Transformer(Base) 25.73 ref DeepTransformer(12+6) 27.94 ref
Word-KD 26.21 +0.48 Word-KD 28.90 +0.96
Seq-KD 27.27 +1.54 Ours 29.12* +1.18
Word-KD+Ours 26.62* +0.89
Table 4: BLEU scores (%) on WMT’14 English-
Seq-KD+Ours 27.61* +1.88
German (En-De) task. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 505>


<Paper ID = 505> <Table 3> <Abstractive Summary> =Here we use Deep Transform-
ers (12 encoders and 6 decoders) for both the teacher
Table 3: BLEU scores (%) on WMT’19 Chinese-
English(Zh-En)task. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 505>


<Paper ID = 506> <Table 0> <Abstractive Summary> =Translation
Table 1: Example where context (italic) is needed to
We are interested in learning a system that trans-
correctlytranslatethepronoun“it”. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 506>


<Paper ID = 506> <Table 1> <Abstractive Summary> =4 IncreasingContextUsage
r
pb
ContextSize (1) (2) (3) 4.1 Context-awareWordDropout
1 0.365 0.315 0.206 Motivatedbytheaboveresultsdemonstratingthe
2 0.366 - - limitedcontextusageofmodelstrainedusingthe
3 0.367 - - standardMLEtrainingparadigm,particularlywith
4 0.366 - - respect to more distant context, we now ask the
question: “Is it possible to modify the training
Table 2: Point-Biserial correlation coefﬁcients on the methodology to increase context usage by the
contrastive datasets with pretrained models for differ-
model?” As an answer, we extend a popular reg-
entcontextsizes.MeasuredonContraPro(1)andBaw-
ularization technique used in sentence-level ma-
den et al. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 506>


<Paper ID = 506> <Table 2> <Abstractive Summary> =Con-
trastivedatasets,asdescribedin§3.2,allowusto
0.0 26.64 0.104 37.85 0.466
multi 0.1 27.45 0.190 37.98 0.460 measuretheperformanceofcontext-awaremodels
0.2 27.31 0.190 38.30 0.484 inspeciﬁcdiscoursephenomenabycomparingthe
probability of correct translation against the con-
Table 5: Results on IWSLT2017 for a multi-encoder
trastive translations. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 506>


<Paper ID = 506> <Table 3> <Abstractive Summary> =Tiede-
multi 0.1 47.29 51.74 50.24
mannandScherrer(2017)ﬁrstproposedthesimple
0.2 47.57 52.50 50.99
approachofconcatenatingtheprevioussentences
inboththesourceandtargetsidetotheinputtothe
Table 7: Results on anaphoric pronoun resolution
system; Jean et al. </Abstractive Summary> <Extractive Summary> COWORD dropout value p > 0 consistently im-
Table 3 illustrates some examples where the provestheperformanceofthecontextualmodels
COWORD dropout increased the per-sample when compared to models running with p = 0
CXMIsigniﬁcantly.  </Extractive Summary>  </Table 3>  </Paper ID = 506>


<Paper ID = 507> <Table 0> <Abstractive Summary> =(2020) 74.3 75.3 84.6 82.4 83.7 82.6 - - -
Ours(mappinginit) 76.8 78.1 86.3 84.2 84.9 84.9 65.7 51.5 76.6
Table 4: BLI results on MUSE dataset in comparison with prior published results (P@1). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 507>


<Paper ID = 508> <Table 0> <Abstractive Summary> =We used the
6http://www.phontron.com/kytea/ TransformerBigarchitecturewithFFNsize8192,
6496System de-en en-de en-ru ru-en zh-en en-zh de-fr fr-de
NT’18WMTbitext 46.2 45.9 33.5 33.4 25.8 39.2 - -
Single NT’18CCMatrix 49.9 50.3 35.7 36.9 30.2 40.8 - -
systems
NT’19WMTbitext 41.0 40.4 31.4 38.1 - - - -
NT’19CCMatrix 43.3 44.5 35.5 41.8 34.8 35.6 37.9 33.5
NT’20WMTbitext 40.3 31.9 24.0 35.5 - - - -
NT’20CCMatrix 39.2 35.1 25.5 37.1 35.0 38.8 33.8 33.8
Ensembles
+BT NT’19best 42.8 44.9 36.3 40.2 39.9 44.6 37.3 35.0
+Reranking
Table 3: BLEU scores on the Newstest’18, Newstest’19 and Newstest’20 test sets. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 508>


<Paper ID = 508> <Table 1> <Abstractive Summary> =Table 4: 8-gram test data overlap. </Abstractive Summary> <Extractive Summary> Table 1 gives a summary for
ingdataprovidedwiththesecorpora,sodonotuse
the54largestlanguages.  </Extractive Summary>  </Table 1>  </Paper ID = 508>


<Paper ID = 51> <Table 0> <Abstractive Summary> =Basedontheﬁndingsfrompsychologi-
FastText-wiki-news-subword-300 84.9 84.8
Word2vec-GoogleNews-300 80.2 72.6 calsurveys,weexpectthesetargetgroupswillbe
GloVe-twitter-200 72.8 74.2 mappedtothefollowingquadrants:2
GloVe-wiki-gigaword-300 78.7 77.9
• Warm-Competent: nurse, psychologist
Table 2: Accuracy of the word embedding models on
predictingthecorrectlabelsfortheextendedlexicon. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 51>


<Paper ID = 51> <Table 1> <Abstractive Summary> =is greater than the absolute value of warmth, and
605Strategy Overall HC-HW LC-HW LC-LW HC-LW |C|>|W| |W|>|C|
n=895 n=192 n=183 n=176 n=344 n=428 n=467
Directantonym 23.4 26.0 32.6 27.8 15.0 27.2 19.2
Oppositequadrant 29.6 30.2 15.5 26.1 38.3 28.1 31.2
Flipwarmth 20.6 14.6 26.5 29.5 16.4 12.3 29.8
Flipcompetence 16.7 24.0 12.7 13.1 16.7 22.8 10.1
Samequadrant 9.6 5.2 12.7 3.4 13.5 9.6 9.6
Table 3: The percentage of times each of the hypothesized strategies of anti-stereotype generation is used for
stereotypes,overallandineachquadrant.QuadrantsarelabelledasHC-HW,LC-HW,LC-LW,andHC-LW,where
HC/LCdenoteshigh/lowcompetence,andHW/LWdenoteshigh/lowwarmth. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 51>


<Paper ID = 51> <Table 2> <Abstractive Summary> =607Target Stereotype Anti-stereotype XbutYconstruction Xand¬Yanti-stereotype
Grandfather old young kindbutfeeble kindandstrong
Entrepreneur savvy lazy inventivebutruthless inventiveandcompassionate
Engineer smart dumb intelligentbutegotistical intelligentandaltruistic
Mommy loving uncaring caringbutchildish caringandmature
Softwaredeveloper nerdy dumb intelligentbutunhealthy intelligentandhealthy
Table 5: Examples of positive anti-stereotypes created by identifying positive and negative words along each of
thedimensions,andtakingtheantonymonlyofthenegativewords. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 51>


<Paper ID = 510> <Table 0> <Abstractive Summary> =BERT-base(Devlinetal.,2019) 22.5 110 84.5 92.0 90.9 71.1 92.9 87.8 58.1 89.8 83.4
GhostBERT(m=12/12) 22.5 110 84.7 92.3 91.1 71.8 93.0 88.0 63.6 89.7 84.3
GhostBERT(m=9/12) 16.9 88 84.8 92.1 91.2 72.6 92.6 87.5 61.1 89.8 84.0
GhostBERT(m=6/12) 11.3 67 84.7 92.2 91.2 72.2 92.9 87.3 58.1 89.2 83.5
GhostBERT(m=3/12) 5.8 46 84.3 91.6 91.4 72.9 94.6 86.5 53.9 89.2 83.1
GhostBERT(m=1/12) 2.0 32 82.8 90.0 90.5 66.1 92.8 86.0 46.1 87.8 80.3
RoBERTa-base(Liuetal.,2019) 22.5 125 87.6 92.8 91.9 78.7 94.8 90.2 63.6 91.2 86.4
GhostRoBERTa(m=12/12) 22.5 125 88.0 93.1 91.9 80.5 95.3 90.7 65.0 91.3 87.0
GhostRoBERTa(m=9/12) 16.9 103 87.6 92.9 91.9 79.4 95.4 89.0 60.8 90.7 86.0
GhostRoBERTa(m=6/12) 11.3 82 86.8 92.6 91.6 77.6 94.4 89.7 57.6 90.3 85.1
GhostRoBERTa(m=3/12) 5.8 61 86.1 91.7 91.2 73.6 94.5 88.0 52.4 89.2 83.3
GhostRoBERTa(m=1/12) 2.0 47 82.1 89.2 90.5 66.1 93.7 83.3 39.8 87.4 79.0
ELECTRA-small(Clarketal.,2020) 1.7 14 78.9 87.9 88.3 68.5 88.3 87.4 56.8 86.8 80.4
GhostELECTRA-small(m=4/4) 1.7 14 82.5 89.3 90.7 71.5 92.0 88.7 59.6 88.4 82.8
Table 1: Development set results of the baseline pre-trained language models and our proposed method on the
GLUEbenchmark. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 510>


<Paper ID = 510> <Table 1> <Abstractive Summary> =GhostBERT 84.3 91.6 91.4 72.9 94.6 86.5 53.9 89.2 83.1
-DA&KD 80.2 88.5 90.0 63.2 91.6 83.8 52.5 86.7 79.6
3/12
-Softmax 84.3 91.5 90.9 71.8 92.3 85.5 52.6 89.1 82.3
-ReLU 84.0 91.7 91.0 70.8 92.3 85.8 47.6 88.6 81.5
GhostBERT 82.8 90.0 90.5 66.1 92.8 86.0 46.1 87.8 80.3
-DA&KD 76.0 83.4 86.6 58.1 86.6 80.6 35.8 84.4 73.9
1/12
-Softmax 82.6 90.0 90.4 65.3 92.1 85.5 40.8 88.1 79.4
-ReLU 82.7 89.8 90.6 60.3 92.0 84.8 37.8 87.1 78.1
Table 4: Ablation study of data augmentation (DA), knowledge distilla- Figure3: Averagescoreoverﬁvetasks
tion (KD), softmax normalization over the convolution kernel, and non- with various kernel sizes of DWConv
linearity. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 510>


<Paper ID = 510> <Table 2> <Abstractive Summary> =(2020) replace
all the feed-forward networks with grouped con-
Table 6: Comparison of different positions to add the
volution. </Abstractive Summary> <Extractive Summary> Table 2 shows the comparison between
of the baseline pre-trained language models and the proposed method and other popular BERT
ourproposedmethod.  </Extractive Summary>  </Table 2>  </Paper ID = 510>


<Paper ID = 510> <Table 3> <Abstractive Summary> =As is noted
Table 8: Hyperparameters for the distillation and ﬁne-
in the GLUE ofﬁcial website1, there are some is-
tuning stages in training GhostBERT on the GLUE
sues with the construction of it. </Abstractive Summary> <Extractive Summary> Forthetestset,the In Table 3 and Figure 1, we also compare the
6516pruned BERT with and without ghost modules.  </Extractive Summary>  </Table 3>  </Paper ID = 510>


<Paper ID = 510> <Table 4> <Abstractive Summary> =9 92.6 85.5 53.4 89.0 69.3 78.0
17 92.4 84.8 53.3 88.9 68.2 77.5
A.3 FLOPs 1 92.1 85.3 41.7 87.6 64.3 74.2
3 92.8 86.0 46.1 87.8 66.1 75.8
Floating-point operations (FLOPs) measures the 1/12 5 92.2 85.3 41.1 87.5 64.6 74.2
9 92.1 84.8 41.4 87.5 63.9 73.9
numberofﬂoating-pointoperationsthatthemodel 17 92.0 84.3 40.9 87.5 63.5 73.7
performsforasingleprocessandcanbeusedasa
Table 9: Comparison of different kernel sizes on the
measureofthecomputationalcomplexityofdeep
development set on ﬁve tasks of GLUE. </Abstractive Summary> <Extractive Summary> Table 4 veriﬁes the ef- If the kernel convolves input over the feature di-
fectiveness of the Data Augmentation (DA) and rection(abbreviatedasConv1D F),thenumberof
KnowledgeDistillation(KD)upontheGhostBERT inputandoutputchannelisn,andtheweighthas
model with width multiplier m ∈ {3/12,1/12}.  </Extractive Summary>  </Table 4>  </Paper ID = 510>


<Paper ID = 511> <Table 0> <Abstractive Summary> =Table 5: Standard deviation of tasks in GLUE (dev)
Searching Super Tickets Efﬁciently. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 511>


<Paper ID = 511> <Table 1> <Abstractive Summary> =4 
LARGE
PercoefWn eti gRhetm ainingP ercoefWn eti gRhetm aining 
Table 8: Standard deviation of some tasks in GLUE Figure 7: Single task ﬁne-tuning evaluation results of
(dev)over3differentlearningrates. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 511>


<Paper ID = 513> <Table 0> <Abstractive Summary> =We transform computations according to (Li and Table 3: Best performing conﬁgurations found in
Eisner,2009). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 513>


<Paper ID = 514> <Table 0> <Abstractive Summary> =4.2 Multi-hopGraphReasoninginText
Model MR R8 R52 Ohsumed Graph
TextCNN(cid:63) 77.75 95.71 87.59 58.44
TextRNN(cid:63) 77.68 96.31 90.54 49.27
fastText(cid:63) 75.14 96.13 92.81 57.70
SWEM(cid:63) 76.65 95.32 92.94 63.12
TextGCN(cid:63) 76.74 97.07 93.56 68.36
GraphCNN(cid:63) - 97.80 94.60 69.40
minCUT (Bianchietal.,2019) 76.52 97.42 93.53 66.37
TextING (Zhangetal.,2020b) 79.82 98.04 95.48 70.42
BERT-base(Jinetal.,2019) 85.80 97.92 96.37 71.04
HDGCN-static 79.70 98.05 95.49 70.75
HDGCN 86.50 98.45 96.57 73.97
Table 1: Test accuracy (%) on small-scale English
datasets,wheretheresultslabeledwith(cid:63)arecitedfrom
(Zhangetal.,2020b). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 514>


<Paper ID = 514> <Table 1> <Abstractive Summary> =Model AG SST-1 SST-2 Yelp-F
fastText(Joulinetal.,2017) 92.5 - - 63.9
DRNN(Wang,2018) 93.6 47.3 86.4 65.3
CNN-NSU(Lietal.,2017) - 50.8 89.4 -
CapNets(Yangetal.,2018) 92.6 - 86.8 -
LK-MTL(Xiaoetal.,2018) - 49.7 88.5 -
BERT(Xiaoetal.,2018) 94.5 50.1 89.3 65.8
TinyBERT(Jiaoetal.,2020) 94.7 51.6 92.6 66.1
Star-Transformer(Guoetal.,2019) - 52.9 - -
HDGCN-static 94.0 52.1 90.8 65.2
HDGCN 95.5 53.9 92.3 69.6
Figure3: Themessageaggregationonadjacencymatrix
Table 2: Test accuracies (%) on large-scale English
A(cid:101) withword-wordco-occurrenceindocument. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 514>


<Paper ID = 514> <Table 2> <Abstractive Summary> =SMART(Jiangetal.,2020) - 82.7 86.0 88.7
CA-MTL(Pilaultetal.,2021) 1.12× 82.8 86.2 88.0
HDGCN 1.02× 80.3 85.6 92.3
Table 4: Test accuracy (%) on SNLI, where the total
parameterstaketheBERT-baseasbase. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 514>


<Paper ID = 515> <Table 0> <Abstractive Summary> =Foralanguagemodeltoworkwellitneeds
Table 1: Impact of selection method on training sen-
tobetrainedondatathatissuitedtothetargetdo-
tencesandperformanceofletterlanguagemodels. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 515>


<Paper ID = 515> <Table 1> <Abstractive Summary> =6586Original we are off to the uk in a couple of days
Abbreviation w r off t th uk n a cpl of dys
Expansion we are off to the uk in a couple of days
Original didn’t get a commitment just told them i thought it would be impossible
Abbreviation dnt gt a cmmt jst tld thm i tht it wd b mpss
Expansion don’t get a comment just told them i thought it would be impress
Original no arrangements he just hasn’t had a good year on a comparative basis
Abbreviation n ats he j h h a go ye on a ct b
Expansion and that’s the job he has a good eye on a city but
Table 4: Examples from the initial automatic expansion experiment in Section 3.2. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 515>


<Paper ID = 515> <Table 2> <Abstractive Summary> =Table 5: Examples of selected text data using three different approaches in Section 4.1. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 515>


<Paper ID = 515> <Table 3> <Abstractive Summary> =6587Voweldropprobability Example
0.5 Reference: hopefully this can wait until monday
0.5 Input: hopeflltthisvamwwtujrlmndy
0.5 Recognition: hopefully this can wait until monday
0.5 Reference: let it rip
0.5 Input: ltutrp
0.5 Recognition: let it rip
0.5 Reference: should systems manage the migration
0.5 Input: shldsystensmnferhemgratin
0.5 Recognition: she’d systems manager he migration
1.0 Reference: could you see where this stands
1.0 Input: cldyusewhtwrgsstnda
1.0 Recognition: could you see where the stands
1.0 Reference: florida is great
1.0 Input: flrdaushrt
1.0 Recognition: florida is great
1.0 Reference: they are more efficiently pooled
1.0 Input: yhyare’rrefgvmyluplf
1.0 Recognition: they are more egg vinyl hold
Table 6: Examples of abbreviated and noisy input and the resulting recognition results for two different vowel
drop probabilities in Section 5.3. </Abstractive Summary> <Extractive Summary> Thesesetscorrespondtophrasesthatwere
Table 3 and Figure 3 show results and statistical likely correctly abbreviated, under-abbreviated,
tests.  </Extractive Summary>  </Table 3>  </Paper ID = 515>


<Paper ID = 516> <Table 0> <Abstractive Summary> =Pre-trained 3https://huggingface.co
6592CoLA SST-2 MRPC QQP MNLI-m QNLI RTE Average
Trainsize 8.6k 67k 3.7k 360k 390k 100k 2.5k
Devsize 1k 0.9k 0.4k 40k 9.8k 5.5k 0.3k
Old:BERT Acc 82.26% 91.17% 86.03% 90.76% 83.82% 91.07% 67.15% 84.61%
base
→BERT -Baseline Acc 82.93% 91.63% 86.03% 90.56% 83.55% 90.65% 63.18% 84.08%
base
RNF 4.41% 1.95% 4.17% 2.32% 3.56% 2.35% 11.43% 4.31%
→BERT -Distillation Acc 84.47% 92.09% 87.01% 91.14% 83.77% 91.16% 68.95% 85.81%
base
RNF 1.92% 0.80% 1.72% 1.69% 4.32% 2.47% 8.30% 2.99%
→BERT -Ensemble Acc 82.17% 91.63% 86.03% 91.06% 84.35% 91.62% 70.76% 85.37%
base
RNF 2.59% 0.92% 1.23% 1.18% 1.66% 1.06% 4.69% 1.90%
→BERT -Baseline Acc 85.62% 92.89% 87.75% 91.11% 86.10% 92.53% 66.43% 86.06%
large
RNF 2.68% 1.72% 5.88% 2.82% 3.95% 2.64% 12.27% 4.57%
→BERT -Distillation Acc 85.62% 92.89% 88.73% 91.50% 86.73% 92.15% 73.65% 87.33%
large
RNF 2.49% 1.26% 2.45% 2.46% 3.76% 2.54% 5.42% 2.91%
→BERT -Ensemble Acc 84.95% 93.12% 89.46% 91.66% 87.05% 93.08% 67.87% 86.74%
large
RNF 2.78% 1.61% 2.45% 2.20% 3.24% 2.27% 10.83% 3.63%
Table 2: Results of ﬁne-tuning with distillation and ensemble on GLUE benchmark. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 516>


<Paper ID = 516> <Table 1> <Abstractive Summary> =representations rather than effectively encourage
6593Old: BERT Acc: 86.03%
base
New: →BERT →BERT
base large
Acc R Acc R
NF NF
Baseline 86.03% 4.17% 87.75% 5.88%
Distillation-R ,Logits 87.01% 1.72% 88.73% 2.45%
KL-div
Distillation-R ,[CLS] 85.54% 3.19% 88.73% 2.21%
l2
Distillation-R ,All[CLS] 85.54% 2.45% 87.99% 4.90%
l2
Ensemble 86.0% 1.23% 89.46% 2.45%
Table 3: Accuracy and regression results on MRPC with BERT →BERT and BERT →BERT
base base base large
updatesusingvariantsofdistillationandensemblemethods. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 516>


<Paper ID = 516> <Table 2> <Abstractive Summary> =regressiononcertainbehaviortestswhenupdating
6595Old(:EBrrEorR%T)base New:BERTlarge(RNF)
1Seed 1Seed KD1Seed 5Seeds KD5Seeds Centric Ensemble
Coref-He/She 0.0% 13.4% 22.4% 12.3(±16.1)% 41.2(±47.0)% 0.0 0.0(±0.0)%
Vocab-People 0.0% 13.8% 1.9% 59.5(±34.8)% 34.1(±47.1)% 89.0% 55.2(±50.8)%
Vocab-More/Less 100.0% 0.0% 0.0% 0.0(±0.0)% 0.0(±0.0)% 0.0% 0.0(±0.0)%
Taxonomy-Synonym 0.0% 42.3% 0.0% 77.0(±26.2)% 20.3(±44.5)% 73.1% 61.9(±54.1)%
SRL-Pharaphrase 0.0% 12.5% 99.9% 63.2(±43.4)% 42.0(±48.3)% 26.9% 61.9(±54.1))%
SRL-AsymmetricOrder 0.0% 47.1% 0.0% 70.7(±20.0)% 22.3(±43.7)% 92.0% 58.6(±52.2)%
SRL-Active/Passive1 0.1% 9.3% 65.2% 58.0(±43.2)% 52.7(±50.1)% 98.5% 42.4(±51.5)%
SRL-Active/Passive2 0.1% 90.0% 0.7% 95.5(±4.8)% 23.8(±43.3)% 99.6% 65.2(±56.5)%
SRL-Active/Passive3 99.9% 0.1% 0.0% 0.1(±0.0)% 0.0(±0.0)% 0.1% 0.1(±0.1)%
Temporal-Before/After 100.0% 0.0% 0.0% 0.0(±0.0)% 0.0(±0.0)% 0.0% 0.0%
Average 38.5% 19.9% 14.8% 38.2% 20.3% 43.8% 33.3%
Table 5: Behavioral tests with CHECKLIST. </Abstractive Summary> <Extractive Summary> 4 Experiments 4.3 MainResults
Table 2 shows the efﬁcacy of distillation method
4.1 ImplementationDetails
and model ensemble on reducing NLP classiﬁca-
Sinceweusuallyupdatemodelsfromelementary
tion task model update regressions.  </Extractive Summary>  </Table 2>  </Paper ID = 516>


<Paper ID = 516> <Table 3> <Abstractive Summary> =The Stanford Sentiment Treebank is a
truth class than the new model D = binary single-sentence classiﬁcation task, where
reg
6600CoLA SST-2 MRPC QQP MNLI-m MNLI-mm QNLI RTE
Trainsize 8.6k 67k 3.7k 360k 390k 390k 100k 2.5k
Devsize 1k 0.9k 0.4k 40k 9.8k 9.8k 5.5k 0.3k
Old:BERT Acc 82.84% 92.20% 86.03% 90.76% 83.82% 84.13% 91.07% 67.15%
base
→BERT Acc 83.80% 91.93% 86.03% 90.56% 83.55% 83.94% 90.65% 63.18%
base
R 3.36% 2.10% 4.17% 2.32% 3.56% 3.67% 2.35% 11.43%
NF
→BERT Acc 85.43% 93.23% 87.75% 91.11% 86.10% 86.49% 92.53% 66.43%
large
R 3.16% 1.95% 5.88% 2.82% 3.95% 3.69% 2.64% 12.27%
NF
→ROBERTAbase Acc 84.85% 94.11% 89.22% 91.25% 87.58% 87.74% 92.71% 63.17%
R 4.67% 1.22% 4.66% 1.98% 2.64% 2.38% 1.74% 13.1%
NF
→ELECTRA Acc 85.81% 95.41% 86.03% 91.35% 88.87% 88.67% 93.30% 72.92%
base
R 5.18% 1.38% 5.39% 3.20% 3.50% 3.57% 2.65% 7.58%
NF
→ALBERTA Acc 76.51% 91.86% 86.27% 90.73% 85.26% 85.14% 91.67% 74.73%
base
R 10.74% 3.67% 6.86% 3.78% 5.22% 5.24% 3.70% 9.03%
NF
Old:BERT Acc 85.43% 93.23% 87.75% 91.11% 86.10% 86.49% 92.53% 66.43%
large
→BERT Acc 85.14% 94.15% 87.01% 91.52% 86.75% 87.24% 93.34% 70.76%
large−wwm
R 5.05% 1.60% 7.82% 3.03% 5.08% 4.67% 2.75% 15.22%
NF
Old:ROBERTAbase Acc 84.85% 94.38% 87.25% 91.28% 88.24% 87.63% 92.51% 70.76%
→ELECTRA Acc 85.81% 95.41% 86.03% 91.35% 88.87% 88.67% 93.30% 72.92%
base
R 4.31% 1.49% 6.62% 2.77% 3.47% 3.48% 2.62% 7.58%
NF
Table 6: Accuracy and regression measures of different model update variants on GLUE benchmark. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 516>


<Paper ID = 516> <Table 4> <Abstractive Summary> =Old: BERT Acc: 86.03%
base
New: →BERT →BERT
base large
Acc R Acc R
NF NF
Baseline 86.03% 4.17% 87.75% 5.88%
Distillation(R ,D ) 87.25% 2.94% 88.73% 3.68%
KL-div train
Distillation(R ,D ) 87.01% 3.92% 88.48% 4.90%
KL-div correct
Distillation(R ,D ) 87.01% 1.72% 88.73% 2.45%
KL-div better
Distillation(R ,D ) 85.29% 2.45% 88.73% 2.21%
l2 better
Table 7: Results on MRPC of our proposed techniques towards regression-free model updates. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 4>  </Paper ID = 516>


<Paper ID = 517> <Table 0> <Abstractive Summary> =Bandwagon 8.4 5 5
Table2showsthatthetechniquescanbefound
Transfer — — 95
bothinthetextualandinthevisualcontentofthe
Appealto(Strong)Emotions — — 90
meme,thussuggestingtheuseofmultimodallearn-
Total 2,119 2,488
ingapproachestoeffectivelyexploitallinformation
Table 2: Statistics about the propaganda techniques. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 517>


<Paper ID = 518> <Table 0> <Abstractive Summary> =6620Resource Num.Passages Num.QAPairs 4 ExperimentsandResults
Train Val Test Train Val Test
Ourstudyallowsustoanswerthreequestions: (i)
BERT 3,412 992 1,056 11,330 1,130 1,130
ELECTRA 3,925 1,352 1,352 14,556 1,456 1,456 howwelldomodelsﬁne-tunedonADCdatagen-
eralize to unseen distributions compared to ﬁne-
Table 1: Number of unique passages and question- tuning on SDC? </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 518>


<Paper ID = 519> <Table 0> <Abstractive Summary> =(GB) (GPU,CPU) (Acc) (Acc)
DrQA(Chenetal.,2017) (cid:51) 26 1.8,0.6 - 29.8
BERTSerini(Yangetal.,2019) (cid:51) 21 2.0,0.4 - 38.6
Retriever-Reader ORQA(Leeetal.,2019) (cid:55) 18 8.6,1.2 33.3 20.2
REALM (Guuetal.,2020) (cid:55) 18 8.4,1.2 40.4 -
News
DPR-multi(Karpukhinetal.,2020) (cid:55) 76 0.9,0.04 41.5 24.1
DenSPI(Seoetal.,2019) (cid:51) 1,200 2.9,2.4 8.1 36.2
PhraseRetrieval DenSPI+Sparc(Leeetal.,2020) (cid:51) 1,547 2.1,1.7 14.5 40.7
DensePhrases(Ours) (cid:55) 320 20.6,13.6 40.9 38.0
Table 1: Retriever-reader and phrase retrieval approaches for open-domain QA. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 519>


<Paper ID = 519> <Table 1> <Abstractive Summary> =}† 33.3 36.4 30.1 45.0 20.2
REALM (Guuetal.,2020) {Wiki.,CC-News}† 40.4 40.7 42.9 - -
News
DPR-multi(Karpukhinetal.,2020) {NQ,WQ,TREC,TQA} 41.5 42.4 49.4 56.8 24.1
Phraseretrieval C :Training
phrase
DenSPI(Seoetal.,2019) {SQuAD} 8.1∗ 11.1∗ 31.6∗ 30.7∗ 36.2
DenSPI+Sparc(Leeetal.,2020) {SQuAD} 14.5∗ 17.3∗ 35.7∗ 34.4∗ 40.7
DenSPI+Sparc(Leeetal.,2020) {NQ,SQuAD} 16.5 - - - -
DensePhrases(ours) {SQuAD} 31.2 36.3 50.3 53.6 39.4
DensePhrases(ours) {NQ,SQuAD} 40.9 37.5 51.0 50.7 38.0
Table 3: Open-domain QA results. </Abstractive Summary> <Extractive Summary> We use a version of Natural
models, we install all models in Table 1 on the
Questions and TriviaQA provided by Min et al.  </Extractive Summary>  </Table 1>  </Paper ID = 519>


<Paper ID = 519> <Table 2> <Abstractive Summary> =(cid:55) (cid:55) (cid:51) (cid:51) 78.3
Table 4: Slot ﬁlling results on the test sets of T-REx
andZeroshotRE(ZsRE)intheKILTbenchmark. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 519>


<Paper ID = 519> <Table 3> <Abstractive Summary> =Table 7: Effect of query-side ﬁne-tuning in
DensePhrases on each test set. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 519>


<Paper ID = 52> <Table 0> <Abstractive Summary> =620Moviereviews(Zaidanetal.,2007) Personalattacks(Cartonetal.,2018)
Pr(z) %(z) F (y) %(x) Pr(z) %(z) F (y) %(x)
1 1
h Hardrationalization 0.37 2.7% 0.72 2.7% 0.17 32.5% 0.73 32.5%
0
h w/Domainknowledge 0.38 3.7% 0.72 3.7% 0.22 16.9% 0.73 16.9%
1
h w/oRationaleregularization 0.31 99.9% 0.92 99.9% 0.19 99.9% 0.82 99.9%
2
h w/Adversarialcomponents 0.33 2.5% 0.70 2.5% 0.22 14.9% 0.75 14.9%
3
s Softrationalization 0.58 3.7% 0.91 100% 0.35 16.9% 0.82 100%
0
s w/Domainknowledge 0.62 3.7% 0.92 100% 0.39 16.9% 0.82 100%
1
s w/Halfrationales 0.64 1.9% 0.92 100% 0.46 8.4% 0.82 100%
2
s w/Doublerationales 0.55 7.4% 0.92 100% 0.31 33.8% 0.82 100%
3
Table 1: Evaluation results for hard and soft rationalization methods. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 52>


<Paper ID = 520> <Table 0> <Abstractive Summary> =Table 2: Effect of different factors on the supervised
trainingofretrieverwhenevaluatedonNQtestset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 520>


<Paper ID = 520> <Table 1> <Abstractive Summary> =researchinOpenQA—withonlyafewhundredex- Ontheotherhand,inJointTop-k,updatingthe
6653Model NQ TriviaQA
Q C Top-1 Top-5 Top-20 Top-100 Top-1 Top-5 Top-20 Top-100
BaseConﬁguration
DPR(Karpukhinetal.,2020) – 67.1 78.4 85.4 – – 79.4 85.0
ICT+Supervised 48.4 72.1 81.8 88.0 58.4 73.9 81.7 86.3
IndividualTop-k (cid:51) (cid:55) 54.5 73.7 83.2 88.6 61.4 75.6 82.1 86.7
IndividualTop-k (cid:51) (cid:51) 56.8 75.0 84.0 89.2 63.5 76.8 83.1 87.0
JointTop-k (cid:51) (cid:55) 51.1 72.1 81.8 87.8 59.1 74.1 81.3 86.3
LargeConﬁguration
ICT+Supervised 52.4 72.7 82.6 88.3 61.9 76.2 82.9 87.1
IndividualTop-k (cid:51) (cid:51) 57.5 76.2 84.8 89.8 66.4 78.7 84.1 87.8
JointTop-k (cid:51) (cid:55) 53.7 73.3 83.2 88.0 61.2 75.9 82.7 87.0
Table 4: Effect of end-to-end training using question-answer pairs on retrieval accuracy. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 520>


<Paper ID = 520> <Table 2> <Abstractive Summary> =Table 5: Effect of score scaling factor (τ) on the re-
Thishighscorewasleadingtoaskewedprobability
trievalaccuracywhenevaluatedontheNQtestset.The
distributionwithmostofthemassbeingcentered
ﬁrstcolumndenotesthemultiple(m)thatismultiplied
√ √
over the top-1 or top-2 retrieved documents. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 520>


<Paper ID = 520> <Table 3> <Abstractive Summary> =Table 6: Answer extraction results using Individual
Top-k approach. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 520>


<Paper ID = 521> <Table 0> <Abstractive Summary> =In response, we propose CRONKGQA, an Free917 (Cai and Yates, 2013) and Complex-
enhancementofEmbedKGQA,whichoutperforms Questions (Bao et al., 2016) that are temporal in
6664Reasoning ExampleTemplate ExampleQuestion
Simpletime Whendid{head}holdthepositionof{tail} WhendidObamaholdthepositionofPresidentofUSA
Simpleentity Whichawarddid{head}receivein{time} WhichawarddidBradPittreceivein2001
Before/After Whowasthe{tail}{type}{head} WhowasthePresidentofUSAbeforeObama
First/Last Whendid{head}playtheir{adj}game WhendidMessiplaytheirﬁrstgame
Timejoin Whoheldthepositionof{tail}during{event} WhoheldthepositionofPresidentofUSAduringWWII
Table 2: Example questions for different types of temporal reasoning. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 521>


<Paper ID = 521> <Table 1> <Abstractive Summary> =Thereisnoentityoverlapbetweentestquestions
Table 3: Slot-ﬁlled paraphrases generated by humans andtrainquestions. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 521>


<Paper ID = 522> <Table 0> <Abstractive Summary> =0.313 0.212 0.290 0.245 0.314 0.477 0.631 0.709
- w/o.context+ 0.360 0.334 0.107 0.160 -0.009 0.134 0.222 0.303
- w/o.both 0.276 0.183 -0.163 0.149 -0.057 -0.092 0.121 0.299
Naive(MLM) 0.449 0.197 0.201 0.324 0.114 0.443 0.307 0.540
Table 3: Pearson’s 𝑟 correlations with human judgements for MARS and seven existing metrics across system
outputs for three generation tasks. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 522>


<Paper ID = 522> <Table 1> <Abstractive Summary> =𝜎 - 0.074 0.104 0.117 0.125 fromContext)
Human: 0.700 MARS:0.399
Table 5: Evaluating correlation with human judge-
ments for various max masking ratios (𝜆max) used in Context: ...washingcloths...
MARS.0% masking(ref.) </Abstractive Summary> <Extractive Summary> correlation with human referencejudgements, Table 1 shows a story generation1 example
but also differentiates well-formed candidates
thatexempliﬁessomeweaknessesofseveralcom-
fromadversarialsamplestoalargerdegree.  </Extractive Summary>  </Table 1>  </Paper ID = 522>


<Paper ID = 522> <Table 2> <Abstractive Summary> =Naive MARS
Mean 4.95 4.81 5.07 4.62 4.50 4.61 5.16 4.61 4.97
Relevance
p - .00* .04* - .05 .95 - .00* .10
Mean 5.67 5.53 5.40 4.54 4.31 4.59 5.41 5.23 5.33
Readability
p - .11 .05 - .12 .41 - .16 .29
Mean 5.69 5.31 5.42 4.87 4.57 4.75 4.62 4.44 4.68
Overall
p - .12 .30 - .10 .22 - .07 .10
Table 7: Human evaluation results on Relevance (to context), Readability, and Overall quality of MARS and
Naiveaugmentationmethod. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 522>


<Paper ID = 523> <Table 0> <Abstractive Summary> =Dist-1 Dist-2 Dist-3
prompts prompts prompts
DEXPERTS(large) 94.46 36.42 45.83 0.56 0.83 0.83
DEXPERTS(medium) 94.31 33.20 43.19 0.56 0.83 0.83
DEXPERTS(small) 94.57 31.64 42.08 0.56 0.83 0.84
Positive GeDi 86.01 26.80 58.41 0.57 0.80 0.79
Positiveexpert 79.83 43.80 64.32 0.59 0.86 0.85
DAPT 77.24 14.17 30.52 0.56 0.83 0.84
DEXPERTS(anti-only) 60.72 4.43 46.00 0.65 0.80 0.78
CTRL 61.81 18.88 43.79 0.51 0.83 0.86
PPLM(10%) 52.68 8.72 142.11 0.62 0.86 0.85
GPT-2 99.08 50.02 0.00 29.28 0.58 0.84 0.84
PPLM(10%) 89.74 39.05 181.78 0.63 0.87 0.86
CTRL 79.05 37.63 35.94 0.50 0.83 0.86
DEXPERTS(anti-only) 93.75 34.05 44.23 0.65 0.81 0.78
DAPT 87.43 33.28 32.86 0.58 0.85 0.84
Negative
Negativeexpert 61.67 24.32 65.11 0.60 0.86 0.85
GeDi 39.57 8.73 84.11 0.63 0.84 0.82
DEXPERTS(small) 45.25 3.85 39.92 0.59 0.85 0.84
DEXPERTS(medium) 40.21 3.79 43.47 0.59 0.85 0.84
DEXPERTS(large) 35.99 3.77 45.91 0.60 0.84 0.83
Table 3: Results for experiments in sentiment-controlled generation. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 523>


<Paper ID = 523> <Table 1> <Abstractive Summary> =ÝαÝ“Ý2Ý.Ñ0 Averynicerestaurant FUDGE(YangandKlein,2021)trainsclassiﬁers
onpartialsequencestopredictwhetheranattribute
Table 4: Examples of input/output from a preliminary willbesatisﬁedinthefuture,andusesBayesianfac-
system that applies DEXPERTS to stylistic rewriting. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 523>


<Paper ID = 523> <Table 2> <Abstractive Summary> =Small 2h:45m 18m:01s 34s 32s
Medium 7h:06m 46m:52s 1m:30s 1m:24s
Large 14h:35m 1h:37m 3m:19s 3m:01s Datasetsize Non-toxic Positive Negative
Tokens 63,457,536 13,240,192 57,805,184
Table 6: Finetuning time for (anti-)experts in DEX- Documents 1,320,876 264,837 1,208,186
PERTS,foreachGPT-2sizeused. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 523>


<Paper ID = 523> <Table 3> <Abstractive Summary> =Table 8: Dataset details for subsets of OpenWebText
usedtoobtaintheDAPTmodels. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 523>


<Paper ID = 523> <Table 4> <Abstractive Summary> =Wekeep
Table 13: Hyperparameters for generation with GeDi. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 4>  </Paper ID = 523>


<Paper ID = 523> <Table 5> <Abstractive Summary> =Foreachcategory,theannotatorisallowed
to choose either one of the continuations, or rate
Table 14: Generation time (in seconds) per continua-
tion of maximum length 20 tokens for toxicity experi- thetwooptionsasequal. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 5>  </Paper ID = 523>


<Paper ID = 524> <Table 0> <Abstractive Summary> =Table 1: We design a list of control codes to guide generation. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 524>


<Paper ID = 524> <Table 1> <Abstractive Summary> =Weverifythatthecodes
RoBERTa 0.47 0.14 1.32
improvethesuccessrateofgeneratingcounterfac-
Table 2: Intrinsic evaluations: Polyjuice counterfactu- tualswiththedesiredperturbationtypessetoutin
alsareclosertotheoriginalinstancethannon-ﬁntuned
Table1byasmuchas42%forperturbationssuch
GPT-2andT5,andmorediversethanRoBERTa. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 524>


<Paper ID = 524> <Table 2> <Abstractive Summary> =Model SNLI MNLI-m MNLI-mm SNLI-CAD break DNC stress diagnostic
m-baseline 85.7±0.4 86.1±0.2 86.6±0.2 72.8±0.3 86.4±1.5 54.5±0.6 65.1±0.6 56.0±0.8
m-CAD 85.8±0.6 86.6±0.1 85.6±0.3 73.8±0.2 89.4±2.9 55.8±0.9 65.5±0.5 56.4±0.4
m-polyjuice 85.3±0.3 86.0±0.1 86.4±0.0 73.6±0.2 89.1±1.2 57.7±0.3 65.1±0.2 57.5±0.5
Table 5: NLI models, with n=20,000 and m=1,574. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 524>


<Paper ID = 524> <Table 3> <Abstractive Summary> =help
Table 6: Polyjuice with n=20,000 and m=1,911 im- Predict  f(x): = Duplicate (98.2% conﬁdent) 0.w00e.1ig0h.2t
provesaccuracyonPAWS-QQP(Zhangetal.,2019b). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 524>


<Paper ID = 525> <Table 0> <Abstractive Summary> =%=indicatesthepercentagethatmatchedthe Table 3: Human evaluations for metaphoricity (Met)
goldmetaphorexactly. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 525>


<Paper ID = 525> <Table 1> <Abstractive Summary> =(2021) 900 MTurk -
the model generates the probability of each
Thiswork 450 Experts .505α
wordinthevocabularybeingthelikelynext
Table 7: Comparison of agreement rates for various word. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 525>


<Paper ID = 526> <Table 0> <Abstractive Summary> =Table 1: Statistics of the Wet Lab Protocol-Material
3 TaskFormulation: MaterialState State Transfer Graph Corpus extended with cross Ac-
tionPhraseTemporalandCausalrelationships. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 526>


<Paper ID = 526> <Table 1> <Abstractive Summary> =Table 2: Comparison of existing WLP corpora. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 526>


<Paper ID = 526> <Table 2> <Abstractive Summary> =weshowourmodeloutperformingthebaselinesfor
6743Action+Entities iAPRelations(85.2%) cAP-TaCRelations(14.8%)
Models P R F1 P R F1 P R F1
DyGIE++(Waddenetal.,2019) 85.0 78.5 81.6 66.1 62.9 64.5 61.5 18.2 28.1
spERT(EbertsandUlges,2019) 76.4 83.1 79.6 34.3 59.0 43.4 20.1 45.1 27.8
OurModel(No-Sharing) 82.9 81.2 82.1 66.9 68.2 67.5 60.1 48.1 53.4
OurModel(SharedDecoder) 82.8 81.3 82.0 67.9 68.2 68.0 57.8 51.5 54.5
Table 3: Micro F1 scores for actions + entities and relation extraction (split into iAP and cAP-TaC relations) on
theWLP-MSTGtestset. </Abstractive Summary> <Extractive Summary> Table 2 provides a of sentences S = {s ,...,s }.  </Extractive Summary>  </Table 2>  </Paper ID = 526>


<Paper ID = 526> <Table 3> <Abstractive Summary> =Models P R F1 cAP-TaCRelations DyGIE++ spERT Ours
MillerandVosoughi(2020) 45.4 86.5 59.6 Acts-on 62.8 25.4 66.9
Single(Sohrabetal.,2020) 80.3 77.4 78.9 Site 30.1 22.8 49.3
Ensemble(Sohrabetal.,2020) 80.8 80.1 80.5 Coreference-Link 6.6 8.8 23.6
Product 51.7 45.0 59.5
OurModel(single) 80.4 79.3 79.9
Enables 62.3 48.5 61.9
Overlaps 14.7 25.4 29.1
Table 4: Micro F1 scores for relation extraction on
MicroF1 52.6 30.8 56.9
WNUT2020sharedtaskbasedongoldentities. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 526>


<Paper ID = 526> <Table 4> <Abstractive Summary> =(a)Intra-SentencecAP-TaCRelations
cAP-TaCRelations DyGIE++ spERT Ours
60 spERT
Acts-on 13.7 35.7 65.4
DyGIE++
Site 5.4 45.6 58.2
s OurModel
ore Coreference-Link 1.9 4.6 14.2
sc 40 Product 6.8 34.4 56.2
F1 Enables 0.0 0.0 0.0
vg Overlaps 0.0 2.7 1.7
a
cro- 20 MicroF1 7.4 31.4 52.9
Mi
(b)Inter-SentencecAP-TaCRelations
0
0 1 2 3
Table 5: cAP-TaC relation extraction performance on
#Sentencesinbetweenentities
the test set, split into (a) intra- and (b) inter-sentence
Figure4: MicroF1scoresforcAP-TaCrelationextrac- relationsandpresentedasperclassandmicroaveraged
tion on the test set split by the distance between head F1scores. </Abstractive Summary> <Extractive Summary> Thus,weeval- WNUT 2020 corpus, which only includes intra-
uate our model against two state-of-the-art mod- sentence relations, Table 4 shows that our model
els for jointly predicting entities and relations in outperforms the best single model that used the
scientiﬁc-textdomain,namelyDyGIE++(Wadden original data by 1.0%.  </Extractive Summary>  </Table 4>  </Paper ID = 526>


<Paper ID = 526> <Table 5> <Abstractive Summary> =Causal(608) 55.5 45.3 56.2 6 ConclusionsandFutureWork
Table 6: Micro F1 scores for cAP-TaC relations split
WepresenttheWLP-MSTGcorpus,anextension
into temporal (and subgroups) and causal relations on
oftheWLPcorpusthatincludescAP-TaCrelation-
WLP-MSTG test set. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 5>  </Paper ID = 526>


<Paper ID = 526> <Table 6> <Abstractive Summary> =In
-RelationConvolutions 58.0 63.1 45.1
-Multi-headR-GCN 59.2 64.3 46.4 Proceedings of the 2019 Conference on Empirical
-Allabove 46.3 52.3 26.0 Methods in Natural Language Processing and the
9th International Joint Conference on Natural Lan-
Table 7: Ablation test of proposed latent structure guage Processing (EMNLP-IJCNLP), pages 3606–
3611.
model evaluated on WLP-MSTG dev set. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 6>  </Paper ID = 526>


<Paper ID = 527> <Table 0> <Abstractive Summary> =We
1 l1 1 l1
experiment with trading periods τ ∈ {3, 7, 15}
y = σ(W O +b ) (10)
l2 1 l2
9https://keras.io/
where,W andb representtheﬁrstlinearlayer,
l1 l1 10https://research.google.com/
Wl2 and bl2 represent the second linear layer, I1 colaboratory/
6756VolatilityPrediction PricePrediction
Model
MSE MSE MSE F1 F1 F1 MCC MCC MCC
3 7 15 3 7 15 3 7 15
RoBERTa+LSTM 0.78(0.009) 0.58(0.009) 0.47(0.006) 0.57 0.58 0.49 0.19 0.22 0.10
GloVe+LSTM 0.80(0.005) 0.60(0.004) 0.48(0.005) 0.55 0.56 0.42 0.19 0.22 0.02
FinBERT+LSTM 0.78(0.008) 0.60(0.004) 0.47(0.005) 0.58 0.58 0.48 0.20 0.21 0.06
MDRM(T) 0.79(0.003) 0.59(0.003) 0.47(0.002) 0.58 0.56 0.48 0.20 0.19 0.12
MDRM(A) 0.79(0.004) 0.60(0.002) 0.47(0.003) 0.24 0.36 0.12 0.02 0.17 0.00
MDRM(T+A) 0.78(0.005) 0.58(0.003) 0.46(0.002) 0.59 0.58 0.46 0.19 0.19 0.11
M3ANet(Ours) 0.77(0.018)* 0.57(0.016)* 0.46(0.011)* 0.59 0.59 0.50* 0.19 0.19 0.13
Table 1: Mean τ-day volatility MSE and price movement prediction results (mean and stdev. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 527>


<Paper ID = 527> <Table 1> <Abstractive Summary> =shadedregionsrepresenttheperformanceover10runs
7.6 QualitativeAnalysis
TestedonAcquisitionsOnly TestedonMergersOnly
TrainedOn Call1: AcquisitionofShapeSecuritybyF5Net-
MSE3 F13 MCC3 MSE3 F13 MCC3
Acquisitions 0.65 0.66 0.12 1.47 0.56 0.015 worksInc Followingthecall,F5NetworksInc
Mergers 0.85 0.28 0.03 1.01 0.47 0.20
sufferedapricedropofupto5.2%withinthenext
Table 3: Ablation Study: Performance of M3A, when month. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 527>


<Paper ID = 529> <Table 0> <Abstractive Summary> =CircumscribedTo 0.05 Triangle 0.03
SumOf 0.04 Quadrilateral 0.02
HeightOf 0.04 Kite 0.01
BaseOf 0.04 HeightOf 0.01
Unlike existing datasets that only collect the
IsHypotenuseOf 0.04 Square 0.01
problem text and diagrams, we further annotate
each data in Geometry3K with dense formal lan- Table 4: Most and least frequent predicates of formal
guage descriptions that bridge the semantic gap descriptionsinGeometry3K(frequency>5). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 529>


<Paper ID = 529> <Table 1> <Abstractive Summary> =Fortheneu- Table 7: Performance of Inter-GPS with different
searchstrategies. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 529>


<Paper ID = 53> <Table 0> <Abstractive Summary> =Theoriginalpodcastcorpuscontains
Table 2: Some examples of LDA topics. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 53>


<Paper ID = 53> <Table 1> <Abstractive Summary> =Table 3: Group mean differences between linguistic
5.1.1 Genres featuresofhighandlowengagementpodcastsineach
popularity quartile, with the ↑ (↓) arrow indicating in-
Amongthepodcastsinthetoppopularityquartile,
crease (decrease) in mean value of the feature for the
highengagementisassociatedwithtopicsaround
high group compared to the low. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 53>


<Paper ID = 53> <Table 2> <Abstractive Summary> =The terms are manually ar-
Table 4: Accuracy of predicting whether a podcast is ranged to indicate contrasting usage of similar classes
highorlowengagement(toporbottom25%bystream ofwordsforqualitativeanalysis. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 53>


<Paper ID = 53> <Table 3> <Abstractive Summary> =Table 6: Classiﬁcation accuracy (using descrip-
tions+transcript)tendstogoesdownasthegapbetween
highandlowengagementgroupsdecreases. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 53>


<Paper ID = 53> <Table 4> <Abstractive Summary> =Positive emotions
Particlesintranscript ↑ ↑
aremoresigniﬁcantlyassociatedwithengagement
Pronounsindescription ↓
Pronounsintranscript ↓ compared to the podcast data, which may be be-
Punctuationindescription ↓ ↑
cause of the inspirational nature of the talks and
Table 7: Signiﬁcance of group mean differences be- therelativepaucityofcrime-relatedcontent(and
tween linguistic features of higher and lower engage- infact,positivesentimentoverallismoreprevalent
ment(topandbottom25%)TEDtalksasgivenbythe
comparedtothepodcastdata). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 4>  </Paper ID = 53>


<Paper ID = 530> <Table 0> <Abstractive Summary> =6790Dataset H@1 H@3 H@5 H@10
Query-matchingword-levelTF-IDF 41.7 54.2 59.0 65.3
Query-matchingcharacter-level(2,3)-gramTF-IDF 34.7 45.5 50.2 56.8
Entity-matchingword-levelexactmatch 48.2 57.9 64.2 67.3
Entity-matchingword-levelTF-IDF 56.0 65.6 74.1 81.2
Entity-matchingcharacter-level(2,3)-gramTF-IDF 69.6 78.8 82.3 86.6
Entity-matchingcharacter-level(1,2,3)-gramTF-IDF 62.3 75.2 80.1 86.1
Table 1: Retrieval accuracy for our entity-based TF-IDF retrieval along with several baselines for the TabFact
validationset, computedusingall16,573TabFact tables. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 530>


<Paper ID = 530> <Table 1> <Abstractive Summary> =Model Dev Test SimpleTest ComplexTest SmallTest
Table-BERT(Chenetal.,2020b) 66.1 65.1 79.1 58.2 68.1
LogicalFactChecker(Zhongetal.,2020) 71.8 71.7 85.4 65.1 74.3
ProgVGAT(Yangetal.,2020) 74.9 74.4 88.3 67.6 76.2
TAPAS(Eisenschlosetal.,2020)* 81.0 81.0 92.3 75.6 83.9
Ours(Oracleretrieval) 78.2 77.6 88.9 72.1 79.4
Ours(1retrievedtable) 74.1 73.2 86.7 67.8 76.6
Ours(Ternaryloss,3tables) 73.8 73.5 86.9 68.1 76.9
Ours(Ternaryloss,5tables) 74.1 73.7 87.1 67.9 76.5
Ours(Ternaryloss,10tables) 73.9 73.1 86.5 67.9 77.3
Ours(Jointloss,3tables) 74.6 73.8 87.0 68.3 78.1
Ours(Jointloss,5tables) 75.9 75.1 87.8 69.5 77.8
Ours(Jointloss,10tables) 73.9 73.8 86.9 68.1 76.9
Table 2: Prediction accuracy of our RoBERTa-based model on the ofﬁcial splits from the TabFact dataset. </Abstractive Summary> <Extractive Summary> in Table 1 the retrieval scores obtained through
ourstrategyontheTabFacttestset.  </Extractive Summary>  </Table 1>  </Paper ID = 530>


<Paper ID = 530> <Table 2> <Abstractive Summary> =Weincludeheretheperformanceofour Ours(noattention) 67.4 78.3 82.3
retrievalcomponentforeachsplit: Ours(attention) 70.9 79.4 82.3
Dataset H@1 H@3 H@5 H@10 Table 8: Ranking performance on the TabFact vali-
dation set, using either our TF-IDF retriever alone or
Train 59.5 71.2 74.8 79.2
reranking with our model. </Abstractive Summary> <Extractive Summary> mentfromtheadditionofmoretables,wecompute
in Table 3 the performance of our reranking-and- 5.3 AblationTests
veriﬁcationmodelwhenTF-IDFreturnsthecorrect Our best-performing model from Table 2 relies
tableatrank1,rank2-3,orrank4-5. Program en- ing to those of Table 2 for our joint model using
hancedfactveriﬁcationwithverbalizationandgraph
RoBERTa-baseinsteadofRoBERTa-large.  </Extractive Summary>  </Table 2>  </Paper ID = 530>


<Paper ID = 530> <Table 3> <Abstractive Summary> =Interestingly, the joint-loss
Table 7: Retrieval accuracy with our entity-based TF-
modelperformsbetterthanasystemtrainedpurely
IDFheuristiconthedifferentTabFactsplits. </Abstractive Summary> <Extractive Summary> mentfromtheadditionofmoretables,wecompute
in Table 3 the performance of our reranking-and- 5.3 AblationTests
veriﬁcationmodelwhenTF-IDFreturnsthecorrect Our best-performing model from Table 2 relies
tableatrank1,rank2-3,orrank4-5.  </Extractive Summary>  </Table 3>  </Paper ID = 530>


<Paper ID = 532> <Table 0> <Abstractive Summary> =6819MultiMWA-MTRef MultiMWA-MTRef MultiMWA-Wiki
Sure Sure+Poss
Models P R F1 EM P R F1 EM P R F1 EM
Pi/Pn Ri/Rn F1i/F1n Pi/Pn Ri/Rn F1i/F1n Pi/Pn Ri/Rn F1i/F1n
JacanaToken(Yaoetal.,2013a) 87.9 72.2 79.3 2.6 82.8 70.5 76.2 1.3 98.8 95.7 97.2 59.8
94.4/65.1 94.7/41.3 94.6/50.5 93.3/61.7 96.7/43.6 95.0/51.1 99.3/77.1 99.5/71.6 99.4/74.3
JacanaPhrase(Yaoetal.,2013b) 84.4 72.4 78.0 1.9 82.8 70.0 75.8 1.4 92.8 97.0 94.9 27.4
94.1/58.5 95.3/40.7 94.7/48.0 93.3/61.4 96.2/42.5 94.8/50.3 98.5/44.4 99.8/49.1 99.2/46.6
PipelineAligner(Sultanetal.,2014) 96.0 67.7 79.4 2.5 97.1 60.8 74.8 1.0 99.5 94.9 97.1 53.4
98.1/78.9 93.3/30.6 95.6/44.1 98.3/82.9 92.9/23.9 95.5/37.1 99.6/66.2 99.6/60.0 99.6/62.9
QA-basedAligner 88.4 92.3 90.3 14.0 91.3 92.9 92.1 21.3 97.4 97.9 97.6 67.4
98.2/76.3 99.2/83.9 98.7/79.9 98.5/84.1 99.2/86.9 98.9/85.5 99.5/82.3 99.8/81.9 99.7/82.1
NeuralCRFAligner 87.6 91.6 89.5 10.8 91.5 90.2 90.8 16.9 96.5 97.6 97.1 63.5
97.3/74.2 99.5/82.2 98.4/78.0 98.5/83.4 99.2/82.1 98.8/82.7 99.3/80.6 99.6/80.6 99.4/80.6
Neuralsemi-CRFAligner 90.6 90.3 90.5 14.1 94.7 90.2 92.4 23.3 97.7 97.5 97.6 68.5
98.9/78.9 98.9/79.1 98.9/79.0 99.3/89.1 98.7/82.3 99.0/85.5 99.6/82.8 99.7/80.8 99.7/81.8∗
Table 2: In-domain evaluation of different monolingual word alignment models on the MultiMWA benchmark. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 532>


<Paper ID = 532> <Table 1> <Abstractive Summary> =MultiMWA-Newsela MultiMWA-arXiv MultiMWA-Wiki
Models P R F1 EM P R F1 EM P R F1 EM
Pi/Pn Ri/Rn F1i/F1n Pi/Pn Ri/Rn F1i/F1n Pi/Pn Ri/Rn F1i/F1n
JacanaToken(Yaoetal.,2013a) 85.5 74.9 79.8 11.0 94.9 96.8 95.8 49.0 94.7 96.9 95.8 33.3
91.2/60.1 97.5/39.7 94.3/47.9 97.3/72.6 99.5/73.4 98.4/73.0 98.4/51.2 99.9/50.1 99.2/50.6
JacanaPhrase(Yaoetal.,2013b) 84.3 75.0 79.4 8.2 90.9 96.6 93.7 31.5 92.9 96.9 94.9 28.0
91.3/53.9 97.4/38.6 94.3/45.0 97.1/53.2 99.1/64.7 98.1/58.4 98.5/44.9 99.8/49.6 99.1/47.1
PipelineAligner(Sultanetal.,2014) 95.2 69.4 80.3 10.0 98.5 94.6 96.5 49.0 99.5 94.9 97.1 53.4
96.9/64.4 95.3/25.4 96.1/36.5 98.8/68.3 99.0/62.4 98.9/65.2 99.6/66.2 99.6/60.0 99.6/62.9
QA-basedAligner 84.8 87.9 86.2 16.2 93.9 94.3 94.1 27.0 96.1 98.2 97.2 57.8
95.3/69.4 99.1/71.4 97.1/70.4 98.0/70.7 95.0/79.9 96.5/75.0 99.3/76.2 99.8/78.3 99.5/77.3
NeuralCRFAligner 88.2 85.0 86.6 15.6 92.9 98.7 95.7 43.5 96.1 98.0 97.0 52.1
95.3/72.3 99.0/66.3 97.1/69.1 96.4/62.9 99.8/73.3 98.0/67.7 99.1/70.5 99.9/71.9 94.5/71.2
Neuralsemi-CRFAligner 89.4 85.0 87.2 21.6 96.2 98.4 97.3 62.5 97.2 97.6 97.4 64.8
96.7/76.1 98.4/66.5 97.6/71.0 98.9/79.3 99.6/83.0 99.3/81.1 99.6/80.4 99.5/79.5 99.5/79.9
Table 3: Out-of-domain evaluation of different monolingual word alignment models on the MultiMWA bench-
mark. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 532>


<Paper ID = 532> <Table 2> <Abstractive Summary> =The phrase bound-
Table 4: Ablation study of our neural semi-CRF
ary error (see 3 in Figure 3 for an example)
alignerwitheachcomponentremovedorswapped.The
is the most prominent error in all models, at-
resultsarebasedonthedevsetofMTRef . </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 532>


<Paper ID = 533> <Table 0> <Abstractive Summary> =6835Label Polisis RoBERTa PrivBERT Support
F1 P R F1 P R F1
FirstPartyCollectionandUse 0.82 0.92 0.89 0.91 0.95 0.88 0.92 250
ThirdPartySharingandCollection 0.82 0.86 0.91 0.88 0.88 0.93 0.91 203
UserChoice/Control 0.72 0.83 0.78 0.80 0.87 0.79 0.83 77
PrivacyContactinformation 0.84 0.84 0.76 0.79 0.82 0.80 0.81 42
Introductory/Generic 0.73 0.88 0.67 0.76 0.79 0.76 0.77 78
PracticeNotCovered 0.13 0.50 0.32 0.39 0.65 0.44 0.52 25
DataSecurity 0.75 0.91 0.75 0.82 0.94 0.80 0.86 40
UserAccess,EditandDeletion 0.70 0.72 0.88 0.79 0.80 0.88 0.84 24
PolicyChange 0.88 0.79 0.90 0.84 0.87 0.95 0.91 21
DoNotTrack 1.0 1.0 1.0 1.0 1.0 1.0 1.0 3
InternationalandSpeciﬁcAudiences 0.82 0.83 0.78 0.81 0.89 0.84 0.86 56
DataRetention 0.40 0.80 0.57 0.67 0.83 0.71 0.77 14
MacroAverages 0.71 0.82 0.77 0.79 0.86 0.82 0.83 833
MicroAverages 0.78 0.86 0.82 0.84 0.88 0.85 0.87 833
Table 2: Test performance comparison of three models on the data practice classiﬁcation task (P:Precision, R:
Recall)
PrivacyQA consists of 1,750 questions about the Model Precision Recall F1
contentsofprivacypoliciesfrom35privacydocu- BERT 0.442 0.348 0.39
ments. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 533>


<Paper ID = 533> <Table 1> <Abstractive Summary> =Whilecrowdworkerswereaskedtocome PrivBERT 0.483 0.424 0.452
upwithprivacyrelatedquestionsbasedonpublic
Table 3: Performance comparison on the answer sen-
informationaboutanapplicationfromtheGoogle
tenceselectiontask
PlayStore,legalexpertswererecruitedtoidentify
relevant evidence within respective privacy poli-
ciesthatansweredthequestionaskedbythecrowd- has been shown to achieve state of the art results
workers. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 533>


<Paper ID = 534> <Table 0> <Abstractive Summary> =BERTSCOREisasaccurateasusingahumanesti-
Table 2: Power analysis for the number of judgments
matorwith600judgmentspersystem,ortheper-
needed to give a pairwise prediction between two sys-
fectannotatorestimatorwith300judgments,across
temsat.9accuracy(α=0.05,β =0.95)underttestas-
theWMTdataset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 534>


<Paper ID = 534> <Table 1> <Abstractive Summary> =0.10
0.08
2016 2017 2018 2019
(cid:112)
Var(H(x)) 30.01 29.65 28.21 28.81 50 100 150 200 250 300
(cid:112)E[Var(H(x)|x)] 17.53 22.96 19.57 21.42 Number of judgments
(cid:112)
Var(P(x)) 24.36 18.76 20.33 19.27
Var(H(x))/Var(P(x)) 1.52 2.50 1.93 2.24
Figure5: Comparisonofmetricstohumanandperfect
annotatorestimatorswithvaryingnumberofjudgments
Table 3: Step-by-step derivation for the efﬁciency ra-
in SummEval. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 534>


<Paper ID = 534> <Table 2> <Abstractive Summary> =7
Var(H(x))/Var(P(x)) 1.201 1.686 devi 0.64 2131 534 238 135 87
Table 4: Step-by-step derivation for the efﬁciency ra- std. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 534>


<Paper ID = 534> <Table 3> <Abstractive Summary> =Difference in system quality
Table 5: Power analysis for the number of judgments
needed from the perfect expert to give a pairwise
judgment between two systems at .9 accuracy (α =
0.05,β = 0.95) under ttest assumptions (normality,
equal variance) in SummEval. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 534>


<Paper ID = 535> <Table 0> <Abstractive Summary> =6858Test(+) JapanNationalRoute1 ,connectsWith,JapanNationalRoute4
Q1191191 Q1055023
Train JapanNationalRoute4,terminus,JapanNationalRoute1
Test(+) Agnese ,sibling,Lucia
Q2726556 Q3838490
Train Maddalena , sibling, Agnese∧Maddalena, mother, Beatrice ∧Valentina, mother, Beatrice∧
Q329555 Q51089
Viridis , sibling, Valentina ∧ Viridis, sibling, Estorre ∧ Elisabetta , sibling,
Q271827 Q943180 Q3733572 Q1941886
Estorre∧Lucia,sibling,Elisabetta
Test(-) Quimper ,capital,Versailles (⊥Yvelines ,capital,Versailles)
Q702161 Q621 Q12820
Train Yvelines,replaces,Seine-et-Oise ∧Seine-et-Oise,capital,Versailles
Q979470
Test(-) Roberto ,placeOfBirth,Baton (⊥Roberto,placeOfBirth,Rome )
Q53003 Q28218 Q220
Train Renzo ,sibling,Roberto∧Renzo,placeOfBirth,Rome
Q1397252
Test(UNK) Mido¯sujiLine ,connectsWith,Keiyo¯Line
Q1192413 Q741145
Train Shin-O¯sakaStation , connectingLine, Mido¯sujiLine∧To¯kaido¯ Shinkansen , terminus, Shin-
Q801438 Q660895
O¯sakaStation∧To¯kaido¯Shinkansen,connectsWith,Keihin-To¯hokuLine ∧Keiyo¯Line,connectsWith,
Q1197028
Keihin-To¯hokuLine
Test(UNK) Mary ,workLocation,London
Q104109 Q84
Train Mary,memberOfPoliticalParty,RepublicanParty ∧Carl ,memberOfPoliticalParty,Republican
Q29468 Q127437
Party∧Carl workLocation,London∧Mary,occupation,actor ∧Mary,spouseOwen
Q127437 Q33999 Q966972
Table 3: Positive, negative, and unknown examples of InferWiki, where the triples with brackets are not in train
set(inferredfromrelatedtrainingtriples),⊥denotescontradictedtriplesandsubscriptsdenoteWikidataID. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 535>


<Paper ID = 535> <Table 1> <Abstractive Summary> =Wecanseethatallofthebaselinesperform
6860InferWiki64k InferWiki16k CoDEx-m-infer
Acc Prec Recall F1 Acc Prec Recall F1 Acc Prec Recall F1
TransE .823 .782 .895 .835 .796 .736 .926 .820 .763 .792 .891 .839
ComplEx .812 .779 .872 .823 .811 .835 .778 .805 .798 .805 .936 .866
RotatE .852 .808 .924 .862 .811 .769 .891 .825 .788 .790 .945 .861
ConvE .881 .864 .906 .884 .897 .887 .911 .899 .851 .853 .948 .898
TuckER .862 .897 .817 .855 .861 .836 899 .866 .803 .919 .784 .846
Table 4: Overall Performance of Triple Classiﬁcation (Closed-world Assumption), where acc and prec stand for
accuracyandprecision,respectively. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 535>


<Paper ID = 536> <Table 0> <Abstractive Summary> =Fur-
Table 1: Example summary of comments from a New
thermore, we incorporate argument mining
YorkTimesarticlediscussingpeople’sfavoritepartsof
through graph construction to directly model
the Super Bowl. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 536>


<Paper ID = 536> <Table 1> <Abstractive Summary> =Dataset/Method Inter-documentSimilarity Redundancy LayoutBias ysisofthegiveninputratherthananotherresponse
NYT -11.71 -0.23 0.2/0.5/0.3
Reddit -7.56 -0.49 0.2/0.5/0.2 orutterance;(2)summariesshouldbeabstractive,
Stack -9.59 -0.27 0.2/0.3/0.4
i.e., annotators were required to paraphrase and
Email -1.76 -0.18 0.3/0.4/0.3
couldnotrepeatmorethanﬁvewordsinarowfrom
Table 3: Multi-document summarization-speciﬁc thesource;and(3)summarylengthsshouldcontain
datasetanalysisonourproposeddatasetswithmetrics
[40,90]tokens. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 536>


<Paper ID = 536> <Table 2> <Abstractive Summary> =Within a single text, the
6871Dataset/Method Lexrank Textrank BERT-ext Data/Method BART BART-arg
NYT 22.30/3.87/19.14 25.11/3.75/20.61 25.88/3.81/22.00
NYT 35.91/9.22/31.28 36.60/9.83/32.61
Reddit 22.71/4.52/19.38 24.38/4.54/19.84 24.51/4.18/20.95
Stack 26.30/5.62/22.27 25.43/4.40/20.58 26.84/4.63/22.85 Reddit 35.50/10.64/32.57 36.39/11.38/33.57
Email 16.04/3.68/13.38 19.50/3.90/16.18 25.46/6.17/21.73 Stack 39.61/10.98/35.35 39.73/11.17/35.52
Email 41.46/13.76/37.70 40.32/12.97/36.90
Table4: ROUGE-1/2/LresultsforextractiveLexRank
(ErkanandRadev,2004),TextRank(MihalceaandTa-
Table 5: ROUGE-1/2/L results for vanilla BART as
rau,2004),andBERT-based(Miller,2019)models. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 536>


<Paper ID = 536> <Table 3> <Abstractive Summary> =AllIssuenodes,aswellasclaimswhichare kens,weusetheLongformer(Beltagyetal.,2020),
notconnectedtoanyIssuenode,areconnectedto which allows for sequences up to length 16k to-
6872Method/Dataset AMI ICSI Dataset/Method Ourresults PreviousSOTA
HMNet 53.02/18.57/- 46.28/10.60/- SAMSum 52.27/27.82/47.92 49.30/25.60/47.70
DDA-GCN 53.15/22.32/- - CQASUMM 32.79/6.68/28.83 31.00/5.00/15.20
Longformer-BART 54.20/20.72/51.36 43.03/12.14/40.26
BC3 39.59/13.98/21.20 -
Longformer-BART-arg 54.47/20.83/51.74 44.17/11.69/41.33
ADS 37.18/11.42/21.27 -
SENSEI 34.57/7.08/16.80 -
Table 6: ROUGE-1/2/L results for DDA-GCN (Feng
etal.,2020)andHMNet(Zhuetal.,2020)ontheAMI
Table 7: Benchmarking results on conversational
and ICSI meeting summarization dataset along with
datasets such as SAMSum (Gliwa et al., 2019b) and
ourLongformerandLongformer-argmodels. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 536>


<Paper ID = 536> <Table 4> <Abstractive Summary> =Table 9: Full ROUGE-1/2/L results for vanilla BART,
-arg-graph, and -arg-ﬁltered input. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 4>  </Paper ID = 536>


<Paper ID = 536> <Table 5> <Abstractive Summary> =All are trained on Table 10: Example source documents and summaries
200pointsfromConvoSumm. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 5>  </Paper ID = 536>


<Paper ID = 536> <Table 6> <Abstractive Summary> =Table 11: Example source documents and summaries
fromRedditdatainwhichthemodelsfailtocompletely
capturesaliencewhileremainingfaithfultotheinput. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 6>  </Paper ID = 536>


<Paper ID = 537> <Table 0> <Abstractive Summary> =summaries is a major concern that limits its
Table 1: Example summaries from the BART-large
wide application. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 537>


<Paper ID = 537> <Table 1> <Abstractive Summary> =Weobservethatourproposed R-C -1.0907 28.47 23.76 44.59 21.88 36.58
Q-F1-C -0.9866 32.76 22.75 44.54 21.63 36.37
method QUALS-CONSEQ (Q-C) achieves more
Q-C-W -0.9856 31.39 21.68 44.42 21.17 35.94
than4pointsimprovementinQAGSovertheMLE
Q-C-O -0.9747 32.26 23.68 45.22 22.19 37.00
baselineinXSUMandabout2pointsimprovement
Q-P -0.9739 31.92 22.68 45.02 22.00 36.83
in CNNDM, where we also achieve a slightly
Q-C -0.9061 34.36 22.42 44.67 21.66 36.47
betterROUGEoverMLE.ImprovingROUGEis
not the goal of our paper; what we show is that Table 2: Test set results on XSUM. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 537>


<Paper ID = 537> <Table 2> <Abstractive Summary> =Weinvestigatedthisissueandfoundthat CNNDM 18 7 75 42 22 36 5 6 89
thegroundtruthsummariesoftheXSUMtestset
Table 4: Human evaluation results on summaries
have a FactCC score of just 21.0, which means generated by QUALS-CONSEQ in comparison to the
that only 21% of the ground truth summaries in BART-large MLE baseline for 100 randomly selected
XSUMarejudgedasfactualaccordingtoFactCC. </Abstractive Summary> <Extractive Summary> In
informativeness and grammatical correctness
comparison, our results reported in Table 2 and
Table 3 represent signiﬁcant improvements.  </Extractive Summary>  </Table 2>  </Paper ID = 537>


<Paper ID = 537> <Table 3> <Abstractive Summary> =Q2: Which airlines
Table 5: Qualitative analysis. </Abstractive Summary> <Extractive Summary> In
informativeness and grammatical correctness
comparison, our results reported in Table 2 and
Table 3 represent signiﬁcant improvements.  </Extractive Summary>  </Table 3>  </Paper ID = 537>


<Paper ID = 538> <Table 0> <Abstractive Summary> =7https://github.com/google-research/
AsshowninFigure1,thismodelcontainstwoen-
google-research/tree/master/rouge
coders: the token-level encodes the whole email 8https://github.com/Tiiiger/bert_score
6899Models EMAILSUMshort EMAILSUMlong
R1 R2 RL RLsum BertS R1 R2 RL RLsum BertS
Oracle 39.04 12.47 30.17 35.61 22.32 45.98 15.49 32.40 42.14 26.31
Lead-1 23.35 5.57 18.22 19.61 12.25 19.75 4.84 14.24 16.88 6.87
Lead-1-Email 26.62 5.60 19.72 23.77 13.00 35.71 8.69 24.70 32.13 16.93
TextRank 22.52 4.54 16.56 20.24 5.89 28.42 6.20 19.08 25.19 5.67
BertSumExt 24.84 5.15 17.81 21.81 7.51 30.23 7.08 19.59 26.68 7.78
FastAbsRL 31.15 6.59 22.73 29.03 6.49 39.35 10.58 27.01 36.51 10.03
T5 36.57 10.56 28.3 32.76 33.90 43.81 14.08 30.47 39.88 32.09
base
CNNDM 35.43 10.75 27.49 32.15 33.61 44.15 14.20 30.84 40.21 32.53
pre
XSum 36.14 10.26 28.66 33.47 33.97 43.48 13.82 30.14 39.80 31.60
pre
SAMSum 34.68 10.56 26.62 31.22 33.25 42.83 13.54 30.00 39.13 31.82
pre
CRD3 36.05 10.04 27.21 32.06 33.52 43.60 13.93 30.49 39.97 31.53
pre
CNNDM 34.38 9.27 27.20 31.30 32.70 43.28 12.37 28.84 39.39 29.95
joint
XSum 34.18 8.17 25.94 30.68 31.83 42.36 11.85 28.23 38.31 29.22
joint
SAMSum 35.57 10.07 27.95 32.57 33.55 42.96 13.44 29.99 39.54 31.82
joint
CRD3 34.66 8.81 26.95 31.59 33.29 42.81 12.96 29.35 39.33 32.14
joint
SemiSup 35.43 10.64 28.59 32.31 33.61 44.56∗∗ 14.60∗∗ 31.38∗∗ 40.73∗∗ 32.81∗∗
w3c
SemiSup 36.73 10.82 28.44 33.25 33.76 43.83 14.61∗∗ 31.21∗∗ 40.52∗ 32.71∗∗
avocado
SemiSup 36.98 11.21∗ 28.76 33.70∗∗ 33.91 44.08 14.06 31.17∗∗ 40.67∗∗ 32.30
together
Hier.T5 36.17 10.37 28.44 33.34 33.39 44.50∗ 14.53∗ 30.89∗ 40.22 32.30
base
Table 3: Summarization performance on the testing set of different models. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 538>


<Paper ID = 539> <Table 0> <Abstractive Summary> =Models Minimum Medium Maximum Scenarios Models En2DeSum Zh2EnSum
IF CC FL IF CC FL IF CC FL
Minimum NCLS 13.48(+4.69) 18.49(+3.51)
MCLAS -0.264 0.164 -0.021 0.000 0.236 0.164 0.057 0.464 0.214 Low-resource NCLS+MS 12.83(+4.04) 18.68(+3.70)
NCLS -0.243 -0.386 -0.364 0.036 -0.221 -0.257 -0.129 -0.329 -0.186
Scenario MCLAS 7.80(−0.90) 13.16(−1.82)
NCLS+MS -0.371 -0.407 -0.286 -0.343 -0.536 -0.407 -0.179 -0.364 -0.214
GOLD 0.879 0.629 0.671 0.300 0.529 0.500 0.257 0.221 0.179
Medium NCLS 13.13(+4.34) 18.60(+3.62)
Low-resource NCLS+MS 12.90(+4.11) 18.57(+3.59)
Table 3: Human evaluation results in Zh2EnSum Scenario MCLAS 8.65(−0.14) 13.10(−1.88)
dataset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 539>


<Paper ID = 539> <Table 1> <Abstractive Summary> =Maximum NCLS 13.37(+4.58) 18.44(+3.46)
Low-resource NCLS+MS 13.37(+4.58) 18.75(+3.77)
Scenario MCLAS 8.46(−0.33) 12.83(−2.15)
Scenarios Fleiss’Kappa OverallAgreement
Gold 8.79 14.98
Minimum 0.37 60.48%
Medium 0.22 51.35% Table 5: Target summary length generated by various
Maxmium 0.20 50.16% models. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 539>


<Paper ID = 539> <Table 2> <Abstractive Summary> =Table 4: Fleiss’ Kappa and overall agreement percent
of our human evaluation results. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 539>


<Paper ID = 539> <Table 3> <Abstractive Summary> =Despite this, re- MCLAS 45.59 23.77 42.51 41.72 27.69 37.92
sults in En2DeSum and Zh2EnSum demonstrate
Table 6: Monolingual summary results in Zh2EnSum
that our proposed MCLAS model is effective for
andEn2ZhSumdatasets. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 539>


<Paper ID = 54> <Table 0> <Abstractive Summary> =Lastly,inthepragma
Hastygeneralization 13.40 41.36
Slipperyslope 34.76 54.44 dialectictheoryofargumentation,fallaciesarevio-
lationsofrulesofcriticaldiscussion,forexample,
Table 8: F1 score on comment level (CL) per fallacy thefallaciesweannotatedviolatetworules,asde-
afterremovingtop30overrepresentedwords. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 54>


<Paper ID = 540> <Table 0> <Abstractive Summary> =Table 1: Model conﬁgurations with different amount i
The selected content could be a continuous span,
of input document and back-end model. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 540>


<Paper ID = 540> <Table 1> <Abstractive Summary> =NOUN PROPN ADP
ALL 100.0%
18.9% 14.3% 13.9%
PT ([0,1.5],[0.5,2])istheleastintuitivecase,where
LM agreeswithS butS doesnot;thatis,ﬁne-
∅ full ∅ Table 2: Percentage of examples falling into each re-
tuningadecoder-onlymodelcausesittoworkless
gionandthetopPOStagsforeachregionsintheXSum
well. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 540>


<Paper ID = 540> <Table 2> <Abstractive Summary> =(2015),thevalida-
tion and test sets of CNN/DM come from March Table 4: Example patterns from FT. wt is in bold. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 540>


<Paper ID = 540> <Table 3> <Abstractive Summary> =ﬁne-tuningwillprobablygiverisetodifferentbe-
havioronthe 70%ofCTXcases,sincetheS will Table 8: More examples of predicted summaries with
∅
hallucinate differently than the newly ﬁne-tuned thecolorsfollowingthemap. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 540>


<Paper ID = 540> <Table 4> <Abstractive Summary> =DISP↓ RM↑
TOK
0 1 2 4 8 16 −∆ 0 1 2 4 8 16 ∆
Random 4.43 4.28 4.11 3.86 3.52 0.57 1.06 1.17 1.43 1.94 2.89 0.78
Lead 4.44 4.22 3.93 3.51 3.01 0.79 0.94 0.97 1.02 1.09 1.21 0.13
Occlusion 4.28 3.97 3.36 2.84 2.23 1.27 1.30 1.54 2.01 2.39 2.98 1.12
4.61 0.92
Attention 3.84 3.64 3.15 2.76 2.33 1.47 1.44 1.56 1.96 2.49 3.33 1.24
InpGrad 3.74 3.54 3.03 2.63 2.19 1.58 1.47 1.59 1.97 2.48 3.27 1.24
IntGrad 3.52 3.35 2.85 2.50 2.08 1.75 1.56 1.69 2.15 2.70 3.46 1.39
Table 10: Token-level evaluation for content attribution methods. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 4>  </Paper ID = 540>


<Paper ID = 542> <Table 0> <Abstractive Summary> =FFT +Random +FN +VN TA +Random +FN +VN
Spanish XLM-R-ZS 42.2 42.3 42.7 42.0 40.7 40.3 40.9 40.8
ES-XLM-R 77.1 77.1 77.6 77.6 74.8 73.9 74.5 75.4
Table 10: Results on Spanish TempEval test sets for full ﬁne-tuning (FFT) and the task adapter (TA) setup, for
zero-shot (ZS) transfer and monolingual target language evaluation with XLM-R Large, with FN/VN adapters
trainedonVTRANS-translatedverbpairs(see§2.4).F1scoresareaveragedover10runs;signiﬁcantimprovements
(pairedt-test;p<0.05)overbothbaselinesmarkedinbold. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 542>


<Paper ID = 544> <Table 0> <Abstractive Summary> =Table 1: DURel relatedness scale (Schlechtweg et al.,
This range is then split into 5 areas of equal fre-
2018). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 544>


<Paper ID = 545> <Table 0> <Abstractive Summary> =Atthesametime,itissomething
that would be somewhat peculiar for a human to
Table 2: Categorizing existing systems responses to say. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 545>


<Paper ID = 545> <Table 1> <Abstractive Summary> =Table 3: Exploring what might be a preferred response to an “are you a robot?" </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 545>


<Paper ID = 546> <Table 0> <Abstractive Summary> =7025nameId Concepts nameId Concepts
acceptreservations acceptreservation ...
accountblocked accountblocked ptorequeststatus ptorequeststatus
alarm setalarm ptoused ptoused
applicationstatus applicationstatus recipe recipedish
apr whatmonth redeemrewards redeemreward
areyouabot youbot reminder reminderaction
balance whatbalance reminderupdate reminderupdate
billbalance whatbillbalance repeat repeataction
billdue whenbilldue replacementcardduration replacementcardduration
bookﬂight bookﬂight reportfraud reportfraud
bookhotel bookhotel reportlostcard reportlostcard
calculator calculate resetsettings resetsetting
calendar calendar restaurantreservation restaurantreservation
calendarupdate calendarupdate restaurantreviews restaurantreview
calories caloriesdish restaurantsuggestion restaurantsuggestion
cancel cancelaction rewardsbalance rewardbalance
cancelreservation cancelreservation rolldice rolldice
carrental carrental rollover401k rollover401k
carddeclined carddeclined routing ﬁndrouting
carryon carry-onrule schedulemaintenance schedulemaintenance
changeaccent changeaccent schedulemeeting schedulemeeting
changeainame changebotname sharelocation sharelocation
changelanguage changelanguage shoppinglist shoppinglist
changespeed changespeed shoppinglistupdate shoppinglistupdate
changeusername changeusername smarthome smarthome
changevolume changevolume spelling spellingword
conﬁrmreservation conﬁrmreservation spendinghistory spendinghistory
cooktime cooktime syncdevice syncdevice
creditlimit creditlimit taxes whattaxes
creditlimitchange creditlimitchange telljoke telljoke
creditscore creditscore text textperson
currentlocation whatcurrentlocation thankyou thank
damagedcard damagedcard time whattime
date whatdate timer settimer
deﬁnition deﬁnition timezone settimezone
directdeposit directdeposit tirechange tirechange
directions whatdirection tirepressure tirepressure
distance whatdistance todolist todolist
doyouhavepets doyouhavepet todolistupdate todolistupdate
exchangerate exchangerate trafﬁc whattrafﬁc
expirationdate expirationdate transactions cardtransaction
ﬁndphone ﬁndphone transfer transferaccount
ﬂightstatus ﬂightstatus translate translateword
ﬂipcoin ﬂipcoin travelalert travelalert
foodlast foodlast travelnotiﬁcation travelnotiﬁcation
freezeaccount blockaccount travelsuggestion travelsuggestion
funfact funfact uber getuber
gas gaslevel updateplaylist updateplaylist
gastype gastype username username
goodbye goodbye vaccines whatvaccine
greeting greeting w2 getw2
howbusy howbusy weather whatweather
howoldareyou howoldyou whatareyourhobbies whathobby
improvecreditscore improvecreditscore whatcaniaskyou whataskyou
income whatincome whatisyourname whatname
ingredientsubstitution ingredientsubstitution whatsong whatsong
ingredientslist ingredientlist whereareyoufrom whereyoufrom
insurance insurancebeneﬁt whispermode whispermode
insurancechange insurancechange whodoyouworkfor whoyouwork
interestrate interestrate whomadeyou whomadeyou
internationalfees internationalfee yes yes
internationalvisa internationalvisa ...
jumpstart jumpstart
lastmaintenance lastmaintenance
Table 2: The taxonomy created for the Larson dataset
lostluggage lostluggage
makecall makecall (cont.). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 546>


<Paper ID = 547> <Table 0> <Abstractive Summary> =ithinkthat’salot budget: 22$million contradiction
model
ofmoneyforamoviethatcameoutin1990.” year: 1990 entailment
Table 1: Example of a dialogue from the series-enc-d1 model trained on KOMODIS. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 547>


<Paper ID = 547> <Table 1> <Abstractive Summary> =cludes more often wrong entity nouns when es-
7034knowledgeprecision naturalness
experiment
base-triples series-enc-d1 base-triples series-enc-d1
KOMODISbeam-search 0.69 0.74 5.0(1.5) 4.8(1.6)
KOMODIStop-k-sampling 0.52 0.56 5.9(1.2) 5.9(1.3)
OPENDIALKGbeam-search 0.73 0.70 4.0(1.6) 3.4(1.5)
OPENDIALKGtop-k-sampling 0.54 0.45 5.3(1.4) 5.4(1.3)
Table 2: Human evaluation results for beam-search and top-k-sampling, with respect to the correct reproduction
ofdialoguecontext. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 547>


<Paper ID = 547> <Table 2> <Abstractive Summary> =We assume
naturalness 4.5 4.5 4.81
thatthisisthecaseduetothelackoftrainingdata,
win-ratio(%) 28.6 56.3 60.01
whichis,inparticular,evidentforOPENDIALKG
thathasmuchmoreentityandrelationtypesthan
Table 4: Inﬂuence of graph depth on various metrics
KOMODIS,i.e.fewersamplespertype. </Abstractive Summary> <Extractive Summary> Weprepared
threeseriesofexperiments,aimedatevaluatingthe Decoding Table 2 shows the results for beam-
inﬂuenceofdecodingalgorithms,encodingstrate- searchandtop-k-samplingdecoding.  </Extractive Summary>  </Table 2>  </Paper ID = 547>


<Paper ID = 547> <Table 3> <Abstractive Summary> =Fi
A B A BA BA B A BABA BA B
1 2
7040dialogue context inference
human “IamafanofFCBayernMunich!”
“theyareagoodteam.theyareintheallianzarenarightnow building:allianzarena neutral
model
andtheyareplayinginthebundesliga,doyoulikethem?” team:fcbayernmunich entailment
human “YesIdo,whatistheAllianzarena?”
“itisabuildingofthefcbayernmunichandwasbuiltby building:allianzarena entailment
model
markvanbommel.” player:markvanbommel contradiction
human “DidtheyparticipateintheUEFAchampionsleague?”
“yes,theydid.itistheteamthatwonthe2012-13 championsleague2012-13
model entailment
championsleague.” champion:fcbayernmunich
Table 6: Example of a dialogue from the series-enc-d1 model trained on OPENDIALKG. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 547>


<Paper ID = 547> <Table 4> <Abstractive Summary> =model hasactor:hankazaria entailment
doyoulikehim?”
human “Yes,whoelseplaysinthemovie?”
“juliarobertsisalsoinprettywoman.sheismarriedto hasactor:juliaroberts entailment
model
danielmoder,whoalsostarredintheplayerandafewothers.” j.robertsspouse:danielmoder entailment
human “dotheyhavechildren?”
model “yes,theyhaveadaughternamedjuliaroberts.” j.robertshaschild:henry contradiction
Table 7: Example of a dialogue from the series-enc-d1 model trained on OPENDIALKG. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 4>  </Paper ID = 547>


<Paper ID = 547> <Table 5> <Abstractive Summary> =Table 8: Example of a dialogue from the series-enc-d1 model trained on KOMODIS. </Abstractive Summary> <Extractive Summary> Table 5 shows the results from an early evalua- Acknowledgements
tionphasefor KOMODISand OPENDIALKG with
We thank our colleagues from the Digital Assis-
graphdepth1and2withoutgraphmasking.  </Extractive Summary>  </Table 5>  </Paper ID = 547>


<Paper ID = 548> <Table 0> <Abstractive Summary> =Table 2: Experimental results on the IEMOCAP
dataset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 548>


<Paper ID = 55> <Table 0> <Abstractive Summary> =whichisalsoreﬂectedfromFigure4(left10bars
Table 3: Dialogue example from the testing set of Di-
vs. right 10 bars). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 55>


<Paper ID = 550> <Table 0> <Abstractive Summary> =MF-OUT 0.2690583 0.17877551 0.24873096
GEN-IN 0.19506726 0.06285714 0.14503263
Table 6: Example prediction errors made byGdEiNf-fOeUrTent models0.f29o8r206c28ases w0i.1t2h489c7h96alleng0i.2n1g392o31p3tions, based on the
phrase and numeral matching rules (§3). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 550>


<Paper ID = 550> <Table 1> <Abstractive Summary> =Table 7: Impact of dialog context on reasoning accu-
racy. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 550>


<Paper ID = 552> <Table 0> <Abstractive Summary> =Offensive(2) 90.51∗ 84.25 85.26 88.28 86.57 90.38 92.41
Sarcasm(2) 46.60‡‡ 68.20 66.76 69.23 72.23 75.04 76.30
Dataset(classes) Task SOTA mBERT XLM-RB XLM-RL AraBERT ARBERT MARBERT
Table 5: Resultsonsocialmeaningtasks. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 552>


<Paper ID = 552> <Table 1> <Abstractive Summary> =AOC(2) Binary 87.23(cid:63) 86.19 86.85 87.30 87.76 88.46 88.59
QADI(18) Country 60.60† 66.57 77.00 82.73 72.23 88.63 90.89
NADI(21) Country 26.78‡ 13.32 16.36 17.17 17.46 22.56 29.14
NADI(100) Province 06.06†† 02.13 04.12 5.30 03.13 06.10 06.28
Table 7: DIAresultsinF . </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 552>


<Paper ID = 553> <Table 0> <Abstractive Summary> =APH-train+APTT5w 121k 0.488 0.812
APT5 180k 0.461 0.731 0.437 0.716
RoBERTa Random APH-train+APT5 184k 0.525 0.816
TestSet base
MCC F1 MCC F1
Table 6: Performance of RoBERTa trained on ad-
MSRP-train 0.349 0.833 0 0.806 base
versarialdatasets. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 553>


<Paper ID = 555> <Table 0> <Abstractive Summary> =Table 1: Comparing BART-based architectures for
jointlyprocessingcontinuousrepresentationsandtext. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 555>


<Paper ID = 555> <Table 1> <Abstractive Summary> =15.2 25.2
differentfromthetasks READONCETransformers
FixedLength M=21 45.6 59.3
are trained on, demonstrating faster training and
Table 2: A comparison of different architectures for inference. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 555>


<Paper ID = 555> <Table 2> <Abstractive Summary> =Toillustrate READONCE(K=2) 75.5|1.5 65.1|1.8 33.4|1.6
thearchitecture-independenceofourapproachand UB 80.5|3.7 70.5|5.3 36.5|3.6
SQuAD+UQA
orthogonalitytotraditionalcompressionmethods,
Table 3: Performance of READONCE Transformers
wealsotrainandevaluate READONCEmodelsus-
on three datasets, vs. corresponding text-to-text trans-
ingtheBART-BaseandDistilBARTmodels. </Abstractive Summary> <Extractive Summary> We see from Table 2 that neither
of this work, we stick to the simpler architecture appendingthesetokensattheendnorinterleaving
of appending the representation at the 6th layer, themintheinputresultsinrepresentationscompa-
denotedAppend(L=6). Table 2 presents 4.3 FinalREADONCEArchitecture
EMandF1scoresonSQuADforthevariousarchi- Basedonthissetofexperiments,weusetheslid-
tecturalchoicesdiscussedin§3.1.  </Extractive Summary>  </Table 2>  </Paper ID = 555>


<Paper ID = 556> <Table 0> <Abstractive Summary> =Majority 90.6 47.5
Random 50.4 50.2 Pairwise+SSVM 67.2 47.0
Pairwise+SSVM 65.7 62.3 BERT-basedPN 54.7 42.7
BERT-basedPN 54.1 52.3
TemporalBART 63.9 50.1
TemporalBART 77.1 74.7 TemporalBART-indexed 74.9 55.1
TemporalBART-indexed 79.7 78.0
Table 2: Temporal ordering results on MCTaco se-
Table1: Averagedpairwiseaccuracybetweenthegold quences. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 556>


<Paper ID = 556> <Table 1> <Abstractive Summary> =Table 3: Comparison of the ability to tackle unseen
eventsbetweenourBART-basedmodelsandbaselines
on CaTeRS. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 556>


<Paper ID = 556> <Table 2> <Abstractive Summary> =Theframework
TemporalBART-indexed(tagsonly) 76.6 56.4 isimplementedwithPyTorch(Paszkeetal.,2019)
andAllenNLP(Gardneretal.,2017),andweuse
Table 5: The comparison between TemporalBART-
the BART-large pretrained model from Hugging-
indexed and its (tags only) variant on temporal event
Face’sTransformerslibrary(Wolfetal.,2020). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 556>


<Paper ID = 557> <Table 0> <Abstractive Summary> =Table 3: the results of ablation experiments The best
resultsineachtypearehighlighted. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 557>


<Paper ID = 558> <Table 0> <Abstractive Summary> =7169Transition From To
(Pre-conditions) Stackσ Bufferβ Stackσ(cid:48) Bufferβ(cid:48)
SHIFT ... b1... ...b1 ...
(|β|≥1)
LEFTARClbl ...s1 b1... ... b1...
lbl
(|σ|≥1;|β|≥1;s1,b1 ∈/ O;φ(s1)(cid:54)={RT}) s1
RIGHTARClbl ...s2s1 ... ...s2 ...
(|σ|≥2;s1,s2 ∈/ O) s lbl
1
conj lbl
BUBBLEOPENlbl ...s2s1 ... ... s2 s1 ...
(|σ|≥2;s ,s ∈/ O;φ(s )(cid:54)={RT})
1 2 2
conj ... conj ... lbl
... s2a ... s1 ... ... s2a ... s1 ...
BUBBLEATTACHlbl
(|σ|≥2;s ∈/ O;s ∈O)
1 2
conj ... conj ...
... s ... s ... ...
1a ... ... 1a
BUBBLECLOSE
(|σ|≥1;s ∈O)
1
Table 1: Illustration of our Bubble-Hybrid transition system. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 558>


<Paper ID = 559> <Table 0> <Abstractive Summary> =Generic(SPANNER),F1:91.57 Generic+decode,F1:91.89
eCon sLen eLen oDen eCon sLen eLen oDen
Generic+length,F1:92.22 Generic+length+decode,F1:92.28
eCon sLen eLen oDen eCon sLen eLen oDen
Table 2: Performance heatmap of pair-wise system diagnosis. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 559>


<Paper ID = 559> <Table 1> <Abstractive Summary> =eCon sLen eLen oDen
NW 90.78† 1.1 90.30 1.4 90.42 1.4 90.44 1.3
BC 81.54† 1.7 80.04 3.6 80.51 3.1 80.65 3.0
MZ 89.17 1.3 88.43 3.2 88.96 2.0 89.57 2.2
WB 67.45† 2.5 64.57 5.3 65.33 5.0 66.14 4.6
TC 68.25 3.8 66.16 6.5 67.54 5.6 68.73 5.5
W16 41.60† 6.4 33.23 9.2 36.19 8.9 39.92 7.9
W17 45.97† 6.1 41.27 9.3 43.32 8.2 44.45 7.7
ES 87.26† 2.6 86.23 4.3 87.24 2.8 87.00 2.8 Table 6: Performance heatmap driven diagnosis
NL 89.92† 3.4 87.59 6.5 88.93 4.7 88.66 5.0 analysis over different entity attributes. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 559>


<Paper ID = 559> <Table 2> <Abstractive Summary> =Each entry
value is the F1 difference between the proposed
Table 5: The average system combination results on SPANNER combiner against the Base systems
23 combination cases of nine datasets. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 559>


<Paper ID = 559> <Table 3> <Abstractive Summary> =CcnnWrand lstmCrf(sp8)
√ √ √
CnoneWrand lstmCrf(sp9)
CongyingXia,ChenweiZhang,TaoYang,YaliangLi,
Nan Du, Xian Wu, Wei Fan, Fenglong Ma, and Table 8: The illustration of SEQLAB’s model name
S Yu Philip. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 559>


<Paper ID = 560> <Table 0> <Abstractive Summary> =They
Attention(Q ,K ,V ,D) = p q V (17) areobtainedbyrandomlysamplingsectionsfrom
i j j i,j i,j j
7201BLLIP BLLIP BLLIP PRPN ON C-PCFG Tree-T Ours
Model PTB
-XS -SM -MD
SBAR 50.0% 52.5% 56.1% 36.4% 48.7%
Transformer 64.05 93.90 19.92 14.31 NP 59.2% 64.5% 74.7% 67.6% 72.1%
StructFormer 60.94 57.28 18.70 13.70 VP 46.7% 41.0% 41.7% 38.5% 43.0%
PP 57.2% 54.4% 68.8% 52.3% 74.1%
ADJP 44.3% 38.1% 40.4% 24.7% 51.9%
Table 1: Masked Language Model perplexities on dif-
ADVP 32.8% 31.6% 52.5% 55.1% 69.5%
ferentdatasets. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 560>


<Paper ID = 560> <Table 1> <Abstractive Summary> =FortheWSJtestset,
Table 2: Unsupervised constituency parsing tesults. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 560>


<Paper ID = 560> <Table 2> <Abstractive Summary> =Andifthe
dependentrelationshipisremoved,themodelwill
Table 5: Dependency Parsing Results on WSJ testset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 560>


<Paper ID = 560> <Table 3> <Abstractive Summary> =7208A.5 ThePerformanceofStructFormerwithdifferentmaskrates
Maskrate MLM Constituency Stanford Conll
PPL UF1 UAS UUAS UAS UUAS
0.1 45.3(1.2) 51.45(2.7) 31.4(11.9) 51.2(8.1) 32.3(5.2) 52.4(4.5)
0.2 50.4(1.3) 54.0(0.6) 37.4(12.6) 55.6(8.8) 33.0(5.7) 53.5(4.7)
0.3 60.9(1.0) 54.0(0.3) 46.2(0.4) 61.6(0.4) 36.2(0.1) 56.3(0.2)
0.4 76.9(1.2) 53.5(1.5) 34.0(10.3) 52.0(7.4) 29.5(5.4) 50.6(4.1)
0.5 100.3(1.4) 53.2(0.9) 36.3(9.8) 53.6(6.8) 30.6(4.2) 51.3(3.2)
Table 6: The performance of StructFormer on PTB dataset with different mask rates. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 560>


<Paper ID = 561> <Table 0> <Abstractive Summary> =Inorderto
Table 1: WALS prediction and linguistic typology
add our learned language embeddings into XLM
clustering results on 26 in-common languages across
andXLM-Rmodels,wenormalizeourembeddings 10 language genera. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 561>


<Paper ID = 561> <Table 1> <Abstractive Summary> =0.71 0.61 0.53 0.51
XLMparallel 0.28 0.57 0.56 0.50
Vowel Ratio, 4A Voicing in Plosives and Frica-
tives, 5A Voicing and Gaps in Plosive Systems,
Table 5: Results on the WALS prediction task and
6AUvularConsonants,9ATheVelarNasal,11A
linguistic typology on 10 languages in comparison to
Front Rounded Vowels, 12A Syllable Structure,
XLM language embeddings trained from XNLI lan-
14AFixedStressLocations,15AWeight-Sensitive guageparalleldata(MLM+TLMobjectives). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 561>


<Paper ID = 561> <Table 2> <Abstractive Summary> =Table 6: Zero-shot parsing results (UAS) comparing
Spe.,Wiki,andXLMmonolanguageembeddings. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 561>


<Paper ID = 562> <Table 0> <Abstractive Summary> =Table 1: Summary of data sets obtained from Project
4 Data Gutenberg. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 562>


<Paper ID = 563> <Table 0> <Abstractive Summary> =DIV-
1.68 39.97±0.26 39.30±0.16 AGNOSTICmodelsperformcomparablyto EQUIV-
ALENTS, whilefactorizingdivergencesimproves
Table 4: BLEU scores on the medical domain. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 563>


<Paper ID = 563> <Table 1> <Abstractive Summary> =(↑) InfECE(↓)
LASER 1.25M 69.09±0.67 62.55±0.29 12.34±0.38 71.88±0.30 60.20±0.18 15.10±0.12
EQUIVALENTS 0.75M 70.96±0.94 63.49±0.10 12.37±0.24 74.35±0.23 61.81±0.30 15.09±0.18
DIV-AGNOSTIC 71.19±0.33 63.54±0.54 12.00±0.06 73.67±0.11 61.44±0.22 15.19±0.17
0.93M
DIV-FACTORIZED 72.16±0.10* 64.29±0.44* 11.81±0.04* 74.50±0.02* 62.26±0.27* 14.70±0.25*
DIV-AGNOSTIC 71.65±0.18 61.34±0.33 11.98±0.22 71.72±0.38 59.29±0.48 15.62±0.19
1.12M
DIV-FACTORIZED 71.83±0.03 64.38±0.08* 11.86±0.01 74.09±0.14* 61.65±0.19* 14.84±0.18*
DIV-AGNOSTIC 68.01±0.37 61.34±0.23 12.63±0.23 68.38±0.25 56.89±0.34 16.24±0.27
1.68M
DIV-FACTORIZED 71.01±0.39* 63.65±0.07* 11.75±0.35* 71.81±0.49* 59.78±0.39* 14.95±0.02*
Table 6: Average token conﬁdence, accuracy, and inference calibration results for EN↔FR translation on the
TED testset(averageandstdevof3runs). </Abstractive Summary> <Extractive Summary> Table 1 presents statis- tothefactthat METEOR allowsmatchesbetween
synonymswhencomparingreferencestohypothe-
tics on the extracted pairs, along with the corpus
createdifwethresholdthe LASERscoreat1.04,as ses.  </Extractive Summary>  </Table 1>  </Paper ID = 563>


<Paper ID = 563> <Table 2> <Abstractive Summary> =--weight-tying-type none
--source-factors-num-embed 8
(a)REFRESD --source-factors-combine concat
--target-factors-num-embed 8
--target-factors-combine concat
--transformer-model-size 504:512
--num-embed 504:504
Table 8: NMT conﬁgurations on Sockeye2 for DIV-
FACTORIZED;formissingsettingsrefertoTable7. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 563>


<Paper ID = 563> <Table 3> <Abstractive Summary> =#Tokens #Types Length %Corr
EQUIVALENTS 751,792 22,723,543 515,154 30.2 0%
SUBTREEDELETION 749,973 20,783,056 483,336 27.7 9.32%
PHRASEREPLACEMENT 750,527 22,735,143 475,567 30.3 16.11%
LEXICALSUBSTITUTION(HYPERNYMS) 724,326 22,014,609 497,658 30.4 12.33%
LEXICALSUBSTITUTION(HYPONYMS) 617,913 18,970,039 442,299 30.7 7.42%
Table 9: WikiMatrix statistics corresponding to extracted EQUIVALENTS and the ﬁne-grained corruptions intro-
ducedinthesyntheticsetting(EN-side). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 563>


<Paper ID = 563> <Table 4> <Abstractive Summary> =LEXICAL SUBSTITU- Table 12: % of degenerated outputs across beams
TION are sampled at random from the pools of (EN→FR). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 4>  </Paper ID = 563>


<Paper ID = 564> <Table 0> <Abstractive Summary> =In general and for each
2https://github.com/pytorch/fairseq/
languagepair,wetunethemodelarchitectureand tree/master/examples/xlmr
7253De-En En-De En-Ta Ru-En
BLEU valid test valid test valid test valid test
beam(fw) 24.7 27.7 23.1 26.6 8.8 6.0 33.5 34.3
+MLM(Salazaretal.,2019) 25.7 28.7 23.5 27.1 8.8 5.8 33.8 34.8
+MLM-ft(Salazaretal.,2019) 25.8 28.8 23.7 27.5 8.8 5.8 33.9 35.0
+LM 26.3 29.2 24.3 28.5 9.4 6.2 34.6 35.8
NCD(Yeeetal.,2019) 27.2 30.9 24.8 29.1 9.7 6.3 35.3 36.8
DrNMT 27.6 31.5 24.7 29.0 9.7 6.4 35.3 37.1
+NCD 27.9 31.8 25.1 29.7 10.0 6.5 35.7 37.3
oracleBLEU 33.3 37.4 31.4 35.9 13.6 9.5 45.3 47.0
Table 2: Validation and test BLEU with beam size 50. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 564>


<Paper ID = 564> <Table 1> <Abstractive Summary> =Even
Table 3: Average validation and test BLEU and TER
though we ﬁx the n-best list size at training time,
onWMT‘19De-Enwithbeamsize50fromrerankers
trainedwithdifferentmetrics(B:BLEU,T:TER). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 564>


<Paper ID = 564> <Table 2> <Abstractive Summary> =+LM 33.1
NCD(Yeeetal.,2019) 33.3
valid
DrNMT 33.1
set-level 27.6
+NCD 33.6
hypothesis-level(proposed) 27.6
Table 5: Reranking the output of a baseline trained
Table 7: Reranking with features computed over the
withback-translation. </Abstractive Summary> <Extractive Summary> We build the baseline MT models in Table 2 fol-
lowingtheTransformerbigarchitecture(Vaswani
etal.,2017)with6layers,embeddingsize1024and
16 attention heads.  </Extractive Summary>  </Table 2>  </Paper ID = 564>


<Paper ID = 564> <Table 3> <Abstractive Summary> =7261ffnembed learning label maxtokens
#params dropout #GPUs
size rate smoothing perGPU
De-En 207M 4096 0.0007 0.3 0.2 4000 4
En-De 207M 4096 0.0003 0.4 0.3 4000 4
En-Ta 197M 4096 0.0007 0.3 0.3 4000 4
Ru-En 276M 8192 0.0007 0.2 0.1 3584 128
Table8: BaselineMTmodelhyper-parameters
De-En En-De En-Ta Ru-En
TER valid test valid test valid test valid test
beam(fw) 60.9 58.0 67.1 63.2 85.1 88.2 52.7 52.3
+MLM(Salazaretal.,2019) 60.9 58.2 66.4 62.6 85.7 88.8 52.5 52.2
+MLM-ft(Salazaretal.,2019) 60.8 58.2 66.5 62.6 85.7 89.1 52.4 52.0
+LM 59.7 57.1 65.8 61.6 84.8 88.6 51.9 51.3
NCD(Yeeetal.,2019) 58.4 54.9 65.2 60.9 84.1 87.8 51.2 50.2
DrNMT 57.7 54.1 65.2 60.6 83.9 87.5 50.5 49.3
+NCD 57.9 54.2 64.9 60.1 83.5 87.4 50.6 49.6
Table 9: Validation and test TER with beam size 50. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 564>


<Paper ID = 566> <Table 0> <Abstractive Summary> =1 human conﬁdent
Stories *0.62 0.60 0.64 0.56 0.10 55.23 52.00
GPT2 *0.58 News *0.57 0.52 0.60 0.47 0.09 60.46 51.38
Recipes 0.55 0.48 0.59 0.40 0.03 65.08 50.31
Stories 0.48 0.40 0.47 0.36 0.03 62.15 47.69
GPT3 0.50 News 0.51 0.44 0.54 0.37 0.05 65.54 52.46
Recipes 0.50 0.41 0.50 0.34 0.00 66.15 50.62
Table 1: §2 results, broken down by domain and model, along with the F , precision, and recall at identifying
1
machine-generated text, Krippendorff’s α, % human-written guesses, and % conﬁdent guesses (i.e., Deﬁnitely
machine- or human-authored). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 566>


<Paper ID = 566> <Table 1> <Abstractive Summary> =1 human conﬁdent
Stories 0.48 0.40 0.47 0.36 0.03 62.15 47.69
None 0.50 News 0.51 0.44 0.54 0.37 0.05 65.54 52.46
Recipes 0.50 0.41 0.50 0.34 0.00 66.15 50.62
Stories 0.50 0.45 0.49 0.42 0.11 57.69 45.54
Instructions 0.52 News 0.56 0.48 0.55 0.43 0.05 62.77 52.15
Recipes 0.50 0.41 0.52 0.33 0.07 67.69 49.85
Stories 0.57 0.55 0.58 0.53 0.06 53.69 64.31
Examples *0.55 News 0.53 0.48 0.52 0.45 0.05 58.00 65.69
Recipes 0.56 0.56 0.61 0.51 0.06 55.23 64.00
Stories 0.56 0.56 0.55 0.57 0.07 48.46 56.62
Comparison 0.53 News 0.52 0.51 0.53 0.48 0.08 53.85 50.31
Recipes 0.51 0.49 0.52 0.46 0.06 54.31 53.54
Table 2: §3 results, broken down by domain and training method, along with the F , precision, and recall at
1
identifying machine-generated text, Krippendorff’s α, % human-written guesses, and % conﬁdent guesses (i.e.,
Deﬁnitelymachine-orhuman-authored).“None”trainingreferstotheGPT3resultsfrom§2. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 566>


<Paper ID = 567> <Table 0> <Abstractive Summary> =7300Ja→En Zh→En  40
System BLEU chrF System BLEU chrF ons 30 CSaocprieedB LsEcoUres
ati Copied w/o SacreBLEU
Tohoku-AIP-NTT 25.5 0.536 Volctrans 36.6 0.653 blic 20
pu 10
Custom1 25.5 0.536 Custom1 36.6 0.653 % 
Custom2 18.7 0.503 Custom2 32.2 0.638  0
2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020
Table 2: BLEU and chrF scores of the customized Figure 3: Percentage of papers copying scores from
Tohoku-AIP-NTT and Volctrans outputs from which previous work (“Copied scores”), using SacreBLEU
only one sentence has been modiﬁed. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 567>


<Paper ID = 567> <Table 1> <Abstractive Summary> =Table 3: BLEU and chrF scores computed by Sacre- 3.4 TheDataApproximation
BLEU after applying different processing on some
InMT,datasetsaremostlymonolingualorparallel
WMT20 MT system outputs (from Tohoku-AIP-NTT
andVolctrans)andonthereferencetranslations. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 567>


<Paper ID = 567> <Table 2> <Abstractive Summary> =BLEU chrF BLEU chrF
--disp-freq 500 --beam-size 12 --normalize
1 --valid-mini-batch 16 --overwrite all 120 (cid:88) 30.9 0.599 20.4 0.478
--early-stopping 5 --cost-type ce-mean-words all 120 31.5♠ 0.604♠ 21.1♠ 0.481
--valid-metrics bleu --keep-best --enc-depth all 100 (cid:88) 30.8 0.597 20.5 0.476
60.-1-d-e-cl-edaerpnt-hra6te--0t.r0a0n0s3fo-r-mlerr--wdarrompuoput16000 all 80 (cid:88) 29.8(cid:7) 0.584(cid:7) 20.0 0.471(cid:7)
--lr-decay-inv-sqrt 16000 --lr-report all 60 (cid:88) 26.6(cid:7) 0.549(cid:7) 18.5(cid:7) 0.453(cid:7)
--label-smoothing 0.1 --devices 0 1 2 3 4 5 6 lidﬁltered 120 (cid:88) 30.3(cid:7) 0.596 20.7 0.480
7 --optimizer-params 0.9 0.98 1e-09 --clip-norm
5 --sync-sgd --exponential-smoothing --seed 1234 -1corpus 120 (cid:88) 30.7 0.600 19.6(cid:7) 0.468(cid:7)
Table4: Hyper-parametersofMarianusedfortraining Table 5: BLEU and chrF scores of systems using dif-
ourNMTsystems. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 567>


<Paper ID = 568> <Table 0> <Abstractive Summary> =(2019) - 1.80x
indomainswithlessdatabutslightlylowerscores
Table 5: Latency cost for training and inference. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 568>


<Paper ID = 569> <Table 0> <Abstractive Summary> =RoBERTa-Large 207 774 322 774
Table 1: Estimated d intrinsic dimension computed 5 IntrinsicDimension,Pre-Training,and
90
with SAID and DID for a set of sentence prediction GeneralizationGap
tasksandcommonpre-trainedmodels. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 569>


<Paper ID = 570> <Table 0> <Abstractive Summary> =This behavior notably Table 1: Examples from the MNLI Matched develop-
differsfromthatofhumans; westrugglewith mentset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 570>


<Paper ID = 570> <Table 1> <Abstractive Summary> =However,re-
BiLSTM SNLItest 0.552 0.862 0.771 0.363 0.607
A1* 0.262 0.671 0.648 0.271 0.340 callthisanalysisexpectsustoknowthegoldlabel
A2* 0.297 0.728 0.672 0.209 0.328 upfront,sothistestcanbethoughtofasrunninga
A3* 0.304 0.731 0.656 0.219 0.331
word-orderprobetestonthemodeluntilthemodel
Mean 0.472 0.814 0.731 0.301 0.520
predicts the gold label (or give up by exhausting
Table 2: Statistics for Transformer-based models oursetofq permutations). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 570>


<Paper ID = 570> <Table 2> <Abstractive Summary> =7336Evaluator Accuracy MacroF1 AcconDc AcconDf EvalDataset A(V) A(ME) Ω (V) Ω (ME)
max max
X 0.581±0.068 0.454 0.649±0.102 0.515±0.089 MNLI m dev 0.905 0.908 0.984 0.328
Y 0.378±0.064 0.378 0.411±0.098 0.349±0.087
MNLI mm dev 0.901 0.903 0.985 0.329
SNLI test 0.882 0.888 0.983 0.329
Table 4: Human (expert) evaluation on 200 permuted
SNLI dev 0.879 0.887 0.984 0.333
examples from the MNLI matched development set. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 570>


<Paper ID = 570> <Table 3> <Abstractive Summary> =Table 5: NLI Accuracy (A) and Permutation Accep-
tance metrics (Ω ) of RoBERTa when trained on
max
much worse than RoBERTa (Table 4), although MNLI dataset using vanilla (V) and Maximum Ran-
their accuracy was a bit higher than random. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 570>


<Paper ID = 570> <Table 4> <Abstractive Summary> =Table 7: Dataset statistics used in this paper for in-
ference. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 4>  </Paper ID = 570>


<Paper ID = 572> <Table 0> <Abstractive Summary> =7367Table 3: Comparison between VOLT and widely-used BPE vocabularies on multilingual translation. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 572>


<Paper ID = 572> <Table 1> <Abstractive Summary> =X-En Es Pt-br Fr Ru He Ar Ko Zh-cn It Ja Zh-tw Nl Ro
BPE-60K 32.77 35.97 31.45 19.39 26.65 22.28 14.13 15.80 29.06 10.31 15.03 26.83 26.44
VOLT 33.84 37.18 32.85 20.23 26.85 22.17 14.36 16.59 30.44 10.75 15.73 27.68 27.45
X-En Tr De Vi Pl Pt Bg El Fa Sr Hu Hr Uk Cs
BPE-60K 16.74 25.92 21.00 18.06 34.17 30.41 29.35 20.49 26.66 17.97 28.30 22.18 22.08
VOLT 17.55 27.01 22.25 18.93 35.64 31.77 31.27 20.05 27.45 19.00 29.25 23.34 23.54
X-En Id Th Sv Sk Sq Lt Da My Sl Mk Fr-ca Fi Hy
BPE-60K 24.58 17.92 30.43 24.68 28.50 19.17 34.65 13.54 20.59 28.23 27.20 15.13 17.68
VOLT 25.87 18.89 31.47 25.69 29.09 19.85 36.04 13.65 21.36 28.54 28.35 15.98 18.44
X-En Hi Nb Ka Mn Et Ku Gl Mr Zh Ur Eo Ms Az
BPE-60K 18.57 35.96 16.47 7.96 15.91 13.39 26.75 8.94 13.35 14.21 21.66 19.82 9.67
VOLT 18.54 35.88 15.97 7.96 16.03 13.20 26.94 8.40 12.67 13.89 21.43 19.06 9.09
Table 4: Results of VOLT, MUV-Search and BPE- Table5: ComparisonbetweenVOLTandstrongbase-
Search. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 572>


<Paper ID = 572> <Table 2> <Abstractive Summary> =(Vaswanietal.,2017) 28.4 210M
(Shawetal.,2018) 29.2 213M
(Ottetal.,2018) 29.3 210M
En-De BLEU Size Cost (Soetal.,2019) 29.8 218M
(Liuetal.,2020) 30.1 256M
BPE-Search 29.9 12.6K 384GH
MUV-Search 29.7 9.70K 5.4CH+30GH SentencePiece 28.7 210M
VOLT 29.8 11.6K 0.5CH+30GH WordPiece 29.0 210M
VOLT 29.8 188M
WegenerateasequenceofBPEvocabularieswith
Table 6: Vocabularies searched by VOLT are bet-
incrementalsize1K,2K,3K,4K,5K,6K,7K,8K, ter than widely-used vocabularies on various archi-
9K,10K,20K.Fort-thvocabularyv(t),itsMUV tectures. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 572>


<Paper ID = 574> <Table 0> <Abstractive Summary> =As a (qualitative) reality check,
Table 2: Snowclone detection task. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 574>


<Paper ID = 578> <Table 0> <Abstractive Summary> =Subsequently,asimilaritymatrixisconstructedby
Motivated by this evaluation mechanism, we pairwisecalculatingthetokensimilarity.Thenthe
measuredifﬁcultyofatranslationbyviewingthe token-levelmatchingscoreisobtainedbygreedily
27En De(All) En De(Top30%) De En(All) De En(Top30%)
Metric → → → →
r τ ρ r τ ρ r τ ρ r τ ρ
| | | | | | | | | | | | | | | | | | | | | | | |
BLEU 0.952 0.703 0.873 0.460 0.200 0.143 0.888 0.622 0.781 0.808 0.548 0.632
TER 0.982 0.711 0.873 0.598 0.333 0.486 0.797 0.504 0.675 0.883 0.548 0.632
METEOR 0.985 0.746 0.904 0.065 0.067 0.143 0.886 0.605 0.792 0.632 0.548 0.632
BERTScore 0.990 0.772 0.920 0.204 0.067 0.143 0.949 0.756 0.890 0.271 0.183 0.316
DA-BERTScore 0.991 0.798 0.930 0.974 0.733 0.886 0.951 0.807 0.932 0.693 0.548 0.632
Table 1: Absolute correlations with system-level human judgments on WMT19 metrics shared task. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 578>


<Paper ID = 579> <Table 0> <Abstractive Summary> =GloVe+S 0.8331 0.8326 0.8321 0.8326
GloVe+U+S 0.8368 0.8368 0.8363 0.8365 6 VisualizingUncertaintyandSurprisal
Table 2: Performance of the features when combined Togetastraightforwardvisionoftheuncertainty
with a content-based classiﬁer. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 579>


<Paper ID = 579> <Table 1> <Abstractive Summary> =38RunningTime
Sim 1.76sec
lch
Sim 1.71sec
wup
Sim 1.71sec
path
Alliteration 1.70sec
Ambiguity 2.94sec
Uncertainty 2.12sec
Surprisal 2.49sec
Uncertainty+Surprisal 2.26sec
Table 3: Running time of the SVM classiﬁers trained
onindividualfeatures. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 579>


<Paper ID = 58> <Table 0> <Abstractive Summary> =Dur- -+IAT 3.69(1.65) 2.37(0.42)
ing training, reference responses are either gen-
erated responses or ground-truth responses in
Table 1: Results on the dialogue history modeling
self-supervisedandsupervisedinverse-adversarial abilityofcomparedmodels,whichismeasuredbythe
trainingrespectively. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 58>


<Paper ID = 58> <Table 1> <Abstractive Summary> =posed inverse adversarial training algorithm per-
699DailyDialog OpenSubtitles
Method
Dist-1 Dist-2 Dist-3 overlap stop-word Dist-1 Dist-2 Dist-3 overlap stop-word
Seq2Seq
-basemodel 2.32 6.28 9.43 15.6 67.4 1.72 5.37 7.64 22.5 77.8
-+MMI-anti 4.15∗ 11.27∗ 19.61∗ 26.7 62.4 3.45 11.35 18.12 30.1 74.2
-+MMI-bidi 3.52 9.29 17.43 31.5 63.1 3.52∗ 12.11∗ 18.56∗ 37.8 74.7
-+AL 2.25 6.01 9.39 16.1 66.8 2.97 5.44 7.46 23.5 76.4
-+DS 3.19 7.84 11.61 18.4 61.5 3.05 6.30 11.59 21.3 71.2
-+CVAE 3.59 9.41 12.93 17.7 61.1 3.35 10.13 17.02 22.5 71.4
-+IAT 3.72 9.81 14.93 15.4∗ 60.9 3.29 10.16 17.30 20.8∗ 70.9∗
Table 2: Results of the diversity of generated responses of compared models. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 58>


<Paper ID = 58> <Table 2> <Abstractive Summary> =Method DailyDialog OpenSubtitles Method Fluency Consistency Diversity
Seq2Seq Seq2Seq
-basemodel 0.75(0.41) 0.42(0.29) -basemodel 2.83 2.69 3.05
-+MMI - - -+MMI-anti 2.73 2.78 3.10
-+AL 0.83(0.47) 0.49(0.34) -+MMI-bidi 2.80 2.82 3.02
-+DS 0.78(0.44) 0.46(0.33) -+AL 2.77 2.69 2.91
-+IAT 0.77(0.45) 0.44(0.31) -+DS 2.85 2.88 3.12
-+CVAE 2.93 2.91 3.19
-+IAT 3.02∗ 3.05∗ 3.34∗
Table 3: Results on the adversarial robustness of
compared models, which is measured by the differ-
ence between perplexity of gold responses when re- Table4: Humanevaluationresultsofcomparedmodel
ceiving original dialogue history and receiving non- ontheDailyDialogdataset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 58>


<Paper ID = 580> <Table 0> <Abstractive Summary> =Table 6: Validation loss and accuracy for MLP classi-
Word embeddings initiated with word2vec ﬁerincounterfactual
(Mikolov et al., 2013) are trained on respective
training sets. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 580>


<Paper ID = 582> <Table 0> <Abstractive Summary> =Table 1: Comparison with baselines on ActivityNet
3.3 ImplementationDetails
Captionsae-testsplit. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 582>


<Paper ID = 583> <Table 0> <Abstractive Summary> =Y/N C Y/N HM Y/N WK BT Reph L-ConVQA CS-ConVQA
RUBi 64.92 57.15 62.59 85.57 77.73 78.02 65.93 46.66
VQA-CP LMH 1.01 22.82 50.10 83.68 75.04 64.54 50.65 53.72
CSS 0.94 11.73 39.95 77.54 68.89 10.67 38.64 58.47
BUTD 67.15 58.68 78.59 87.43 79.28 75.78 70.19 63.09
BAN 74.40 62.45 82.51 88.17 81.14 79.37 70.18 65.92
VQA
Pythia 65.00 60.61 81.60 88.42 82.86 77.02 69.45 64.56
VisualBERT 79.99 68.29 85.98 88.52 84.09 82.09 71.75 65.62
FGA 31.36 57.69 - 91.42 - - - 53.07
VisDial
VisDialBERT 62.08 56.06 - 94.04 - - - 55.78
Table 2: RAD over our proposed augmentations (Y/N C, Y/N HM, Y/N WK) and alternatives (BT, Reph,
ConVQA). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 583>


<Paper ID = 583> <Table 1> <Abstractive Summary> =This RAD(D(cid:48),D) 0.849±0.213
trend is reversed when looking at RAD scores -
Table 4: Linear regression experiments, predicting ac-
CSShasthelowestscorewhileRUBihasthehigh-
curacyperformanceonunseenaugmentationtypes. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 583>


<Paper ID = 584> <Table 0> <Abstractive Summary> =Weobservethatthemultiplieractsasa Sports Academia 24.43 22.25
“regularizer”inlearningamorebalancedweightfor
Table 2: F1 scores on using IRL and RL for domain
therewardcomponentsconsidered. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 584>


<Paper ID = 586> <Table 0> <Abstractive Summary> =Algorithm1DependencyBasedResponse(DBR) Metrics DBA Seq-To-Seq
%GC 81.6 87.2
nodes ← dependencyParse(Question)
ARS 3.97 3.66
foreachtemplateintemplatePooldo
if(templateconditionmatched)then Table 2: Human evaluation between the two ap-
Populatetemplateusingnodes proaches. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 586>


<Paper ID = 588> <Table 0> <Abstractive Summary> =niques commonly used to speed up decoding
in Transformer-based models, such as greedy Table 1: Translation of a simple source sentence by 4
search, quantization, average attention net- different commercial English to Spanish MT systems. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 588>


<Paper ID = 588> <Table 1> <Abstractive Summary> =ofLaborstatisticsofhigh-demandoccupations.1 A
Table 2: Example Templates, Keywords and a sample fulllistoftemplates,keywordsandvaluesisinta-
oftheresultinggeneratedsourcesentences. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 588>


<Paper ID = 588> <Table 2> <Abstractive Summary> =For
Table 3: Our evaluation protocol with an example
eachofthese7conﬁgurations,wetrainAANver-
sourcesentenceandfourexampletranslations. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 588>


<Paper ID = 588> <Table 3> <Abstractive Summary> =Table 4: Results showing the effect of speed-up optimizations applied individually (in Table 4a) and stacked in
Table 4b). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 588>


<Paper ID = 589> <Table 0> <Abstractive Summary> =Simi-
LANGVARMT-RANDOM-SOFTMAX 14.1 larly,usingTGTembeddingstrainedfromscratch
(LANGVARMT w/poorembeddings)resultsina
Table 3: BLEU scores on EN-UK test corpus with drasticperformancedrop,providingevidencefor
1MUKmonolingualcorpus. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 589>


<Paper ID = 589> <Table 1> <Abstractive Summary> =raw 6.1 13.5 15.3 2.3 8.8 9.8
lemma 12.8 19.5 21.3 3.5 13.7 15.8
(1) To measure transfer from STD to TGT em-
beddings,weﬁnetunetheSUP(SRC→STD)model Table 4: BLEU scores on raw vs lemmatized text with
using TGT embeddings trained from scratch (as LANGVARMT. </Abstractive Summary> <Extractive Summary> Across all data sizes, both UK and BE
achieveasubstantialincreaseinBLEU(upto+6
4 ResultsandAnalysis
BLEU; see Appendix D for details) compared to
thatobtainedonrawtext,indicatingmorphological
Table 1 compares the performance of LANG-
errorsinthetranslations.  </Extractive Summary>  </Table 1>  </Paper ID = 589>


<Paper ID = 589> <Table 2> <Abstractive Summary> =Table 5: Translation accuracies of words based on their (Ineverthoughtofahiddenconnection.) </Abstractive Summary> <Extractive Summary> LANGVARMTalsoimprovesin Table 2 shows that our proposed method is fairer
allotherArabicvarieties,althoughnaturallysome across all dialects, compared to baselines where
varietiesremainchallenging.  </Extractive Summary>  </Table 2>  </Paper ID = 589>


<Paper ID = 589> <Table 3> <Abstractive Summary> =We use training, development and carbon)
testsetsfromtheJW300corpus(Agic´ andVulic´,
Table 6: Examples of EN-UK translations generated by
2019)containing500KEN–AMparallelcorpusand
LANGVARMTandthebestperformingbaselines. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 589>


<Paper ID = 589> <Table 4> <Abstractive Summary> =Conceptually,ifthesystemproducesaper-
Table 8: BLEUscoresforEnglishtoLaoandEnglishto fect translation (BLEU=1) then the user will re-
Tigrinyatranslation
ceive the highest beneﬁt of 1. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 4>  </Paper ID = 589>


<Paper ID = 59> <Table 0> <Abstractive Summary> =Weusethis
Table 1: Data statistics from the Wizard of Wikipedia
measurebecauseitisrelevanttogroundingpreci- dataset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 59>


<Paper ID = 59> <Table 1> <Abstractive Summary> =Evid Entail
ControlCodes B1 B2 B3 B4 %N1P Prec Rec %Entail
GPT-2+NoControl 27.6 12.5 8.1 6.0 49.9 56.4 48.4 34.9
+Objective 26.4 12.8 8.6 6.4 98.1 62.3 50.5 50.1
+HighLexPrec 29.9 15.1 10.4 7.9 63.4 70.6 60.3 51.9
+Entailment 27.3 13.9 9.4 7.1 80.5 72.6 56.2 69.7
+All 27.9 14.8 10.2 7.7 99.4 76.6 60.3 72.3
T5+NoControl 28.6 14.4 9.7 7.3 49.8 63.9 50.1 44.4
+Objective 27.4 14.8 10.3 7.9 99.4 70.7 53.4 65.1
+HighLexPrec 29.6 15.9 11.1 8.4 63.3 76.1 59.8 60.7
+Entailment 27.8 15.3 10.6 8.1 80.3 77.7 57.3 80.0
+All 27.4 15.5 11.0 8.5 99.9 84.2 60.7 89.4
Table 2: Ablation Study: The effects of using different types of control codes for generation on the Wizard of
Wikipediaseentopicdevelopmentset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 59>


<Paper ID = 59> <Table 2> <Abstractive Summary> =NLI
Model B4 % Prec Rec % B4 % Prec Rec %
E2Emodel(Dinanetal.,2019) 1.5 48.0 47.9 30.4 29.3 0.3 37.6 33.2 21.7 9.5
dodecaDialogue(Shusteretal.,2020) 10.0 78.3 81.1 67.7 70.3 9.7 77.7 81.3 66.5 70.6
GPT-2(none) 6.2 50.9 56.1 49.4 34.2 5.7 52.1 56.4 48.3 34.2
GPT-2(controlcodes) 7.8 99.3 76.6 61.5 73.8 7.6 99.2 77.0 60.3 74.0
GPT-2(resampling) 7.6 75.1 70.4 57.7 71.4 7.2 76.2 70.3 56.5 72.3
GPT-2(both) 8.9 99.9 83.1 66.3 93.9 8.4 99.8 83.2 64.7 94.4
T5(none) 7.6 51.1 64.0 51.9 45.1 7.4 51.4 65.2 51.9 44.9
T5(controlcodes) 8.6 99.7 84.3 62.1 89.0 8.5 99.4 85.0 61.5 89.8
T5(resampling) 8.2 77.5 73.3 55.5 74.7 8.1 78.5 74.4 55.5 76.3
T5(both) 8.4 99.8 85.0 62.1 94.0 8.7 99.8 86.1 62.2 94.4
Table 3: Experimental results on the seen/unseen topic portions of the Wizard of Wikipedia test set. </Abstractive Summary> <Extractive Summary> Table 2 shows the re-
oftheproposedcontrollabledialoguesystemand sults on the seen topics portion of the Wizard of
itsvariouscomponents.  </Extractive Summary>  </Table 2>  </Paper ID = 59>


<Paper ID = 59> <Table 3> <Abstractive Summary> =B4 % Prec Rec %
8.5 99.4 86.1 61.1 91.5
A.2 TrainingOverFaithfulResponsesonly
Table 6: Training on faithful responses only: Exper-
We additionally experiment with a baseline in
imental results of a T5 model that was trained over
which we train T5 over just the portions of the
only “faithful” examples instead of using explicit con-
WizardofWikipediatrainingdatawheretheevalu- trolcodesorresampling
ationmeasuresaresatisﬁed(Table6). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 59>


<Paper ID = 59> <Table 4> <Abstractive Summary> =LexicalPrecwrtEvid 0.03 0.05 0.83 0.72
LexicalRecwrtEvid 0.02 0.05 0.67 0.38
A.4 Correlationsbetweenhumanjudgements %Entail -0.04 0.01 0.68 0.70
andautomaticmetrics
Table 7: Pearson’s R values between human metrics
Weobservethatourproposedmetricsgenerallycor- (ﬂuency, relevance, faithfulness, and objectivity) and
relatetohumanperceptionsofwhetheraresponse automatic metrics. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 4>  </Paper ID = 59>


<Paper ID = 590> <Table 0> <Abstractive Summary> =IMDb 20-News SST
IMDb 20-News SST BiLSTM(tanh) -0.935 -0.675 -0.866
H˜(ghi(x)) H˜(ghi(x)) H˜(ghi(x)) Transformer(dot) -0.830 -0.409 -0.810
BiLSTM(Softmax) 0.71 0.09 0.75 0.12 0.93 0.05
± ± ±
BiLSTM(Sparsemax) 0.72 0.10 0.68 0.12 0.91 0.07
Transformer(Softmax) 0.76 ±0.08 0.48 ±0.06 0.73 ±0.09 Table 2: Correlation between sparsegen parameter2  
Transformer(Sparsemax) 0.72 ±±0.09 0.46 ±±0.06 0.63 ±±0.08 andentropyofgradient-basedinputFIH˜(gyˆ(x)). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 590>


<Paper ID = 593> <Table 0> <Abstractive Summary> =√ (cause) 
acquired the ability of causal reasoning  Table 1: A challenging case where BERT predicts 
remains  a  question. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 593>


<Paper ID = 593> <Table 1> <Abstractive Summary> =The  Fleiss’ Kappa  0.919   0.893   0.890  
final parameters in our experiments are shown in 
Table 7: Human evaluation result of generated 
Table 6.  dataset. </Abstractive Summary> <Extractive Summary> We  explore  whether  PLMs  rely 
COPA development set in Table 1 seems to confirm 
excessively on semantic similarity with special 
our conjecture.  </Extractive Summary>  </Table 1>  </Paper ID = 593>


<Paper ID = 594> <Table 0> <Abstractive Summary> =Ground 34.06 8.51 7.40 2.33
Table 5: Averaged statistics per sentence for the different datasets (training sets). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 594>


<Paper ID = 595> <Table 0> <Abstractive Summary> =+ RERANK(Goldmanetal.,2018) 85.7 67.4 84.0 65.0 82.5 63.9
ITERATIVE SEARCH(Dasigietal.,2019) 85.4 64.8 82.4 61.3 82.9 64.3
+LogicalLanguageDesign(ours) 88.2 73.6 86.0 69.6 - -
+ConsistencyReward(ours) 89.6 75.9 86.3 71.0 89.5 74.0
Table 1: Performance on NLVR: Design changes in the logical language and consistency-based training, both
signiﬁcantly improve performance. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 595>


<Paper ID = 597> <Table 0> <Abstractive Summary> =queantube.com/
theyareonlystupidarabfromwp-arhaha
Delimit adelaide-femaleescorts.webcam
Yeah,dumbassn*gger†
N-gram nudeattentionwhoreasianbastards Table 2: Sample of URLs of adult content websites
InAmericaallmalelooklikethishomo identiﬁed by the n-gram approach. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 597>


<Paper ID = 597> <Table 1> <Abstractive Summary> =Table 1: Examples of hate speech found by the ap-
proaches tested. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 597>


<Paper ID = 598> <Table 0> <Abstractive Summary> =The repre-
Table 1: Number of instances per post-editor (PE) for sentationofthe‘[CLS]’tokenisthenpassedtoa
theQT21dataset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 598>


<Paper ID = 598> <Table 1> <Abstractive Summary> =PEID Train Dev Test
A1 121 40 42
A2 121 40 42
Hyper-parameter Value
A3 121 40 42
A4 121 40 42 Learningrate 3e-5
A5 121 40 42 Mini-batchsize 16
A6 121 40 42 Max.sequencelength 100
A7 121 40 42
A8 121 40 42
Table 6: Hyper-parameter values for all compared ap-
Total 968 320 336 proaches
Table4: NumberofinstancesperPostEditor(PE)for
theWPTP12dataset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 598>


<Paper ID = 599> <Table 0> <Abstractive Summary> =O O O
Table 5: Examples of label predictions for NICTA-PIBOSO abstract by BERT+BiLSTM+CRF (Base) and our
proposedmethod(Ours). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 599>


<Paper ID = 60> <Table 0> <Abstractive Summary> =Table 1: Salient entity classiﬁcation results. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 60>


<Paper ID = 60> <Table 1> <Abstractive Summary> =50.8 51.1 51.1 41.2 48.4 44.6
CitationIE
w/Citances 69.2 69.2 71.3 43.3 46.7 44.0
w/GraphEmbeddings 72.9 70.4 56.1 51.0† 54.1† 57.1
w/Graph+Citance 66.2 65.9 68.1 48.0† 51.4 52.7
Table 2: Comparing methods on relation extraction. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 60>


<Paper ID = 60> <Table 2> <Abstractive Summary> =(latefusion) 74.1 73.1 75.1†
• For Python’s random library, we use seeds Table 5: Comparing CitationIE models for mention
identiﬁcation with early graph embedding fusion vs
11370,1111,and2222
latefusion.Resultsareshownfromsingle-modelevalu-
ation. </Abstractive Summary> <Extractive Summary> SalientEntityClusterEvaluation
Relation Extraction Table 2 shows that using
Baseline(reimpl.)  </Extractive Summary>  </Table 2>  </Paper ID = 60>


<Paper ID = 60> <Table 3> <Abstractive Summary> =Table 6: Comparing CitationIE models for salient en-
tity classiﬁcation with early graph embedding fusion
vslatefusion.Theearlyfusionmodelwastrainedonce,
Weincluderesultsfromusingcitationgraphin-
whilelatefusionnumbersarereportedoveranaverage
formationforthementionidentiﬁcationtaskinTa-
of 3 runs. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 60>


<Paper ID = 60> <Table 4> <Abstractive Summary> =730Model F1 P R F1 P R
4-aryRelationExtraction
Document-LevelMetrics Corpus-LevelMetrics
GraphEmbeddings(earlyfusion) 68.5 67.5 76.2 58.7 61.0 59.6
GraphEmbeddings(latefusion) 63.3 61.8 67.3 75.8† 76.0† 76.1†
BinaryRelationExtraction
Document-LevelMetrics Corpus-LevelMetrics
GraphEmbeddings(earlyFusion) 72.9 70.4 56.1 51.0 54.1 57.1
GraphEmbeddings(latefusion) 58.3 58.0 59.0 53.6 58.1† 66.4
Table 7: Comparing CitationIE models for relation extraction with early graph embedding fusion vs late fusion. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 4>  </Paper ID = 60>


<Paper ID = 600> <Table 0> <Abstractive Summary> =Table 2: Top: text classiﬁcation prediction results on
sensitive texts; best BoW bolded, best overall itali-
We report results in an easier setting (cid:96) =
cized. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 600>


<Paper ID = 601> <Table 0> <Abstractive Summary> =Summary Doc
Dataset ARI FKGL GFI SMOG CLI
ratio #word#sent#word
nt WikiSum 7.4 6.82 10.15 9.71 8.83
WIKISUM instructional 39,775 13.9 101.2 5.0 1,334.2 me arXiv 14.02 13.51 18.47 15.44 14.31
ARXIV academic 215,913 39.8 292.8 9.6 6,913.8 cu PubMed 16.74 16.27 20.64 17.03 15.01
PUBMED academic 133,215 16.2 214.4 6.9 3,224.4 Do BigPatent 13.46 13.32 17.47 14.68 11.68
BIGPATENT academic 1,341,362 36.4 116.5 3.5 3,572.8 y WikiSum 9.71 8.49 11.91 10.24 8.78
WIKIHOW instructional 215,365 14.5 69.0 7.2 500.8 ar arXiv 16.44 16.1 20.5 16.8 15.23
m
CNN/DM news 312,085 13.0 55.6 3.8 789.9 m PubMed 17.73 17.35 21.6 17.44 16.6
NYT news 654,788 12.0 44.9 2.0 795.9 Su BigPatent 22.47 20.91 25.12 18.75 14.0
NEWSROOM news 1,212,726 43.0 30.4 1.4 750.9
XSUM news 226,711 18.8 23.3 1.0 431.1
Table2:Readabilityscoresforthedocuments(top)and
summaries(bottom),measuredinyearsofformaledu-
Table 1: Statistics comparison of summarization
cationrequiredtoreadthetext. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 601>


<Paper ID = 601> <Table 1> <Abstractive Summary> =The an-
214dataset time difﬁculty exhausting qualiﬁed unknown Models LEAD-3 TextRank PEGASUSLARGE
(minutes) (rating) (rating) (rating) (%)
WikiSum 6.8±1.2 1.9±0.3 2.2±0.5 4.2±0.3 0.2±0.1 WIKISUM 25.3/6.84/16.2 32.7/8.8/18.9 43.35/15.48/26.91
PubMed 10.0±1.2 3.7±0.3 3.9±0.4 2.2±0.4 3.7±1.4 ARXIV 25.53/5.98/15.22 33.1/9.7/18.1 43.07/19.70/34.79
PUBMED 26.38/8.73/16.6 35.3/13.1/20.4 44.70/17.27/25.80
BIGPATENT 28.9/7.96/18.17 33.0/9.8/19.6 45.49/19.90/27.69
Table 3: Evaluation time per sample, evaluation dif-
ﬁculty/exhaustion rating, perceived qualiﬁcation, and Table 4: ROUGE-1/2/L F1 scores on coherent-
the ratio of unknown words in the document. </Abstractive Summary> <Extractive Summary> Finally, Table 1 compares
2 RelatedWork WikiSumtocommonexistingdatasets.  </Extractive Summary>  </Table 1>  </Paper ID = 601>


<Paper ID = 602> <Table 0> <Abstractive Summary> =tionsforeachimage.Differentfromotherdatasets,
Repetition&Removal Weﬁndthatsomeofthe this dataset provides 4,000 caption triplet <A, B,
captionshaverepeatedwordsorhaveincomplete C>composedof50referencecaptions(A)andtwo
sentences.Hence,werandomlyrepeatorremove candidatecaptions(B,C)forthegivenimage.There
222Metric Flickr8k Composite CapEval1k PASCAL50s
Score distributions in Benchmark Dataset
BLEU-1 0.274 0.406 0.233 74.3
0.40 Composite BLEU-4 0.286 0.439 0.238 73.4
Flickr8k ROUGE-L 0.300 0.417 0.220 74.9
0.35 CapEval1k METEOR 0.403 0.466 0.288 78.5
CIDEr 0.419 0.473 0.307 76.1
0.30
SPICE 0.457 0.486 0.279 73.6
0.25 BERTScore 0.396 0.456 0.273 79.5
BERT-TBR 0.467 0.439 0.257 80.1
0.20 VBTScore 0.525 0.514 0.352 79.6
0.15 VIFIDEL 0.336 0.191 0.143 70.0
UMIC 0.468 0.561 0.328 85.1
0.10
UMIC-C 0.431 0.554 0.299 84.7
0.05
0.00 Table 1: Columns 1 to 3 represent Kendall Correla-
0.0 0.2 0.4 0.6 0.8 1.0
tionbetweenhumanjudgmentsandvariousmetricson
Flickr8k, Composite and CapEval1k. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 602>


<Paper ID = 603> <Table 0> <Abstractive Summary> =Model//CorpusSize 1M 2M 5M 10M 20M 37M
BaselineWord2Vec(CBOW) 0.0(0.0) 0.7(0.0) 6.0(1.9) 18.1(7.9) 28.0(15.1) 37.0(20.4)
TrainedandAveraged(CBOW) 1.6(0.4) 4.7(1.6) 13.1(5.6) 26.3(13.4) 35.5(18.4) 44.7(24.2)
Table 2: Anchor method vs. baseline (MUSE) at varying data sizes reporting acc@5 (acc@1) for English-
Macedonian. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 603>


<Paper ID = 604> <Table 0> <Abstractive Summary> =Therefore,thecode-switchedcorporaD
C
canbeconstructedinasimilarwayforotherlan- Table 3: The statistics of the training, valid, and test
setsonWMTdatasetsof10languagepairs. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 604>


<Paper ID = 604> <Table 1> <Abstractive Summary> =Table 4: Comparison of BLEU points between the Agreement-basedLearning Manyworkstryto
word-level and the phrase-level substitution strategies use the agreement-based method (Liang et al.,
onX→Endirections. </Abstractive Summary> <Extractive Summary> The results of our model are separately listed in ▁This 0.7
▁means
Table 1 and Table 2. Table 1 shows that One- ▁that 0.6
to-Many outperforms bilingual NMT by +1.8 ▁fruitful 0.5
▁Koordinierung
BLEUpointsonaverage.  </Extractive Summary>  </Table 1>  </Paper ID = 604>


<Paper ID = 606> <Table 0> <Abstractive Summary> =2https://github.com/abachaa/MeQSum
QTRandQFRasfollows:
3https://github.com/WHUIR/MATINF
r(Qp,Q∗)=γ ×r (Qp,Q∗)+γ ×r (Qp,Q∗) 4https://huggingface.co/microsoft/
QTR QTR QFR QFR
(2) prophetnet-large-uncased
251MEQSUM MATINF∗
Models
R-1 R-2 R-L R-1 R-2 R-L
Seq2Seq(Sutskeveretal.,2014) 25.28 14.39 24.64 17.77 5.10 21.48
Seq2Seq+Attention(Bahdanauetal.,2015) 28.11 17.24 27.82 19.45 6.45 23.77
PointerGenerator(PG)(Seeetal.,2017) 32.41 19.37 36.53 23.31 7.01 26.61
SOTA(BenAbachaandDemner-Fushman,2019) 44.16 27.64 42.78 − − −
es SOTA∗(BenAbachaandDemner-Fushman,2019) 40.00 24.13 38.56 24.58 7.30 28.08
n
eli Transformer(Vaswanietal.,2017) 25.84 13.66 29.12 22.25 5.89 26.06
as BertSumm(LiuandLapata,2019) 26.24 16.20 30.59 31.16 11.94 34.70
B
T5 (Raffeletal.,2019) 38.92 21.29 40.56 39.66 21.24 41.52
BASE
PEGASUS(Zhangetal.,2019a) 39.06 20.18 42.05 40.05 23.67 43.30
BART (Lewisetal.,2019) 42.30 24.83 43.74 42.52 23.13 43.98
LARGE
MINILM(Wangetal.,2020) 43.13 26.03 46.39 35.60 18.08 38.70
ProphetNet(Qietal.,2020) 43.87 25.99 46.52 46.94 27.77 48.43
ProphetNet+ROUGE-L 44.33 26.32 46.90 48.17 28.13 48.66
g ProphetNet+Q-type 44.40 26.63 47.05 47.19 28.02 48.70
ntnin ProphetNet+Q-focus 44.62 26.61 47.28 47.14 28.06 48.64
Joiear ProphetNet+Q-type+Q-focus 44.67 26.72 47.34 47.18 28.04 48.65
L
dh ProphetNet+QTR 44.60 26.69 47.38 47.51 28.40 48.94
oseoac ProphetNet+QFR 45.36 27.33 47.96 47.53 28.29 49.11
ropppr ProphetNet+QTR+QFR 45.52 27.54 48.19 47.73 28.54 49.33
PA
Table 1: Comparison of the proposed models and various baselines. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 606>


<Paper ID = 606> <Table 1> <Abstractive Summary> =MEQSUM MATINF
SummaryLabel
M1 M2 M3 M4 M1 M2 M3 M4
SemanticsPreserved(PC/FC) 14/19.5 9.5/29 18/28 19.5/29 6/32.5 9.5/33 13.5/34 14/35
FactualConsistent(PC/FC) 11/25 7.5/35 9.5/36.5 10/38 5.5/35 7/36 7.5/41 9/42.5
Incorrect 23 11 12.5 11 10.5 11.5 11.5 10
Acceptable 18.5 10 12.5 12.5 15 10.5 8.5 9.5
Perfect 8.5 29 25 26.5 24.5 28 30 30.5
Table 2: Results of the manual evaluation of the summaries generated by ProphetNet (M1), M1+QTR (M2),
M1+QFR(M3),andM1+QTR+QFR(M4).ForSemanticPreservedandFactualConsistent,wereportthepartially
correct(PC)andfullycorrect(FC)numbers. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 606>


<Paper ID = 606> <Table 2> <Abstractive Summary> =of the generated summaries, we categorize each
Table 3: Correct/Incorrect summaries generated on summaryintooneofthefollowingcategories: ‘In-
MEQSUM. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 606>


<Paper ID = 607> <Table 0> <Abstractive Summary> =Simple Falcon2.0 0.35 0.44 0.39
Questions SemReL 0.69 0.70 0.69
• LC-QuAD2.0(Dubeyetal.,2019): Alarge
dataset based on Wikidata with 6,046 test
Table 1: SemReL compared to SoTA systems on the
questionsandaround24ktrainingquestions. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 607>


<Paper ID = 607> <Table 1> <Abstractive Summary> =Itcomprisesof
5,622testquestions,andaround19Ktraining
Table 2: SemReL F1 for all, one-hop and multi-hop
questions. </Abstractive Summary> <Extractive Summary> In ad- Table 1 compares SemReL with existing ap-
dition,weuseasubsetof80kexamplesfromthe proaches.  </Extractive Summary>  </Table 1>  </Paper ID = 607>


<Paper ID = 609> <Table 0> <Abstractive Summary> =ATTN+RsWr 36.2 27.3 56.7 120.1 21.0 44.9 84.8
Foroneimage,thereareﬁvereferences,constitut-
Table 3: Comparison with pairwise similarity and re-
ingtenreferencepairs. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 609>


<Paper ID = 61> <Table 0> <Abstractive Summary> =We use BERT-base and set all hyper-parameters
Table 1: Number comparison of event relations in
using the default settings of the SotADRR ASER++andexistingevent-relatedresources. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 61>


<Paper ID = 61> <Table 1> <Abstractive Summary> =BERT(ASER++) 66.2
BERT(ASER++&WscR) 74.1
4.2 ExtrinsicExperiments
Table 5: The overall results of extrinsic experiments. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 61>


<Paper ID = 610> <Table 0> <Abstractive Summary> =Table 5: Accuracy results on the TR2016hard test set
forModelF+(MF+)andMOLEMAN(MM) RicoAngell, NicholasMonath, SunilMohan, Nishant
Yadav, and Andrew McCallum. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 610>


<Paper ID = 611> <Table 0> <Abstractive Summary> =thesewordsasP(w ) = k ∀ w ∈ E;3)Toensure
e e
287wemask15%ofthewordsintotal,welowerthe SST-2 SST-5
masking probability of the non-emotionally-rich
ACC F-1 ACC F-1
wordsusingthefollowingformula:
BERT 0.912 0.922 0.532 0.541
eMLM(S) 0.919 0.928 0.541 0.552
eMLM(E) 0.920 0.931† 0.547 0.558†
max(|S|·0.15−|E|·k, 0)
P(w ) = , ∀ w ∈/ E
n |S|−|E| n Table 2: Performance on the sentiment analysis task. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 611>


<Paper ID = 611> <Table 1> <Abstractive Summary> =Table 3: F-1 scores on the Goemotion dataset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 611>


<Paper ID = 611> <Table 2> <Abstractive Summary> =Table 6: Robustness of our models in terms of pertur-
4 RobustnessTest bationsuccessrates.Lowersuccessratesindicatemore
robustmodels. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 611>


<Paper ID = 612> <Table 0> <Abstractive Summary> =Con- Table 1: Example negative review on Yelp. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 612>


<Paper ID = 612> <Table 1> <Abstractive Summary> =Table 4: Sentences with negation sampled from nega-
(b)Amazondatasets. </Abstractive Summary> <Extractive Summary> Table 1 shows a
1BoucherandOsgood(1969)usedamorphologicalanal-
negative review from Yelp.  </Extractive Summary>  </Table 1>  </Paper ID = 612>


<Paper ID = 614> <Table 0> <Abstractive Summary> =(2020)to UN (cid:88) 51.78 88.90 89.67 89.28
F (cid:88) (cid:88) 57.22 88.64 90.03 89.33
preparealarge-scalepaymentdocumentcollection
Table 1: Different positional encodings for GCNs on
thatconsistsofaround18Ksingle-pagepayments. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 614>


<Paper ID = 615> <Table 0> <Abstractive Summary> =Toshedlightonwhyit
Beneﬁciary “Whoissomethingboughtfor?”
isthecase,weidentifythekeychallengesbehind Time “Whenisthepurchase?”
Place “Whereisthepurchase?”
the gap, and attribute each of them to the intrin-
sic weakness of pretrained models, our usage of
Table 1: The predeﬁned question for each argument
them, or the task itself. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 615>


<Paper ID = 618> <Table 0> <Abstractive Summary> =Then,weextractgender-distincteventswith
Table 2: Statistics showing the number of celebrities
a higher chance to occur for one group than the
with Career section or Personal Life section, together
other. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 618>


<Paper ID = 618> <Table 1> <Abstractive Summary> =We aim to calibrate the top 50 most skewed
Table 3: The performance for off-the-shelf event ex-
events in females’ and males’ Career and Per-
tractionmodelinbothcommoneventextractiondataset
sonal Life descriptions after using the OR sepa-
TB-Dense(TB-D)andourcorpuswithmanualannota-
tion. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 618>


<Paper ID = 618> <Table 2> <Abstractive Summary> =353Occupation EventsinFemalePersonalLifeDescription EventsinMalePersonalLifeDescription WEAT∗ WEAT
Writer bury, birth,attend, war,grow know,report,come, charge,publish -0.05 0.31
Acting pregnant,practice,wedding,record,convert accuse, trip, ﬂy, assault,endorse -0.14 0.54
Comedian feel, birth,fall,open,decide visit,create,spend,propose,lawsuit -0.07 0.07
Podcaster date,describe,tell,life,come play,write, born,release,claim -0.13 0.57
Dancer marry,describe,diagnose,expect,speak hold,involve, award,run,serve -0.03 0.41
Chef death,serve,announce,describe, born birth,lose, divorce,speak, meet -0.02 -0.80
Annotations: Life Transportation Personell Conﬂict Justice Transaction Contact
Table 5: Top 5 events in Personal Life section across 6 occupations.9 There are more Life events (e.g., “birth”
and“marry”)infemales’personallifedescriptionsthanmales’formostoccupations. </Abstractive Summary> <Extractive Summary> Table 2 shows the tionaries Em = {em : |em|,...,em : |em|} and
1 1 M M
statisticsofthenumberofcelebritieswithCareer Ef = {ef : |ef|,...,ef : |ef|}mappingeventsto
1 1 F F
orPersonalLifesectionsinourcorpora,together theirfrequencyformaleandfemalerespectively.  </Extractive Summary>  </Table 2>  </Paper ID = 618>


<Paper ID = 619> <Table 0> <Abstractive Summary> =(2020) - 14.08 1.00
xx→En 30.98 26.78
En→xx 24.17 78.72 20.08
Ours 14.71 1.31
xx→En 32.19 87.23 27.92
Table1: Mainresults
BLEU Main en de fr ar zh ru
94
Models
En→xx xx→En
1 rw sv pt he ja sh
Full 24.17 32.19 2 yi da it mt ko lt
-MIMO 23.78 31.61 3 gd nn ca fa th sr
-MIMO-TaskAttention 23.54 31.27 4 de nb es ga vi mk
5 xh no mt yo bn lv
Table 2: Ablation on the MIMO and task-aware atten-
tion. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 619>


<Paper ID = 619> <Table 1> <Abstractive Summary> =Table 4: Languages with similar task-aware attention
weights. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 619>


<Paper ID = 62> <Table 0> <Abstractive Summary> =Methods de(Selected) de(Other) es(Selected) es(Other) nl(Selected) nl(Other)
mBERT-ft 73.65 70.66 77.29 70.39 81.67 69.89
mBERT-TLADV 74.05 72.49 78.04 73.86 81.83 77.89
UniTransw/otranslation 74.48 71.71 77.29 73.18 83.15 70.39
AdvPicker 75.11 73.76 79.19 75.68 84.19 79.15
Table 7: F1 scores over the Select/Other test set splits in different target languages. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 62>


<Paper ID = 620> <Table 0> <Abstractive Summary> =faiss
370Domain IT(BaseNMT:38.35) Med(BaseNMT:39.99) Koran(BaseNMT:16.26) Law(BaseNMT:45.48) Avg(BaseNMT:35.02)
Model V U A V U A V U A V U A V U A
1 42.19 41.21 42.52 51.41 50.32 51.82 18.12 17.15 18.10 58.76 58.05 58.81 42.62 41.68 42.81
2 44.20 41.43 46.18 53.65 52.44 55.20 19.37 17.36 19.12 60.80 59.81 61.76 44.50 42.76 45.56
4 44.89 42.31 47.23 54.16 53.01 55.84 19.50 17.88 19.69 61.31 60.75 62.89 44.97 43.49 46.41
K
8 45.96 42.46 48.04 54.06 53.46 56.31 20.12 18.59 20.57 61.12 61.37 63.21 45.32 43.97 47.03
16 45.36 43.05 47.71 53.54 54.08 56.41 20.30 19.45 21.09 60.21 61.52 63.07 44.85 44.53 47.07
32 44.81 43.78 47.68 52.52 53.95 56.21 19.66 19.99 20.96 59.04 61.53 63.03 44.00 44.81 46.97
σ2(K≥4) 0.21 0.33 0.08 0.42 0.18 0.05 0.10 0.65 0.30 0.81 0.10 0.01 0.24 0.26 0.07
Table 2: The BLEU scores of the vanilla kNN-MT (V) and uniform kNN-MT (U) baselines and the proposed
Adaptive kNN-MT model (A). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 620>


<Paper ID = 620> <Table 1> <Abstractive Summary> =Dataset IT Medical Koran Laws
k 8 4 16 4
T 10 10 10 100
λ 0.7 0.8 0.8 0.8
Table 9: Optimal choice of hyper-parameters for each
domaininvanillakNN-MT. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 620>


<Paper ID = 624> <Table 0> <Abstractive Summary> =409Method R@1000(%)
MediaWikiAPI 89.56
Anserini 94.76
Anserini+MediaWikiAPI 96.87
Table 4: Comparison of document retrieval methods
ontheFEVERdevelopmentset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 624>


<Paper ID = 625> <Table 0> <Abstractive Summary> =Avg.GloVeembeddings(Penningtonetal.,2014) 55.14 70.66 59.73 68.25 63.66 58.02 53.76 61.32
Avg.BERTembeddings 38.78 57.98 57.98 63.15 61.06 46.35 58.40 54.81
BERTCLS-vector 20.16 30.01 20.09 36.88 38.08 16.50 42.63 29.19
InferSent-Glove(Conneauetal.,2017) 52.86 66.75 62.15 72.77 66.87 68.03 65.65 65.01
UniversalSentenceEncoder(Ceretal.,2018) 64.49 67.80 64.61 76.83 73.18 74.92 76.69 71.22
Sentence-BERT-base(Mean) 70.97 76.53 73.19 79.09 74.30 77.03 72.91 74.89
Sentence-BERT-large(Mean) 72.27 78.46 74.90 80.99 76.25 79.23 73.75 76.55
Sentence-RoBERTa-base(Mean) 71.54 72.49 70.80 78.74 73.69 77.77 74.46 74.21
Sentence-RoBERTa-large(Mean) 74.53 77.00 73.18 81.85 76.82 79.10 74.29 76.68
DefSent-BERT-base(CLS) 67.56 79.86 69.52 76.83 76.61 75.57 73.05 74.14
DefSent-BERT-large(CLS) 66.22 82.07 71.48 79.34 75.38 73.46 74.30 74.61
DefSent-RoBERTa-base(CLS) 65.55 80.84 71.87 78.77 79.29 78.13 74.92 75.62
DefSent-RoBERTa-large(Mean) 58.36 76.24 69.55 73.15 76.90 78.53 73.81 72.36
Table 3: Spearman’s rank correlation ρ×100 between cosine similarities of sentence embeddings and human
ratings. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 625>


<Paper ID = 625> <Table 1> <Abstractive Summary> =BERT-base CLS 67.56±0.26 79.86±0.25 69.52±0.39 76.83±0.32 76.61±0.33 75.57±0.37 73.05±0.32 74.14±0.25
Mean 67.30±0.44 81.96±0.24 71.92±0.28 77.68±0.47 76.71±0.48 76.90±0.40 73.28±0.30 75.11±0.21
Max 64.61±0.87 82.06±0.21 72.43±0.31 76.56±0.74 75.61±0.43 76.61±0.52 72.15±0.46 74.29±0.33
BERT-large CLS 66.22±0.79 82.07±0.39 71.48±0.33 79.34±0.44 75.38±0.60 73.46±0.45 74.30±0.50 74.61±0.41
Mean 64.18±0.96 82.76±0.42 73.14±0.32 79.66±0.92 77.93±0.78 77.89±0.89 73.98±0.46 75.65±0.53
Max 58.94±1.06 81.03±0.66 71.34±0.88 76.23±1.83 76.07±0.56 75.75±0.70 71.69±0.74 73.01±0.74
RoBERTa-base CLS 65.55±0.89 80.84±0.26 71.87±0.39 78.77±0.70 79.29±0.27 78.13±0.61 74.92±0.18 75.62±0.38
Mean 60.78±1.41 77.17±0.60 69.71±0.73 75.13±1.00 77.75±0.38 76.52±0.63 74.10±0.45 73.02±0.63
Max 63.85±0.86 78.55±0.90 71.19±0.86 76.55±1.12 77.86±0.59 78.02±0.77 73.97±0.46 74.28±0.62
RoBERTa-large CLS 63.84±1.34 77.33±2.53 68.64±1.34 72.86±1.96 77.13±1.32 78.32±1.08 74.14±1.31 73.18±1.20
Mean 58.36±1.16 76.24±0.87 69.55±0.85 73.15±1.32 76.90±0.94 78.53±0.54 73.81±0.88 72.36±0.73
Max 62.89±1.42 77.99±1.88 69.83±1.66 75.60±1.51 79.63±0.60 79.34±0.48 74.04±0.84 74.19±0.88
Table 8: Spearman’s rank correlation ρ×100 between the cosine similarities of the sentence embeddings and
the human ratings for each model and pooling strategy. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 625>


<Paper ID = 626> <Table 0> <Abstractive Summary> =Speciﬁcally, ES→DE 57.67 56.46 60.53 59.83 57.87
we used a sample of 1 million parallel sentences
Table 2: Sentence translation retrieval accuracy based
fromWMT’13common-crawldata;thissubsetis
onoutofdomainpre-trainedFasttextembeddings. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 626>


<Paper ID = 629> <Table 0> <Abstractive Summary> =In order to fool the 18: endif
19: return X(cid:98)
target CSC model while maintaining the context,
the character with the highest logit output in the Table 1: Statistics information on the used data re-
sources. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 629>


<Paper ID = 629> <Table 1> <Abstractive Summary> =2https://github.com/BYVoid/OpenCC
443Table 2: Performance of three models trained with the proposed pretraining strategy and adversarial training
method. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 629>


<Paper ID = 630> <Table 0> <Abstractive Summary> =452A ExperimentalDetails
A.1 Hyper-parameters
Hyper-parameter Value
learningrate 1e-4
batchsize 24
epoch 2
optimiser Adam
Adam(cid:15) 1e-6
Adam(β ,β ) (0.9,0.999)
1 2
maxsequencelength 256
pooling max-pooling
numberofpassages 5/10/20
device NvidiaV100
Table 4: Hyper-parameters for the HasAnswer model
training. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 630>


<Paper ID = 633> <Table 0> <Abstractive Summary> =Thissetupachievesaper-image 2https://github.com/ChenRocks/UNITER
470Model QuestionType Q+F+I Q+F Q+I F+I Q F I
Entropy 1-Hop 65.7 65.7 32.4 3.9 32.4 3.8 4.5
QuestionType MemNet UNITER 1-HopCounting 78.0 78.0 30.3 0.0 30.3 0.0 0.0
(Base2)
1-HopSubtraction 28.9 28.6 28.8 0.8 30.3 0.6 6.5
1-Hop 61.0 65.7 7.8 Boolean 94.6 94.6 55.2 1.3 55.2 1.0 10.5
1-HopCounting - 78.0 1.4 Comparison 90.4 90.4 38.7 1.0 38.7 0.9 10.7
Counting 79.4 79.4 66.1 0.6 65.9 0.4 1.4
1-HopSubtraction - 28.6 4.3
Intersection 79.4 79.4 61.0 0.4 60.6 0.3 0.0
Boolean 75.1 94.6 1.1 Multi-Entity 77.1 77.1 41.3 0.8 41.2 0.7 6.4
Comparison 50.5 90.4 2.1 Multi-Hop 87.9 87.9 29.0 0.8 28.9 0.8 0.0
Multi-Relation 75.2 75.2 25.1 3.0 25.0 3.0 2.5
Counting 49.5 79.4 2.3
Spatial 21.2 21.2 0.0 13.0 0.0 13.0 0.0
Intersection 72.5 79.4 1.2 Subtraction 34.4 34.4 1.3 1.0 0.9 0.7 0.0
Multi-Entity 43.5 77.1 3.3 Overall 69.3 69.3 31.6 3.1 31.5 3.0 3.6
Multi-Hop 53.2 87.9 3.7
Table 2: Ablation Study of Information. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 633>


<Paper ID = 633> <Table 1> <Abstractive Summary> =Spatial 3.3 1.2 21.1 0.0
We observe a similar trend in the fact and im-
Subtraction 2.1 2.6 39.2 1.6
age ablation setting (‘Q’ column of Table 3 and
Overall 47.0 40.8 69.3 32.8
ofTable2)thatthemodelisabletogreaterlever-
Table 3: Further Ablation and Adversarial Studies. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 633>


<Paper ID = 634> <Table 0> <Abstractive Summary> =Table 3: Examples of claims in FEVER that require
commonsenseorworldknowledge(underlined). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 634>


<Paper ID = 634> <Table 1> <Abstractive Summary> =Table 4: Performance evaluation of the Question Gen-
2020. </Abstractive Summary> <Extractive Summary> 18,541 Wikipedia articles in the FEVER train-
3.1 MainResults
ing set, we generate a total number of 176,370
supported claims, 360,924 refuted claims, Table 1 summarizes the fact veriﬁcation perfor-
and 258,452 NEI claims.  </Extractive Summary>  </Table 1>  </Paper ID = 634>


<Paper ID = 636> <Table 0> <Abstractive Summary> =The ATE-F1, Baseline &TSMTD&PRD 78.61
OTE-F1,andASC-F1measureeachsubtask’sF-1
Table 3: Ablation study on the REST14 dataset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 636>


<Paper ID = 636> <Table 1> <Abstractive Summary> =DCRAN ELECTRA 78.62 74.48 66.23 67.69
Single- base
w/oTSMTD&PRD 78.42 73.79 64.21 66.67
Aspect
w/oTSMTD&PRD&AP&OP 77.45 73.10 62.50 64.29
DCRAN ELECTRA 81.19 64.24 68.20 52.34
Multiple- base
w/oTSMTD&PRD 80.22 61.70 65.16 48.60
Aspect
w/oTSMTD&PRD&AP&OP 79.88 61.39 64.84 46.73
Table 4: Aspect analysis on the REST14 and REST15 datasets. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 636>


<Paper ID = 636> <Table 2> <Abstractive Summary> =restaurant(pos)
DCRAN beautiful
staff(neg)
food(pos)
RACL disgusted
service(pos)
Ihaveneverbeensodisgustedbyboth food(pos)
E3 DCRANw/o disgusted
food(neg)andservice(neg) service(neg)
food(neg)
DCRAN disgusted
service(neg)
Table 5: Case study on the REST15 dataset. </Abstractive Summary> <Extractive Summary> 3.2 QuantitativeResults masked term discrimination (TSMTD), and pair-
wise relations discrimination (PRD), we conduct
Table 2 reports the quantitative results on the
ablationexperimentsontheREST14dataset.We
LAP14, REST14, and REST15 datasets.  </Extractive Summary>  </Table 2>  </Paper ID = 636>


<Paper ID = 637> <Table 0> <Abstractive Summary> =SDRN(Chenetal.,2020) 66.18 73.30 65.75 73.67
GAS-ANNOTATION-R 68.74 72.66 65.03 73.75
TargetAspectSentimentDetection(TASD) is GAS-EXTRACTION-R 67.58 73.22 65.83 74.12
thetasktodetectall(aspectterm,aspectcategory, GAS-ANNOTATION 69.55 75.15 67.93 75.42
GAS-EXTRACTION 68.08 74.12 67.19 74.54
sentiment polarity) triplets for a given sentence
(Wan et al., 2020), where the aspect category be-
Table 1: Main results of the AOPE task. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 637>


<Paper ID = 637> <Table 1> <Abstractive Summary> =GAS-ANNOTATION-R 67.37 75.77 65.75 71.87
Target (Extraction-style): (pizza, GAS-EXTRACTION-R 66.71 76.30 64.00 72.39
food quality, negative); (cheese, food quality, GAS-ANNOTATION 68.64 76.58 66.78 73.21
negative);(null,restaurantgeneral,negative); GAS-EXTRACTION 68.06 77.13 65.96 73.64
Table 2: Main results of the UABSA task. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 637>


<Paper ID = 637> <Table 2> <Abstractive Summary> =506L14 R14 R15 R16 Rest15 Rest16
CMLA+(Wangetal.,2017) 33.16 42.79 37.01 41.72 Baseline(BrunandNikoulina,2018) - 38.10
Li-uniﬁed-R(Lietal.,2019a) 42.34 51.00 47.82 44.31 TAS-LPM-CRF(Wanetal.,2020) 54.76 64.66
Pipeline(Pengetal.,2020) 42.87 51.46 52.32 54.21
TAS-SW-CRF(Wanetal.,2020) 57.51 65.89
Jet(Xuetal.,2020) 43.34 58.14 52.50 63.21
Jet+BERT(Xuetal.,2020) 51.04 62.40 57.53 63.83 TAS-SW-TO(Wanetal.,2020) 58.09 65.44
GAS-ANNOTATION-R 52.80 67.35 56.95 67.43 GAS-ANNOTATION-R 59.27 66.54
GAS-EXTRACTION-R 58.19 70.52 60.23 69.05 GAS-EXTRACTION-R 60.63 68.31
GAS-ANNOTATION 54.31 69.30 61.02 68.65 GAS-ANNOTATION 60.06 67.70
GAS-EXTRACTION 60.78 72.16 62.10 70.10 GAS-EXTRACTION 61.47 69.42
Table 3: Main results of the ASTE task. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 637>


<Paper ID = 637> <Table 3> <Abstractive Summary> =The best re-
Table 4: Main results of the TASD task. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 637>


<Paper ID = 637> <Table 4> <Abstractive Summary> =By formulating the
targetsentenceswithourproposedannotation-style
Table 5: Example cases of the predictions before and andextraction-styleparadigms,wesolvemultiple
afterthepredictionnormalization. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 4>  </Paper ID = 637>


<Paper ID = 638> <Table 0> <Abstractive Summary> =granularitywhiledifﬁculttokensareupdatedwith
511
Proceedingsofthe59thAnnualMeetingoftheAssociationforComputationalLinguistics
andthe11thInternationalJointConferenceonNaturalLanguageProcessing(ShortPapers),pages511–516
August1–6,2021.©2021AssociationforComputationalLinguisticsga¯ox`ıng(81);yu´kua`i(74);
pleasing(847)
xˇıyue` (63);quˇyue` (49)...
bearings(847) zho´uche´ng(671)...
Table 1: An example from the WMT19 Chinese-
Englishtrainingset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 638>


<Paper ID = 638> <Table 1> <Abstractive Summary> =(2017) 27.3 -
0.10 26.89 23.61
Chi-Square 27.51 -
0.15 26.93 23.49
1.0 Exponential 27.60 -
0.20 26.98 23.39
OurNMTsystems
0.25 26.91 23.24
Transformer 27.97 24.37
0.30 26.85 23.50 +Chi-Square 28.08(+0.11) 24.62(+0.25)
0.15 26.93 23.31 +Exponential 28.17(+0.20) 24.33(-0.04)
BMI 0.9 0.20 26.88 23.31 +BMI 28.53(+0.56)* 25.19(+0.82)*
0.25 26.96 23.41
Table 3: BLEU scores (%) on the WMT14 En-De
0.15 27.01 23.40
test set and the WMT19 Zh-En test set. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 638>


<Paper ID = 638> <Table 2> <Abstractive Summary> =514Models MATTR HD-D MTLD 5 Conclusion
Transformer 89.41 94.05 230.36
Weproposeanovelbilingualmutualinformation
+Chi-Square 89.37 94.02 230.02
basedadaptivetrainingobjective,whichcanmea-
+Exponential 89.41 94.08 232.98
+BMI 89.45 94.10 236.43 sure the learning difﬁculty for each target token
Reference 90.92 94.88 259.98 from the perspective of bilingualism, and adjust
the learning granularity dynamically to improve
Table 4: The lexical diversity of WMT14 En-De token-leveladaptivetraining. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 638>


<Paper ID = 64> <Table 0> <Abstractive Summary> =P denotes the percentage of Table 2: Main results on three benchmark datasets. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 64>


<Paper ID = 64> <Table 1> <Abstractive Summary> =Model F1 DisF1 DisF1(cid:63)
Mac 78.7 56.4 46.6
–TagBandS 78.2 55.8 46.1
–Segmentlengthembedding 78.1 55.7 46.2
–CLNmechanism 76.8 52.7 44.4
–Segmentinnerrepresentation 72.9 55.6 46.3
Table 4: An ablation study on the ShARe 13 dev set. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 64>


<Paper ID = 640> <Table 0> <Abstractive Summary> =Dataset
Hyperparameters TDDMan TDDAuto MATRES TB-Dense
DropoutRatio 0.5 0.5 0.5 0.5
Optimizer Adam Adam Adam Adam
InputDimension(ContextEncoder) (n,768) (n,768) (n,768) (n,768)
InputDimension(SyntacticGraph) (n,768) (n,768) (n,768) (n,768)
InputDimension(TimeGraph) (n,256) (n,256) (n,64) (n,64)
InputDimension(RhetoricGraph) (n,768) (n,768) (n,768) (n,768)
HiddenDimension(GR-GCN) 256 256 64 64
Numberofhiddenlayers(GR-GCN) 1 1 1 1
HiddenDimensionofSpanExt {256,64} {256,64} {128,64} {128,64}
Epochs 20 20 20 20
BatchSize 8 8 16 16
ActivationFunctionofLinearlayers ReLU ReLU ReLU ReLU
DimensionofﬁnalFCN [(1792xr)] [(1792xr)] [(1024xr)] [(1024xr)]
OutputClasses 5 5 4 5
Table 5: Hyperparameters Details: Training hyperparameters of TIMERS for TDDMan, TDDAuto, MATRES
andTB-Densedatasets. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 640>


<Paper ID = 640> <Table 1> <Abstractive Summary> =Circumstance Frameworkforinterpretation
SS: SingleSent, CR: Chain Reasoning, TI: Tense Indi-
Table 6: RST relations used in Rhetoric-aware graph
cator, FE: Future Events, HN: Hypothetical/Negated,
G inTIMERS,withdeﬁnitionasprovidedbyMann
DG
EC: Event Coreference, CP: Causal/Prereq, WK:
(1987)
World Knowledge. </Abstractive Summary> <Extractive Summary> Table 1 reports the data statistics and madeonthebasisoftheendpointsofthetimexes,
label distributions.  </Extractive Summary>  </Table 1>  </Paper ID = 640>


<Paper ID = 641> <Table 0> <Abstractive Summary> =DropoutRate 0.1
BatchSize 16,32,64
11WedownloadtheATBpart1,2and3arefromhttps:
//catalog.ldc.upenn.edu/LDC2010T13, https: Table 5: The hyper-parameters tested in tuning our
//catalog.ldc.upenn.edu/LDC2011T09 and models. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 641>


<Paper ID = 641> <Table 1> <Abstractive Summary> =Allmodelsare Table 8: Numbers of trainable parameters (Para.) </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 641>


<Paper ID = 642> <Table 0> <Abstractive Summary> =Table 2: Performance of different segmentation algo-
rithmsontheMorphEvalEn-Fibenchmark. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 642>


<Paper ID = 645> <Table 0> <Abstractive Summary> =(1)) 1
Table 10: Hyperparameters along with their search
grid. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 645>


<Paper ID = 646> <Table 0> <Abstractive Summary> =Forinstance,recentworksug-
𝑘 =9 1.18E-41 0.131 0.545 geststhatwordtypes(e.g.,verbs,nouns,punctua-
𝑘 =20 4.06E-47 0.262 0.603 tions),entities(e.g.,personhood,nationalities,and
dates),andevenwordsenses(Michaeletal.,2020;
Table 1: CWRs isotropy after clustering and making
Loureiroetal.,2021;Reifetal.,2019)createlocal
eachclusterzero-meanseparately(resultsfordifferent
distinctclusteredareasinthecontextualembedding
numberofclusters(𝑘)onSTS-Bdevset). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 646>


<Paper ID = 646> <Table 1> <Abstractive Summary> =similarmeaningsbutdifferentfrequenciescouldbe
582Model STS2012 STS2013 STS2014 STS2015 STS2016 SICK-R STS-B
Baseline
GPT-2 1.4E-178 1.0E-170 1.4E-172 2.9E-177 6.0E-174 9.9E-140 2.6E-105
BERT 3.1E-05 1.9E-04 2.6E-04 3.7E-07 2.8E-04 4.2E-05 1.1E-04
RoBERTa 3.1E-06 3.1E-07 3.8E-06 3.8E-06 3.5E-06 3.7E-07 2.9E-06
Globalapproach
GPT-2 0.57 0.40 0.05 0.12 0.60 0.57 0.51
BERT 0.48 0.41 0.55 0.72 0.65 0.63 0.58
RoBERTa 0.67 0.87 0.87 0.84 0.85 0.90 0.88
Cluster-basedapproach
GPT-2 0.71 0.74 0.47 0.74 0.74 0.78 0.70
BERT 0.68 0.61 0.77 0.81 0.75 0.82 0.73
RoBERTa 0.89 0.91 0.93 0.92 0.89 0.94 0.90
Table 6: Isotropy of CWRs on multiple STS datasets calculated based on I(W); a higher value indicates a more
isotropicembeddingspace. </Abstractive Summary> <Extractive Summary> (2016)showedthat𝐹(𝑢)canbeapproximated Table 1 shows the results for different number of
using a constant for isotropic embedding spaces.  </Extractive Summary>  </Table 1>  </Paper ID = 646>


<Paper ID = 649> <Table 0> <Abstractive Summary> =seed generatedevents
ﬁrespreadtoneighborhood,peoplereportedﬁre peopleﬁretoﬂoor,personspokesmanfordepartment
HAQAE-baseline
ﬁrespreadtoforest,peoplereportedﬁre ﬁreﬁghtersﬁretoﬂoor,personspokesmanfordepartment
ﬁrespreadtoneighborhood,peoplereportedﬁre Firespreadthroughﬂoors,ﬁrecamefromﬂoor
HAQAE-permuted
ﬁrespreadtoforest,peoplereportedﬁre ﬁresbegantoday,peopleworkinginarea
Table 4: Generated schemas for two-event seeds. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 649>


<Paper ID = 650> <Table 0> <Abstractive Summary> =Trainedwithhardnegatives
128dim 90.32 77.92 54.45 27.34
4.2 Model 256dim 91.10 78.90 55.51 28.16
768dim 91.48 79.42 56.05 28.55
Forsparse,lexicalretrieval,weuseElasticSearch,
Table 1: Dev performance (MRR@10 ×100) on MS
which is based on BM25. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 650>


<Paper ID = 650> <Table 1> <Abstractive Summary> =rndtitle 0.17% 0.28% 0.34% 0.51%
alltitles 2.48% 5.59% 9.31% 12.08%
devtitles 4.18% 5.36% 6.66% 8.01%
observe that dense approaches drastically reduce
Table 3: Percentage of queries for which a random
the error rate compared to BM25 retrieval. </Abstractive Summary> <Extractive Summary> 2020)asabi-encoder: Thequeryandthepassage
arepassedindependentlytothetransformermodel
Table 1 shows the MRR@10 performance for
and the output is averaged to create ﬁxed-sized
the different systems.  </Extractive Summary>  </Table 1>  </Paper ID = 650>


<Paper ID = 651> <Table 0> <Abstractive Summary> =learn better as well, since they provide a “short-
4https://universaldependencies.org cut”betweendocumentsthatishighlylikelytobe
615XLM-R 1 2 3 4 5 6 7 fullmodel
word-doc (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88)
POStags (cid:88) (cid:88) (cid:88) (cid:88)
translationedges (cid:88) (cid:88) (cid:88) (cid:88) (cid:88)
similarityedges (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88)
unlabeled (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88)
EN→DE 90.01 87.60 90.60 90.75 90.77 90.67 89.90 91.26 90.97
EN→FR 89.52 90.62 89.95 90.65 90.70 90.37 89.82 90.85 90.92
EN→JA 86.61 86.26 87.19 87.31 87.35 87.44 87.18 86.57 87.54
Table 4: Ablation study results. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 651>


<Paper ID = 651> <Table 1> <Abstractive Summary> =html
6https://microsoft.github.io/XGLUE/
7https://fb.me/multilingual_task_
oriented_data
619dataset #category language #train #valid #test #unlabeled avg.length
English 2,000 / 2,000 50,000 168.31
German 2,000 / 2,000 165,457 151.27
AmazonReview(Books) 2
French 2,000 / 2,000 32,868 123.84
Japanese 2,000 / 2,000 169,756 155.05
English 2,000 / 2,000 30,000 167.31
German 2,000 / 2,000 91,506 158.58
AmazonReview(Dvd) 2
French 2,000 / 2,000 9,356 138.89
Japanese 2,000 / 2,000 68,324 150.87
English 2,000 / 2,000 25,220 146.18
German 2,000 / 2,000 60,382 143.50
AmazonReview(Music) 2
French 2,000 / 2,000 15,940 142.21
Japanese 2,000 / 2,000 55,887 131.62
English 100,000 10,000 10,000 / 553.65
German / 10,000 10,000 / 484.69
XGLUENC 10 French / 10,000 10,000 / 567.86
Spanish / 10,000 10,000 / 533.09
Russian / 10,000 10,000 / 426.80
English 30,521 4,181 8,621 / 8.05
MultilingualSLU 12 Spanish 3,617 1,983 3,043 / 8.74
Thai 2,156 1,235 1,692 / 5.12
Table 5: Summary statistics of the datasets. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 651>


<Paper ID = 652> <Table 0> <Abstractive Summary> =622Results(F1-score) avg avg
L pop
Model eng ara ben ﬁn ind swa rus tel (withouteng)
Baseline:SQuADzero-shot
(reproduction) 74.2 59.0 57.3 55.7 63.2 60.3 65.6 44.6 58.0±6.3 59.3
MonolingualFew-Shot(+50) 73.9 64.9 66.4 70.9 73.3 70.1 66.3 62.5 67.8±3.5 67.1
MultilingualFew-Shot
(+10/lang,90total) 73.7 64.6 62.9 66.5 67.0 63.1 65.9 59.6 64.2±2.4 64.4
(+50/lang,450total) 73.4 69.2 65.8 69.0 73.4 68.8 67.2 66.2 68.5±2.4 68.6
(+100/lang,900total) 74.2 72.5 70.9 71.9 75.5 72.3 69.3 69.3 71.7±2.0 71.9
(+500/lang,4500total) 76.1 76.3 74.5 78.2 81.4 79.2 73.3 73.7 76.7±2.8 76.2
DataAugmentation+MultilingualFew-Shot
+tSQuAD 74.9 65.4 58.4 66.7 65.2 69.4 60.2 44.7 61.4±7.7 61.2
+mSQuAD 75.1 65.6 68.6 71.7 70.3 66.2 75.5 49.4 66.7±7.7 67.6
+mSQuAD+500/lang 77.6 78.7 75.0 78.5 83.5 82.5 73.2 75.3 78.1±3.6 77.6
+tSQuAD+500/lang 77.9 78.8 80.0 79.5 82.8 83.6 72.5 73.5 78.7±3.9 78.6
Skyline:FulltrainingonTyDiQAtrain
(reproduction) 77.5 82.4 78.9 80.1 85.4 83.8 76.5 78.3 80.8±3.0 80.9
Table 1: Data augmentation combined with multilingual few-shot learning can reach about 98% of the skyline
accuracyusingonly10timeslesstrainingdataonthetestlanguagesbeyondEnglish. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 652>


<Paper ID = 652> <Table 1> <Abstractive Summary> =623Results(F1-score) Overall ∆ avg
l
eng ara ben ﬁn ind swa rus tel (w/oeng) (max-min) seenunseen
Baseline:nobudgetforadditionaldata(zero-shotexceptforeng)
74.2 59.0 57.3 55.7 63.2 60.3 65.6 44.6 58.0±6.3 29.6 74.2 58.0
Monolingualbudgetallocation(max4500perlanguage;7experiments)
76.0±1.8 74.0±3.9 69.1±5.0 75.8±2.7 78.4±4.1 71.7±4.1 75.7±6.3 61.3±12.3 72.3±5.3 17.1 77.1 71.3
Tri-lingualbudgetallocation(1500perlanguage;7randomlanguageselectionexperiments)
76.7±1.2 77.2±2.8 68.6±4.8 77.9±1.6 80.9±3.3 81.5±3.3 72.7±2.3 62.9±13.3 74.5±6.3 18.6 78.9 68.5
Uniformbudgetallocation(500perlanguage)
77.9 78.8 80.0 79.5 82.8 83.6 72.5 73.5 78.7±3.9 11.1 78.6 –
IdealFew-Shot(4500ineachlanguage;in-languageresults)
78.4 81.8 77.7 79.7 83.9 84.0 75.7 78.2 79.9±3.0 8.3 79.9 -
Table 2: A more egalitarian budget allocation leads to better and more equitable performance across languages
(avg±std:higheraverage,lowerstd.deviation)reducingthegap(∆l)betweenbestandworstperforminglanguages. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 652>


<Paper ID = 655> <Table 0> <Abstractive Summary> =648Model Mean-F1 C@75 C@90 Model SQuAD NQ NewsQA
Bart-Base 28.44(±1.58) 5.76(±2.10) 0.74(±0.00) Bart-Base 74.79(±0.91) 49.78(±0.95) 56.37(±0.90)
+HYPTER 28.96(±1.15) 6.32(±2.02)* 1.08(±0.62) +HYPTER 75.53(±0.68)* 50.39(±1.01)* 56.41(±0.85)
Bart-Large(reported) 40 13 8 Bart-Large 79.32(±0.34) 59.21(±0.89) 55.41(±0.54)
Bart-Large 41.17(±1.16) 15.74(±2.16) 7.17(±1.66) +HYPTER 79.73(±0.50) 59.58(±0.57) 55.60(±0.90)
+HYPTER 41.65(±1.34) 16.41(±2.15)* 7.62(±1.66)*
Table 3: Performance on Synthetic SQuAD dataset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 655>


<Paper ID = 655> <Table 1> <Abstractive Summary> =@2390 C@751124 11.4711.4713.3614.16 C@75112410.3910.3910.3210.32
+HYPTER 32.32 6.72 2.53 10 10
8 7.48 7.48 8
Bart-Large(reported) 37.93 11.19 3.96 6 6
Bart-Large 40.13 10.91 3.98 25% 50% 75% 100% 25% 50% 75% 100%
+HYPTER 40.41 11.35 4.43 (a)#Tasks (b)#ExamplesperTask
Figure3: Competence@75PerformanceonZESTDev
Table 2: Performance on ZEST Test Set. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 655>


<Paper ID = 655> <Table 2> <Abstractive Summary> =Model Mean-F1 C@75 C@90
1 "train": ["why were", "what years", "who said", "
what percent", "when did", "where do", "who is" Bart-Large 41.17(±1.16) 15.74(±2.16) 7.17(±1.66)
Bart-LargewithAdapters 39.76(±1.26) 15.61(±1.14) 6.96(±1.15)
, "how are", "what decade", "how does", "how
long", "where was", "what has", "which two", "
who was", "who were", "where are", "where does" Table 4: Performance comparison when adapters are
, "what did", "how far", "what organization", "
plugged/notpluggedduringﬁne-tuning. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 655>


<Paper ID = 655> <Table 3> <Abstractive Summary> =other", "what happens", "was the", "what was",
"which of", "when were", "what sort", "what
city", "what year"],
2 "dev": ["what month", "why is", "what part", "what Model Mean-F1 C@75 C@90
term", "how was", "how were", "how do", "who Bart-Base 29.72 7.87 4.05
led", "which country", "when does"], +HYPTER 29.81 8.67 4.05
3 "test": ["where were", "what political", "what
Bart-Large(reported) 40 13 8
religion", "why did", "what type", "what
Bart-Large 42.10 16.72 8.85
language", "who had", "what percentage", "what
can", "how much"] +HYPTER 43.50 17.46 9.64
Table 5: Dev set performance of models submitted to
B TrainingDetails
ZESTleaderboard. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 655>


<Paper ID = 659> <Table 0> <Abstractive Summary> =Seetable2forthe
2
number of claims and langauges in each of these
Table 2: Dataset details. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 659>


<Paper ID = 659> <Table 1> <Abstractive Summary> =Claim-Only+Meta 37.1(2.7) 14.5(0.5) 14.4(0.3)
Attn-EA+Meta 38.0(4.5) 14.7(2.6) 14.3(1.9) Isabelle Augenstein, Christina Lioma, Dongsheng
Wang, Lucas Chaves Lima, Casper Hansen, Ch-
Table 4: Performance comparison when augmenting ristian Hansen, and Jakob Grue Simonsen. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 659>


<Paper ID = 659> <Table 2> <Abstractive Summary> =681ISO
Language 639-1 FactChecker LanguageFamily Train Dev α α α
1 2 3
code
Arabic ar misbar.com Afro-Asiatic
Bengali bn dailyo.in IE:Indo-Aryan
Spanish es chequeado.com IE:Romance
Persian fa factnameh.com IE:Iranian
Indonesian id cekfakta.com Austronesian
Indonesian id cekfakta.tempo.co Austronesian
Italian it pagellapolitica.it IE:Romance
Italian it agi.it IE:Romance
Hindi hi aajtak.in IE:Indo-Aryan
Hindi hi hindi.newschecker.in IE:Indo-Aryan
Gujarati gu gujarati.newschecker.in IE:Indo-Aryan
Georgian ka factcheck.ge Kartvelian
Marathi mr marathi.newschecker.in IE:Indo-Aryan
Punjabi pa punjabi.newschecker.in.txt IE:Indo-Aryan
Polish pl demagog.org.pl IE:Slavic
Portuguese pt piaui.folha.uol.com.br IE:Romance
Portuguese pt poligrafo.sapo.pt IE:Romance
Romanian ro factual.ro IE:Romance
Norwegian no faktisk.no IE:Germanic
Sinhala si srilanka.factcrescendo.com IE
Serbian sr istinomer.rs IE:Slavic
Tamil ta youturn.in Dravidian
Albanian sq kallxo.com IE:Albanian
Albanian sq faktoje.al IE:Albanian
Russian ru factcheck.kz IE:Slavic
Turkish tr dogrulukpayi.com Turkic
Turkish tr teyit.org Turkic
Azerbaijani az faktyoxla.info Turkic
Portuguese pt aosfatos.org IE:Romance
German de correctiv.org IE:Germanic
Dutch nl nieuwscheckers.nl IE:Germanic
French fr fr.africacheck.org IE:Romance
Table 6: Details of the X-FACT dataset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 659>


<Paper ID = 66> <Table 0> <Abstractive Summary> =ForPAR,weobtainanaverageF1of0.52
2https://www.upwork.com acrossallpossiblepairs,andastandarddeviationof
790PAR WSD PAR WSD
100
Context Correct Notconﬁdent Correct Notconﬁdent very
0+0 78.4 27.0 88.7 7.0 rs 80 somewhat
e not at all
1+0 90.6 13.2 88.7 6.5 w
s 60
0+1 93.0 9.2 87.5 6.7 n
a
1+1 93.6 6.7 87.1 6.5 of  40
5+5 95.9 2.8 88.7 5.9 % 
20
Noante 75.4 33.8 – –
Hasante 96.0 3.3 – – 0
0+01+00+11+15+5 0+01+00+11+15+5
Table 2: Percentage of correct and zero-conﬁdence Context level
answers by varying context level. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 66>


<Paper ID = 66> <Table 1> <Abstractive Summary> =Thisresultcorroboratesprior
AP Encself 32.3 37.4 0.48 0.44 91.5 66.5 52.5
AP Deccross 32.3 37.4 0.47 0.43 92.1 63.0 55.0 results where models have better alignment with
AP Decself 32.3 36.9 0.48 0.44 90.6 62.5 52.5 supportingcontextonattentionthatattendstothe
Table 7: Performance of models with various regular- source (encoder self-attention and decoder cross-
ized attention. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 66>


<Paper ID = 66> <Table 2> <Abstractive Summary> =(2017);
Table 8: Contrastive performance with various masks Bawden et al. </Abstractive Summary> <Extractive Summary> 3.3 AnswerAccuracyandConﬁdence
Table 2 shows the accuracy of answers and the
mine its gender, so we hypothesize that the an-
percentageofanswersbeingreportedasnotatall
tecedentisofhighimportancefordisambiguation.  </Extractive Summary>  </Table 2>  </Paper ID = 66>


<Paper ID = 660> <Table 0> <Abstractive Summary> =(Metric) (F1/EM) (EM) (F1) (ROUGE-L)
mT5 66.3/49.8 43.7 58.4 25.2 46.3
+MLM(additional100Ksteps) 71.3/55.6 48.6 59.9 26.1 49.5
+MLM+TLM 71.1/54.6 48.6 61.4 26.1 49.7
+MLM+NMT 75.1/60.1 57.7 61.4 27.4 53.5
+MLM+denoisedNMT 75.3/60.2 56.5 61.5 27.4 53.3
+MLM+denoisedNMT-LM 75.0/59.4 56.0 62.4 26.9 53.1
Table 2: Results are averaged across all the languages in each dataset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 660>


<Paper ID = 660> <Table 1> <Abstractive Summary> =∆ 12.2/12.7 0.6/1.5 1.0/1.2
Model ckb hsb xmf “Avg.”
Table 4: Performance on the TyDi QA eval set when
ﬁne-tuned in the few-shot (100 examples from TyDi mT5-Large 66.5 64.8 58.4 54.9
QAEnglish),low(fullTyDiQAEnglishwith3.7Kex- nmT5-Large 72.2 69.8 62.2 57.4
amples) and high data regime (SQuAD English with ∆ 5.7 5.0 3.8 2.5
80Kexamples). </Abstractive Summary> <Extractive Summary> ThemC4corpusconsistsofun- Table 1 lists further details of each dataset.  </Extractive Summary>  </Table 1>  </Paper ID = 660>


<Paper ID = 661> <Table 0> <Abstractive Summary> =693QuestionGeneration Weframequestiongener- Model(Spanish) AUC(seen) AUC(unseen)
LM-KT 0.75±.0001 0.76±.001
ationasﬁnetuninganewautoregressiveLM.Given
StandardDKT 0.72±.0001 0.70±.001
randomsamplesofstudentsandquestionsfroma QuestionOnly 0.67±.0001 0.58±.002
held-outsetnotusedtotrainLM-KT,wecancon- Model(French) AUC(seen) AUC(unseen)
struct a new dataset D(cid:48) consisting of s d <G> q LM-KT 0.73±.0002 0.71±.002
i i i StandardDKT 0.70±.0001 0.65±.002
sequences,where<G>isaspecialgenerationtoken QuestionOnly 0.65±.0002 0.62±.001
andd = p (<Y>|s ,q )isthecontinuousdifﬁ-
i θKT i i Table 1: LM-KT improves AUC for both questions in
cultyvalueassignedbyLM-KT.Welearnalinear
the Duolingo test set that were seen during training
layertomapthecontinuousinputdifﬁcultyintoa
(forotherstudents)andnovelquestions,overStandard
difﬁcultycontrolvectorc ofdimensionmatching
d DKT with Question IDs and question-only baselines. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 661>


<Paper ID = 661> <Table 1> <Abstractive Summary> =Figure 3 shows that we are able to achieve Table 2: Perplexity of the question generation model
ﬁne-grainedcontrolovertargetdifﬁcultyforboth overaheld-outevaluationsetwithablations. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 661>


<Paper ID = 662> <Table 0> <Abstractive Summary> =Table 2: F Scores. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 662>


<Paper ID = 662> <Table 1> <Abstractive Summary> =Forinstance,thefollowingsource–targetpair
704LR WER Sub Del Ins 4
L-1 est
LANG-8 98% 15.46 8.85 2.41 4.19 NL At
CLANG-8 98% 10.11 5.85 1.35 2.92 Model #params TrainingData Co BE
CLANG-8-S 99% 01.22 0.64 0.00 0.58
SOTA 66.8 73.6
Table 3: Dataset statistics of English LANG-8 and gT5xxl 65.65 69.83
CLANG-8, including sequence Length Ratio between FELIX 220M LANG-8 41.63 30.54
the source and the target, Word Error Rate, which is FELIX 220M LANG-8+BEA 48.75 48.80
comprisedofSubstitutions,Deletions,andInsertions. </Abstractive Summary> <Extractive Summary> sizeisinferiortothecurrentstate-of-the-artmod-
Table 1 reports statistics of datasets available for els.  </Extractive Summary>  </Table 1>  </Paper ID = 662>


<Paper ID = 662> <Table 2> <Abstractive Summary> =Disregarding50%wasthebestperforming SPELL 74.38 84.64 85.83 88.29
setupandtherewasnotasigniﬁcantdifferencebe-
Table 5: BEA test scores for the top ﬁve error types. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 662>


<Paper ID = 665> <Table 0> <Abstractive Summary> =largestmomentretrievaldataset,andalsohasthe (16.6) 乔伊催餐时摆了摆手。
advantageofhavingdialogues(intheformofsub-
titletext)asadditionalcontextforretrieval,incon- Table 1: MTVR English and Chinese query examples
trasttopurevideocontextintheotherdatasets. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 665>


<Paper ID = 665> <Table 1> <Abstractive Summary> =Query Encoder
English Query (ZH)
Q 13.45 15,201 3,015 7,143 2,290 763
Sub 10.78 49,325 6,441 19,223 7,504 1,740 Sub (EN)
Q+Sub 11.27 52,545 7,151 20,689 8,021 1,976
Subtitle Encoder
Chinese
Sub (ZH)
Q 12.55 34,752 12,773 18,706 1,415 1,669
Sub 9.04 101,018 36,810 53736 4,958 5,568
Q+Sub 9.67 117,448 42,284 62,611 5,505 6,185 Video Video Encoder
Table 2: Comparison of English and Chinese data neighborhood constraint
inMTVR.Weshowaveragesentencelength,andnum-
berofuniquetokensbyPOStags,forQuery(Q)andor Figure 2: Illustration of mXML’s encoding process. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 665>


<Paper ID = 665> <Table 2> <Abstractive Summary> =Givenpairedsentence XML 6.4M 7.25 3.25 5.91 2.57
embeddings eien ∈ Rd and eizh ∈ Rd, we sample mXML 4.5M 8.30 3.82 6.76 3.20
negativesentenceembeddingsej ∈ Rdandek ∈
Rd fromthesamemini-batch,wenherei (cid:54)= j,iz(cid:54)=h k. Table 3: Baseline comparison on MTVR test-public
split. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 665>


<Paper ID = 665> <Table 3> <Abstractive Summary> =4.5M 6.09 2.85 4.72 2.25 video(74.32%) 4.12 1.89 3.73 1.86
+NC(mXML) 4.5M 6.22 2.96 5.17 2.41 sub(8.85%) 1.97 1.24 1.35 1.04
video+sub(16.83%) 2.67 1.2 2.45 1.15
Table 4: mXML ablation study on MTVR val split. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 665>


<Paper ID = 665> <Table 4> <Abstractive Summary> =video+sub 6.22 2.62 4.2 2.13
Modelinput:video+subtitle
ModelType EnglishR@1 ChineseR@1
video 5.77 2.67 5.14 2.32
IoU=0.5 IoU=0.7 IoU=0.5 IoU=0.7 sub 6.12 3.32 4.05 1.87
video+sub 8.29 4.09 5.89 3.11
Querytype:video
Baseline 5.46 2.53 4.78 2.47
Table 6: mXML performance breakdown on
mXML 5.77 2.67 5.14 2.32
MTVRvalsetbyquerytypes,withdifferentinputs. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 4>  </Paper ID = 665>


<Paper ID = 665> <Table 5> <Abstractive Summary> =baseline 8.02 3.38 5.18 2.62
Thevideomodelperformsmuchbetteronthevideo
mXML 8.29 4.09 5.89 3.11
queriesthanonthesubqueries,whilethesubtitle
Table 5: Comparison of mXML and the baseline on model achieves higher scores on the sub queries
MTVR val set, with breakdown on query types. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 5>  </Paper ID = 665>


<Paper ID = 665> <Table 6> <Abstractive Summary> =Visual question answering dataset for bilin-
Table 7: mXML performance on the MTVR val split
gualimageunderstanding: Astudyofcross-lingual
Friendsexamples,inbothunseenandseensettings. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 6>  </Paper ID = 665>


<Paper ID = 667> <Table 0> <Abstractive Summary> =Themethodsincludereplac-
ing constraints (Crego et al., 2016), constrained Table 1: Top 10 most frequent terms in Dinu et al. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 667>


<Paper ID = 667> <Table 1> <Abstractive Summary> =(De→En) (441K/3K/3K) 1,677,852 2.33
TRG 30.77 27,755
3 Approach (MDee→dicEanl) SRC (48489K4/,33K1/63K) 19.01 1,494,269 1.34 8,633
TRG 20.25 8,990
3.1 Source-ConditionedMaskedSpan Law SRC 93,240 16.52 2,354
Prediction (Ko→En) TRG (87K/3K/3K) 34.56 353,894 3.52 2,733
Wepositthatadoptingauxiliaryspan-levelsupervi- Table 2: Statistics of the ﬁltered corpus and matched
sioningenerationcanbeneﬁtbothshortandlong terms. </Abstractive Summary> <Extractive Summary> Byanalyzingthepre-
1 Introduction vioussetupscarefully,wediscoverthattheterms
found in WMT are mostly uni- or bi-grams (see
Despiteitsrecentsuccessinneuralmachinetransla-
Figure 1) and highly colloquial (see Table 1 for
tion(NMT)(Wuetal.,2016;Johnsonetal.,2017;
the top 10 most frequent terms).  </Extractive Summary>  </Table 1>  </Paper ID = 667>


<Paper ID = 667> <Table 2> <Abstractive Summary> =Law(De→En) Law(Ko→En)
Model Term%(↑) LSM-3(↑) Term%(↑) LSM-3(↑)
BLEU BLEU
1-gram 2-gram 2>micro 2>macro 2>micro 2>macro 1-gram 2-gram 2>mirco 2>marco 2>micro 2>macro
SUSANTO20 62.20 94.38 92.95 82.06 64.06 94.93 92.14 50.56 81.67 76.74 58.47 38.66 69.63 62.60
CHEN20 73.05 96.64 93.29 78.73 51.47 90.00 80.29 52.60 84.74 83.94 67.33 59.53 75.59 74.54
+SSP 74.72 97.15 95.95 84.67 57.48 93.94 83.62 53.38 95.86 94.92 88.58 79.34 94.17 91.48
Table 4: (With dictionary) Results on legal domain corpora when the GT terms are provided at test time. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 667>


<Paper ID = 667> <Table 3> <Abstractive Summary> =+SSP 75.50 95.86 94.92 88.58 79.34 94.17 91.48
Table 5: Results on the medical domain dataset 5 Conclusion
(De→En). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 667>


<Paper ID = 667> <Table 4> <Abstractive Summary> =Law(De→En)
Model Term%(↑) LSM-3(↑)
BLEU
1-gram 2-gram 2>micro 2>macro 2>micro 2>macro
Withoutdictionary
GU19 68.14 93.71 91.87 72.32 46.24 85.05 74.22
VASWANI17 72.86 95.30 93.36 78.68 54.99 88.40 78.69
+SSP 73.15 95.57 93.54 79.98 59.18 89.64 81.53
CHEN20 71.89 95.04 93.54 78.83 54.55 88.43 79.63
+SSP 72.93 95.46 94.14 79.74 56.63 89.19 80.88
Withdictionary
SUSANTO20 59.23 94.10 92.89 82.86 68.22 95.28 93.36
CHEN20 70.90 96.36 94.01 77.26 51.97 89.12 80.06
+SSP 72.70 96.85 95.68 83.65 58.33 93.30 83.40
Table 7: Results on the law domain dataset with no
duplicationindata(De→En). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 4>  </Paper ID = 667>


<Paper ID = 669> <Table 0> <Abstractive Summary> =I.e.,twoliststhatshare
LDA 0.0173 0.1627 0.9897 some of the same words, albeit at different rank-
ings,arepenalizedlessthantwoliststhatsharethe
Table 2: Averaged results over 5 numbers of topics. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 669>


<Paper ID = 669> <Table 1> <Abstractive Summary> =Thepriorsoverthetopicanddocument
Table 3: Comparison of τ between CombinedTM
distributions are learnable parameters. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 669>


<Paper ID = 669> <Table 2> <Abstractive Summary> =Table 4: τ performance of CombinedTM using differ-
entcontextualizedencoders. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 669>


<Paper ID = 67> <Table 0> <Abstractive Summary> =LRL→En Un-adaptedModel AdaptedModels
LRL HRL HRL→En Adv BT BT+Adv
Portuguese Spanish 12.3 21.7 32.7 36.0
Catalan Spanish 12.2 13.9 25.3 24.6
Marathi Hindi 3.9 7.0 8.1 12.7
Nepali Hindi 14.8 16.9 14.1 18.2
Urdu Hindi 0.3 1.0 10.5 10.5
EgyptianArabic MSA 14.9 14.0 15.2 15.8
LevantineArabic MSA 9.3 6.7 9.3 9.0
Table 3: BLEU score of the ﬁrst iteration on the LRL to English direction. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 67>


<Paper ID = 67> <Table 1> <Abstractive Summary> =Table 5: Comparison with previous work on FLoRes
dataset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 67>


<Paper ID = 670> <Table 0> <Abstractive Summary> =For tokenisation we use
Chinese 3,832 1,514,181 39,705 950,310 the Moses tokenizer (Koehn et al., 2007) for En-
glish,whileweusethedefaultmodeoftheJieba
Table 2: Vocabulary sizes and number of tokens. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 670>


<Paper ID = 670> <Table 1> <Abstractive Summary> =DataSplits Wedistinguishbetweengold(manu- Table 3: F-scores for DRS parsing with different in-
allycorrectedmeaningrepresentations)andsilver putrepresentations,averagedover5trainingruns. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 670>


<Paper ID = 672> <Table 0> <Abstractive Summary> =dataless-classifier
787Topic(Yahoo) Emotion Situation AG’sNews SST-2 Snips
Majority 10.0 5.9 11.0 25.0 50.9 17.7
ESA 28.6 8.0 26.0 73.3 55.5 63.4
Word2Vec 35.7 6.9 15.6 44.1 53.7 63.6
RTE(Yinetal.,2019) 43.8 12.6 37.2 56.7 52.5 56.4
FEVER(Yinetal.,2019) 40.1 24.7 21.0 78.3 71.7 69.4
MNLI(Yinetal.,2019) 37.9 22.3 15.4 72.4 67.5 77.6
MNLI(ourbestoverallrun) 49.1 19.9 14.5 77.7 67.5 77.6
NSP(Reverse) 53.1 16.1 19.9 78.3 79.7 81.3
NSP 50.6 16.5 25.8 72.1 73.9 73.4
Table 1: Text classiﬁcation results. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 672>


<Paper ID = 672> <Table 1> <Abstractive Summary> =Ineachcell:
the change of accuracy after input shufﬂing, followed
Table 2: Results of ﬁve runs of BERT ﬁne-tuned on
bythepercentageofexampleswherethepredictionsdo
MNLIandtestedonclassiﬁcationdatasets
notchange.Alltheseresultsarereportedastheaverage
scoreofﬁvedifferentrandomshufﬂes. </Abstractive Summary> <Extractive Summary> 10
A.2 QualitativeAnalysis
0
Table 1 shows that NSP(reverse) achieves better searchevacinfrautilswatersheltermedfoodcrimeterr.regi.none
performance than NSP on several datasets.  </Extractive Summary>  </Table 1>  </Paper ID = 672>


<Paper ID = 672> <Table 2> <Abstractive Summary> =Table 3: Results of ﬁve runs for training BERT on
MNLIwithmodelselectionviatargetdomaindevset TheresultsareshowninTable5. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 672>


<Paper ID = 673> <Table 0> <Abstractive Summary> =causes(X,Y):-causes(X,Z),causes(Z,Y)
isa(X,Y):-partof(X,Z),isa(Z,Y)
5 Conclusion
relatedto(X,Y):-relatedto(X,Z),relatedto(Z,Y)
In this work, we propose a neural-symbolic rea-
Table 3: Examples of rules learned by our proposed
relationpredictionmodule. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 673>


<Paper ID = 676> <Table 0> <Abstractive Summary> =818Adapter Finetune #params(M)
Dict D d ENC DEC ENC DEC trainable/total de es fr it nl pt ro ru avg
Trainingdata(hours) 408 504 492 465 442 385 432 489
1 mono - - - - - 8 31.1/8 31.1 22.16 30.42 27.92 22.92 24.10 27.19 21.51 14.36 23.82
× ×
2 multi - - - - - 32.1/32.1 22.37 30.40 27.49 22.79 24.42 27.32 20.78 14.54 23.76
3 multi 64 - (cid:88) - - 8 0.2/33.7 22.32 30.50 27.55 22.91 24.51 27.36 21.09 14.74 23.87
4 multi 256 64 (cid:88) (cid:88) - - 8××0.6/36.9 22.75 31.07 28.03 23.04 24.75 28.06 21.20 14.75 24.21
5 multi 128 - (cid:88) - - 8 0.4/35.3 22.45 30.85 27.71 23.06 24.57 27.52 20.93 14.57 23.96
6 multi 128 (cid:88) (cid:88) - - 8×1.2/41.7 22.84∗ 31.25∗ 28.29∗ 23.27∗ 24.98∗ 28.16∗ 21.36∗ 14.71 24.36
×
7 multi - - - - (cid:88) 8 14.6/8 32.1 23.49 31.29 28.40 23.63 25.51 28.71 21.73 15.22 24.75
8 multi - - - (cid:88) (cid:88) 8×32.1/8×32.1 23.13∗ 31.39∗ 28.67∗ 23.80∗ 25.52∗ 29.03∗ 22.25∗ 15.44∗ 24.90
× ×
9 mono - - - - - 8 74.3/8 74.3 21.93 30.46 27.90 22.64 23.98 25.98 20.50 14.01 23.42
× ×
10 multi - - - - - 76.3/76.3 23.98 32.47 29.24 24.97 26.20 29.81 22.74 15.30 25.59
11 multi 64 - (cid:88) - - 8 0.4/79.5 24.24 32.52 29.47 24.74 26.13 29.72 22.53 15.25 25.57
12 multi 64 (cid:88) (cid:88) - - 8×1.2/85.9 24.13 32.80 29.55 24.90 26.04 30.25 22.73 15.31 25.72
13 multi 12 128 - (cid:88) - - 8×0.8/82.7 24.34 32.86 29.51 24.73 26.15 30.01 22.58 15.07 25.66
14 multi 5 128 (cid:88) (cid:88) - - 8×2.4/95.5 24.30 32.61 29.72∗ 25.07 26.29 30.46∗ 22.99 15.47 25.86
×
15 multi 256 - (cid:88) - - 8 1.6/89.1 24.38 32.78 29.69 24.72 26.25 29.93 22.63 15.40 25.72
16 multi 256 (cid:88) (cid:88) - - 8×4.8/114.7 24.61 32.94 29.67 25.12 26.16 30.53 22.66 15.31 25.88
×
17 multi - - - - (cid:88) 8 35.5/8 36.3 24.67 33.12 30.11 25.05 26.33 29.85 23.04 15.61 25.97
18 multi - - - (cid:88) (cid:88) 8×76.3/8×76.3 24.54∗ 32.95∗ 29.96∗ 25.01 26.31 30.04 22.66 15.54∗ 25.88
× ×
Table 1: BLEU on MuST-C dev set for reﬁnement. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 676>


<Paper ID = 676> <Table 1> <Abstractive Summary> =Table 5: BLEU on dev set for parallel vs. serial
AsaCooperSticklandandIainMurray.2019. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 676>


<Paper ID = 677> <Table 0> <Abstractive Summary> =825
Proceedingsofthe59thAnnualMeetingoftheAssociationforComputationalLinguistics
andthe11thInternationalJointConferenceonNaturalLanguageProcessing(ShortPapers),pages825–830
August1–6,2021.©2021AssociationforComputationalLinguisticsTable 1: Experimental results from Mullenbach et al. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 677>


<Paper ID = 677> <Table 1> <Abstractive Summary> =826Table 2: MIMIC-III-50 results from past works that have directly listed values in Mullenbach et al. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 677>


<Paper ID = 677> <Table 2> <Abstractive Summary> =LEAM(Wangetal.,2018) 0.540 0.619 0.612 Y labelembeddingsused
MVC-RLDA(Sadoughietal.,2018) 0.615 0.674 0.641 N labeldescriptionused
MSATT-KG(Xieetal.,2019) 0.638 0.684 0.644 N knowledgegraph
HyperCore(Caoetal.,2020a) 0.609 0.663 0.632 N labelco-occurrenceandhi-
erarchyused
G-Coder with additional information - 0.692 0.653 N knowledgegraph,adversar-
(Tengetal.,2020) iallearning
ResultsofourinvestigationinSection3arelistedbelowforcomparison(valuesaveragedfromTable4)
CNN 0.606 0.659 0.634 Y
parameterselectionapplied
CAML 0.635 0.684 0.651 Y
Table 3: Parameter ranges considered in Mullenbach needed. </Abstractive Summary> <Extractive Summary> • Resultsarenotsensitivetotherandomseeds.5
• A comparison with Table 2 shows that most
3.3 ParameterSelectionforMIMIC-III-50 subsequent developments cannot surpass our
Weapplytheparameter-selectionprocedureinMul- CAMLresults. Because works mentioned in Table 2 may not in-
dicate if they use the same Macro-F1 formula as
Mullenbachetal.  </Extractive Summary>  </Table 2>  </Paper ID = 677>


<Paper ID = 679> <Table 0> <Abstractive Summary> =Step/Model MULTI-LAST CL-BASELINE SELF-TR EWC CL-KD
1 74.57 74.57 74.57 74.57 74.57
2 81.78 79.47 78.39 79.62 79.90
3 84.89 82.34 82.61 82.46 83.42
4 85.87 84.52 84.24 84.44 85.33
5 86.81 86.09 85.71 85.98 86.75
6 87.89 87.17 86.97 87.41 87.73
Table 2: PAWS-X performances for the observed languages (as in Figure 2b), i.e., at each step we report the
averageofthemeasureforthelanguagesobservedincludingthelaststep(step≤ k). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 679>


<Paper ID = 679> <Table 1> <Abstractive Summary> =845Step/Model MULTI-LAST CL-BASELINE SELF-TR EWC CL-KD
1 - - - - -
2 60.27 65.44 60.43 64.22 60.19
3 57.23 63.20 62.98 62.64 58.79
4 55.19 61.76 62.09 62.33 57.24
5 53.96 59.97 59.54 59.78 55.56
6 52.71 59.27 59.11 59.14 55.05
Table 7: MARC performances for the Past Languages (as in Figure 4a), i.e., at each step we report the average
measure for the languages observed till that step (step < k). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 679>


<Paper ID = 679> <Table 2> <Abstractive Summary> =Step/Model MULTI-LAST CL-BASELINE SELF-TR EWC CL-KD
1 91.99 91.99 91.99 91.99 91.99
2 80.93 80.24 87.83 80.48 82.02
3 74.12 74.44 79.88 74.18 74.52
4 72.41 73.94 78.59 74.24 72.50
5 66.69 70.43 73.32 70.12 68.55
6 - - - - -
Table 10: MARC performances for the Future Languages (zero-shot setting, as in Figure 1a). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 679>


<Paper ID = 68> <Table 0> <Abstractive Summary> =Table 3: F scores (×100) on the BUCC 2020 test
1
set. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 68>


<Paper ID = 68> <Table 1> <Abstractive Summary> =By ensembling the argmax
MUSE 93.4 78.8 85.5
GEN-RTV 96.6 71.9 82.5 anditermaxCRISS-basedSimAlignresults(Sec-
tion 5), we set the new state of the art of word
Table 5: Comparison of Chinese-English lexicons alignmentwithoutusinganybitextsupervision. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 68>


<Paper ID = 68> <Table 2> <Abstractive Summary> =編劇 writers < screenwriter
可笑 laughing < ridiculous
極權 authoritarian < Totalitarian
押韻 couplets < rhyme
烙印 tattooed < brand
業主 homeowners < owner
安娜 grande < Anna
包頭 header < Baotou
編輯 editorial < edit
陣風 winds < gust
火柴 ﬁrewood < matches
盃 bowl < cup
武士道 samurai < Bushido
詩句 poem < verse
肚臍 belly < bellybutton
現代化 modern < modernization
感冒 ﬂu < cold
協商 negotiate > Consult
納米 nanometer > Nano
類人猿 apes > Anthropoid
配件 accessories > Fitting
匯 aggregated > exchange
貸方 lenders > Credit
逆差 deﬁcit > Tradedeﬁcit
如果 if > incase
附件 accessories > annex
實習 internship > practice
加冕 crowned > Crown
助理 assistant > assistantManager
親和性 agreeableness > Afﬁnity
國土 homeland > land
過境 crossings (cid:55) Transit
環流 circulation (cid:55) Circumﬂuence
羊群 sheep (cid:55) Herd
Table 10: all errors cases among 400 random outputs of GEN-RTV compared to both our judgement and Google
translateforreference. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 68>


<Paper ID = 680> <Table 0> <Abstractive Summary> =We compare Hi-Transformer
Table 3: Complexity of different methods. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 680>


<Paper ID = 681> <Table 0> <Abstractive Summary> =56.34 68.59 89.76/86.37 89.24/88.87 64.87 92.78 91.12 90.92/87.88 84.14
Table 1: Performance on the development dataset of GLUE. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 681>


<Paper ID = 682> <Table 0> <Abstractive Summary> =0.2155 0.7107 0.2748 0.5835
Table 1: Data with enough information to generate a
Table2: Mainresultsofourﬁnetuningexperimentson
probabilitydistributionoverthelabels.Themarker“1r”
AmbiNLI.Gold meansthatgold-labels, andnotambi-
denotesthefactthatthereisonlyonedata-pointavail-
guitydistribution,wasusedfortraining. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 682>


<Paper ID = 682> <Table 1> <Abstractive Summary> =Table 3: Model accuracy when performing three-fold
Learning to capture question ambiguity. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 682>


<Paper ID = 682> <Table 2> <Abstractive Summary> =Table 5: Transfer learning comparison on UNLI and Samuel R. Bowman, Gabor Angeli, Christopher Potts,
IMDB movie reviews (std is ×10−4). </Abstractive Summary> <Extractive Summary> Table 2 details the re-
modelandcomparethegold-labelapproachagainst
sultsofourmainexperiment.  </Extractive Summary>  </Table 2>  </Paper ID = 682>


<Paper ID = 683> <Table 0> <Abstractive Summary> =IND OOD
models
ACC F1 Recall F1
CE 86.34 87.73 63.72 65.23
CE+SCL 82.29 83.59 61.96 63.40
multitask 86.69 88.02 65.76 67.25
SCL+CE 87.01 88.28 66.80 67.68
Table 7: Results of combining two training stages in
differentways
waysoftwotrainingstagesonCLINC-Fulldataset
using LSTM and GDA detection method in Ta-
ble7. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 683>


<Paper ID = 684> <Table 0> <Abstractive Summary> =+CL(hybrid) 58.85±0.23%
+SaCLog(w/o.review) 60.19±0.26%
4 Experiments
+SaCLog(w/o.preview) 60.23±0.34%
Twopopulardatasets,WOZ2.0(Wenetal.,2017) +SaCLog 60.61±0.31%
andMultiWOZ2.1(Ericetal.,2020),areusedto Table 2: Ablation results on MultiWOZ2.1. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 684>


<Paper ID = 685> <Table 0> <Abstractive Summary> =(2019)proposedaknowledge-routedrelationaldi- Table 1: Statistics of the English and Chinese dialog
alogsystemthatincorporatesmedicalknowledge datasetsaboutCOVID-19. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 685>


<Paper ID = 685> <Table 1> <Abstractive Summary> =Table 2 shows the statistics of
Table 3: Human evaluation on the CovidDialog-
the data split. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 685>


<Paper ID = 685> <Table 2> <Abstractive Summary> =Our method achieves the lowest (best)
Table 8: Human evaluation on CovidDialog-Chinese perplexity among all methods. </Abstractive Summary> <Extractive Summary> Table 2 shows the statistics of
Table 3: Human evaluation on the CovidDialog-
the data split.  </Extractive Summary>  </Table 2>  </Paper ID = 685>


<Paper ID = 685> <Table 3> <Abstractive Summary> =Table 9: An exemplary consultation in the CovidDialog-English dataset. </Abstractive Summary> <Extractive Summary> Our method and
Additional analysis of results in Table 3 1)
TAPT are both applied to the BERT encoder in
Pretrained models including GPT-2 and BART
BERT-GPT,wheretheprobabilityofmaskingto-
perform better than Transformer.  </Extractive Summary>  </Table 3>  </Paper ID = 685>


<Paper ID = 685> <Table 4> <Abstractive Summary> =Transformer GeForceGTX1080Ti×4 72
GPT-2 GeForceGTX1080Ti×4 252
BART GeForceGTX1080Ti×4 180 C.2.3 AdditionalDetailsaboutHuman
Ours TeslaP100-PCIE-16GB×1 270 Evaluation
TAPT TeslaP100-PCIE-16GB×1 150
InhumanevaluationonCovidDialog-Chinese,we
Table 13: Computing infrastructure and runtime (sec- randomly select 100 examples. </Abstractive Summary> <Extractive Summary> Second, our Table 4 summarizes the automatic evaluation
method performs better than BART+TAPT.  </Extractive Summary>  </Table 4>  </Paper ID = 685>


<Paper ID = 686> <Table 0> <Abstractive Summary> =Avg#ofsubstitutedimagesinadialogue 1.86 1.00 1.00
Avg#oftargetsinadialogue 1.64 1.12 1.12
Contextual-Similarity-basedFiltering Weem-
ployacontextual-similarity-basedﬁlteringstepto Table 2: Multi-modal dialogue dataset statistics for
enhancethecontextcoherenceofthecreatedimage- splitsoftraining,validation,andtestset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 686>


<Paper ID = 686> <Table 1> <Abstractive Summary> =Basedonthisassumption,wedetermine be2.56,2.17,and3.13,respectively,indicatingthat
899Model Task R@1 R@5 MeanRank Modelinputs R@1 R@5 MeanRank
IRBaseline Current 21.62 49.49 30.04 ImageOnly 37.30 80.66 3.91
IRBaseline Next 8.13 21.07 29.41 DialogueContextOnly 28.06 56.83 12.57
RetrievalModel Current 50.35 86.64 3.11 Image+DialogueContext 51.21 86.34 3.08
RetrievalModel Next 14.38 36.10 20.58
Table4:Ablationstudiesofourretrievalmodelsonthe
Table 3: Automatic evaluation results about retrieval
currentdialoguepredictiontask. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 686>


<Paper ID = 687> <Table 0> <Abstractive Summary> =908Immigrants Women
Test IT EN ES Test IT EN ES
IT 0.777 0.635∗∗ 0.666 IT 0.808 0.545 0.463∗∗
EN 0.590∗∗ 0.368 0.633 EN 0.449∗∗ 0.559 0.546∗∗
n ES 0.683∗∗ 0.596∗∗ 0.630 n ES 0.337∗∗ 0.558 0.839
ai ai
Tr EN+ES 0.706* 0.353 0.676* Tr EN+ES 0.440 0.449∗∗ 0.873∗
ES+IT 0.757 0.538∗∗ 0.686* ES+IT 0.820 0.502 0.878∗
EN+IT 0.771 0.340 0.657 EN+IT 0.798 0.469∗∗ 0.603∗∗
Baseline 0.799 - - Baseline 0.844 - -
(a) (b)
Table 2: Macro-F1 results for the two hate speech targets. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 687>


<Paper ID = 687> <Table 1> <Abstractive Summary> =The
IT 294(29%) 9(3%) 291(99%)
results in terms of macro-F1 are: 0.572 for
ES 627(78%) 365(58%) 514(82%)
ES+IT⇒EN; 0.513 for ES+EN⇒IT; 0.632 for
Table 3: Correct predictions for instances containing EN+IT⇒ES(seeAppendixB). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 687>


<Paper ID = 687> <Table 2> <Abstractive Summary> =EN 0.564∗∗ 0.416 0.648∗∗
n ES 0.513∗∗ 0.576∗∗ 0.752
ai
Tr EN+ES 0.513∗∗ 0.335∗∗ 0.768
ES+IT 0.797 0.572∗∗ 0.744
EN+IT 0.802 0.399 0.632∗∗
Baseline - 0.651 0.730
Table 4: Results in terms of macro-F1 for the merged
corpora containing hate speech towards immigrants
andwomen. </Abstractive Summary> <Extractive Summary> Thisisbecausetrain-
Table 2 shows the macro-averaged F1 score for
ing sets based on other languages do not contain
hatespeechdetectionondifferenttrainingandtest
theabove-mentionedspeciﬁcwordsandtherefore
languages(inrowsandcolumns,respectively).  </Extractive Summary>  </Table 2>  </Paper ID = 687>


<Paper ID = 689> <Table 0> <Abstractive Summary> =First,eachinstancefromBioDRB Table 1: Performances on BioDRB across domains. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 689>


<Paper ID = 689> <Table 1> <Abstractive Summary> =(2020) proposed a Knowledge-enabled Bidirec-
Table 2: Performances on BioDRB within domain. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 689>


<Paper ID = 69> <Table 0> <Abstractive Summary> =Inorder
833Target
De En Es Fr It Pt
De 12.8/20.6 10.2/13.8 11.6/14.9 6.6/8.6 10.4/13.0
En 13.1/22.5* 23.1/32.3* 22.1/30.0* 14.9/21.5 20.7/28.4
ce Es 9.2/12.1 18.9/26.0 19.0/21.8 13.3/15.4 20.0/21.9
r
u Fr 9.8/13.6 19.8/27.9* 18.6/21.7 13.8/15.2 19.7/21.4
o
S It 10.1/11.9 19.8/25.6 18.8/20.8 19.1/20.0* 19.8/19.2
Pt 9.0/11.4 19.0/24.1 19.8/19.6 18.1/18.6 15.6/16.1
Table 5: Zero-shot performance (baseline/XMEF) on Europarl. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 69>


<Paper ID = 69> <Table 1> <Abstractive Summary> =Ourworkattemptstoleverage
Table 6: Ablation on LNA-Minimalist ﬁnetuning, pretrained components from different modalities
whereweevaluatetheeffectofﬁnetuningLayerNorm (textandspeech)toperformtheSTtask. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 69>


<Paper ID = 69> <Table 2> <Abstractive Summary> =Empirical studies shows
Table 7: Ablation on length adaptor with different that ﬁnetuning the ﬁnal layers of BERT account
downsamplingratiosofspeechinput. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 69>


<Paper ID = 69> <Table 3> <Abstractive Summary> =We re-
portcase-sensitivedetokenizedBLEUusingsacre-
Table 8: A list of 21 languages and their ISO codes
BLEU(Post,2018),exceptforJapaneseandChi-
withexperimentresultsreportedinthispaper. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 69>


<Paper ID = 690> <Table 0> <Abstractive Summary> =(380k) 58.56(0.6821) 78.39 83.88 79.04 73.27
Gutenberg-10k 57.93(-) 75.09 81.21 77.15 79.21
Gutenberg-50k 57.40(-) 76.19 77.84 75.10 74.26
Gutenberg-100k 58.56(-) 72.53 75.00 74.40 75.25
Gutenberg-300k 57.38(-) 75.82 81.56 76.44 78.22
Gutenberg-500k 59.19(0.6748) 76.56 80.50 79.12 85.51
Gutenberg-Easy(33k) 56.43(-) 69.60 70.92 75.10 77.23
Gutenberg-Medium(33k) 57.00(-) 75.10 80.32 78.17 79.21
Gutenberg-Hard(33k) 57.54(-) 75.82 80.67 79.98 74.36
Table 3: Zero-shot transfer performances (%) on downstream datasets. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 690>


<Paper ID = 691> <Table 0> <Abstractive Summary> =In this paper, we address these problems by Table 1: An example of the ”semantic drift” issue in
a novel Rationale-Enriched Answer Genera- generative reading comprehension from the MARCO
tor (REAG), which incorporates an extractive dataset (Nguyen et al., 2016). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 691>


<Paper ID = 691> <Table 1> <Abstractive Summary> =1https://microsoft.github.io/msmarco/
944Model ROUGE-L BLEU-1 Method SemanticAcc ROUGE-L BLEU-1
BIDAF+Seq2Seqa 34.15 29.68 PALM 81.67 69.87 66.31
S-Netb 42.71 36.19 REAG 84.33 70.31 68.59
S-Net+Seq2Seqb 46.83 39.74
Table 4: Comparison of the semantic accuracy,
gQAc 45.46 40.22
ROUGE-LandBLEU-1ofREAGwiththoseofPALM
KEAGd 51.68 45.97
Masquee 69.77 65.56
ROUGE-L BLEU-1
PALMf 69.87 66.31
GeneratedAnswers 47.25 50.34
REAG 70.98 69.12
GoldAnswers 38.14 43.12
Table 2: Performance of generative reading com- Table5:Agreementofgenerated/goldanswerswithex-
prehension in ROUGE-L and BLEU-1 on MARCO tractedrationalesforREAG
Q&A+NLG. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 691>


<Paper ID = 691> <Table 2> <Abstractive Summary> =Thisablationleadstoadropfrom70.98to
Table 3: Ablation tests of REAG on the MARCO 69.54onRouge-L,whichdemonstratesthepower
Q&A+NLGdataset. </Abstractive Summary> <Extractive Summary> OurREAGmodelsurpassesPALMin
results in the Table 2 are from (Bi et al., 2019),
generatingcorrectanswerswithoutsemanticdrift.  </Extractive Summary>  </Table 2>  </Paper ID = 691>


<Paper ID = 692> <Table 0> <Abstractive Summary> =The bottom section
p p
makingitmoredifﬁcultfortheencodertokeepthe containsShufﬂing(Grenanderetal.,2019),which
950Model CNN/DM XSum
R1 R2 RL Mean R1 R2 RL Mean
Lead 40.30 17.52 36.54 31.45 16.32 1.60 11.96 9.96
Oracle 56.04 33.10 52.29 47.14 30.98 8.98 23.51 21.16
BasicTransformer(Vaswanietal.,2017) 41.02 18.39 37.39 32.27 16.79 1.84 12.33 10.32
–NoPositionEncoding 37.82↓ 15.59↓ 34.32↓ 29.24 18.29↑ 2.53↑ 13.45↑ 11.42
–OnlyPositionEncoding 40.13↓ 17.36↓ 36.38↓ 31.29 16.22↓ 1.62↓ 11.90↓ 9.91
Learned-Mixin(Clarketal.,2019) 40.72↓ 18.27 37.17↓ 32.05 16.67 1.91↑ 12.28 10.29
Shufﬂing(Grenanderetal.,2019) 41.00 18.43 37.37 32.27 16.98↑ 1.96↑ 12.48↑ 10.47
OurMethod 40.88↓⇓ 18.37 37.27↓ 32.18 17.20↑⇑ 1.99↑⇑ 12.63↑⇑ 10.61
Table 1: The ROUGE-1/2/L F1 scores and “Mean” (mean of ROUGE-1/2/L) on CNN/DM and XSum test data. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 692>


<Paper ID = 693> <Table 0> <Abstractive Summary> =956AnswerType % Examples
Algorithm 1: Annotate an instance for
Date 24.7 15分钟(15minutes)
Number 17.5 53.28厘米(53.28cm) over-stabilitysubset
Interval 11.8 1%至5%(1%to5%) Input:{(cid:104)q,p,A(cid:105)}tuple
Person 8.8 成龙(JackieChan) Output:{(cid:104)q(cid:48),p,A(cid:48)(cid:105)}tupleornull
Organization 7.5 湖南卫视(HunanSatelliteTV) Identifythenamedentities{e ,...,e }alongwith
1 n
Money 7.0 2.7亿美元(270milliondollars) theirentitytypesinp
Location 6.0 北京(Beijing) Keepthenamedentities{ei,...,em}withthesame
Software 2.2 百度地图(BaiduMap) typesasA
Item 1.6 华为P9(HuaweiP9) if1<m<kthen
Other 12.9 管理学(ManagementScience) iflinguisticexpertsconsiderthepassagep
containsatrapthen
annotateanewquestionq(cid:48)andanswersA(cid:48)
Table 3: The frequency distribution and examples of
AandA(cid:48)sharethesamenamedentitytype
differentanswertypesinDuReaderrobust. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 693>


<Paper ID = 693> <Table 1> <Abstractive Summary> =Table 4: Comparing MRC baselines to human on the
development,testandallchallengesets. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 693>


<Paper ID = 693> <Table 2> <Abstractive Summary> =All the metrics
large
are calculated at Chinese character level, and we
Table 5: The results on the three subsets of the chal- normalizeboththepredictedandtrueanswersby
lengeset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 693>


<Paper ID = 694> <Table 0> <Abstractive Summary> =As a result, the expression trees they produce
Table 1: Example problem that requires geometry
are lengthy and uninterpretable because they
knowledge. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 694>


<Paper ID = 694> <Table 1> <Abstractive Summary> =followpreviousseq2treework(XieandSun,2019; Equation: x=300/10
Wuetal.,2020)andsetourobjectivetominimize Answer: 30
thenegativeloglikelihood:
Table 3: Example problem that contains misleading
n keywords (perimeter, rectangular) but do not require
(cid:88)
L(T,P) = −logP(yt|st,P,KG). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 694>


<Paper ID = 694> <Table 2> <Abstractive Summary> =Mohammad Javad Hosseini, Hannaneh Hajishirzi,
Table 4: Answer accuracy of S2G and other SOTA
Oren Etzioni, and Nate Kushman. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 694>


<Paper ID = 696> <Table 0> <Abstractive Summary> =984Appendixfor“EfﬁcientPassageRetrieval Dataset Train Validation Test
withHashingforOpen-domainQuestion
NQ 58,880 8,757 3,610
Answering” TQA 60,413 8,837 11,313
A DetailsofExperimentalSetup Table 4: Number of questions in the preprocessed
datasetusedinourexperiments. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 696>


<Paper ID = 698> <Table 0> <Abstractive Summary> =Table 2: Entity coverage ratio of dev and test data in
• We design a simple yet effective algorithm differentChineseNERdatasets. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 698>


<Paper ID = 698> <Table 1> <Abstractive Summary> =organization 33.33 45.71 +37.14%
position 35.90 52.63 +46.60%
Model MSRA OntoNotes Resume Weibo scene 74.56 78.31 +5.03%
Glyce-BERT 95.54 81.63 96.54 67.60 MSRA
(Meng et al.,
Category Baseline Proposed F1Improvement
2019)
LOC 86.79 89.17 +2.74%
BERT+FLAT 96.09 81.82 95.86 68.55
ORG 89.69 89.69 +0.00%
(Lietal.,2020)
PER 95.85 96.35 +0.52%
BERT+CRF 95.57 82.29 95.71 69.89
(Ours) OntoNotes4.0
Category Baseline Proposed F1Improvement
Table 4: Comparison between BERT+CRF and the GPE 64.93 66.94 +3.10%
LOC 37.88 45.03 +18.88%
state-of-the-art models using the same train/dev/test
ORG 65.10 73.31 +12.61%
splitsas(Lietal.,2020,2019;Xuanetal.,2020) PER 96.45 96.32 -0.13%
Weibo
Category Baseline Proposed F1Improvement
4.2 Results PER.NAM 69.09 75.23 +8.89%
PER.NOM 46.67 45.28 -2.98%
Table5presentsthecomparisonsbetweenthepro- Resume
posed method and the baseline on ﬁve Chinese Category Baseline Proposed F1Improvement
NAME 1.00 1.00 0%
NERdatasets. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 698>


<Paper ID = 7> <Table 0> <Abstractive Summary> =(1)
i w bj w 11_[00:41.36]*油烟的*⾹味弥漫*不那么⼤*的屋 
12_[00:44.28]*外婆的故*事总会*让⼤⼈笑*着哭
Table 1: The statistics of three mined datasets. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 7>


<Paper ID = 7> <Table 1> <Abstractive Summary> =ObjectiveEvaluation SubjectiveEvaluation
Model
PPL↓ RA↑ RD↑ Theme↑ Fluency↑ Quality↑ Diversity↑
Baseline 24.65 32.29 0.23 3.13 2.55 3.10 3.46
Baseline+PT 13.47 39.59 0.35 3.41 2.69 3.25 3.65
DeepRapper 5.65 66.95 1.65 3.67 3.57 4.16 4.14
Subjective Evaluation Similar to previous Table 3: The ablation studies on each component in
DeepRapper. </Abstractive Summary> <Extractive Summary> alignedbeats(namedasD-LYRIC).Wesummarize
the statistics of the three datasets in Table 1 and 4.2.1 Reverse-OrderLanguageModel
showarapsongwithalignedbeatsfromD-Rapin Rhyming words usually occur at the end of each
Figure2.  </Extractive Summary>  </Table 1>  </Paper ID = 7>


<Paper ID = 70> <Table 0> <Abstractive Summary> =Wemeasurethefaithfulnessofthetrained
Table 1: Correlation and Neighborhood faithfulness
embeddings,using3metrics,oneperpropertyas
measuresoftheembeddingstrainedforboththeGiga-
per Eqns 4, 5, 6. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 70>


<Paper ID = 70> <Table 1> <Abstractive Summary> =For the uniformity condition, we Faithful-RoBERTa 0.30 0.18 574
measurethemeansoftheper-dimensionvaluesof
Table 2: Uniformity measures on the embeddings
thewordembeddingsandcomputethe1st Wasser-
learntforGigawordCausalGraph. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 70>


<Paper ID = 70> <Table 2> <Abstractive Summary> =845Embedding P@1 MRR
cEmbedBi 37.28 46.39
1.0 Causal-BERT 38.12 47.26
Causal-RoBERTa 38.74 49.01
0.8 Faithful-BERT 39.21 49.72
Faithful-RoBERTa 41.07 51.42
n AblationStudyofFaithful-BERT
o0.6
si w/oNeighborhood 38.55 48.67
ci w/oUniformity 39.01 48.92
e
Pr0.4 w/oDistanceCorrelation 38.28 48.04
cEmbedBi AblationStudyofFaithful-RoBERTa
CausalBERT
w/oNeighborhood 39.69 49.39
0.2 FaithfulBERT
Causal-RoBERTa w/oUniformity 40.43 50.06
Faithful-RoBERTa w/oDistanceCorrelation 39.50 49.28
0.0
0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0
Recall Table 3: Performance on the QA task in Yahoo! </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 70>


<Paper ID = 70> <Table 3> <Abstractive Summary> =in causal graph from the embeddings by applying
thresholdondistancemeasure
Cause Non-cause
Associated rain→ﬂood accident→fog
Non-Associated war→epidemic earthquake→spring
5.2 QAtask
Table 4: Examples of word-pairs chosen to inspect
Toevaluateiflearningfaithfulembeddingsisuseful
faithfulnessovertheGigawordcausalgraph. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 70>


<Paper ID = 700> <Table 0> <Abstractive Summary> =To account for cross-domain
Table 1: LectureBankCD statistics on NLP, CV and knowledge, we additionally consider the domain
BIO domain: Tks/pg (Tokens per slide page), Con. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 700>


<Paper ID = 700> <Table 1> <Abstractive Summary> =EyeTracking EyeTracking
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and
Table 3: Successors of the concept Image Processing,
Kristina Toutanova. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 700>


<Paper ID = 700> <Table 2> <Abstractive Summary> =After generating
Node2vec 0.8197 0.8172 0.8223 0.8140
concept node embeddings, we train a classiﬁer
topredictconceptrelationsandreportin-domain
Table 4: Supervised evaluation results: CV→CV. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 700>


<Paper ID = 700> <Table 3> <Abstractive Summary> =DeepWalk 0.7911 0.8079 0.7334 0.9091
Node2vec 0.7956 0.8060 0.7547 0.8727
Table 5: Supervised evaluation results: BIO→BIO. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 700>


<Paper ID = 701> <Table 0> <Abstractive Summary> =In addi- Table 1: MAP, P@5 and P@10 performance of base-
tion, for the CNN fusion model, see (2), we use lines(inpercentages)ontextandcodeviews. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 701>


<Paper ID = 701> <Table 1> <Abstractive Summary> =AMNMbert-svms gconv 11.4 14.2 13.9
Table 2: Model performance across different fusion
3.1 ExperimentalResults
functions. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 701>


<Paper ID = 702> <Table 0> <Abstractive Summary> =andShivade(2018),whoreportamicro-F1score p(token,class)
PMI(token,class) = log
of61.9butdonotidentifyoranalyzeartifacts: 2p(token,·)p(·,class)
dev test Entailment Entailment hypotheses are charac-
majorityclass 33.3 33.3
terizedbytokens about: (1)patientstatusandre-
fastText 64.8 62.6
sponsetotreatment(e.g.,responsive;failed;longer
Table 1: Performance (micro F1-score) of the as in no longer intubated); (2) medications and
fastTexthypothesis-onlyclassiﬁer. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 702>


<Paper ID = 702> <Table 1> <Abstractive Summary> =Neutral Neutral hypotheses feature tokens re- entailment neutral contradiction
mean median mean median mean median
latedto: (1)chronicandacuteclinicalconditions
separate 5.6 5.0 5.2 5.0 5.6 5.0
(e.g.,obesity; joint_pain; brain_injury); (2)clini- merged 5.3 5.0 4.9 5.0 5.3 5.0
callyrelevantbehaviors(e.g.,smoking;alcoholic;
Table 4: Average and median hypothesis length by
drug_overdose);and(3)genderandreproductive
classandentityrepresentation. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 702>


<Paper ID = 702> <Table 2> <Abstractive Summary> =(83.8%)
entities merged, and (2) X : premise and hy-
ph,m
Table 5: Results of χ2 test statistic by heuristic, com- pothesisconcatenated,multi-tokenentitiesmerged. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 702>


<Paper ID = 702> <Table 3> <Abstractive Summary> =Table 6: Performance (micro F1-score) for the major-
AFLiterequiresdistributedrepresentationsof ityclassbaselineandfastTextclassiﬁers,withand
thefulldatasetasinput,andproceedsinaniterative withoutpremise,bypartition(e.g.,full,easy,difﬁcult). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 702>


<Paper ID = 703> <Table 0> <Abstractive Summary> =Table 2: Evaluation of the impact of post-ﬁltering on
BEST,BERTandBERT-HAE. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 703>


<Paper ID = 703> <Table 1> <Abstractive Summary> =Threatofadver-
Table 3: Evaluation of BERT, BERT-HAE, BERT- sarialattacksondeeplearningincomputervision:A
PHAE,BERT-AHandtherobustvariantswithdifferent survey. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 703>


<Paper ID = 704> <Table 0> <Abstractive Summary> =thenselecttheenclosingLA.Weaimtoshowthat
ourproposedmethodprovidescomparableresults
Model F1 HAF1
to ROBERTADM whilebeingconsiderablyfaster RoBERTa 48.6 7.6
while decoding and displaying improved perfor- VAULT 49.3 16.1
mance over experiments just using the language
Table 2: Results on TechQA dev set. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 704>


<Paper ID = 705> <Table 0> <Abstractive Summary> =evaluation metrics for NLG (Zhang et al., 2019;
1043
Proceedingsofthe59thAnnualMeetingoftheAssociationforComputationalLinguistics
andthe11thInternationalJointConferenceonNaturalLanguageProcessing(ShortPapers),pages1043–1048
August1–6,2021.©2021AssociationforComputationalLinguisticsDataset #Sentences Domain Mean Median
Bolt 133 Web Count1st 13.85 13.0
Consensus 100 News Count2nd 7.87 8.0
DFA 229 Web Count3rd 7.16 7.0
Proxy 823 News ROUGE1st 0.64 0.68
Xinhua 86 News ROUGE2nd 0.33 0.35
ROUGE3rd 0.29 0.32
Table 1: The number of test sentences and domain
BLEU1st 0.39 0.36
of each AMR dataset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 705>


<Paper ID = 706> <Table 0> <Abstractive Summary> =This might be
8% 0.471
becausetheproposedsentence-levelperturbation
16% 0.442
32% 0.408 strategycanseriouslybreakthesemanticsofeach
post and thus inﬂuence the overall performance,
Table 1: Results of different proportions of added
andrandomsamplingoversentenceshurtsmost. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 706>


<Paper ID = 706> <Table 1> <Abstractive Summary> =As
O’ConnorandNock(2014)pointout,depression
Table 3: Class-wise performance (F1) for PL-
basedmethods(a=no-risk;b=low-risk;c=medium-risk; is a serious mental issue and has become one of
d=high-risk). </Abstractive Summary> <Extractive Summary> Table 1 show proves over the BERT baseline.  </Extractive Summary>  </Table 1>  </Paper ID = 706>


<Paper ID = 706> <Table 2> <Abstractive Summary> =Macro-F1
30
BERT No No No 0.427 a 23 3 2 4
XLNET No No No 0.422
25
RoBERTa No No No 0.408
elb 1 2 1 9 20
Table 4: Experiment results for different PLMs. </Abstractive Summary> <Extractive Summary> Clinical Psychology Inspired Pseudo-labeling
Exp 7, 8 and 9 in Table 2 achieve the Top-3
3 ExperimentsandResults
Macro-F1 scores.  </Extractive Summary>  </Table 2>  </Paper ID = 706>


<Paper ID = 706> <Table 3> <Abstractive Summary> =elb 2 1 3 7 25
b
a
MixingProportion Macro-F1 e l 20
11::52 00..349683 Truc 1 3 7 17 15
1:1 0.434
10
2:1 0.441
5:1 0.442 d 4 4 4 40 5
a b c d
Table 5: Experiment results for different mixing pro-
Predicted label
portions. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 706>


<Paper ID = 706> <Table 4> <Abstractive Summary> =Approach Setup a b c d
1 Baseline BERT 0.742/0.719/0.730 0.077/0.077/0.077 0.400/0.286/0.333 0.525/0.615/0.566
2 TAP BERT 0.774/0.750/0.762 0.143/0.154/0.148 0.250/0.107/0.150 0.588/0.769/0.667
3 MVL Word-Mask 0.788/0.812/0.800 0.111/0.077/0.091 0.391/0.321/0.353 0.567/0.654/0.607
4 MVL Sent-Mask 0.551/0.844/0.667 0.091/0.077/0.083 0.294/0.179/0.222 0.583/0.538/0.560
5 MVL BegEd 0.686/0.750/0.716 0/0/0 0.320/0.286/0.302 0.531/0.654/0.586
6 MVL K-Sum 0.686/0.750/0.716 0/0/0 0.320/0.286/0.302 0.531/0.654/0.586
Depression
7 PL 0.913/0.656/0.764 0.333/0.231/0.273 0.333/0.321/0.327 0.561/0.712/0.627
(c)
Anxiety
8 PL 0.808/0.656/0.724 0.167/0.154/0.160 0.440/0.393/0.415 0.565/0.673/0.614
(b)
Depression
9 PL 0.821/0.719/0.767 0.133/0.154/0.143 0.385/0.357/0.370 0.554/0.596/0.574
+Anxiety
TaskC
10 PL 0.774/0.750/0.762 0.083/0.077/0.080 0.438/0.250/0.318 0.606/0.769/0.678
(b)
TaskC
11 - (crowd- 0.760/0.594/0.667 0/0/0 0.357/0.357/0.357 0.556/0.673/0.609
labeled)
Table 6: Class-wise decomposition results for models considered in this paper. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 4>  </Paper ID = 706>


<Paper ID = 707> <Table 0> <Abstractive Summary> =94.5 88.8 84.2 80.8 77.9
GPT2-med-id 93.1 98.8 90.0 94.0
Table 2: Results of Zero-Shot KBST varying the
Table1:AccuracyofZero-ShotShufﬂeTestsofmodels blocksizefromonetoﬁve.TheGPT2-mediummodel
onthreedomains: WallStreetJournal(WSJ),Billsum was tested on all three domains, and human perfor-
documents (Legal), and Reddit. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 707>


<Paper ID = 709> <Table 0> <Abstractive Summary> =Wealsocombinethese
Table 6: Examples of predictive patterns of satire
scoresthroughthemacroF andmicroF (accu-
1 1 learnedbythecharacter-levelCNN. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 709>


<Paper ID = 709> <Table 1> <Abstractive Summary> =We opted for formeaza˘ ca˘” that”
thecharacter-levelCNNinfavoroftheﬁne-tuned
Table 7: Examples of predictive patterns of legitimate
BERT, as the former method allows us to visual-
newslearnedbythecharacter-levelCNN. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 709>


<Paper ID = 709> <Table 2> <Abstractive Summary> =1
Ro-BERT 0.6800 0.6750 0.7800 0.5100 0.6350 0.8550
Char-CNN 0.6500 0.6510 0.6389 0.6900 0.6630 0.6100
Humans 0.8735 0.8711 0.9416 0.7970 0.8332 0.9500
Table 8: Averaged performance of ten human annotators versus deep learning baselines on 200 news headlines
fromSaRoCo. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 709>


<Paper ID = 710> <Table 0> <Abstractive Summary> =Evaluationisalsoperformedontheconcatenation
1082Model SourceText Full Purpose Method Findings Value
FacetSumTest
Oracle GreedyExtractive(Nallapatietal.,2017) corresponding 60.39 44.66 41.00 46.44 38.10
Heuristic Lead-K corresponding 36.78 17.83 15.29 15.92 16.08
Models Tail-K sections 33.31 21.67 12.62 16.66 17.43
SumBasic(Vanderwendeetal.,2007) 38.71 18.17 15.41 16.31 16.57
Unsupervised LexRank(ErkanandRadev,2004) corresponding 42.18 18.72 16.23 18.11 17.75
Models LSA(GongandLiu,2001) sections 35.98 18.29 15.86 16.92 16.62
TextRank(MihalceaandTarau,2004) 41.87 21.67 13.62 18.63 19.23
HipoRank(Dongetal.,2020) 42.89 22.73 15.20 18.38 19.68
BART(Lewisetal.,2020) I+C 44.36 41.14 20.75 14.72 5.85
Supervised BART-Facet I+C 47.09 43.47 29.07 30.97 28.90
Models BART fullpaper 42.74 41.21 20.53 14.33 5.07
BART-Facet fullpaper 45.76 42.55 28.07 28.98 28.70
FacetSumOA-Test
BART I+C 44.97 43.51 26.73 11.79 0.31
BART-Facet I+C 51.32 43.66 30.16 32.22 29.68
Table 3: Model performance on FacetSum (Rouge-L). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 710>


<Paper ID = 710> <Table 1> <Abstractive Summary> =identiﬁ relationship higher
Value provid studi new
contribut paper social
develop research differ
base manag empir
examin literatur import
Table 5: Top ﬁve frequent verbs/nouns/adjectives in
each facet of structured abstract. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 710>


<Paper ID = 710> <Table 2> <Abstractive Summary> =R1/R2/RL Full Purpose Method Findings Value
FacetSumTest
Lead-K 39.65/11.01/36.78 21.95/4.89/17.83 18.69/5.94/15.29 18.84/4.31/15.92 20.14/3.05/16.08
Tail-K 35.90/10.96/33.31 25.48/7.23/21.67 14.88/2.64/12.62 19.25/4.41/16.66 20.90/4.71/17.43
SumBasic 42.11/10.01/38.71 22.23/4.68/18.17 18.40/5.02/15.41 19.15/3.93/16.31 20.64/3.08/16.57
LexRank 46.35/15.12/42.18 22.97/5.28/18.72 19.44/5.84/16.23 21.66/5.66/18.11 22.39/4.05/17.75
LSA 39.84/9.59/35.98 22.47/4.91/18.29 19.10/5.58/15.86 20.29/4.59/16.92 20.96/3.31/16.62
TextRank 46.90/16.04/41.87 28.29/9.39/21.67 17.55/4.32/13.62 23.90/7.17/18.63 25.99/7.07/19.23
HipoRank 46.48/15.42/42.89 27.71/8.29/22.73 18.27/4.65/15.20 21.75/5.31/18.38 24.54/5.26/19.68
BARTI+C 47.21/19.59/44.36 46.61/27.10/41.14 23.85/7.98/20.75 16.84/5.34/14.72 7.21/1.93/5.85
BART-FacetI+C 50.62/20.97/47.09 49.59/28.70/43.47 34.61/11.82/29.07 36.42/12.63/30.97 35.37/11.75/28.90
BARTfullbody 45.49/18.10/42.74 46.74/27.09/41.21 23.66/7.92/20.53 16.39/4.63/14.33 6.30/1.62/5.07
BART-Facetfullbody 49.29/19.60/45.76 48.65/27.72/42.55 33.49/11.01/28.07 34.46/10.49/28.98 35.27/11.44/28.70
FacetSumOA-Test
BARTI+C 48.85/20.84/44.97 49.43/29.44/43.51 31.1/10.16/26.73 13.78/4.45/11.79 0.4/0.1/0.31
BART-FacetI+C 48.31/22.63/51.32 49.59/28.69/43.66 35.82/12.84/30.16 37.46/14.02/32.22 35.9/12.75/29.68
Table 7: Full results (Rouge-1/2/L) of different models on FacetSum. </Abstractive Summary> <Extractive Summary> Table 2 is populated by
Full 62.09 56.47 48.47 43.32 49.73 50.42
varying A and Si across the rows and columns,
Purpose 49.76 47.06 44.23 30.12 33.87 36.23 j
respectively.  </Extractive Summary>  </Table 2>  </Paper ID = 710>


<Paper ID = 710> <Table 3> <Abstractive Summary> =Table 8: Outputs by BART and BART-Facet on different facets. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 710>


<Paper ID = 711> <Table 0> <Abstractive Summary> =is likely that lessons drawn from this replication
1090
Proceedingsofthe59thAnnualMeetingoftheAssociationforComputationalLinguistics
andthe11thInternationalJointConferenceonNaturalLanguageProcessing(ShortPapers),pages1090–1098
August1–6,2021.©2021AssociationforComputationalLinguisticsOriginal 10seeds
CoNLL18 UDPipe1.2 UDPipe2.0 CoNLL18 UDPipe1.2 UDPipe2.0
Trainingsize 0.014 0.100 0.060 -0.019 -0.346 -0.005
+DUG 0.228 0.061 0.097 -0.004 -0.553 0.091
+(cid:104)Ltest(cid:105) 0.195 0.169 0.146 -0.007 -0.370 0.140
All -0.078 0.157 0.086 -0.413 -0.138 0.106
Table 1: Issues with using multivariable linear model and cross-validation (CV) to evaluate explained variance. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 711>


<Paper ID = 711> <Table 1> <Abstractive Summary> =Further,cross-validationisusedsoasto Table 3: Using multivariable linear model and CV to
avoidover-ﬁtting. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 711>


<Paper ID = 711> <Table 2> <Abstractive Summary> =This entails taking each sen-
size 0.44(p=0.011) 0.42(p<0.001) 0.46(p<0.001)
(cid:104)Ltest(cid:105)-0.96(p<0.001)-0.91(p<0.001)-0.92(p<0.001) tence of length l for each treebank, in both the
trainingandtestdata,andcalculatingDUGandthe
Table 2: Spearman’s ρ for variables with respect to corresponding LAS based on these subsets. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 711>


<Paper ID = 711> <Table 3> <Abstractive Summary> =When controlling for both covariants, correla-
LAS 0.47(p<0.001) 0.31(p=0.003) tions are small, and p-values very high, for both
size 0.91(p<0.001) 0.91(p<0.001)
(cid:104)Ltest(cid:105) 0.32(p=0.002) -0.34(p=0.001)
log-size 0.319 0.126 CoNLL18 UDPipe1.2 UDPipe2.0
+DUG 0.331 0.147
+(cid:104)Ltest(cid:105) 0.452 0.294 DUG -0.13(p=0.458)-0.13(p=0.213)-0.18(p=0.083)
All 0.406 0.265
size -0.44(p=0.010)-0.50(p<0.001)-0.46(p<0.001)
(cid:104)Ltest(cid:105) 0.18(p=0.329)-0.13(p=0.213) 0.21(p=0.049)
Table 4: Correlations wrt focused DUG (top) and ex- both -0.27(p=0.126) 0.01(p=0.915)-0.12(p=0.245)
plained variance (bottom) for focused DUG (sentence
lengths9to14)withshufﬂingforCV(10seeds). </Abstractive Summary> <Extractive Summary> Table 3 shows the results of the limited linear
We then tested this same procedure using dif-
modelandcross-validationtechniqueusing10dif-
ferent seeds to shufﬂe the cross-validation splits.  </Extractive Summary>  </Table 3>  </Paper ID = 711>


<Paper ID = 711> <Table 4> <Abstractive Summary> =Ud- both 0.17(p=0.110) 0.04(p=0.683)
pipe: Trainable pipeline for processing CoNLL-U
ﬁles performing tokenization, morphological anal- Table 6: Partial Spearman’s ρ for focused DUG (i.e. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 4>  </Paper ID = 711>


<Paper ID = 712> <Table 0> <Abstractive Summary> =For each lan-
1101Rating GIF-as-pivot Image-as-pivot M20
TestSet TrainingSet 500 1000 1500 1900 2500
Hi-En 13.08 2.5 10.0
5 Direction:HinditoEnglish
Ta-En 6.0 3.5 -
GIF GIF 6.41 13.06 14.39 14.81 16.09
Hi-En 35.77 15.5 26.43
>=4 GIF Image 5.71 8.17 9.5 9.7 10.49
Ta-En 37.0 14.0 -
GIF M20 3.19 6.84 7.99 6.9 N/A
Hi-En 61.15 39.0 51.43
>=3 Image GIF 2.93 8.18 9.11 8.84 9.24
Ta-En 67.5 42.5 -
Image Image 8.46 10.05 11.15 11.25 12.14
Hi-En 82.69 63.0 75.0 Image M20 1.27 5.79 6.76 6.68 N/A
>=2
Ta-En 92.5 72.5 -
M20 GIF 1.66 5.21 5.75 6.78 6.69
Hi-En 100.0 100.0 100.0 M20 Image 1.63 4.53 4.98 5.09 5.63
>=1
Ta-En 100.0 100.0 - M20 M20 5.08 6.96 7.23 8.23 N/A
All GIF 3.47 8.46 9.35 9.81 10.28
Table 3: Cumulative percentages with respect to each All Image 4.9 7.28 8.19 8.32 9.04
setting;GIF-as-pivotshowsthebestresults; All M20 3.37 6.57 7.32 7.37 N/A
Direction:EnglishtoHindi
GIF GIF 0.63 1.68 2.01 1.72 3.07
guage pair, we select the same random 100 sen-
GIF Image 0.81 2.18 1.43 2.29 1.86
tence pairs from the GIF-as-pivot and image-as- GIF M20 0.42 2.09 2.99 3.06 N/A
pivotsettings. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 712>


<Paper ID = 714> <Table 0> <Abstractive Summary> =F1
1 baseline - - - +0.0% 52.7±2.48
2 toptoken +24.4% 53.7±0.91
entity independent
3 joint +24.7% 54.6±0.50
4 toptoken +98.7% 52.3±1.25
conditional
5 joint +99.7% 51.7±1.36
mixed
6 toptoken +98.6% 53.7±0.89
independent
7 joint +99.7% 53.3±0.61
8 toptoken +33.8% 56.3±1.21
MLMDA conditional
9 joint +35.8% 55.6±1.12
context
10 toptoken +33.8% 55.0±1.16
independent
11 joint +35.8% 56.0±0.06
12 toptoken +96.8% 54.9±0.40
conditional
13 joint +99.7% 54.5±1.21
randomcontext
14 toptoken +96.9% 53.7±0.93
independent
15 joint +99.7% 53.5±2.40
Table 4: Results of the MLM-based augmentation on the W-NUT dataset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 714>


<Paper ID = 714> <Table 1> <Abstractive Summary> =The annotation contains 12 independent joint +99.7% 8.1
entitytypes: location,organization,
Table 9: Average number of masked tokens for each
person, other, location deriv,
augmentationstrategyonW-NUTdataset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 714>


<Paper ID = 714> <Table 2> <Abstractive Summary> =Table 10: Average number of masked tokens on
CoNLLdataset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 714>


<Paper ID = 714> <Table 3> <Abstractive Summary> =Masked
CoNLL #tokens 203621 51362 46435 entity independent joint +47.9% 1.0
#entitytypes 4 4 4 toptoken +51.4% 4.4
%labelled 16.7 16.8 17.5 conditional joint +58.5% 5.7
#sentences 3394 1008 1287 context toptoken +51.4% 4.3
#entities 1976 836 1080 independent joint +58.5% 5.3
W-NUT #tokens 62730 15723 23394 randomcontext conditional toptoken +94.1% 6.0
#entitytypes 6 6 6
%labelled 5.0 7.9 7.4 Table 11: Average number of masked tokens on Ger-
#sentences 24001 2199 5099
mEvaldataset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 714>


<Paper ID = 714> <Table 4> <Abstractive Summary> =#entities 29077 2674 6178
#tokens 452790 41635 96475
GermEval
#entitytypes 12 12 12
%labelled 9.3 9.5 9.3 B.2 DataExamples
Table 8: Dataset sizes in number of sentences, tokens Weshowthedataexamplesondifferentdatasetby
and entities. </Abstractive Summary> <Extractive Summary> Table 4 shows the re-
wherethedatacomesfromdifferentsources, e.g. Weuse
thebestbaselinesystemwith54.6%F1scoreand dataset,werepeattheseexperiments,sincegener-
thebestmodelcorrespondingtothesetupofline atingnewentitiesisthemostinterestingscenario
8 in Table 4 with 57.4% F1 score.  </Extractive Summary>  </Table 4>  </Paper ID = 714>


<Paper ID = 715> <Table 0> <Abstractive Summary> =Table 1: Human and System Generated Description in Figure 1. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 715>


<Paper ID = 715> <Table 1> <Abstractive Summary> =We select
+Wikipedia 61.3 72.2 72.0 70.5
15relatedcategories(Astronaut,University,Monu- +Position 60.6 72.1 72.4 70.6
ment, Building, ComicsCharacter, Food, Airport, +Wiki+Position 61.9 72.8 73.5 71.6
SportsTeam, WrittenWork, Athlete, Artist, City,
Table 3: Results with both Wikipedia Fine-tuning and
MeanOfTransportation,CelestialBody,Politician)
Positional Embedding for Various Pre-trained Models
thatappearintheWebNLGdataset(Gardentetal.,
overAllCategoriesonDevelopmentSetEvaluatedby
2017) and collect 542,192 data pairs. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 715>


<Paper ID = 715> <Table 2> <Abstractive Summary> =(2020b) 89.36 91.96 90.59
T5-large+Wiki+Position 96.36 96.13 96.21 triples into one sentence, such as combining the
city,thecountry,theafﬁliation,andtheafﬁliation’s
Table 4: System Results on WebNLG Test Set Evalu- headquarterofauniversityintoasinglesentence:
atedbyBERTScoreprecision,recall,F1(%)
“TheSchoolofBusinessandSocialSciencesatthe
Aarhus University in Aarhus, Denmark is afﬁli-
ated to the European University Association in
3.2 ResultsandAnalysis
Brussels”. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 715>


<Paper ID = 715> <Table 3> <Abstractive Summary> =[S|FCAmkarPermP|managerO|GadzhiGadzhiyev;S|AleksandrPrudnikov
P|clubO|FCAmkarPerm]
Table 5: System Error Examples. </Abstractive Summary> <Extractive Summary> Table 3 shows
dent”,themodelmistakenlydescribesaprofessor
thepre-trainedmodelswith2-stepﬁne-tuningand
asaPh.D.student.  </Extractive Summary>  </Table 3>  </Paper ID = 715>


<Paper ID = 716> <Table 0> <Abstractive Summary> =27.4
Union’s Horizon 2020 research and innovation
Table 2: Experimental results on the German-English programme(grantagreementNo694537,project
alignmenttaskinAER[%]. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 716>


<Paper ID = 717> <Table 0> <Abstractive Summary> =AutoRC 86.1 89.87
The architecture learned on kbp37, which is an
Table 4: Experiments on the coreference resolution
open-domain dataset, AR , transfer well on
kbp37 andspanbasedNER. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 717>


<Paper ID = 718> <Table 0> <Abstractive Summary> =Experiments
In the pre-training phase, we perform various related to Bi-LSTM, CRF, vanilla transformers,
experimentsoverdifferentcombinationsofMLM and FT were performed on a single 8GB Nvidia
48Technique S US SS HE
F1-Score
VanillaTransformer
HMM 0.815
UrIIISeg 36.32 2.202
Rules+
UrIIIComp 33.45 2.242 0.991
CRF
AllSeg 37.01 2.360
Bi-LSTM+
0.763
AllComp 42.23 2.431 CRF
+3×FT(cid:63) 41.98 2.358 FLAIR 0.499
+5×FT 44.14 2.504
RoBERTa 0.949
+7×FT 42.95 2.367
XLM Table 2: POS Tagging for Sumerian. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 718>


<Paper ID = 718> <Table 1> <Abstractive Summary> =MLM+TLM,WMT 0.94 –
Mixed 13.08 21.23 1.104,–
F1-Score
Orig 12.73 24.64 1.294,–
HMM 0.656
XLM+DataAugmentation
Rules+
BERT 13.06 29.50 1.320,1.704 0.913
CRF
WordNet 13.08 28.57 1.269,1.690
Bi-LSTM+
0.775
CharSwap 12.92 29.04 CRF
BERT+WordNet 13.34 26.57 1.460,1.666 FLAIR 0.187
BERT+CharSwap
13.23 30.10 –,1.757 RoBERTa 0.953
+WordNet
Table 3: NER for Sumerian. </Abstractive Summary> <Extractive Summary> outputsoastoassignanimportancescoretoeach
input token, based on its ‘inﬂuence’ on that out-
Machine Translation Table 1 summarises
put.  </Extractive Summary>  </Table 1>  </Paper ID = 718>


<Paper ID = 718> <Table 2> <Abstractive Summary> =Table 1: Sumerian-English Machine Translation. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 718>


<Paper ID = 719> <Table 0> <Abstractive Summary> =The Table 2: Spearman correlations between input fre-
shadedareasrepresentonestanrderrorofmean(SEM). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 719>


<Paper ID = 72> <Table 0> <Abstractive Summary> =How- their corresponding sentiment labels in the form
ever, In Table 1 we see that none of the existing ofaconstituencyparsetree,thiscanbeeasilyob-
870Axioms/Properties SCD/SOC HEDGE LS-Tree STI Archipelago IDG
Well-BehavedCharacteristicFunction NA NA ✗ ✗ ✗ ✓
InDistributionEvaluations ✗ ✗ ✗ ✗ ✗ ✓
Non-Negativity ✗ ✗ ✗ ✗ ✗ ✓
Normality ✗ ✗ ✗ ✗ ✗ ✓
Monotonicity ✗ ✗ ✗ ✗ ✗ ✓
Superadditivity ✗ ✗ ✗ ✗ ✗ ✓
Sensitivity ✗ ✗ ✓ ✓ ✓ ✓
SymmetryPreservation ✗ ✗ ✓ ✓ ✓ ✓
Linearity ✗ ✗ ✓ ✓ ✓ ✗
Completeness ✗ ✗ ✓ ✓ ✓ ✓
ImplementationInvariance ✗ ✗ ✓ ✓ ✓ ✓
Table 1: A comparison of axiomatic guarantees / properties of feature interaction attribution methods:
SCD/SOC (Jin et al., 2019), HEDGE (Chen et al., 2020), LS-Tree (Chen and Jordan, 2020), Shapley-Taylor In-
teractionIndex(STI)(Sundararajanetal.,2020), Archipelago(Tsangetal.,2020), andIDG(proposedmethod). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 72>


<Paper ID = 72> <Table 1> <Abstractive Summary> =SST 6920/872 0.915 0.916 0.769
Yelp 560K/38K 0.979 0.983 0.947
IMDB 25K/25K 0.967 0.967 0.957 5 Discussion
Table 2: Accuracy of the trained models on the three
5.1 QuantitativeEvaluationsandHuman
datasets. </Abstractive Summary> <Extractive Summary> How- their corresponding sentiment labels in the form
ever, In Table 1 we see that none of the existing ofaconstituencyparsetree,thiscanbeeasilyob-
870Axioms/Properties SCD/SOC HEDGE LS-Tree STI Archipelago IDG
Well-BehavedCharacteristicFunction NA NA ✗ ✗ ✗ ✓
InDistributionEvaluations ✗ ✗ ✗ ✗ ✗ ✓
Non-Negativity ✗ ✗ ✗ ✗ ✗ ✓
Normality ✗ ✗ ✗ ✗ ✗ ✓
Monotonicity ✗ ✗ ✗ ✗ ✗ ✓
Superadditivity ✗ ✗ ✗ ✗ ✗ ✓
Sensitivity ✗ ✗ ✓ ✓ ✓ ✓
SymmetryPreservation ✗ ✗ ✓ ✓ ✓ ✓
Linearity ✗ ✗ ✓ ✓ ✓ ✗
Completeness ✗ ✗ ✓ ✓ ✓ ✓
ImplementationInvariance ✗ ✗ ✓ ✓ ✓ ✓
Table 1: A comparison of axiomatic guarantees / properties of feature interaction attribution methods:
SCD/SOC (Jin et al., 2019), HEDGE (Chen et al., 2020), LS-Tree (Chen and Jordan, 2020), Shapley-Taylor In-
teractionIndex(STI)(Sundararajanetal.,2020), Archipelago(Tsangetal.,2020), andIDG(proposedmethod).  </Extractive Summary>  </Table 1>  </Paper ID = 72>


<Paper ID = 720> <Table 0> <Abstractive Summary> =Amicus 120 4,268 485
Unlikepriorwork(ParidaandMotlicek,2019;
Table 1: A comparison between the Amicus legal
MagoodaandLitman,2020)tacklingdatascarcity
briefsdatasetandthepopularCNN/DailyMailbench-
insummarization,ourmethodneedsnosynthetic mark. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 720>


<Paper ID = 720> <Table 1> <Abstractive Summary> =NE f.t.BART 43.47 16.30 19.35
Random f.t.BART 44.63 15.11 18.57
TextRank f.t.BART 45.10 15.51 18.74 Choiceoff(s,t) R-1 R-2 R-L
Bottom-up f.t.BART 44.89 17.26 23.40
Entailment(usingRoBERTa) 43.66 16.95 23.24
Ours f.t.BART 47.07 17.64 24.40
Similarity(usingBERT) 44.67 16.69 23.81
BLEU(usingnltk) 43.95 17.38 23.69
Table 3: Comparison of our method on the Amicus Perplexity(usingGPT-2) 47.07 17.64 24.40
datasetwithstrongbaselines. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 720>


<Paper ID = 720> <Table 2> <Abstractive Summary> =Ourmethodoutperforms
all baselines in both Abstractor settings: (1) a pre- Table 4: Results of our extract-then-abstract pipeline
trained CNN/DM BART; (2) the pretrained CNN/DM (afterﬁnetuningBART)byvaryingf(s,t). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 720>


<Paper ID = 720> <Table 3> <Abstractive Summary> =Table 7: This table shows the sentences classiﬁed as salient and non-salient from one Amicus source document. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 720>


<Paper ID = 720> <Table 4> <Abstractive Summary> =Metric BART Ours+BART f.t.BART Ours+f.t.BART
Recall 40.87 47.46 46.90 56.04
ROUGE-1 Precision 47.21 49.97 48.68 46.16
F-1 40.17 44.97 43.47 47.07
Recall 13.76 16.54 17.84 21.50
ROUGE-2 Precision 15.46 17.04 17.84 17.10
F-1 13.36 15.37 16.30 17.64
Recall 18.34 25.58 21.30 29.62
ROUGE-L Precision 21.04 26.27 21.35 23.47
F-1 17.95 23.95 19.35 24.40
Table 8: Overall pipeline results by adding our extractor (f(s,t) as GPT-2 perplexity + Classiﬁer) to BART and
ﬁnetunedBART(f.t. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 4>  </Paper ID = 720>


<Paper ID = 720> <Table 5> <Abstractive Summary> =Table 9: The table shows the comparison of summaries where the top summary is the target summary and the
bottomsummaryistheonegeneratedbyourextractorandf.tBART.Aswecansee,thesummaryiscoherentand
hasﬂuentinformationﬂow. </Abstractive Summary> <Extractive Summary> methodsexperimentedwere:
Analysis: (a) Table 5 shows the classiﬁer ac-
5https://publichealthlawcenter.org/amicus-briefs curacies for combinations of f(s,t) and sampling
6https://pypi.org/project/spacy/ methods.  </Extractive Summary>  </Table 5>  </Paper ID = 720>


<Paper ID = 722> <Table 0> <Abstractive Summary> =Besidestheexperimentswithtext,motion None 35.75
andspatialfeaturesobtainedbyourmethods, de- Text+Spatial LSTM 35.37
noted as “Ours: Text+Motion+Spatial,” we also GRU 35.27
conductedtheexperimentswithonlytextandspa-
Table 2: BLEU-4 scores of our models with different
tialfeaturesdenotedas“Ours: Text+Spatial.”
settingsandmiddlelayerchoice. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 722>


<Paper ID = 723> <Table 0> <Abstractive Summary> =1 0.108
2 0.0996
3 0.0906
A Appendices
4 0.128
5 0.0923
A.1 Annotationalgorithm 6 0.163
7 0.225
Algorithm1Annotator Table 7: Average number of everyday Singlish terms
per1000words. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 723>


<Paper ID = 723> <Table 1> <Abstractive Summary> =Input: Anarray‘score’containingthenumber
ofvotesforeachpost
A.3 ListofSinglishwords
Output: Anotherarray‘classes’containingthe
annotations ‘abuden’,‘actblur’,‘agak’,‘ai’,‘aiya’,‘alamak’,
‘ang mo’, ‘ang moh’, ‘atas’, ‘bao toh’, ‘barang’,
get indexes(array,condition)←functionwhich ‘bo’, ‘bodoh’, ‘bojio’, ‘boliao’, ‘botak’, ‘chao’,
returnsthelistofindexesxinthearrayforwhich ‘chee bai’, ‘chim’, ‘cheem’, ‘chio bu’, ‘chiong’,
array[x]satisﬁescondition ‘chope’, ‘gahmen’, ‘heng’, ‘huat’, ‘jialat’, ‘jio’,
‘kena’, ‘kiasu’, ‘la’, ‘lah’, ‘lao’, ‘leh’, ‘lepak’,
class indexes←newarray[8] ‘liao’, ‘liddat’, ‘mafan’, ‘mah’, ‘meh’, ‘paiseh’,
class indexes[0]←get indexes(score,x≤1) ‘ps’, ‘paktor’, ‘sabo’, ‘sia’, ‘sian’, ‘siao’, ‘simi’,
rest of posts←get indexes(score,x>1) ‘tahan’,‘ulu’,‘wa’,‘walao’,‘wayang’,‘ya’,‘yah’
fori,1≤i≤ 7do
median←medianscoreofrest of posts
class indexes[i] ← get indexes(score, x <
median)
rest of posts←get indexes(score,x≥me-
dian)
endfor
class indexes[7]=rest of posts
classes←newarray[len(score)]
fori,0≤i≤ 7do
classes[class indexes[i]]=i
endfor
A.2 Extranumericalresults
SG UK
Level1 0.721 0.728
Level2 0.727 0.724
Level3 0.711 0.743
Level4 0.734 0.768
Level5 0.746 0.813
Level6 0.781 0.851
Level7 0.835 0.920
Table 6: F1 scores for each individual level for the
modelwithallfeatures. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 723>


<Paper ID = 724> <Table 0> <Abstractive Summary> =The best model, VLP, encodes each
imageregiontogetherwiththeclasslikelihoodon
Table 1: CHAIR results on human and machine- 1600 object categories, so it has access to a suit-
generateddialoguesontheGuessWhat?!testset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 724>


<Paper ID = 724> <Table 1> <Abstractive Summary> =AswecanseefromTable3,forallthemodels
106BL GDSE LXMERT-GDSE VLP HUMAN
person 2803 chair 1649 bottle 716 table 480 table 389
couch 1113 person 1525 table 488 chair 462 bike 237
table 656 table 1483 bike 375 bike 352 person 211
chair 538 car 629 book 362 bottle 315 car 91
computer 404 bottle 605 cup 320 person 223 chair 88
bike 332 bench 468 bear 310 cup 220 bottle 83
car 229 book 468 chair 301 book 157 bowl 73
sink 224 phone 413 fridge 198 car 140 bear 60
dog 182 cup 376 car 195 bowl 111 cup 58
bear 171 dog 296 ball 186 ball 100 truck 54
keyboard 161 boat 255 person 163 bear 79 book 51
Table 4: Most frequent hallucinated MSCOCO categories for machine-generated and human dialogues, together
withtheirrawfrequency. </Abstractive Summary> <Extractive Summary> As Table 1 shows, BL and GDSE gener-
4WealsocomputedtheCHAIRmetricforthemodelpro-
3Simultaneously,Sugliaetal.  </Extractive Summary>  </Table 1>  </Paper ID = 724>


<Paper ID = 726> <Table 0> <Abstractive Summary> =120Tokens Emoji Hashtags @ Uppercase Punctuation Exclamation
Generic 14.76±0.2% 0.31±1.7% 0.87±0.6% 0.59±0.9% 13.4±0.3% 9.41±0.2% 0.17±1.2%
Misinformation 17.04±0.1% 0.21±1.7% 0.76±0.7% 1.32±0.8% 15.26±0.4% 9.23±0.2% 0.27±1%
Table 1: Set of features from the COVID-19 Twitter Misinformation dataset: quantities represent the average
numbers(95%conﬁdenceintervals)ofinstancespertweet. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 726>


<Paper ID = 726> <Table 1> <Abstractive Summary> =TTR MTLD TTR MTLD
In the case of the ‘Politics’ subtopic the lexical WholeCorpus 0.03 593.74 0.02 268.83
diversitydifferenceissmalltononexistentwiththe Covid/Weapon 0.23 294.81 0.19 185.12
generic and misinformation tweets achieving the 5G 0.25 648.48 0.15 151.74
Politics 0.04 393.67 0.04 337.53
35G:5GPolitics:trump,democrat,republican,obama,
tedcruz,tedcruz,joebiden,joebiden,leftwing,rightwing,left Table 2: Lexical diversity of generic and misinforma-
wing,rightwing,leftwing,rightwingCovid/Weapon:
tiontweetsMetricsused: TypeTokenRatio(TTR)and
weapon,bioweapon,weaponizing,biologicalweapon
4Thecomparisonwasmadebetweenequalsizesubsets. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 726>


<Paper ID = 726> <Table 2> <Abstractive Summary> =SVM 0.84 0.84 0.84 0.84
BERT 0.89 0.89 0.89 0.89
Table 7: Overall classiﬁcation results for May - July
period. </Abstractive Summary> <Extractive Summary> The tweetsfromJanuaryarefocusedonChina(terms
keywordsused notdisplayed),whichwastheinitialcentreofthe
Table 2 displays the lexical diversity statistics epidemic,andthefollowingmonthsbecomemore
forthewholecorpusaswellasforthreedifferent diverse.  </Extractive Summary>  </Table 2>  </Paper ID = 726>


<Paper ID = 728> <Table 0> <Abstractive Summary> =3https://taku910.github.io/mecab/
141Table 3: Mean classiﬁcation accuracy on the CSJ cor-
pususinglearnedembeddings. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 728>


<Paper ID = 729> <Table 0> <Abstractive Summary> =The basic assumption of #Avg.wordspersample 367.9 571.3
#Avg.paragraphspersample 12.1 5.6
auto-regressive generation is that the probabil-
ity of a word sequence equals the product of
Table 1: Detailed information of the ﬁltered Writing-
conditional word probability: P (w1:T|W0) = PromptsdatasetandtheChineseEssaydataset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 729>


<Paper ID = 729> <Table 1> <Abstractive Summary> =According to
graph information (ParaType) are shown in Ta- theTable3,wecanﬁndthattheﬁne-tunedGPT2
ble 2 and Table 3: concatenating all paragraphs with NL as SEP achievesthebestresultsonword
into an uninterrupted sequence (None); concate- andtokenlevelperplexitymetrics. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 729>


<Paper ID = 73> <Table 0> <Abstractive Summary> =883Table 1: Trainable model parameter counts and sen- all the supervised approaches we compare to are
tence embedding dimensions. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 73>


<Paper ID = 73> <Table 1> <Abstractive Summary> =SentEval vec.zip
884Table 2: Results on the downstream tasks from the test set of SentEval. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 73>


<Paper ID = 73> <Table 2> <Abstractive Summary> =As a simple experiment, we SentEval
892Table 4: Results on the downstream and probing tasks from the validation set of SentEval. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 73>


<Paper ID = 730> <Table 0> <Abstractive Summary> =MRR P@1 MRR P@1 MRR P@1 MRR P@1 MRR P@1 MRR P@1
(cid:88) - - (cid:88) - 0.673 - 0.524 - 0.551 - 0.486 - 0.311 - 0.226
BLIfrom - (cid:88) (cid:88) - - 0.509 - 0.697 - 0.302 - 0.542 - 0.198 - 0.259
phrasetable (cid:88) (cid:88) (cid:88) (cid:88) - 0.673 - 0.522 - 0.551 - 0.486 - 0.311 - 0.226
(cid:88) - - (cid:88) 0.640 0.636 0.615 0.634 0.552 0.509 0.545 0.520 0.347 0.295 0.272 0.227
joint - (cid:88) (cid:88) - 0.587 0.579 0.643 0.685 0.535 0.491 0.577 0.549 0.279 0.226 0.305 0.249
training (cid:88) (cid:88) (cid:88) (cid:88) 0.654 0.642 0.642 0.650 0.585 0.532 0.520 0.518 0.325 0.267 0.295 0.234
mapping (cid:88) - (cid:88) - 0.670 0.612 0.650 0.614 0.579 0.484 0.587 0.488 0.471 0.378 0.364 0.242
(cid:88) - (cid:88) (cid:88) 0.709 0.666 0.687 0.688 0.656 0.582 0.635 0.563 0.514 0.405 0.436 0.304
mapping (cid:88) (cid:88) (cid:88) - 0.728 0.684 0.703 0.700 0.647 0.566 0.636 0.562 0.486 0.392 0.407 0.297
(+pseudo) (cid:88) (cid:88) (cid:88) (cid:88) 0.721 0.677 0.696 0.700 0.652 0.574 0.637 0.563 0.497 0.387 0.426 0.300
Table 2: Comparison with previous approaches in BLI. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 730>


<Paper ID = 730> <Table 1> <Abstractive Summary> =More
xling-eval
11https://translate.google.com/ concretely,weﬁrstsplittheoriginaltrainingdata
167Extension
en-fr en-de en-ja
pseudo parallel
- - 0.621/711 0.502/877 0.426/1776
× × 0.630/838 0.509/1714 0.429/2301
(cid:88) × 0.686/123 0.569/272 0.454/1050
(cid:88) (cid:88) 0.695/144 0.585/183 0.459/1024
Table 4: Results of BLI score and eigenvector similarity. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 730>


<Paper ID = 731> <Table 0> <Abstractive Summary> =OneIE 89.6 75.6 72.8
Ourmethod
3.2 Evaluation
FullModel 91.96 77.67 75.06
Similartopreviouswork(Zhangetal.,2019;Wad-
-GloVe 91.94 76.69 74.07
denetal.,2020;Linetal.,2019),weevaluatede-
-aggregation 91.03 77.32 73.74
tection of entities and event triggers as follows:
+goldinputs
an entity or event trigger mention is considered
mentions 95.97 - 92.69
to be correctly identiﬁed (Trig-I) if both of the
clusters 97.58 - 94.25
offsetsarecorrectlymatched,andoutofthosemen-
tionstheoneswiththecorrectlypredictedtypeare
Table 2: Entity and Event Trigger Extraction Results
consideredcorrectlyclassiﬁed(Entities-C,Trig-C). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 731>


<Paper ID = 734> <Table 0> <Abstractive Summary> =C =5 44.19 25.84 45.18 11.5M 19.0k 19.71 82.59
q
C =20 48.19 25.29 48.26 4.9M 22.4k 19.72 44.41
q Metrics Toevaluatethediversityofthegener-
atedquestions,ourmodelsgenerated50questions
Table 2: Results of answer-aware QG on the test set. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 734>


<Paper ID = 734> <Table 1> <Abstractive Summary> =φ
(cid:20)
p (q|y,a,c)p (y|c)
= E log θ θ
z,y pθ(y|q,c) NLL NLLa NLLq DKLz DKLy
p (a|z,c)p (z|c) Pipeline 36.26 3.99 32.50 - -
θ θ
+log VQAG
pθ(z|a,c) C=0 34.46 4.46 30.00 0.027 0.036
q (y|q,c) q (z|a,c)(cid:21) C=5 37.00 5.15 31.51 4.862 4.745
φ φ
+log +log C=20 59.66 14.38 43.56 17.821 17.038
qφ(y|q,c) qφ(z|a,c) C=100 199.43 81.01 112.37 92.342 91.635
= E [logp (q|y,a,c)+logp (a|z,c)
z,y θ θ
Table 8: QA pair modeling capacity measured on the
p (y|c) q (y|q,c)
+log θ +log φ testset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 734>


<Paper ID = 734> <Table 2> <Abstractive Summary> =213Relevance Diversity
B1 B2 B3 B4 ME RL Token D1 D2 E4 SB4
ZhangandBansal(2019) 48.59 32.83 24.21 18.40 24.86 46.66 133.8k 10.2k 46.4k 15.78 -
B1-R B2-R B3-R B4-R ME-R RL-R Token D1 D2 E4 SB4
ZhangandBansal(2019) 62.32 47.77 37.96 30.05 36.77 62.87 7.0M 15.8k 218.9k 18.28 91.44
VQAG
C =0 35.57 18.75 10.79 6.35 18.31 33.92 7.6M 14.4k 155.3k 17.33 97.61
q
C =3 44.05 26.74 16.08 9.26 24.61 44.10 9.0M 17.8k 394.2k 19.14 85.88
q
C =5 44.19 27.09 16.33 9.71 25.84 45.18 11.5M 19.0k 481.1k 19.71 82.59
q
C =10 44.00 27.15 16.78 10.24 25.64 44.78 10.2M 18.8k 461.5k 19.69 80.39
q
C =15 45.23 27.91 16.67 10.11 26.12 45.41 11.3M 19.5k 381.5k 19.40 84.56
q
C =20 48.19 32.87 22.96 14.94 25.29 48.26 4.9M 22.4k 549.2k 19.72 44.41
q
C =25 47.20 31.16 21.15 13.66 25.30 45.97 6.8M 22.3k 706.9k 20.34 47.00
q
C =30 47.96 31.69 21.26 13.83 24.95 47.07 7.3M 22.9k 732.8k 18.54 50.32
q
C =40 46.31 31.29 21.52 13.94 23.73 46.46 5.4M 21.0k 487.8k 19.39 55.95
q
C =50 43.92 25.95 15.54 9.61 23.61 43.18 10.8M 22.2k 527.2k 19.29 73.78
q
C =100 35.22 19.88 13.25 9.20 22.27 37.55 8.2M 22.1k 508.8k 19.74 44.22
q
Table 10: Detailed results of answer-aware QG on the test set. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 734>


<Paper ID = 735> <Table 0> <Abstractive Summary> =The moderator then discuses the partic-
Table 1: Functional differences between Parlay and ipants’ annotations. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 735>


<Paper ID = 736> <Table 0> <Abstractive Summary> =We mask 20% of Table 1: Average number of iterations given token
all WordPiece tokens but do not always replace types during the pre-training. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 736>


<Paper ID = 736> <Table 1> <Abstractive Summary> =Avg.Gluescore
BERT-base 76.9
ALBERT-base 75.6
ALBERT-base+Adapt.Depth 75.2
ALBERT-small+Adapt.Depth 74.2
ALBERT-tiny+Adapt.Depth 72.6
Table 2: GLUE Test results, scored by the evaluation
server but without the WNLI task. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 736>


<Paper ID = 736> <Table 2> <Abstractive Summary> =Wedesignedanoriginalmodelthatpro-
gressively transforms each token through a dy-
Table 3: Distribution of the iterations across token de-
namicnumberofiterations. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 736>


<Paper ID = 736> <Table 3> <Abstractive Summary> =87.3 94.0 96.0 91.9
Table 4: Distribution of the iterations across token de-
pendencytypes. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 736>


<Paper ID = 736> <Table 4> <Abstractive Summary> =87.3 94.0 96.0 91.9
Table 5: Distribution of the iterations across token de-
pendency types. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 4>  </Paper ID = 736>


<Paper ID = 737> <Table 0> <Abstractive Summary> =Table 1: Examples with simple transformations (bold Table 2: Examples with drastic transformations (bold
fontsindicatewordsthatshouldberewritten) fontsindicatewordsthatshouldberewritten)
2 Preliminary: CurriculumLearningfor adoptedwordrarity:
NeuralMachineTranslation
(cid:88)Ni
Initialcurriculumlearningmethodsforneuralma- d (s ) (cid:44) − logpˆ(w ), (2)
rarity i j
chinetranslationconsideredonlythedifﬁcultyof
j=1
thetrainingsample(KocmiandBojar,2017;Zhang
etal.,2018). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 737>


<Paper ID = 737> <Table 1> <Abstractive Summary> =Table 3: Statistics of GYAFC (Train* indicates the
Output: Trained neural machine translation trainingsetafterexpansion.) </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 737>


<Paper ID = 738> <Table 0> <Abstractive Summary> =1500 63.51 64.83 57.80
k
3000 65.71 66.59 64.61
Duringourexperiments,wereliedontheSemCor
datasetfortrainingandtheuniﬁedwordsensedis- Table 1: Results of our experiments when relying on
sparse representations created by using various hyper-
ambiguation framework introduced in (Raganato
parametercombinations. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 738>


<Paper ID = 739> <Table 0> <Abstractive Summary> =Moreover, the scale of val-
Table 5: Classiﬁcation results (F1-macro, XLM- ues could be misunderstood by some annotators
RoBERTa)forthetextstranslatedintoeightlanguages. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 739>


<Paper ID = 739> <Table 1> <Abstractive Summary> =Thephenomenonofimprovinginference
Table 6: Regression results (R-squared, XLM- thankstopersonalizationisthesameforeachofthe
RoBERTa)forthetextstranslatedintoeightlanguages. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 739>


<Paper ID = 74> <Table 0> <Abstractive Summary> =Table 1: Precedingtags as the symbol of begin-of-
AMR Parsing Tasks, which include both
sentencetodistinguishlanguages. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 74>


<Paper ID = 74> <Table 1> <Abstractive Summary> =(2021)‡ 62.7 67.9 67.4 - - -
Previousworksoncross-lingualAMR-to-textgeneration
FanandGardent(2020)‡ - - - 15.3 21.7 19.8
Table 2: Performance of AMR parsing in Smatch F1 and AMR-to-text generation in BLEU for German (DE),
Spanish (ES), and Italian (IT). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 74>


<Paper ID = 74> <Table 2> <Abstractive Summary> =Table 5: Performance comparison for German
XuefengBai,LinfengSong,andYueZhang.2020. </Abstractive Summary> <Extractive Summary> allthemodelsinbothpre-trainingandﬁne-tuning
5.3 MainResults
5https://www.statmt.org/wmt14/
translation-task.html
Table 2 shows the performance of AMR parsing
6https://www.statmt.org/europarl/index.  </Extractive Summary>  </Table 2>  </Paper ID = 74>


<Paper ID = 74> <Table 3> <Abstractive Summary> =In Proceedingsof the7thLinguis-
Table 6: Performance comparison for AMR parsing tic Annotation Workshop and Interoperability with
and AMR-to-text generation for English and other Discourse,pages178–186. </Abstractive Summary> <Extractive Summary> Theperfor-
mance comparison between XLPT-AMR Table 3 compares the performance of ﬁne-
one4all
andXLPT-AMR suggeststhatselectively grained metrics for AMR parsing.  </Extractive Summary>  </Table 3>  </Paper ID = 74>


<Paper ID = 742> <Table 0> <Abstractive Summary> =Informativeness 91.62% 0.90
When data collection is complete, we will re-
lease the transcribed and annotated dataset to re-
Table 1: Percent agreement and interrater reliability
searchers who have completed their institution’s (Krippendorf’sα)forpragmaticfeatureannotation. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 742>


<Paper ID = 746> <Table 0> <Abstractive Summary> =We train the translation models on the
Table 2: Results on translation task in IWSLT’14
IWSLT’14German-EnglishandASPECJapanese-
GermantoEnglish(De→En)andASPECJapaneseto
English(Nakazawaetal.,2016)datasets. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 746>


<Paper ID = 746> <Table 1> <Abstractive Summary> =However,
the decrease in UF by synchronous constrain by
Table 3: Results on constituency parsing task in
ranklossissmall,whereassynchronousconstrain
IWSLT’14 German to English (De→En). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 746>


<Paper ID = 746> <Table 2> <Abstractive Summary> =PositionalEmbedding 33.84 29.58 totheimprovementofAER,butsynchronouscon-
strainbyranklossconverselyworsenedAER.How-
Table 6: Results on IWSLT’14 German to English
ever, rank loss resulted in a signiﬁcant improve-
(De→En) and ASPEC Japanese to English (Ja→En)
ment AER in the third and fourth layers. </Abstractive Summary> <Extractive Summary> 4.3.1 TranslationTask
WereportunlabeledF-measure(UF)asthequality
Table 2 compares the performance of our meth-
ofEnglishlatentphrasestructures,inductedfrom
ods against baselines. Figure2showsexamplesofparsetreefromStan-
Although not shown in previous work (Htut
fordParserandourTransformerwithLSPI.Inthe
et al., 2019), Table 2 shows that the use of ex-
ﬁrst example ”a ﬂash of the human spirit”, our
plicit latent phrase structure is useful for the MT
modelalmostcorrectlyinductsphrasestructurein
task.  </Extractive Summary>  </Table 2>  </Paper ID = 746>


<Paper ID = 747> <Table 0> <Abstractive Summary> =assume its start and end positions equal to that of
[CLS]anddeﬁnethescoreasfollows:
Datasets argument SBJ OB1 OB2
arg arg ZPratio(%) 20.58 3.67 0.24
scorenull = pstart([CLS])·pend([CLS]) (3) NPCMJ ZPnumber 15,824 2,823 184
OntoNotes ZPratio(%) 21.59 0.05 0.00
There are two cases for score and
null 5.0 ZPnumber 29,195 61 1
score (ˆı,ˆ):
arg
Table 2: The ratio and the number of ZPs to queries
score score (ˆı,ˆ) (4)
null ≤ arg in train datasets of NPCMJ and Chinese subsets
score > score (ˆı,ˆ) (5) OntoNotes. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 747>


<Paper ID = 747> <Table 1> <Abstractive Summary> =In this example
ALL 88.3 80.5 81.0 80.4
sentence, the gold ZP class is the ﬁrst person
Table 5: Argument(Arg) span accuracy and ZP detec- “speaker”, but it is impossible to identify the ZP
tiononOntoNotes5.0.for“pro”class.TherowofALL without knowing the context before and after the
indiciataesthevalueforSBJ,OBJandIO2arguments. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 747>


<Paper ID = 748> <Table 0> <Abstractive Summary> =Table 1: Model setups. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 748>


<Paper ID = 75> <Table 0> <Abstractive Summary> =split we randomly assign 20% of the training set
913SCAN-SP CLEVR GEOQUERY
Model
IID RIGHT AROUNDRIGHT IID CLOSURE IID TEMPLATE LENGTH
dev test dev test dev test dev test dev test dev test dev test dev test
SEQ2SEQ 100 99.9 100 11.6 100 0.0 100 100 100 59.5 83.3 78.5 71.6 46.0 86.7 24.3
+ELMo 100 100 100 54.9 100 41.6 100 100 100 64.2 83.3 79.3 83.3 50.0 86.7 25.7
BERT2SEQ 99.9 100 99.9 77.7 99.9 95.3 100 100 100 56.4 88.3 81.1 85.0 49.6 90.0 26.1
GRAMMAR 100 100 100 0.0 100 4.2 100 100 100 51.3 78.3 72.1 76.7 54.0 81.7 24.6
BART 100 100 100 50.5 100 100 100 100 100 51.5 93.3 87.1 86.7 67.0 90.0 19.3
END2END - - - - - - 99.9 99.8 99.9 63.3 - - - - - -
SPANBASEDSP 100 100 100 100 100 100 97.0 96.7 98.9 98.8 88.3 86.1 93.3 82.2 95.0 63.6
-lexicon 100 100 100 100 100 100 99.4 99.3 98.5 88.6 88.3 78.9 86.7 65.9 90.0 41.4
-nonprojective - - - - - - - - - - 85.0 80.0 90.0 80.2 93.3 59.3
+goldtrees 100 100 100 100 100 100 100 96.8 100 96.7 91.2 86.4 100 81.8 96.7 68.6
Table 2: Denotation accuracies for all models, including SPANBASEDSP ablations. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 75>


<Paper ID = 75> <Table 1> <Abstractive Summary> =On the LENGTH GEOQUERY TEMPLATE 91.6
split, SPANBASEDSP yieldsanaccuracyof63.6, LENGTH 93.7
substantiallyoutperformingallbaselinesbymore
Table 3: F scores on the test set w.r.t to the semi-
than37accuracypoints. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 75>


<Paper ID = 751> <Table 0> <Abstractive Summary> =6POS Tagging Coarse-grained NER
Log-linear CRF DNN CRF DNN
EN ZH EN ZH EN ZH EN ZH EN ZH
F1 96.76 93.94 96.50 93.73 97.04 98.08 73.24 67.26 83.12 75.23
Sents/sec 3.9K 1.3K 149 1.1K 107
Table 3: Evaluation results for some POS Tagging and coarse-grained NER algorithms in TexSmart on
both English (EN) and Chinese (ZH) datasets. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 751>


<Paper ID = 751> <Table 1> <Abstractive Summary> =English Chinese
Algorithms Sents/Sec
MRPC QUORA LCQMC AFQMC BQ_CORPUS PAWS-zh
ESIM 861 - - 82.63 51.30 71.05 61.55
Linkage 1973 82.18 74.94 79.26 48.66 71.23 62.30
Table 4: Text matching evaluation results. </Abstractive Summary> <Extractive Summary> Table 1 shows the evaluation results of semantic
TheCRFalgorithmisonthehigh-speedside,while
expansion and ﬁne-grained NER.  </Extractive Summary>  </Table 1>  </Paper ID = 751>


<Paper ID = 752> <Table 0> <Abstractive Summary> =Assub-wordsegmentationisusedtotrainthe 2https://pytext.readthedocs.io/en/master/xlm r.html
14(WithPredictedQE) (WithOracleQE)
Model TER↓ BLEU↑ TER↓ BLEU↑
Baseline(MT) 31.37 50.37 31.37 50.37
XLM-R
(Conneauetal.,2020)
Top-1 30.28(-1.09) 50.78(+0.41) 26.57(-4.80) 56.02(+5.65)
Top-3 29.47(-1.90) 50.89(+0.52) 24.10(-7.27) 60.28(+9.91)
Top-5 28.75(-2.62) 51.85(+1.48) 22.78(-8.59) 62.40(+12.03)
Proposed
Top-1 29.04(-2.33) 51.93(+1.56) 24.26(-7.11) 59.38(+9.01)
Top-3 26.69(-4.68) 54.70(+4.33) 19.08(-12.29) 67.51(+17.14)
Top-5 25.36(-6.01) 56.52(+6.15) 17.30(-14.07) 70.50(+20.13)
Table 1: TER and BLEU for machine-translated sentences (Baseline) and post-edited sentences (XLM-R and
Proposed)basedonword-levelQEandtranslationsuggestion. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 752>


<Paper ID = 754> <Table 0> <Abstractive Summary> =considers the most probable token at each gener-
Inourexperiments,werunmodelswiththepa- ation step, the top-k search strategy means sort-
rameterconﬁgurationsdescribedintheiroriginal ing by probability and zero-ing out the probabili-
34Tasks Datasets Models Distinct-1 Distinct-2 BLEU-1 BLEU-2 BLEU-3 BLEU-4
LSTM-VAE - - 63.97 46.56 18.53 5.97
SeqGAN - - 99.76 82.32 51.26 25.18
Unconditional
COCO RankGAN - - 99.76 82.92 52.46 26.40
Generation
MailGAN - - 99.71 81.95 50.86 24.87
GPT-2 - - 88.15 78.13 55.81 31.88
Attribute-to-Text Context2Seq 0.07 0.39 17.21 2.80 0.83 0.43
AMAZON
Generation Attr2Seq 0.14 2.81 17.14 2.81 0.87 0.48
RNN+Attn 0.24 0.72 17.51 4.65 2.11 1.47
Dialogue Personal
Transformer 0.38 2.28 17.29 4.85 2.32 1.65
Systems Chat
HRED 0.22 0.63 17.29 4.72 2.20 1.60
Table 2: Performance comparisons of different methods for three tasks, i.e., unconditional generation, attribute-
to-text generation, and dialogue systems. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 754>


<Paper ID = 754> <Table 1> <Abstractive Summary> =Model Strategy BLEU2 BLEU3 BLEU4 Model ROUGE-1 ROUGE-2 ROUGE-L
Top-k 26.68 16.95 10.85 RNN+Attn 36.32 17.63 38.36
RNN+Attn Greedy 33.74 23.03 15.79 Transformer 36.21 17.64 38.10
Beam 35.68 24.94 17.42
BART 39.34 20.07 41.25
Top-k 30.96 20.83 14.16 BERT2BERT 38.16 18.89 40.06
Transformer Greedy 35.48 24.76 17.41 ProphetNet 38.49 18.41 39.84
Beam 36.88 26.10 18.54 T5 38.83 19.68 40.76
Table 3: Performance comparison of different genera- Table 4: Performance comparison of different genera-
tion models with three strategies for machine transla- tion models for text summarization. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 754>


<Paper ID = 757> <Table 0> <Abstractive Summary> =In detail, we removed all punctuations and
lowercasedthesentencesinthesourcesidewhile
3.1 Datasets
5https://github.com/alicank/
Wechoosethefollowingpubliclyavailablespeech
Translation-Augmented-LibriSpeech-Corpus
translationcorporathatincludespeechinasource 6https://ict.fbk.eu/must-c/
57Model tok detok
ESPnet-STASRtransf-s+CTC→MT(Inagumaetal.,2020)† - 17.0
Cascade
NeurSTASRtransf-s→MT 18.2 16.8
STBiLSTM(Baharetal.,2019) 17.0 16.2
STtransf-s(Liuetal.,2019) 14.3 -
STtransf-s+KD(Liuetal.,2019) 17.0 -
ESPnet-STSTtransf-s(Inagumaetal.,2020)† - 16.7
End-to-End TCEN-LSTM(Wangetal.,2020b)(cid:91) - 17.1
STtransf-s(Wangetal.,2020c) 16.0 -
STtransf-s+curriculumpre-training(Wangetal.,2020c) 17.7 -
LUT(Dongetal.,2021) 17.8 -
NeurSTSTtransf-s 18.7 17.2
Table 2: Case-insensitive BLEU scores on libri-trans test set under constrained setting (without additional ASR
andMTdata). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 757>


<Paper ID = 757> <Table 1> <Abstractive Summary> =Table 4: Case-sensitive BLEU scores on libri-trans
test set under constrained setting. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 757>


<Paper ID = 757> <Table 2> <Abstractive Summary> =22.8 -
we applied SpecAugment technique (Park et al.,
2019)withfrequencymasking(mF = 2,F = 27)
Table 6: Case-sensitive detokenized BLEU scores on
andtimemasking(mT = 2,T = 70,p = 0.2). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 757>


<Paper ID = 757> <Table 3> <Abstractive Summary> =8https://github.com/mjpost/sacrebleu md
59Model BLEU References
largeMT(w/punc.&cased) 36.2 Ebrahim Ansari, Amittai Axelrod, Nguyen Bach,
largeMT(w/opunc.&lc) 34.3
OndˇrejBojar,RoldanoCattoni,FahimDalvi,Nadir
largecascadeST 31.4
Durrani, Marcello Federico, Christian Federmann,
largeend-to-endST 29.7
JiataoGu,FeiHuang,KevinKnight,XutaiMa,Ajay
Nagesh,MatteoNegri,JanNiehues,JuanPino,Eliz-
Table 7: Case-sensitive detokenized BLEU scores on
abeth Salesky, Xing Shi, Sebastian Stu¨ker, Marco
MuST-CEN-DEtst-COMMON. </Abstractive Summary> <Extractive Summary> In or- Table 3 illustrates the results on MuST-C tst-
der to compare with existing works, we also COMMON.Theresultsofourend-to-endSTmodel
report case-insensitive tokenized BLEU using arecompetitivewithbothfairseq-ST andESPnet-
multi-bleu.perl in Moses for libri-trans ST.
dataset.  </Extractive Summary>  </Table 3>  </Paper ID = 757>


<Paper ID = 758> <Table 0> <Abstractive Summary> =It
Overall 726 containsstrongopinionsandworldviews(e.g.,on
divorceandhomosexuality)thatarenotgenerally
Table 2: Runtime in seconds for each part of the
shared. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 758>


<Paper ID = 759> <Table 0> <Abstractive Summary> =Recently, several meth-
System Y makes substantial gain over System X. odshavebeenproposedtoimprovethetranslation
76Table 1: Example of named entity errors produced Online-G system in comparison to the PROMT system from
theWMT20sharedtask. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 759>


<Paper ID = 76> <Table 0> <Abstractive Summary> =Ouralgo-
[1] [2]
selectridfromNT wherename="NT "(cid:105)
[1] [2] rithmiterativelyidentiﬁesarulethatcanbeadded
to G that decreases our codelength objective by
Table 1: Examples of induced QCFG rules. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 76>


<Paper ID = 76> <Table 1> <Abstractive Summary> =(Russinetal.,2019) 91.0 99.9 15.2 2.9 77.5 70.6 23.6 0.0 3.9
CGPS(Lietal.,2019) 98.8 99.7 20.3 2.0 62.1 32.8 9.3 32.3 4.4
GECA(Andreas,2020) 87.0 — — — 78.0† — — — —
SBSP(HerzigandBerant,2020) 100 100 100 100 86.1† — — — —
SBSP −lexicon 100 100 100 100 78.9† — — — —
T5-Base(Raffeletal.,2020) 99.5 62.0 14.4 15.4 92.9 87.0 39.1 54.3 2.9
T5-3B(Raffeletal.,2020) 99.0 65.1 3.3 11.6 93.2 83.1 36.8 51.6 —
NQG-T5-Base 100 100 100 100 92.9 88.8 52.2 56.6 1.0
NQG-T5-3B 100 100 100 100 93.7 85.0 51.4 54.1 —
NQG 100 100 100 100 76.8 61.9 37.4 41.1 2.3
Table 2: Main Results. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 76>


<Paper ID = 760> <Table 0> <Abstractive Summary> =C5:Metainfo 0.662±0.029 0.591±0.056
Ensemblemodel 0.708±0.036 0.679±0.032
Table 2: Performance (mean ± standard deviation) of To measure to what extent a model is gender
theriskclassiﬁers,averagedover10randomsplits. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 760>


<Paper ID = 761> <Table 0> <Abstractive Summary> =Asaprogrammingframework,CogIEsupports96 different tasks and deploy pre-trained models forTask Corpus Language Types Metric Score
WordSegmentation MSRA Chinese - F 91.2
1
CoNLL2003 English 4 F 91.4
1
NamedEntityRecognition OntoNotes5.0 English 18 F 85.6
1
OntoNotes4.0 Chinese 4 F 80.0
1
EntityTyping BBN English 47 F 75.5
1
KBP37 English 37 F 69.9
1
RelationExtraction
DuIE Chinese 48 F 93.0
1
Trigger 33 F 68.9
1
ACE2005 English
Argument 35 F 46.4
1
EventExtraction
Trigger 33 F 58.8
1
ACE2005 Chinese
Argument 35 F 52.8
1
Frame 749 Acc 91.0
Frame-SemanticParsing Frame1.5 English
Element 816 F 56.4
1
Table 1: Performance of each task. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 761>


<Paper ID = 762> <Table 0> <Abstractive Summary> =Table 3: Speed test for fastHan. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 762>


<Paper ID = 764> <Table 0> <Abstractive Summary> =Table2: Entitystatistics Table 4: Explanations for the BERT paper (Devlin
etal.,2019)giventhreedifferentqueries:BERT,Trans-
Statistics Quantity former,andSQuAD. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 764>


<Paper ID = 77> <Table 0> <Abstractive Summary> =Human RTs are at or below chance for RNNG 0.65 < 0.01
3/4oftheReﬂexiveAnaphoraagreementtestsand
theSubject-VerbNumberAgreementwithanOb-
Table 2: Correlations between model accuracy scores
ject Relative Clause modiﬁer. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 77>


<Paper ID = 772> <Table 0> <Abstractive Summary> =We collect
PolicyMetrics Accuracy,Hit@{1,3,5}
commonlyusedfunctionsinvariousmodels(e.g.,
CNN, RNN and Transformer layers) to constitute
Table 3: The implemented automatic evaluation met-
ricsinCRSLab. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 772>


<Paper ID = 778> <Table 0> <Abstractive Summary> =For tra- ProphetNet-Dialog-Zh 23,309,502 6,985,425
ditional Chinese data, we ﬁrstly use OpenCC 3
Table 2: Statistics of Chinese Dialog pre-training cor-
to convert them to simpliﬁed Chinese. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 778>


<Paper ID = 778> <Table 1> <Abstractive Summary> =In other words, for
3https://github.com/BYVoid/OpenCC
4https://github.com/google/sentencepiece maximum 512 encoder sequence length, totally
5https://www.douban.com/group 8(spans) × 9(tokens per span) = 72 tokens
234MATINF-QA MATINF-SUMM LCSTS
Method
R-1 R-2 R-L R-1 R-2 R-L R-1 R-2 R-L
TextRank(MihalceaandTarau,2004) - - - 35.53 25.78 36.84 24.38 11.97 16.76
LexRank(ErkanandRadev,2004) - - - 33.08 23.31 34.96 22.15 10.14 14.65
Seq2Seq(Sutskeveretal.,2014) 16.62 4.53 10.37 23.05 11.44 19.55 - - -
Seq2Seq+Att(Luongetal.,2015) 19.62 5.87 13.34 43.05 28.03 38.58 33.80 23.10 32.50
WEAN(Maetal.,2018) - - - 34.63 22.56 28.92 37.80 25.60 35.20
GlobalEncoding(Linetal.,2018) - - - 49.28 34.14 47.64 39.40 26.90 36.50
BertAbs(LiuandLapata,2019) - - - 57.31 44.05 55.93 - - -
MTF-S2S (Xuetal.,2020a) 20.28 5.94 13.52 43.02 28.05 38.55 33.75 23.20 32.51
single
MTF-S2S (Xuetal.,2020a) 21.66 6.58 14.26 48.59 35.69 43.28 - - -
multi
ProphetNet-Zh 24.18 6.38 15.47 58.82 44.96 54.26 42.32 27.33 37.08
Table 3: Results of ProphetNet-Zh on MATINF-QA, MATINF-SUMM, and LCSTS. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 778>


<Paper ID = 778> <Table 2> <Abstractive Summary> =Task Model De En Es Fr It Pt Ru AVG
M-BERT(Devlinetal.,2018) 0.1 7.8 0.1 0.1 0.2 0.1 - 1.4
XLM-R (Conneauetal.,2019) 0.1 6.0 0.0 0.0 0.1 0.0 - 1.0
base
QG Unicoder (Liangetal.,2020) 3.0 14.0 12.4 4.2 15.8 8.3 - 9.6
DAE
Unicoder (Liangetal.,2020) 3.7 13.9 14.8 4.9 17.0 9.5 - 10.6
FNP
ProphetNet-Multi 4.9 14.9 17.0 6.0 19.2 11.3 - 12.2
M-BERT(Devlinetal.,2018) 0.7 9.0 0.4 0.4 - - 0.0 2.1
XLM-R (Conneauetal.,2019) 0.6 8.1 0.4 0.3 - - 0.0 1.9
base
NTG Unicoder (Liangetal.,2020) 6.8 15.6 9.0 8.7 - - 7.7 9.6
DAE
Unicoder (Liangetal.,2020) 7.5 15.8 11.9 9.9 - - 8.4 10.7
FNP
ProphetNet-Multi 8.7 16.7 12.7 11.4 - - 8.5 11.6
Table 4: Results of ProphetNet-Multi on XGLUE zero-shot cross-lingual generation task. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 778>


<Paper ID = 778> <Table 3> <Abstractive Summary> =DailyDialog PersonaChat
Model
B-1 B-2 D-1 D-2 AVG B-1 B-2 D-1 D-2 AVG
Seq2Seq(VinyalsandLe,2015) 0.336 0.238 0.03 0.128 0.183 0.448 0.353 0.004 0.016 0.205
iVAE MI(Fangetal.,2019) 0.309 0.249 0.029 0.25 0.209 - - - - -
LIC(Golovanovetal.,2019) - - - - - 0.405 0.320 0.019 0.113 0.214
PLATOw/olatent(Baoetal.,2020) 0.405 0.322 0.046 0.246 0.255 0.458 0.357 0.012 0.064 0.223
PLATO(Baoetal.,2020) 0.397 0.311 0.053 0.291 0.263 0.406 0.315 0.021 0.121 0.216
ProphetNet-Dialog-En 0.461 0.402 0.038 0.208 0.277 0.459 0.382 0.010 0.060 0.228
Table 6: Results of ProphetNet-Dialog-En on DailyDialog and PersonaChat. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 778>


<Paper ID = 778> <Table 4> <Abstractive Summary> =Wesee Table 7: Results of ProphetNet-Dialog-Zh on STC
consistentgainsonbothChinesequestionanswer- dataset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 4>  </Paper ID = 778>


<Paper ID = 778> <Table 5> <Abstractive Summary> =Com-
paringtheresultsbetweentheUnicoder and
FNP Table 8: Human evaluated results for ProphetNet-
ProphetNet-Multi, we see that more pre-training Dialog-Zh on real-world Xiaoice dataset. </Abstractive Summary> <Extractive Summary> ForEnglishopen-domaindialoggeneration,we
show the results in Table 5 and Table 6, com-
paredwithstrongnewproposedPLATO(Baoetal., generateﬂuentandmeaningfulresponsesbuthave
2020),weseethatProphetNet-Dialogachievesper- lower BLEU scores because of the writing style
formanceimprovements.  </Extractive Summary>  </Table 5>  </Paper ID = 778>


<Paper ID = 778> <Table 6> <Abstractive Summary> =CNN/DM Gigaword MSNews
Method
R-1 R-2 R-L R-1 R-2 R-L R-1 R-2 R-L
LSTM(Bahdanauetal.,2014) 37.3 15.7 34.4 33.6 15.4 31.2 30.0 14.6 27.7
Transformer(Vaswanietal.,2017) 39.5 16.7 36.7 36.4 17.7 33.8 33.0 15.4 30.0
MASS(Songetal.,2019) 42.9 19.8 39.8 38.9 20.2 36.2 40.4 21.5 36.8
BART(Lewisetal.,2019) 44.1 21.2 40.9 37.5 17.6 34.3 43.8 24.0 39.2
ProphetNet-En 44.2 21.1 41.3 39.5 20.4 36.6 44.1 24.4 40.2
Table 10: Results of ProphetNet-En for text summarization. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 6>  </Paper ID = 778>


<Paper ID = 778> <Table 7> <Abstractive Summary> =Table 11: Results of ProphetNet-En for question gen-
eration on SQuAD1.1 and MSQG. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 7>  </Paper ID = 778>


<Paper ID = 78> <Table 0> <Abstractive Summary> =Aninterestingexampleis
Table 7: Replicating the Setup of Marasovic´ and Frank
(2016)ontheGMEData.ResultsdropforGMEwhenusing thefollowingsentence,withmodaltriggersinbold
onlysentenceswithmodalverbs(MV),andevenfurtherwhen (senseinbrackets): "Howcan(Plausibility),under
usingallofGME’ssentences(namelywithallmodaltriggers). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 78>


<Paper ID = 78> <Table 1> <Abstractive Summary> =960F1 No-Head Head Head Joint F1 No Trigger Trigger Joint
Gold Predict Trigger Gold Predict Joint
Modal/Not-Modal 73.2 87.6 69.4 73.3 Modal/Not 51.1 71.13 53.55 50.05
Coarse-Grained 68.9 79.8 63.2 67.3 Span Coarse-Grained 51.1 70.91 53.56 49.85
Fine-Grained 58.14 66.7 52.1 56.0 Fine-Grained 51.1 70.38 53.09 48.24
Modal/Not 56.3 72.3 55.8 56.9
Table 8: Modal Trigger Tagging Results, F1 on Detected Head Coarse-Grained 56.3 71.6 56.0 60.7
Spans,withandwithoutEventHeadInformation. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 78>


<Paper ID = 78> <Table 2> <Abstractive Summary> =Fine-Grained 56.3 70.9 55.2 55.3
Table 9: Event Detection Results, F1 on Detected Spans,
withandwithoutModalTriggerInformation. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 78>


<Paper ID = 782> <Table 0> <Abstractive Summary> =Call for Papers (CFPs) by various confer-
Others 7,623
ences and workshops: Users can view the TotalTweets 19,395
announcements for call for papers and sub-
Table 1: Distribution of tweets (curated since October
missiondeadlinesbyvariousworkshopsand
2017)intovarioustopics. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 782>


<Paper ID = 783> <Table 0> <Abstractive Summary> =To col­ python/index.html
276BLEU HumanRating
Model QE Chr­En En­Chr Chr­En En­Chr
Supervised XGBoost 0.75 0.71 0.63 0.44
SMT TranslationModel/length 0.36 0.46 0.07 ­0.09
Unsupervised LM/length 0.34 0.43 ­0.11 0.11
PhrasePenalty/length ­0.33 ­0.52 0.06 0.03
Supervised XGBoost 0.79 0.68 0.53 0.38
NMT(ensemble)
Exp(LogProbability/length) 0.75 0.63 0.59 0.44
Unsupervised
LogProbability/length 0.45 0.50 0.37 0.52
Table 1: Pearson correlation coefficients between QE and BLEU or between QE and human rating. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 783>


<Paper ID = 784> <Table 0> <Abstractive Summary> =TheEXPLAINABOARD TextGeneration
Translation 4 60 9
currentlyincludesfourconcretetasks: nameden-
tityrecognition(TjongKimSangandDeMeulder,
Table 2: Brief descriptions of tasks, datasets and sys-
2003), part-of-speech tagging (Toutanova et al., temsthatEXPLAINABOARDcurrentlysupports.“Attr.”
2003),textchunking(AndoandZhang,2005),and denotesAttribute. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 784>


<Paper ID = 788> <Table 0> <Abstractive Summary> =©2021AssociationforComputationalLinguisticsDialCrowd ParlAI
Toolkit LEGOEval Mephisto
(Leeetal.,2018) (Milleretal.,2018)
SampleTemplates (cid:51) (cid:51) (cid:51) (cid:51)
FlexibleInterfaceDesign (cid:51) (cid:55) (cid:55) (cid:55)
BranchingLogic (cid:51) (cid:55) (cid:55) (cid:55)
Plug&Play (cid:51) (cid:55) (cid:55) (cid:51)
DataReviewingTool (cid:51) (cid:51) (cid:55) (cid:51)
Table 1: Comparison of related crowdsourcing tools. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 788>


<Paper ID = 788> <Table 1> <Abstractive Summary> =Table 2: Human-Chat ACUTE-Eval of engagingness use. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 788>


<Paper ID = 788> <Table 2> <Abstractive Summary> =Table 3: One example conversation between Blender-
BotandhumancollectedbyLEGOEval. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 788>


<Paper ID = 789> <Table 0> <Abstractive Summary> =rel→relation instantiatearelationinI
set→type instantiateatypeinI Whenpredictingak,theprobabilityofselecting
ent→entity|literal instantiateanentityorliteralinI
theactionγ follows:
num→literal instantiateagrammarruleforanyliteralinI
Table 1: Knowledge-agnostic (Top) and knowledge- P(a =γ)∝exp(cid:0)φa(γ)tanh([h−→D;c ]Wo)(cid:1), (3)
speciﬁc(Bottom)grammarruledeﬁnitionsusedinour k k k
grammar-baseddecoder. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 789>


<Paper ID = 789> <Table 1> <Abstractive Summary> =Precision Recall F1 100.0
Prior 81.2 81.7 81.4 90.0
BOOTLEG 58.3 58.6 58.5
80.0
BOOTLEG+Prior 82.8 83.3 83.1
70.0
Table 6: Entity linking performance (set level metric
60.0
P/R/F1)onWebQSPtestset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 789>


<Paper ID = 79> <Table 0> <Abstractive Summary> =AllmodelshavebeentrainedonanNVIDIA
8https://digital.library.unt.edu/ (1) a. INPUT1: t a x e s
explore/collections/MDR
9https://www.sil.org/resources/search/ b. INPUT2/3: t a x e s N
language/ntu
10https://fairseq.readthedocs.io/en/ c. OUTPUT: tax#levy -es#PL
latest/
970Language 1% 3% 6.5% 10% 20% 30% 40% 100%
Alas .00 .02 .02 .03 .05 .05 .04 -.09
Lamkang .05 .08 .07 .07 .08 .08 .08 -.01
Lezgi .03 -.01 .02 .04 .03 .03 .03 .02
Manipuri -.01 .00 .01 .00 .00 .01 .00 .00
Natu¨gu .01 .03 .02 .03 .02 .03 .04 .00
Table 3: The difference in F scores with/out POS tags when training segmentation and glossing on increasing
1
amounts of annotated data, as percentages of total available training data. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 79>


<Paper ID = 793> <Table 0> <Abstractive Summary> =©2021AssociationforComputationalLinguisticsModel Accessibility Perturbation MainIdea
SEA(Ribeiroetal.,2018) Decision Sentence Rule-basedparaphrasing
SCPN(Iyyeretal.,2018) Blind Sentence Paraphrasing
GAN(Zhaoetal.,2018) Decision Sentence Textgenerationbyencoder-decoder
TextFooler(Jinetal.,2020) Score Word Greedywordsubstitution
PWWS(Renetal.,2019) Score Word Greedywordsubstitution
Genetic(Alzantotetal.,2018) Score Word Geneticalgorithm-basedwordsubstitution
SememePSO(Zangetal.,2020) Score Word Particleswarmoptimization-basedwordsubstitution
BERT-ATTACK(Lietal.,2020) Score Word Greedycontextualizedwordsubstitution
BAE(GargandRamakrishnan,2020) Score Word Greedycontextualizedwordsubstitutionandinsertion
FD(Papernotetal.,2016b) Gradient Word Gradient-basedwordsubstitution
TextBugger(Lietal.,2019) Gradient,Score Word+Char Greedywordsubstitutionandcharactermanipulation
UAT(Wallaceetal.,2019a) Gradient Word,Char Gradient-basedwordorcharactermanipulation
HotFlip(Ebrahimietal.,2018) Gradient Word,Char Gradient-basedwordorcharactersubstitution
VIPER(Egeretal.,2019) Blind Char Visuallysimilarcharactersubstitution
DeepWordBug(Gaoetal.,2018) Score Char Greedycharactermanipulation
Table 1: Textual adversarial attack models involved in OpenAttack, among which the three sentence-level
models SEA, SCPN and GAN together with FD, UAT and VIPER are not included in TextAttack for now. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 793>


<Paper ID = 793> <Table 1> <Abstractive Summary> =Efﬁciency AverageRunningTime Lower
Table 2: Evaluation metrics in OpenAttack. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 793>


<Paper ID = 793> <Table 2> <Abstractive Summary> =tomizationofattackmodelsthankstoitsinclusive
367Type Effectiveness AdversarialExampleQuality AttackEfﬁciency
Model
Accessibility Perturbation ASR WMR LES SemSim Fluency Grm #Query T1 T2 S
SEA Decision Sentence 0.12 – 14.7 0.90 398 2.2 2.0 37.1 – –
SCPN Blind Sentence 0.68 – 55.6 0.56 432 2.7 11.0 3.58 2.30 1.56
GAN Decision Sentence 0.41 – 68.8 0.26 512 4.2 2.0 0.60 2.00 0.30
TextFooler Score Word 0.90 0.11 14.1 0.87 621 4.6 130.5 5.75 3.25 1.77
PWWS Score Word 0.78 0.20 17.9 0.84 613 2.9 124.8 5.26 2.88 1.83
Genetic Score Word 0.36 0.11 13.4 0.88 689 4.7 242.1 54.11 27.56 1.96
SememePSO Score Word 0.82 0.14 2.9 0.89 711 2.9 177.9 102.44 52.41 1.95
BERT-ATTACK Score Word 0.87 0.31 4.2 0.86 796 4.4 51.9 2.38 1.57 1.51
BAE Score Word 0.77 0.68 5.4 0.82 1147 4.3 103.0 2.97 1.79 1.66
FD Gradient Word 0.16 0.24 17.9 0.85 908 3.1 10.9 34.57 28.36 1.22
TextBugger Gradient Word+Char 0.25 0.15 10.6 0.61 512 7.1 150.0 8.49 4.37 1.94
UAT Gradient Word 0.43 0.15 24.0 0.85 620 2.8 2.0 0.08 – –
HotFlip Gradient Word 0.47 0.08 8.9 0.93 333 2.7 105.4 2.77 1.82 1.52
VIPER Blind Char 0.27 – 24.2 0.22 347 15.8 3.0 4.01 2.04 1.97
DeepWordBug Score Char 0.46 – 7.9 0.73 731 6.1 22.0 0.97 0.62 1.56
Table 3: Evaluation results of different attack models when attacking BERT on SST-2. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 793>


<Paper ID = 8> <Table 0> <Abstractive Summary> =3https://www.wikidata.org/wiki/Wikidata:MainPage
84Table 1: The statistics of the training and test set in
PENS.“wd.” inthetablemeansword. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 8>


<Paper ID = 80> <Table 0> <Abstractive Summary> =(2019) in training each Table 2: F1 Tperformance of the text-only and
model10timeswithdifferentrandomseeds. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 80>


<Paper ID = 80> <Table 1> <Abstractive Summary> =Segmentation Parsing
Precision Recall F1 F1
Textonly 78.84 68.61 73.31 82.73
Pipeline
Text+prosody 99.96 99.45 99.71 90.89
Textonly 55.01 75.78 63.74 86.09
E2E
Text+prosody 99.41 99.41 99.41 90.90
Table 3: Development set performance of the pipeline model on segmentation and parsing as compared to the
end-to-endmodel. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 80>


<Paper ID = 80> <Table 2> <Abstractive Summary> =Pauseonly 86.21 90.09 84.32
These results largely concur with previous work
Table 4: F1 for the text and text+prosody turn-based describingthesimilaritiesanddifferencesbetween
modelswhentestedontheentiredevelopmentset,the prosodic features of disﬂuencies and SU bound-
subsetofthedevelopmentsetconsistingofonlyﬂuent aries(Shriberg,2001;WagnerandWatson,2010). </Abstractive Summary> <Extractive Summary> Table 2 shows this
formancedescribedinTranetal.  </Extractive Summary>  </Table 2>  </Paper ID = 80>


<Paper ID = 80> <Table 3> <Abstractive Summary> =Meanwhile, the log-pitch with
Noprosodicfeatures 86.09(*)
POV-weighted mean subtraction is signiﬁcantly
loweratinterruptionpointsthanatSUboundaries Table 6: Results of ablation testing, measured by F1
(p < 0.01). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 80>


<Paper ID = 80> <Table 4> <Abstractive Summary> =96
S (i,k,j) = S (i,k)+S (k,j)
split span span
Table 7: Model hyperparameters. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 4>  </Paper ID = 80>


<Paper ID = 81> <Table 0> <Abstractive Summary> =Inthefollowingpart,wereferto
theoriginalspeechas“sourcespeech”andtothe Table 1: Statistics for unlabeled (“Unlab.”) and tran-
interpretedoneas“targetspeech”. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 81>


<Paper ID = 81> <Table 1> <Abstractive Summary> =We leverage
994Target(OralInterpretation)
Source
En De Fr Es Pl It Ro Hu Cs Nl Fi Sk Sl Lt Da Total
En - 463 427 441 432 461 457 382 427 400 442 433 434 398 370 6.0K
De 187 - 196 204 214 217 198 205 214 196 217 208 218 164 179 2.8K
Fr 169 187 - 187 172 197 195 144 170 158 168 168 156 139 134 2.3K
Es 130 138 135 - 118 148 128 93 118 115 124 114 108 83 86 1.6K
Pl 68 66 54 55 - 67 55 43 67 42 55 62 57 50 34 775
It 69 77 76 79 72 - 75 61 68 64 71 66 70 53 60 961
Ro 60 59 59 58 49 61 - 38 50 43 48 50 46 38 29 688
Hu 30 38 25 27 29 30 27 - 27 20 31 29 26 21 18 378
Cs 39 35 29 30 36 32 31 23 - 23 29 55 29 25 18 434
Nl 31 43 35 29 27 38 24 25 25 - 32 25 23 19 25 401
Fi 15 18 15 13 13 13 13 12 13 11 - 14 12 11 9 182
Hr 31 27 27 24 27 28 24 22 24 22 24 26 37 21 20 384
Sk 21 22 14 16 19 16 16 14 32 13 16 - 17 13 10 239
Sl 6 6 4 5 5 6 5 4 5 4 5 6 - 4 3 68
Lt 1 1 1 1 1 1 1 1 1 1 1 1 1 - 0 13
Total 857 1.2K 1.1K 1.2K 1.2K 1.3K 1.2K 1.1K 1.2K 1.1K 1.3K 1.3K 1.2K 1.0K 995 17.3K
Table 2: Duration statistics (hours) of aligned speech-to-speech data in VoxPopuli between 15 source languages
and15targetlanguages. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 81>


<Paper ID = 81> <Table 2> <Abstractive Summary> =Transcribedspeech TheVoxPopulitranscribed
Table 3: An example from VoxPopuli for interpretese
data contains 16 languages totaling 1.8K hours
vs.translationese.Translationeseisverbatimandexact,
and 4.3K speakers, whose detailed statistics can
whileinterpretesetendstobemoregeneralandsumma-
rizingwithunimportantdetailsdropped. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 81>


<Paper ID = 81> <Table 3> <Abstractive Summary> =Dev 30.1 29.0 41.6 28.6 27.4 27.1 28.5 27.4 35.7 27.8 95.7 45.7 44.9 30.2 37.1
baseline Test 30.0 29.3 45.2 30.5 31.4 25.6 27.7 27.9 38.3 27.7 96.5 41.6 40.2 32.7 37.5
VP-10K Dev 15.5 17.2 19.1 13.9 8.6 12.8 8.3 11.5 18.5 11.1 20.6 21.1 15.6 10.4 14.6
+FT Test 16.2 16.2 21.5 15.4 11.0 12.5 9.4 12.0 19.7 11.8 26.1 17.1 14.1 11.1 15.3
Table 4: VoxPopuli ASR baselines and in-domain unsupervised pre-training. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 81>


<Paper ID = 81> <Table 4> <Abstractive Summary> =En+Fr-500 6.9/9.8 9.0/13.1 8.6/9.6 0.9/1.6
For non-wav2vec models, we extract 80-
Table 5: Phoneme discriminability of unsupervised dimensional log-mel ﬁlterbank speech features
features across languages. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 4>  </Paper ID = 81>


<Paper ID = 81> <Table 5> <Abstractive Summary> =PER
Domain Hours In Out Es Fr It Nl Sv Ky Ru Tr Tt Zh Avg.↓ Std.↓
m-CPC† Out 60K 0 1 36.4 44.3 37.8 43.1 46.5 37.5 42.4 45.7 40.6 53.2 42.7 4.8
wav2vec2.0Base(95M)
XLSR-Mono‡ In <0.4K 1 0 6.8 10.4 10.9 37.4 63.6 29.6 11.6 44.0 21.4 31.4 26.7 17.2
XLSR-10‡ In 1.4K 10 1 9.4 13.4 13.8 16.3 21.0 8.6 11.2 11.7 8.3 24.5 13.8 5.1
VP-Mono-5K Out 4.5K 1 0 6.8 8.6 7.5 9.7 9.3 - - - - - - -
VP-10K Out 10K 5 18 8.5 11.9 11.0 13.6 15.0 10.9 12.4 13.1 8.8 19.3 12.5 3.0
VP-100K Out 100K 5 18 7.6 10.3 9.7 12.2 13.0 9.4 10.7 11.7 8.0 17.5 11.0 2.7
wav2vec2.0Large(317M)
XLSR-10‡ In 1.4K 10 1 7.9 12.6 11.7 14.0 20.6 7.0 9.3 9.7 7.2 22.8 12.3 5.2
XLSR-53‡ In+Out 56K 10 43 2.9 5.0 6.7 5.8 12.2 6.1 8.1 7.1 5.1 18.3 7.6 4.2
VP-Mono-5K Out 4.5K 1 0 5.5 7.0 6.1 7.2 6.3 - - - - - - -
VP-10K Out 10K 5 18 6.3 8.9 7.9 9.3 9.7 9.3 9.2 11.3 7.6 18.8 9.8 3.2
VP-100K Out 100K 5 18 5.4 7.7 6.5 8.0 8.3 8.5 8.0 9.8 6.9 17.3 8.6 3.1
Table 6: Few-shot ASR with out-of-domain out-of-language unsupervised pre-training. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 5>  </Paper ID = 81>


<Paper ID = 81> <Table 6> <Abstractive Summary> =across languages and are more robust on unseen
998Fr→En↑ Es→En↑ De→En↑ Fr↓ Es↓ De↓
Trainhours(EP+CV) 38+264 32+113 42+184 38+264 32+113 42+184
Testset EP CV EP CV EP CV EP CV EP CV EP CV
(Cascaded)Baseline† 25.4 27.6 26.5 27.4 21.3 21.0 24.3 18.3 15.0 21.4 19.8 16.0
Ourend-to-endbaseline 24.5 27.0 20.5 26.6 17.5 20.0 20.8 18.8 17.2 14.1 23.2 18.4
With800hself-training 26.7 28.6 22.4 26.8 18.8 20.1 19.5 17.3 15.6 13.7 21.8 17.5
With3000hself-training 27.4 28.9 22.7 27.3 19.6 20.0 19.0 17.0 15.3 13.2 21.4 17.3
400hweaklylabeled 22.9 10.1 22.2 10.9 18.0 8.8
+labeled 31.1 30.3 28.4 29.7 24.4 23.4
Table 8: ST and ASR using VoxPopuli data for self-training or weak supervision. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 6>  </Paper ID = 81>


<Paper ID = 810> <Table 0> <Abstractive Summary> =B-trigger,I-triggerandO)andeach
Table 1: Distribution of event triggers and arguments. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 810>


<Paper ID = 810> <Table 1> <Abstractive Summary> =13Model InputFormat Overall Triggers Arguments
P R F1 P R F1 P R F1
BERT Document 51.524.20 42.684.98 46.231.98 78.974.32 63.724.76 70.251.87 31.5017.54 29.6116.09 29.9416.49
NEWS-BERT Document 36.113.77 33.637.79 34.183.48 69.965.18 52.0010.32 58.875.41 22.614.69 20.969.62 19.966.95
PROTEST-ER Document 54.563.18 48.473.69 51.110.87 70.481.35 67.903.51 69.081.24 37.5920.28 40.2017.91 37.8618.42
BERT Sentence 32.856.27 25.186.61 27.414.19 80.015.98 29.3013.03 41.1612.81 18.9515.46 22.7917.38 19.7415.43
NEWS-BERT Sentence 52.868.83 10.761.94 17.672.32 92.921.84 9.833.08 18.245.90 29.476.16 10.151.12 14.460.85
PROTEST-ER Sentence 49.911.99 54.130.63 51.910.97 77.631.41 68.931.75 72.990.80 39.8217.61 46.1317.86 41.9817.26
BestCLEF2019 Sentence 66.20 55.67 60.48 79.79 69.77 74.44 56.55 48.66 51.54
Table 3: India data (source). </Abstractive Summary> <Extractive Summary> Were- News has 5 times less triggers and 4 times less
port in Table 1 the distribution of the markables arguments.2 Unlike ACE, event triggers are not
(eventtriggersandarguments)foreventextraction further classiﬁed into subtypes.  </Extractive Summary>  </Table 1>  </Paper ID = 810>


<Paper ID = 810> <Table 2> <Abstractive Summary> =Model InputFormat Overall Triggers Arguments
P R F1 P R F1 P R F1
PROTEST-ER Document 64.485.01 36.532.76 46.391.02 74.074.74 69.305.66 71.231.05 42.7018.68 20.1114.83 25.1914.71
PROTEST-ER Sentence 52.625.34 39.183.25 44.621.97 74.083.20 64.867.44 68.732.75 39.0616.03 23.5611.99 27.0211.81
BestCLEF2019 Sentence 62.65 46.24 53.21 77.27 70.83 73.91 49.64 33.57 39.56
Table 4: China data (target). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 810>


<Paper ID = 810> <Table 3> <Abstractive Summary> =We use
thefulltext,includingthetitle,ofeachnewsarti- Table 7: Hyperparameter conﬁguration used for task
cle. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 810>


<Paper ID = 811> <Table 0> <Abstractive Summary> =We compare our
TextRank@k=1 65.63 50.33 56.97 ﬁnalframeworkwiththreebaselinemodels:
TextRank@k=2 66.59 51.18 57.87
• GiveMe5W1H(Hamborgetal.,2019): isan
BiasedTRank@k=1 70.48 56.73 62.86
unsupervised approach for extracting docu-
BiasedTRank@k=2 60.48 68.91 64.42
ment level phrases related to the six 5W1H
ArgFuse 67.98 64.90 66.40
questions(what,where,when,who,why,and
Table 2: Comparison of our models with the deﬁned how) from English News Articles. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 811>


<Paper ID = 813> <Table 0> <Abstractive Summary> =46Keyword p-value F-statistic
DistributionofProtestWordOccurrences
democracy 7.4e-103 490.5 cle15
protest 5.3e-76 354.6 Arti
protests 4.2e-65 300.6 Per10
s
freedom 3.2e-31 137.2 unt
o
occupation 1.9e-27 119.4 C 5
d
crackdown 5.8e-17 70.6 or
w
y
confrontation 1.4e-15 64.1 Ke 0
tension 1.5e-15 64.0 non-western western
SourceLocation
resistance 3.8e-12 48.4
confront 3.4e-08 30.5
riot 1.9e-07 27.2 Figure2: Quantileplotof“Protest”CountsPerSource
Location
unrest 7.3e-06 20.1
rights 2.6e-05 17.6
freedom of speech 6.8e-04 11.5 DistributionofProtestsWordOccurrences
independence 7.2e-04 11.4 e
cl
severe 1.3e-02 6.1 Arti15
rule of law 2.3e-01 1.4 er
P
terrorist 4.9e-01 0.4 nts10
u
terrorism 5.2e-01 0.4 o
C
d 5
or
w
Table 1: ANOVA of 19 selected keywords’ frequency y
betweenWestern-basedandHongKong–basedarticles. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 813>


<Paper ID = 815> <Table 0> <Abstractive Summary> =Due to absence
of event annotated datasets for industrial inci- Table 1: Sample Incident Report summary from Con-
dentsweemployatransferlearningbasedap- structionDomain
proach which is shown to outperform several
baselines.Wefurtherprovidedetailedanalysis
regardingeffectofincreaseinpre-trainingdata purpose, they carry out detailed investigations of
andprovideexplainabilityofwhypre-training incidentsthathavepreviouslyoccurredtoidentify
improvestheperformance. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 815>


<Paper ID = 816> <Table 0> <Abstractive Summary> =URL *  URL of the article  Text  
Inspired by the gating mechanism introduced in 
Publication  Publication time as  Integer  
(Wang et al., 2018), we first take each feature from 
timestamp*  unix timestamp 
the non-lexical data (nu and c) and combine them 
Tweet ID *  ID of tweet   Integer 
using a gating mechanism to produce a new non- Embedded  Raw data from  Text  
lexical vector h, as shown in Equation (1):  tweet*  tweets (on news)  
ℎ =𝑔 ⊙(𝑊𝑐)+𝑔 ⊙(𝑊 𝑛𝑢)+𝑏 (1) 
𝑐 𝑐 𝑛𝑢 𝑛𝑢 ℎ  Table 1:  Dataset features, * is side information 
where c is categorical feature, nu is numerical 
feature, W denotes a weight matrix, 𝑏  denotes a  3  Experiment 
scalar bias, and 𝑔   and 𝑔   are the gating vector 
𝑐 𝑛𝑢
for c and nu respectively. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 816>


<Paper ID = 816> <Table 1> <Abstractive Summary> =The sequences are 
created  in  a  chronological  order  of  a  news 
7 2
 
 Model/  VGCN- Deep 
TriFN  Grover  Declare  BERT  GPT2  SVM  Faker 
Metric  BERT  Walk 
Binary Classification 
ACC  0.695  0.602  0.579  0.690  0.652  0.602  0.459  0.620  0.824 
F1  0.660  0.598  0.552  0.612  0.635  0.609  0.468  0.610  0.768 
AUC  0.698  0.678  0.577  0.619  0.632  0.648  0.430  0.542  0.804 
Multiclass Classification 
ACC  0.675  0.582  0.559  0.660  0.650  0.582  0.400  0.519  0.810 
F1  0.640  0.580  0.540  0.591  0.605  0.589  0.456  0.598  0.750 
AUC  0.680  0.660  0.563  0.601  0.632  0.636  0.420  0.529  0.780 
Table 2: Results of all models using Binary and Multiclass classification 
 
4.2  Multi-label Classification Results 
The results in Table 3 show that Faker accuracy is 
In addition to the simplified binary classification,  96.3%. </Abstractive Summary> <Extractive Summary> Table 1 shows the 
||𝑥||
2 features of US Elections data that we use.  </Extractive Summary>  </Table 1>  </Paper ID = 816>


<Paper ID = 816> <Table 2> <Abstractive Summary> =This probably shows 
Predicted Real  37  1845  that more data obviously helps us to better classify 
Table 3:  Confusion Matrix of Sample data  the truth. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 816>


<Paper ID = 817> <Table 0> <Abstractive Summary> =The“event clusters”ﬁeldisnot
Table 1: Sample9 counts for all subtasks in all lan-
sharedfortestdata. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 817>


<Paper ID = 817> <Table 1> <Abstractive Summary> =Table 2: Number of clusters (events) in a sample in
a. </Abstractive Summary> <Extractive Summary> However,
"The farmworkers’ strike
it can be observed in Table 1 that subtask 3 has
resumed on Tuesday when
signiﬁcantlylessdatathansubtask4.  </Extractive Summary>  </Table 1>  </Paper ID = 817>


<Paper ID = 818> <Table 0> <Abstractive Summary> =4.4.1 ExperimentalApproach
Table 4: Sentence-wise translations (contrast with
For Subtask 4, we use a pre-trained XLM-
words/grammarofTable5)
RoBERTa with a Token Classiﬁcation head and
ﬁne-tuneditonGLOCONdataset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 818>


<Paper ID = 818> <Table 1> <Abstractive Summary> =95Model Viterbi W-to-W EnglishF SpanishF PortugueseF AverageF
1 1 1 1
BaselineBERT 71.54 - - -
MultiLingualBERT 70.99 54.94 64.96 63.63
XLM-RoBERTa 70.81 53.46 68.14 64.14
XLM-RoBERTa (cid:88) 72.80 54.65 70.46 65.97
XLM-RoBERTa (cid:88) (cid:88) 82.53 62.17 72.75 72.48
Table 7: Model ablation for Subtask 4 on validation set. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 818>


<Paper ID = 82> <Table 0> <Abstractive Summary> =Dataset Pairs Admissible(%) Control&Consistency(%)
Stereoset
WinoBias (WB) includes pronoun-resolution Intra-sentence 2106 6% 10%
Inter-sentence 2123 0% 9%
tests to assess whether coreference resolution CrowS-Pairs 1508 3% 7%
WinoBias
systems link pronouns to occupations dominated
WB-Syntax 792 38% 48%
by the gender of the pronoun (pro-stereotyping) WB-Knowledge 792 22% 28%
WinoGender 120 58% 59%
moreaccuratelythanoccupationsnotdominatedby
Table 1: Estimated prevalence of admissible (not af-
thatgender(anti-stereotyping)(Zhaoetal.,2018). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 82>


<Paper ID = 822> <Table 0> <Abstractive Summary> =supportvector Table 1: Data distribution over train and test sets in
machines, decision trees) including different fea- subtask1
ture extraction techniques (e.g. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 822>


<Paper ID = 822> <Table 1> <Abstractive Summary> =Spanish(es) 11 40
Portuguese(pt) 21 40
Table 2: Data distribution over train and test sets in
subtask3
4 Methodology
The main motivation behind the proposed ap-
proaches for event document identiﬁcation and
eventsentencecoreferenceidentiﬁcationisthere-
cent success gained by transformer-based archi-
tecturesinvariousNLPandinformationretrieval
taskssuchaslanguagedetection(Jauhiainenetal.,
2021)questionanswering(Yangetal.,2019)and
offensivelanguagedetection(HusainandUzuner,
2021;RanasingheandZampieri,2021). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 822>


<Paper ID = 822> <Table 2> <Abstractive Summary> =(2019)
proposedanewarchitecturenamedSentenceTrans-
Table 3: Sentence pairs and labels of data sample in
former(STransformer),amodiﬁcationtothetrans- Listing1
formerstoderivesemanticallymeaningfulsentence
embeddings. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 822>


<Paper ID = 823> <Table 0> <Abstractive Summary> =Intraditionalneu-
2 CNN-LexStem 2 0.85 0.71
ralnetworkbasedmodels,RNNbasedones,both
LSTM and GRU, suffer from serious overﬁtting
Table 3: Subtask 1 & 2 Stemming Experiments F1
even though all the efforts of regularization and
Scores. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 823>


<Paper ID = 823> <Table 1> <Abstractive Summary> =According to the Figure 1, conﬁdence scores
7https://www.nltk.org/_modules/nltk/
stem/wordnet.html lowerthan10%andhigherthan90%achievethe
133Model Validation Test
LSTM 0.82 0.68
GRU 0.83 0.64
CNN-LexStem 0.85 0.71
RoBERTa 0.88 0.82
RoBERTa+RNN 0.89 0.83
RoBERTa+LexStem 0.88 0.84
Table 4: Subtask 2 - Ensemble Models F1 Macro
Scores
model is not conﬁdent; using a weighted voting
andcombiningthesepowerscanbeuseful. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 823>


<Paper ID = 824> <Table 0> <Abstractive Summary> =Weobservethat:
XLM-R(en+es+pt) 90.0 75.2 88.3
• A monolingual XLM-R model trained with
Table 2: Macro F score on the development sets for
1
onelanguagecanachievegoodzero-shotper-
subtask1(documentclassiﬁcation). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 824>


<Paper ID = 824> <Table 1> <Abstractive Summary> =XLM-R(pt) 83.2 82.2 85.1
XLM-R(en+es+pt) 89.4 86.2 85.6 6 Subtask3: EventSentenceCoreference
Identiﬁcation
Table 3: Macro F score on the development sets for
1
Typically, for the task of event coreference reso-
subtask2(sentenceclassiﬁcation). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 824>


<Paper ID = 826> <Table 0> <Abstractive Summary> =Table 3: Effect of Data Augmentation. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 826>


<Paper ID = 826> <Table 1> <Abstractive Summary> =AsbotharedownstreamtasksofSubtask2 worse than the baseline of considering only the
155Sub1 Sub2 Sub3+4
# F1
EN+ EN- ES&PT+ ES&PT- EN ES&PT EN ES&PT
1 (cid:88) 0.8283
2 (cid:88) (cid:88) 0.8282
3 (cid:88) (cid:88) 0.8303
4 (cid:88) (cid:88) (cid:88) 0.8363
5 (cid:88) (cid:88) (cid:88) (cid:88) 0.8362
6 (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) 0.8275
6 (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) 0.8254
7 (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) 0.7646
8 (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) 0.7439
Table 4: Effect of Training Data. </Abstractive Summary> <Extractive Summary> Weshowtwoexamples
thesameprocedureasintroducedinSection3but
in Table 1 in sentences 3 and 4.  </Extractive Summary>  </Table 1>  </Paper ID = 826>


<Paper ID = 826> <Table 2> <Abstractive Summary> =We
TAPT 0.8155
consider setting 1 but freeze the RoBERTa back-
Table 6: Validation performance of ﬁnetuning DAPT bone;3. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 826>


<Paper ID = 826> <Table 3> <Abstractive Summary> =Setting F1Score
Default 0.8283
1 0.8280
2 0.5631
3 0.8301
4 0.8155
Table 8: Performance of the model under other ﬁne-
tuning settings. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 826>


<Paper ID = 827> <Table 0> <Abstractive Summary> =4.4 Stability
Dataset Train Eval Test
CoNLL2003 14,041 3,250 3,453 Tostudythestabilityofthemodelandtheimpact
CoNLL2002 8,324 1,916 1,518 ofbehavioralﬁne-tuningwemade6setsofexperi-
HAREM 121 8 128 mentswith20experimentsineachset:
Table 2: Number of elements for each dataset used in
• normal ﬁne-tuning with random data order
thebehavioralﬁne-tuningineachsplit. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 827>


<Paper ID = 827> <Table 1> <Abstractive Summary> =English Spanish Portuguese Hindi
Sub-task1 53.46(84.55) 46.47(77.27) 46.47(84.00) 29.66(78.77)
Sub-task2 75.64(85.32) 76.39(88.61) 81.61(88.47) /
Sub-task4 69.96(78.11) 56.64(66.20) 61.87(73.24) /
Table 4: Score of our ﬁnal submissions for each sub-task, in parenthesis the score achieved by the best scoring
teamoneachsub-task. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 827>


<Paper ID = 827> <Table 2> <Abstractive Summary> =CoNLL2002 86.1
6 Conclusion
HAREM 76.1
6.1 Sub-task1and2
Table 5: Macro-F1 score of the NER task on the test
splitofeachdatasetusedinbehavioralﬁne-tuningafter AswecanseeinTable4,ourﬁnalresultsforsub-
trainingthebaseM-BERTfor1epoch. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 827>


<Paper ID = 829> <Table 0> <Abstractive Summary> =UNCC1.1 0.798 0.739 0.736
Table 1: Overall performance overview Subtask 1:
7 EvaluationResults
weightedaveragescores. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 829>


<Paper ID = 829> <Table 1> <Abstractive Summary> =UNCC2.1 Zero-S. 0.670 0.658 0.635
1
UNCC2.2 Zero-S. 0.670 0.658 0.635
The two teams that reported using undersam-
pling due to lack of sufﬁcient computational re- Table 2: Overall performance overview Subtask 2:
sources,arealsotheoneshavingtheoveralllowest weightedaveragescores. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 829>


<Paper ID = 829> <Table 2> <Abstractive Summary> =Table7for Table 3: Overall performance overview Subtask 3:
details. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 829>


<Paper ID = 829> <Table 3> <Abstractive Summary> =baseline
191ACLEDclass F1onACLED F1onNews-likedata ∆F1
Abduction/forceddisappearance 0.903 0.865 -0.04
Agreement 0.831 0.842 0.01
Air/dronestrike 0.987 0.971 -0.02
Armedclash 0.956 0.736 -0.22
Arrests 0.89 0.938 0.05
Attack 0.915 0.727 -0.19
Changetogroup/activity 0.838 0.844 0.01
Chemicalweapon 0.829 0.943 0.11
Disruptedweaponsuse 0.891 0.938 0.05
Excessiveforceagainstprotesters 0.692 0.650 -0.04
Governmentregainsterritory 0.839 0.904 0.07
Grenade 0.893 0.909 0.02
Headquartersorbaseestablished 0.758 0.905 0.15
Looting/propertydestruction 0.808 0.370 -0.44
Mobviolence 0.851 0.595 -0.26
Non-stateactorovertakesterritory 0.784 0.776 -0.01
Non-violenttransferofterritory 0.73 0.781 0.05
Other 0.64 0.400 -0.24
Peacefulprotest 0.984 0.902 -0.08
Protestwithintervention 0.813 0.755 -0.06
Remoteexplosive/landmine/IED 0.97 0.959 -0.01
Sexualviolence 0.93 0.955 0.02
Shelling/artillery/missileattack 0.978 0.841 -0.14
Suicidebomb 0.933 0.907 -0.03
Violentdemonstration 0.862 0.772 -0.09
Table 8: Comparison of BBbaseline performances when applied on ACLED data vs. news-like data: weighted
averagescores
192 </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 829>


<Paper ID = 83> <Table 0> <Abstractive Summary> =Table 7: Validation ranking results for FB15k-237-
C SupplementaryTables
Sparse. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 83>


<Paper ID = 83> <Table 1> <Abstractive Summary> =SNOMEDCTCore
MR MRR H@1 H@3 H@10
DistMult 5039 .294 .226 .319 .427
ComplEx 3850 .303 .225 .335 .457
ConvE 3618 .271 .191 .303 .429
ConvTransE 3484 .293 .216 .323 .446
SNOMEDCTCore
BERT-ConvE 386 .384 .278 .431 .593
MR MRR H@1 H@3
BERT-ConvTransE 487 .374 .274 .417 .569
BERT-ResNet 2 .698 .561 .787
BERT-DeepConv 250 .481 .376 .534 .687 +Re-ranking+KD+TE 2 .822 .724 .901
BERT-ResNet 249 .493 .389 .546 .694
CN-100K
MR MRR H@1 H@3
Table 4: Validation ranking results for SNOMED CT
BERT-ResNet 3 .648 .488 .758
Core. </Abstractive Summary> <Extractive Summary> The
etal.,2013),theprecursortoFB15k-237,wascu-
summarystatisticsforalldatasetsarepresentedin
ratedtoonlyincludeentitieswithatleast100links
Table 1 and we visualize the connectivity of the
inFreebase(Bollackeretal.,2008).  </Extractive Summary>  </Table 1>  </Paper ID = 83>


<Paper ID = 83> <Table 2> <Abstractive Summary> =Table 8: Validation re-ranking results. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 83>


<Paper ID = 830> <Table 0> <Abstractive Summary> =subtask3
ATTRIB attributionofresponsibility 3 SupervisedSequenceClassiﬁcationfor
DIPLO diplomaticevent
SeenTypes
Table 1: Type labels (some truncated) and names for
the25knowntypesofsubtask1,thethreeunseentypes For the text classiﬁer we used a standard
ofsubtask2,andthetwounseentypesofsubtask3 transformer-based sequence classiﬁcation model
(Vaswanietal.,2017)withapre-trainedlanguage
model. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 830>


<Paper ID = 830> <Table 1> <Abstractive Summary> =For both of these, large mod-
Table 2: Comparison of micro F score, macro
1 els ﬁne-tuned for the NLI task are available
F score, and weighted F score on test fold 1 of
1 1 from Hugging Face: bart-large-mnli and
the ACLED-C-III dataset. </Abstractive Summary> <Extractive Summary> Table 1 lists
Socio-politicalEvents thetypelabelsandnamesforthethreesubtasks.  </Extractive Summary>  </Table 1>  </Paper ID = 830>


<Paper ID = 830> <Table 2> <Abstractive Summary> =name organizedcrime
keywords organizedcrime,smuggling,humantrafﬁcking,counterfeitproducts,propertycrime,cyber
crime,assassination,corruption
disj-kw organizedcrime|smuggling|humantrafﬁcking|counterfeitproducts|propertycrime|
cybercrime|assassination|corruption
Table 3: Example type representations for a sentence of the type ORG CRIME. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 830>


<Paper ID = 830> <Table 3> <Abstractive Summary> =Table 4: Effect of different type representations on
To ﬁne tune a few-shot supervised NLI model
zero-shotaccuracyforthe142-exampledevsetforthe
for the three unseen types of subtask 2, we cre-
threeunseentypes. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 830>


<Paper ID = 830> <Table 4> <Abstractive Summary> =s2 attack
Table 5: Example positive and negative instances generated from a sentence whose gold event type label is
ORG CRIME.Sentence2(s2)forthepositiveinstanceisthekeywordfromthegoldeventtypekeywordsscored
highestbyroberta-large-mnli. </Abstractive Summary> <Extractive Summary> modelscanbeusedas“pre-tuned”modelsforfew- Table 4 shows how critical the choice of type
shot(SchickandSchu¨tze,2021)orevenzero-shot representationis.  </Extractive Summary>  </Table 4>  </Paper ID = 830>


<Paper ID = 830> <Table 5> <Abstractive Summary> =Both
Table 7: Comparison of three NLI models tested on experimentsshowapreferenceforRoBERTa. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 5>  </Paper ID = 830>


<Paper ID = 830> <Table 6> <Abstractive Summary> =3 0.756(0.746) 0.771 2 Reranking of the 25 original types was super-
vised when using the RoBERTa NLI model ﬁne-
Table 10: Ofﬁcial challenge results (weighted F
1 tunedontheACLEDdata(rob-mnli-FT24in
scores). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 6>  </Paper ID = 830>


<Paper ID = 831> <Table 0> <Abstractive Summary> =Wethen
203
Proceedingsofthe4thWorkshoponChallengesandApplicationsofAutomatedExtractionofSocio-politicalEventsfromText
(CASE),pages203–207August5–6,2021,©2021AssociationforComputationalLinguisticsSubtask Eventclass Precision Recall F -score Support
1
1 Disruptedweaponsuse 0.971 0.569 0.717 58
1 Abductionforceddisappearance 0.714 0.750 0.732 20
1 Agreement 1.000 0.516 0.681 31
1 Airdronestrike 0.786 0.917 0.846 36
1 Armedclash 0.449 0.924 0.604 66
1 Shellingartillerymissileattack 0.646 0.861 0.738 36
1 Attack 0.333 0.852 0.479 27
1 Changetogroupactivity 0.571 0.533 0.552 30
1 Chemicalweapon 0.867 0.703 0.776 37
1 Arrests 0.684 0.382 0.491 34
1 Excessiveforceagainstprotesters 0.833 0.652 0.732 23
1 Governmentregainsterritory 0.780 0.842 0.810 38
1 Grenade 0.949 0.771 0.851 48
1 Headquartersorbaseestablished 0.870 0.909 0.889 22
1 Mobviolence 0.314 0.647 0.423 17
1 Nonstateactorovertakesterritory 0.810 0.708 0.756 24
1 Nonviolenttransferofterritory 0.714 0.476 0.571 21
1 Other 0.000 0.000 0.000 8
1 Peacefulprotest 0.689 0.895 0.779 57
1 Lootingpropertydestruction 0.143 0.048 0.071 21
1 Protestwithintervention 0.548 0.773 0.642 22
1 RemoteexplosivelandmineIED 0.522 0.972 0.680 36
1 Sexualviolence 0.955 0.913 0.933 23
1 Suicidebomb 0.946 0.854 0.897 41
1 Violentdemonstration 0.642 0.642 0.642 53
1 microavg 0.739 0.739 0.739 829
1 macroavg 0.770 0.697 0.698 829
1 weightedavg 0.798 0.739 0.736 829
2 Organizedcrime 0.500 0.103 0.171 29
2 Naturaldisaster 0.562 0.243 0.340 37
2 Manmadedisaster 0.167 0.019 0.034 52
2 microavg 0.658 0.658 0.658 947
2 macroavg 0.648 0.632 0.613 947
2 weightedavg 0.670 0.658 0.635 947
3 Attributionofresponsibility 0.167 0.071 0.100 28
3 Diplomaticevent 0.511 0.523 0.517 44
3 microavg 0.629 0.629 0.629 1019
3 macroavg 0.621 0.602 0.582 1019
3 weightedavg 0.644 0.629 0.605 1019
Table 1: Event types by subtask. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 831>


<Paper ID = 833> <Table 0> <Abstractive Summary> =Their model is based on a RoBERTa NYT(cid:5)(cid:5) 0.745 0.762 302.96
NoConﬂict NYT(cid:5)(cid:5)(cid:5) 0.601 0.658 303.407
(Liuetal.,2019)backbonewithasecondpretrain-
Twitter 0.534 0.524 287.88
ing (Gururangan et al., 2020) stage done on the Merged 0.522 0.537 286.59
POLUSA(GebhardandHamborg,2020)dataset
Table 1: Correlation coefﬁcients and error rates for
beforeﬁnetunedonSubtask2data. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 833>


<Paper ID = 835> <Table 0> <Abstractive Summary> =(2020), which contains 4793 goal-oriented
predicts 20431 3972 198 787
dialoguesandatotalof488associatedgrounding
documents from four domains for social welfare: Table 1: Statistics of dialogue data of different data
dmv,va,ssa,andstudentaid. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 835>


<Paper ID = 835> <Table 1> <Abstractive Summary> =They also adapt data augmentation ap-
Table 4: Participating teams and evaluation results on
proachesthatutilizeadditionalQuestionAnswer- testsetofSubtask2. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 835>


<Paper ID = 836> <Table 0> <Abstractive Summary> =65.55 50.69 40.61 60.50 69.35 12.94 SN(Guoetal.,2019) 57.32 62.20 47.90 80.43 89.95 4.17
SeqMRN-DE-D+SeqIPN-GE-G 67.26 56.41 44.44 69.67 79.51 7.44 SN†(Guoetal.,2019) 57.88 63.42 49.30 80.77 90.68 3.97
SeqDialN:4Dis+4Gen 68.61 58.11 45.94 71.66 81.22 6.73 NMN(Kotturetal.,2018) 58.10 58.80 44.15 76.88 86.88 4.81
DAN(Kangetal.,2019) 57.59 63.20 49.63 79.75 89.35 4.30
DAN†(Kangetal.,2019) 59.36 64.92 51.28 81.60 90.88 3.92
Table 2: Comparison of SeqDialN to state-of-the-art ReDAN†(Ganetal.,2019) 61.86 53.13 41.38 66.07 74.50 8.91
VisDial-BERT:w/CC+VQA(Muraharietal.,2019) 63.87 67.50 53.85 84.68 93.25 3.32
visualdialogmodelsonVisDialv1.0validationset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 836>


<Paper ID = 836> <Table 1> <Abstractive Summary> =66.91 56.84 44.30 70.85 80.93 6.87
score to rank the 100 candidate answers and eval-
Table 3: Comparison of SeqDialN to state-of-the-art
uatethemetricsbasedonthenewrank. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 836>


<Paper ID = 836> <Table 2> <Abstractive Summary> =Our model also outperforms
VisDial-BERT(Muraharietal., 2019) by > 3.5% Table 4: Using reweighting method to lessen perfor-
mance drop on VisDial v1.0 validate set. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 836>


<Paper ID = 836> <Table 3> <Abstractive Summary> =72.41 55.11 43.23 67.65 79.77 6.55
reweightingmethodgreatlymitigatesperformance Table 5: Comparison of SeqDialN to state-of-the-art
drop in our ﬁne-tuning experiment. </Abstractive Summary> <Extractive Summary> Table 3 shows the comparison between
tuninggenerativemodelsdon’timproveNDCGas
our model and state-of-the-art visual dialog mod-
muchasdiscriminativecase.  </Extractive Summary>  </Table 3>  </Paper ID = 836>


<Paper ID = 837> <Table 0> <Abstractive Summary> =0.6 1.75 56.6
After achieving the precision, the BLEU score is 1.0 1.00 56.5
thencalculatedas:
Table 3: Experimental results in terms of BLEU on
4
(cid:88) DSTC2byusingdifferentθ. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 837>


<Paper ID = 837> <Table 1> <Abstractive Summary> =THPN 12.8 37.8 50.0 37.9 27.5 Therefore, the best way to generate some unseen
words is to directly copy from the input query,
Table 6: Evaluation results on the In-Car Assistant
which is consistent with the ﬁndings of previous
datasetwithθ =0.3. </Abstractive Summary> <Extractive Summary> tions such as reserving restaurants and booking
Table 1 shows two conversations from real task-
ﬂights.  </Extractive Summary>  </Table 1>  </Paper ID = 837>


<Paper ID = 838> <Table 0> <Abstractive Summary> =Table 2: Sample questions generated by the Nishant Nikhil. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 838>


<Paper ID = 838> <Table 1> <Abstractive Summary> =Table 3: This set comprises of the time-related
words that have a high chance of being used in a
storybook. </Abstractive Summary> <Extractive Summary> enni" (quantiﬁer - based) questions are built
Table 1 liststhenumberoftimeseachquestion
from diverse quantiﬁers (for example: time, age,
wordoccurredandthenumberoftimesitappeared
number of people - these quantiﬁers are often
wrong in the experiment with ﬁve stories.  </Extractive Summary>  </Table 1>  </Paper ID = 838>


<Paper ID = 839> <Table 0> <Abstractive Summary> =Frankenbot 5,268 16
TheevaluationofDrQAreportsanF1scoreof DrQA 421 4,903
0.36 in the non-modular setting which is compa-
Table 3: Confusion Matrix of module selection with
rable to the results reported in the original paper
the predicted module in the rows and true label in the
(Chen et al., 2017). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 839>


<Paper ID = 84> <Table 0> <Abstractive Summary> =BiLSTM-T 0.184351719915866 -0.64785711467266 -0.465365642681717
BiLSTM-A -0.0904324240982532 -0.795884847640991 -0.403448916971683
4.1.4 Baselines
Table 2: The thresholds determined by Algo-
Wecompareourmethodwiththefollowingbase-
rithm 4. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 84>


<Paper ID = 84> <Table 1> <Abstractive Summary> =73.20 65.65 71.21 70.55 63.38 69.32
Table 3: Performance on DEV set and blind TEST set of FEVER (%). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 84>


<Paper ID = 84> <Table 2> <Abstractive Summary> =50.09 46.55 53.00
2 60.74 54.94 72.69
52.84 58.66 55.59
Table 4: Comparison between our method and KGAT (w./o.) </Abstractive Summary> <Extractive Summary> Table 2 shows the thresholds recall is that the number of sentences in precise
2000
evidencesislessthanthatinimpreciseevidences,
2https://www.mediawiki.org/wiki/API: which means other methods have a higher proba-
Main_page
bilitytorecalltheground-trueevidencesthanours.  </Extractive Summary>  </Table 2>  </Paper ID = 84>


<Paper ID = 84> <Table 3> <Abstractive Summary> =(First...Unit,0) (First...Unit,1) (First...Unit,0) (First...Unit,0)
(Zero(2016ﬁlm),0) (First...Unit,2) (First...Unit,2)
(First...Unit,8) (Zero(2016ﬁlm),0)
Table 7: Cases in FEVER. </Abstractive Summary> <Extractive Summary> (orlargestevidencesize,i.e.,K)is5,thediscount Results in Table 3 show that all versions (except
factorλis0.95, andthelayernumberofthecon- BiLSTM-A)withpost-processingsigniﬁcantlyout-
textsub-moduleis3.  </Extractive Summary>  </Table 3>  </Paper ID = 84>


<Paper ID = 840> <Table 0> <Abstractive Summary> =RoBERTa∗ denotes the
ensemble
Table 2: The hyper-parameter settings in the shared resultsoftheensemblemodelonthetestset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 840>


<Paper ID = 840> <Table 1> <Abstractive Summary> =Althoughresource-and
time-consuming, this approach is easy to imple-
Table 4: The results of selected models on subtask 2
mentandeffectiveatenablingthemodeltolearn
arelisted. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 840>


<Paper ID = 844> <Table 0> <Abstractive Summary> =However,it
Single-Turneasetoanswer 0.51 0.14 0.35
performswellonBLEUscoressinceitlearnswell
Multi-turngeneralquality 0.71 0.17 0.12
to reproduce the responses as in the ground truth
Table 2: Human Evaluation Results. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 844>


<Paper ID = 845> <Table 0> <Abstractive Summary> =We apply the
News-LA longonly 3048 same preprocessing method as in the NQ dataset
tocreatealong-answertestset—News-LA.We
Table 1: QG Data summary. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 845>


<Paper ID = 845> <Table 1> <Abstractive Summary> =Removing BERT initializationcausesno-
tabledropsforbothNQ-LA(3.6dropsinBLEU-4)
Table 3: Ablation study of the BERTPGN. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 845>


<Paper ID = 845> <Table 2> <Abstractive Summary> =However, the M gener- Span 1.5 1.1 −0.8 −0.6
NQ
Entire 0.4 0.3 0.4 0.3
ates more questions with both positive s and
ans None −1.5 −1.2 0.6 0.6
s than those from M , indicating the effec-
gra SD
tivenessofourmodeltogenerateintroductoryand Table 6: Pearson correlation (1×10−1) between hu-
self-explanatoryquestions. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 845>


<Paper ID = 845> <Table 3> <Abstractive Summary> =Soldiersatthebasehave measurestoprepareforpossiblerefugees,theArmyhas
94BERTPGN-NQ-whole-article BERTPGN-SQuAD-ﬁrst-line
whoarethenewastronautsonthemoon howmanyitalianswalkintoaspacestationin2013
whenisthespaceshuttlediscoverycomingout howmanydaysisthespaceshuttlediscoveryscheduled
tolaunch
whatistheaverageunemploymentrateinspain whatpercentageofspain’spopulationisoutofwork
whatisthemeaningofsouljaboytellem whatwasdeandrecortezwayknownas
wheredoestheusrefugeesatguantanamobaycomefrom whatisthenameoftheusmilitaryfacilityintheus
whathappenedtothegirlinthetexaspolygamistranch whatwasthenameofthetexaspolygamistranch
whoscoredtheﬁrstgoalinthepremierleague whichteamdidevertonfcbeattowinthepremierleague’s
homedrawwithtottenhamonsunday
Table 7: Comparing generated questions side-by-side. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 845>


<Paper ID = 846> <Table 0> <Abstractive Summary> =SinceweuseK
Table 4: Subtask2 test-dev phase results. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 846>


<Paper ID = 847> <Table 0> <Abstractive Summary> =1https://huggingface.co/datasets/quac
104QADataset Validation QADataset Validation Testdev Test
EM F1 EM F1 EM F1 EM F1
bert-large-uncased-whole-word-masking
Doc2Dial 42.1 57.8
Doc2Dial 50.1 63.4 – – – –
+SQuAD 45.0 60.3
+SQuAD 52.4 63.9 – – – –
+NewsQA 45.5 59.8
+QuAC(1) 53.2 68.0 47.4 66.5 – –
+NaturalQuestions(NQ) 44.2 59.9 +CoQA(2) 54.3 70.3 49.4 68.7 45.5 65.5
+HotpotQA 43.0 58.0 +CoQA,QuAC(3) 54.2 70.1 51.0 68.1 – –
+SearchQA 42.3 57.5
albert-xl
+TriviaQA 43.1 58.0
+QuAC(4) 59.1 72.6 47.6 67.1 52.6 67.4
+MRQA-19(Train) 43.4 58.9
+CoQA(5) 60.0 74.1 48.0 67.9 50.8 69.5
+SQuAD+NewsQA+NQ 43.0 59.2
Ensembles
+SQuAD+NewsQA+NQ(IS) 43.8 59.4
E(4,5) 61.4 75.3 49.5 66.6 53.5 70.9
+QuAC 46.4 60.3
E(1,2,3,4,5) 61.5 76.1 49.5 68.7 52.0 69.9
+CoQA 47.7 66.0
Table 3: Performance (EM (%), F1 (%)) of large
Table 2: Performance (EM (%), F1 (%)) of
transformer-based QA models on DialDoc validation
bert-base-uncased on DialDoc validation set
andtestdevsetwhenfurtherpretrainedondifferentQA
whenfurtherpretrainedondifferentQAdatasets. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 847>


<Paper ID = 847> <Table 1> <Abstractive Summary> =albert-xl HotpotQA 114.0 14.3 945.0 0.457
+ QuAC is the best-performing single model ac- Doc2Dial 61.4 129.3 4814.2 0.427
cordingtotheEMmetric(EM = 52.60),whereas
Table 4: Statistics of Average Question Length, Aver-
albert-xl + CoQA performs the best on F1
ageAnswerLength,AverageContextLength,andAv-
metric(F1 = 69.48)onthetestset. </Abstractive Summary> <Extractive Summary> the validation set (Table 2) portray that pretrain-
Table 1 presents the size of the different pre- ing on different QA datasets is indeed beneﬁcial.  </Extractive Summary>  </Table 1>  </Paper ID = 847>


<Paper ID = 848> <Table 0> <Abstractive Summary> =thepredictionatinferencetime,toensurethatthe Additionally,weonlyappendthepasttwodialogue
110turnstothesupportingdocumentintheinput, in- Table 1: Model performance on Doc2Dial sub-task1. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 848>


<Paper ID = 848> <Table 1> <Abstractive Summary> =The intuition is that the decoder
Table 2: Model performance on Doc2Dial sub-task2. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 848>


<Paper ID = 85> <Table 0> <Abstractive Summary> =bSST-5 6.9k 1.1k 2+1
TheimplementationisbasedonPyTorch(Paszke
etal.,2019)andtheHuggingfaceTransformersLi-
Table 2: Dataset statistics. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 85>


<Paper ID = 85> <Table 1> <Abstractive Summary> =91.0 16.2 2.18 91.2 117.5 1.12 84.6/85.2 461.1/429.8 2.26/2.30
Table 3: Comparing different regularizers (Reg.) </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 85>


<Paper ID = 850> <Table 0> <Abstractive Summary> =Table 1: An example of data augmentation for domain classiﬁcation. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 850>


<Paper ID = 850> <Table 1> <Abstractive Summary> =Wepresentseveralexamples
ofthegeneratedresponsesbyoursystemcompared
Table 5: Ablation study of the knowledge matching
againstthebaselineandtop2systemsinSection
module for knowledge selection by removing entities
and hinge loss. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 850>


<Paper ID = 850> <Table 2> <Abstractive Summary> =Systems Accuracy Appropriateness Average
Samplingratios MRR@5 Recall@1 Recall@5 OurSystems:
Originalmodel T5-Base 4.5994∗ 4.4572† 4.5283∗
[0.1,0.1,0.1,0.7] 0.9811 0.9693 0.9936 Pegasus-Large 4.5451† 4.4591† 4.5021†
[0.25,0.25,0.25,0.25] 0.9761 0.9615 0.9929 DSTC9Track1Systems(Top-2):
[1.0,0.0,0.0,0.0] 0.9712 0.9514 0.9933 Team19 4.4979 4.4698 4.4838
[0.0,1.0,0.0,0.0] 0.9559 0.9248 0.9906
(4.3917) (4.3922) (4.3920)
[0.0,0.0,1.0,0.0] 0.9728 0.9540 0.9933
Team3 4.4524 4.4064 4.4294
[0.0,0.0,0.0,1.0] 0.9751 0.9596 0.9929
(4.3480) (4.3634) (4.3557)
Table 6: Ablation study of the knowledge matching
Table7: Humanevaluationresultsofthetestsetforre-
module for knowledge selection by tuning the mixed
sponsegeneration.Numberswithintheparenthesesare
negativesamplingratio. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 850>


<Paper ID = 852> <Table 0> <Abstractive Summary> =ShopB 3,992,794 102,942 5,7
Following industry standards, nDCG@K (Mitra
and Craswell, 2018) with K = 10 is the chosen
Table 2: Descriptive statistics for the training dataset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 852>


<Paper ID = 852> <Table 1> <Abstractive Summary> =Hence,
Prod2BERT 240-1200 48.96-244.8$
given the range of downstream applications and
theactivedebateontransferabilityinNLP,wein-
Table 4: Time (minutes) and cost (USD) for training
vestigatehowProd2BERTrepresentationsperform
one model instance, per shop: prod2vec is trained on
whenusedintheintentpredictiontask. </Abstractive Summary> <Extractive Summary> Table 1 shows the relevant hy-
sionsfromtwopartneringshops,ShopAandShop
perparameteranddesignvariantsforProd2BERT;
B:similarlytothedatasetreleasedbyRequenaetal.  </Extractive Summary>  </Table 1>  </Paper ID = 852>


<Paper ID = 852> <Table 2> <Abstractive Summary> =As a more general
prod2vec - ShopB 0.558
consideration–reinforcedbyaqualitativevisual
Prod2BERT enc 0 ShopA 0.593 assessmentofclustersintheresultingvectorspace
prod2vec - ShopA 0.602 –,theperformancegapisverysmall,especiallycon-
sideringthatlongtrainingandextensiveoptimiza-
Table 5: Accuracy scores in the intent prediction task tionsareneededtotakeadvantageofthecontextual
(bestscoresforeachshopinbold). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 852>


<Paper ID = 853> <Table 0> <Abstractive Summary> =Consider the two at- master/publish_data.txt
14Method EM(%) P(%) R(%) F (%) Models SUOTag ILM T5
1
SUOTag 68.88 70.81 71.31 71.06 Precision(%) 41.73 75.25 77.32
ILM 81.14 83.35 83.38 83.37 NULL Recall(%) 93.10 78.99 74.09
T5 81.35 83.89 83.75 83.82 F1(%) 57.63 77.07 75.67
EM(%)whenattributes
28.86 61.11 54.57
Table 2: Performance comparison on the AV-109K appearincontext
dataset EM(%)whenattributesdoes
69.53 81.22 81.78
notappearincontext
Valueshavingmultiple
47.00 62.74 62.96
To further examine the model’s ability to gen- wordsEM(%)
erate values for unseen attributes, we select ﬁve Numericalvalues 43.24 66.56 72.06
attributeswithrelativelylowfrequency(< 0.1%)
Table3:PerformanceofmodelsonAV-109Kdatasetin
in the dataset: Frame Color, Lenses Color, Shell
differentscenarios. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 853>


<Paper ID = 853> <Table 1> <Abstractive Summary> =multiplewords,and(d)whenvaluehasnumerical
15Attributes Model EM(%) P(%) R(%) F1(%) Attributes Model EM(%) P(%) R(%) F1(%)
BiLSTM-CRF 85.77 80.99 86.37 83.59 SUOTag 71.30 71.76 72.22 71.99
Frame
Brand SUOTag 91.05 92.53 92.35 92.44 Color ILM 69.44 69.44 69.44 69.44
Name ILM 94.72 94.93 94.89 94.91 T5 74.07 74.07 74.07 74.07
T5 94.97 95.35 95.29 95.32 SUOTag 64.52 64.52 64.52 64.52
Lenses
BiLSTM-CRF 65.03 65.20 67.08 66.13 Color ILM 67.74 67.74 67.74 67.74
T5 69.35 69.35 69.35 69.35
SUOTag 68.09 72.21 72.36 72.28
Material SUOTag 30.56 41.2 52.78 46.28
ILM 85.24 88.59 88.10 88.34
Shell
ILM 47.22 59.72 72.22 65.38
T5 84.57 88.94 87.48 88.20 Material
T5 58.33 68.06 77.78 72.59
BiLSTM-CRF 42.64 40.74 42.64 41.67
SUOTag 47.83 52.90 60.87 56.60
SUOTag 42.64 43.15 43.09 43.12 Wheel
Color ILM 69.57 69.57 69.57 69.57
ILM 75.63 80.29 79.8 80.04 Material
T5 78.26 78.26 78.26 78.26
T5 76.65 80.63 81.02 80.82
SUOTag 20.84 21.63 21.8 21.71
BiLSTM-CRF 48.06 51.25 50.08 50.66 Product
ILM 57.17 68.84 68.59 68.72
SUOTag 52.43 56.55 55.26 55.90 Type
Category T5 52.20 62.01 64.15 63.06
ILM 79.13 81.56 81.96 81.76
T5 74.27 81.67 80.18 80.92 Table 5: Performance comparison of different models
onAV-zeroforidentifyingvaluesofunseenattributes. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 853>


<Paper ID = 853> <Table 2> <Abstractive Summary> =Table 4: Performance comparison of different models
onfourfrequentattributes. </Abstractive Summary> <Extractive Summary> CRF (Huang et al., 2015) and SUOTag (Scaling Table 2 reports the performance on the AV-109K
UpOpenTag)(Xuetal.,2019)2. dataset.  </Extractive Summary>  </Table 2>  </Paper ID = 853>


<Paper ID = 854> <Table 0> <Abstractive Summary> =The ﬁrst pass LM we used was
+JointSD+DA 9.8% 13.0%
+BF+DA 21.5% 25.3% a domain-general Kneser-Ney (KN) (Kneser and
+BF+DA+JointSD 21.0% 25.8% Ney,1995)smoothed4-grammodelestimatedon
aweightedmixofdatasetsspanningmultipledo-
Table 3: Relative perplexity reduction (PPLR) from
mains. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 854>


<Paper ID = 858> <Table 0> <Abstractive Summary> =Wefollowthe
Table 2: Average kNN prediction accuracy using the
suggestions from (Gururangan et al., 2020; Liu
classiﬁcationvectorsfromthepretrainedmodels
etal.,2019)forDAPTandTAPTand(Devlinetal.,
2019)forﬁnetuning. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 858>


<Paper ID = 858> <Table 1> <Abstractive Summary> =Area Under the
D/TAPTALBERT,wesampleacouplethousand Curve-ReceiverOperatingCharacteristics(AUC
53Table 3: The average and sample-weighted average we apply DAPT, D/TAPT and SS incrementally. </Abstractive Summary> <Extractive Summary> Table 1 shows a few sample training data
ones,andre-trainthemodelwiththelabeleddata withdummyfeaturesandintents.  </Extractive Summary>  </Table 1>  </Paper ID = 858>


<Paper ID = 859> <Table 0> <Abstractive Summary> =HomeGymCombo]
i can [SuratDreamPortableMiniSewingMa- [Whirlpool7.5kg5Star,HardWater days since in-
2000 green chine Handheld Handy Stitch Machine washFullyAutomaticTopLoadGrey, cident creation,
color Manual Cordless Electric Stitching Ma- AsianRunningShoesForWomen] days since last
mobile chine Electric Sewing Machine, I Kall chat, rank wrt
phone K1000 (Green, 64 GB), I Kall K1000 sellingprice
(Blue,64GB)]
blue 2 [Hardys Full Sleeve Solid Men Jacket, [NcertChemistryClass12(Part1And2) iscancelled?,is
dead phone BrawoPartyWearPartyWearForMen,T Combo2Book(K.C.G),STROMCOL- incidentcreated
ke liye GOOD Lite SH12 Bluetooth Headset, LECTION Men Formal Black Gen- in last 2 days?,
T GOOD Lite SH12 Bluetooth Head- uineLeatherBelt,OPPOF15(Blazing number of days
set,SPINOZAPinkdiamondstuddedat- Blue,128GB)] since return ini-
tractivebutterﬂystylishwomenAnalog tiation
Watch-ForGirls]
Table 1: Examples of top matches from fuzzy search and predictive model. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 859>


<Paper ID = 859> <Table 1> <Abstractive Summary> =66A FlowofFuzzySearch
Start
Pre-Processing
Is query  Yes
No match
blank
No
Direct  Yes
Match
No
Partial 
Yes Matching 
N-Gram 
Products Found 
Match
No
Yes
Phonetic 
Match
No
No match
Figure 4: Flow Chart showing the stages involved in
fuzzysearch
67B Hyper-parametertuningforOrderPrediction
Model Hyper-parameter Rangeofvalues Besthyper-parameter
penalty l1,l2,elasticnet,none l2
LogisticRegression tol [1e-2,1e-6] 1e-5
C [1e2,1e-2] 1
n estimators [10,1000] 50
criterion gini,entropy gini
Randomforest max depth 10,20,50,100 20
min samples leaf 2,10,50,100 10
bootstrap False,True True
numberofhiddenlayers 2,3 2
numberofneurons 50,100,200 100
DNN
lr [1e-2,1e-4] 1e-3
activation relu,sigmoid,leakyrelu,tanh leakyrelu
Table5: Rangeofvaluesforvarioushyper-parametersandthechosenhyper-parameterwithbesttop-1accuracy
onvalidationsetforvariousorderpredictionmodels
68C Samplepredictionsfromfuzzysearch&ecommercesearch
Customer Ut- Producttitlesofactiveorders Comments
terance
mitvkebaare [STAMEN153cm(5ft)PolyesterWindowCurtain(PackOf4),Sauran26-55inch (cid:51)Fuzzy
mein HeavyTVWallMountforalltypesofFixedTVMountFixedTVMount,Mi4A100 Search
cm(40)FullHDLEDSmartAndroidTV,LeemaraVirusProtection,Anti (cid:51)Ecommerce
Pollution,FaceMask,Reusable-WashableOutdoorProtectionCottonSafetyMask] Search
cover ke [Aspir Back Cover for Vivo V15, Mobi Elite Back Cover for Vivo (cid:51)Fuzzy
baare mein V15,RUNEECHBackCameraLensGlassProtectorforVIVOV20,ShoesKingdom Search
mobile cover ShoesKingdom LB791MocassinsCasualLoafersForMen(Brown)LoafersForMen, (cid:55)Ecommerce
kebaaremein AspirBackCoverforVivoV20,CatBullIn-earBluetoothHeadset] Search
datacable ke [Easy Way Fashion Doll with Dresses Makeup and Doll Accessories, Vrilliance (cid:51)Fuzzy
liye Traders Type C Compatible Fast Data Cable Charging Cable for Search
TypeCAndroidDevices(1.2M,Black)1.2mUSBTypeCCable] (cid:55)Ecommerce
Search
in clinics hot [JOKINA1MULTIFUNCTIONALSMARTWATCHSmartwatch, Inﬁnix Hot 9 (cid:51)Fuzzy
94 Pro (Violet, 64 GB),VivoZ1Pro(SonicBlue,64GB),VivoZ1Pro(SonicBlue, Search
64GB),VivoZ1Pro(SonicBlue,64GB),TechUnboxingLedRechargeableFanWith (cid:55)Ecommerce
Torch120mm3BladeExhaustFan] Search
chappal ke [HighlanderFullSleeveWashedMenJacket,OricumSlides,BOLAXBlackSlouchy (cid:55)Fuzzy
liye paanch woolenLongBeanieCapforWinterskullheadUnisexCap,OricumSlides,BOLAX Search
sau saat sattar BlackSlouchywoolenLongBeanieCapforWinterskullheadUnisexCap] (cid:51)Ecommerce
pe ka product Search
thamera
Table 6: Examples of predictions from fuzzy search and ecommerce search. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 859>


<Paper ID = 86> <Table 0> <Abstractive Summary> =n 3 65.8 67.5 62.9 69.3 54.3 59.4 51.0 58.5
2 62.6 63.2 75.7 68.8 60.4 58.6 55.6 59.9
Baselines To examine the effectiveness of our
1 68.1 63.5 70.0 71.0 60.9 64.6 55.6 58.5
newlyproposedanomalyscorebasedonMDFthat
utilizes the representations of all layers, we com-
Table 2: The AUROC scores of OOD detection
pareitwiththefollowingbaselines. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 86>


<Paper ID = 86> <Table 1> <Abstractive Summary> =[CLS]embeddingoraveragingtokenembeddings Weﬁndusingf (xxx)ofBERTisgenerallybetter
(cid:96)
1057SST CLINIC150
#feats AUROC DTACC AUIN AUOUT AUROC DTACC AUIN AUOUT
BERT-Singlelayer(best) 768 92.7 85.8 93.4 91.7 64.6 60.9 88.4 26.7
RoBERTa-Singlelayer(best) 768 89.8 91.5 79.2 93.8 59.9 57.6 86.8 22.7
BERT+Mean-Pooling 768 81.8 76.5 77.2 82.8 62.9 59.9 87.0 27.9
BERT+Max-Pooling 768 67.2 66.1 64.2 59.4 63.0 60.0 88.0 25.8
RoBERTa+Mean-Pooling 768 91.0 92.3 80.9 94.5 57.1 56.2 85.7 20.5
RoBERTa+Max-Pooling 768 93.2 91.9 89.3 95.1 54.9 54.4 84.8 19.4
BERT+EDF 12 90.1 84.8 92.8 84.2 55.3 55.2 84.3 20.3
BERT+MDF 12 93.3 87.5 94.9 89.1 76.7 71.1 93.4 38.2
BERT+IMLM+MDF 12 93.6 88.1 97.5 89.4 77.8 72.2 93.8 39.1
BERT+BCAD+MDF 12 97.0 94.5 98.0 94.8 81.2 74.5 94.6 47.4
BERT+IMLM+BCAD+MDF 12 98.1 95.4 98.7 95.9 82.1 75.6 95.0 47.6
RoBERTa+EDF 12 99.5 95.8 99.5 99.4 56.9 56.9 86.3 19.6
RoBERTa+MDF 12 99.8 97.7 99.8 99.8 78.6 71.9 93.8 42.6
RoBERTa+IMLM+MDF 12 99.9 97.8 99.8 99.8 80.1 73.1 94.5 44.9
RoBERTa+BCAD+MDF 12 99.2 96.6 99.4 98.7 80.5 72.9 94.3 49.4
RoBERTa+IMLM+BCAD+MDF 12 99.9 98.6 99.9 99.9 84.4 76.7 95.4 59.9
TF-IDF+SVD 100 78.0 72.0 78.2 73.2 58.5 56.5 86.2 21.8
BERT+BCAD+MSP - 68.5 69.0 61.5 65.4 68.3 63.5 89.7 34.1
RoBERTa+BCAD+MSP - 73.7 69.3 69.0 75.3 62.1 59.6 85.9 27.8
Table 3: OOD detection performance on SST and CLINIC 150 for all models. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 86>


<Paper ID = 861> <Table 0> <Abstractive Summary> =Table 4: Attribute-wise percentage improvement on
varioustasks
4.2 PerformanceComparison
Attribute #Ex. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 861>


<Paper ID = 861> <Table 1> <Abstractive Summary> =Table 3: Comparison of macro-F1 scores between Trouser
single 1.0 0.17 0.29
single-taskandmulti-taskmodelsforvariousverticals I occas. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 861>


<Paper ID = 863> <Table 0> <Abstractive Summary> =Actual CosineSimilarity FastText SANTA
SurfaceForm Comment
CanonicalForm Prediction Prediction prediction
multi multicoloured multicoloured green multicoloured
thermoplastic plastic plastic silicone plastic
FastTextfails
amdradeonr3 atiradeon atiradeon nvidiageforce atiradeon
freesize onesize onesize small onesize
2years 2-3years 11-12years 3-4years 2-3years
BothString
elbowsleeve halfsleeve 3/4sleeve shortsleeve halfsleeve
Similarityand
cane bamboo polyurethane rattan bamboo
fastTextfails
productwill requires require butSANTA
alreadyassembled d-i-y
beassembled assembly assembly givescorrect
3seater mapping
threeseat fourseat ﬁveseat threeseat
sofaset
nokiaos symbian palmwebos symbian symbian
StringSimilarity
silicone rubber silk rubber rubber
fails
coffee brown off-white brown brown
noassembly
already requires
required, requiresassembly alreadyassembled
assembled assembly SANTAfails
pre-aseembled
mechancial handdriven handdriven handdriven automatic
Table 3: Qualitative Examples for multiple normaliza-
tionapproaches. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 863>


<Paper ID = 864> <Table 0> <Abstractive Summary> =Table 2: Macro-F1 on the three product genres. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 864>


<Paper ID = 865> <Table 0> <Abstractive Summary> =Beyond the traditional to-
Characters: amercium ist ein
ken level representation, we adopted the sub-
word and character level representations for chemisches element
information retrieval that had shown to im-
prove neural machine translation by reducing Table 1: Example of a Pre-processed Document with
theout-of-vocabularyissuesinmachinetrans- DifferentTextRepresentations
lation. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 865>


<Paper ID = 865> <Table 1> <Abstractive Summary> =Theyshowed
thatthemodeloutperformscompetitivenon-neural
Table 2: Corpus statistics on Wikipedia documents in
traditionalIRsystemsonafewofthesub-tasks. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 865>


<Paper ID = 867> <Table 0> <Abstractive Summary> =Table 1: Number of data points in our data sets. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 867>


<Paper ID = 867> <Table 1> <Abstractive Summary> =138LFIndex Change Polarity Coverage Overlaps Conﬂicts %gaininF2
0 / [1] 0.02 0.01 0.01 4.35
1 / [0] 0.06 0.04 0.01 0.00
2 / 0.00 0.00 0.00 0.00
3 / 0.00 0.00 0.00 0.00
4 / 0.00 0.00 0.00 0.00
5 A [0] 0.69 0.23 0.05 0.53
6 A [0] 0.14 0.13 0.00 -0.41
7 A [0] 0.01 0.01 0.00 0.00
8 / [0] 0.01 0.01 0.00 0.00
9 / [0] 0.01 0.00 0.00 0.00
10 / [1] 0.01 0.01 0.01 -0.36
11 / [0] 0.06 0.04 0.00 0.00
12 / [0] 0.00 0.00 0.00 0.00
13 A [1] 0.11 0.06 0.05 73.21
14 N [0] 0.00 0.00 0.00 0.00
Table 4: This table contains the characteristics of the individual LFs for single-use plastic after they have been
adjustedwiththeinspirationSet1. </Abstractive Summary> <Extractive Summary> Table 1 summarizes the data
ticedthatmoderatorsaddedandchanged,butdid
thatweuse.  </Extractive Summary>  </Table 1>  </Paper ID = 867>


<Paper ID = 868> <Table 0> <Abstractive Summary> =ofDomains 12 2 2
Table 1: Some basic comparative statistics between the aspect extraction and aspect based sentiment analysis
datasets. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 868>


<Paper ID = 868> <Table 1> <Abstractive Summary> =Given
144Comparison ROUGE-L Fleiss’Kappa thejth domainas:
Aspect-aware 0.8994 0.8961
Aspect-blind 0.8722 0.9244 1 (cid:88)N (cid:88)k
p = n , 1 = p (5)
Overall 0.8960 0.9130 j Nn ij j
i=1 j=1
Table 2: The average ROUGE-L and Fleiss’ Kappa
We then calculate P , the degree of agreement
score in the translation and annotation tasks respec- i
tively. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 868>


<Paper ID = 869> <Table 0> <Abstractive Summary> =Table 1 shows
Table 2: Sequence length distribution when split by
thatwehaveslightlymorenegativethanpositive whitespacefortrainingset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 869>


<Paper ID = 869> <Table 1> <Abstractive Summary> =Anexamplewe Precision +0.50% -0.14%
often observe is when a user searches for a Lam- Recall -0.70% +0.10%
borghini(whichisnotpurchasableone-commerce
Table 6: Relative difference when using different dis-
platforms),thereturnedmatchesareLamborghini
tancemetrics(withcosinesimilarityasthebaseline)
toys, legos, etc. </Abstractive Summary> <Extractive Summary> Table 1 shows
Table 2: Sequence length distribution when split by
thatwehaveslightlymorenegativethanpositive whitespacefortrainingset.  </Extractive Summary>  </Table 1>  </Paper ID = 869>


<Paper ID = 869> <Table 2> <Abstractive Summary> =The multiple negatives
Precision +23.30% +24.95% +23.88%
rankinglossfunctionisusuallymoreusefulinthe
Recall -3.65% -4.88% -3.85%
informationretrievalusecase,whenonehasmore
Table 4: Relative difference between the system us-
positivepairs. </Abstractive Summary> <Extractive Summary> std and standard quantiles of number of tokens in se-
Table 2 displays the sequence length distribution quence.  </Extractive Summary>  </Table 2>  </Paper ID = 869>


<Paper ID = 869> <Table 3> <Abstractive Summary> =Henceextendingthecomparisonbetween Table 7: Relative difference when using alternative
itemNamecandidatesandmatchedproductswith lossfunctionscomparedtoonlinecontrastiveloss
thewholeutteranceinformationisbeneﬁcial. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 869>


<Paper ID = 87> <Table 0> <Abstractive Summary> =CoLA SST-2 MRPC STS-B QQP MNLI-m/mm QNLI RTE Score
TinyBERT(66M) 51.1 93.1 87.3/82.6 85.0/83.7 71.6/89.1 84.6/83.2 90.4 70.0 78.1
BERT (110M) 52.1 93.5 88.9/84.8 87.1/85.8 71.2/89.2 84.6/83.4 90.5 66.4 78.3
BASE
MobileBERT(66M) 51.1 92.6 88.8/84.5 86.2/84.8 70.5/88.3 84.3/83.4 91.6 70.4 78.5
DistilRoB.+KD(82M) 54.3 93.1 86.0/80.8 85.7/84.9 71.9/89.5 83.6/82.9 90.8 74.1 78.9
BERT (340M) 60.5 94.9 89.3/85.4 87.6/86.5 72.1/89.3 86.7/85.9 92.7 70.1 80.5
LARGE
MATE-KD(82M) 56.0 94.9 91.7/88.7 88.3/87.7 72.6/89.7 85.5/84.8 92.1 75.0 80.9
Table 2: Leaderboard test results of experiments on GLUE tasks. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 87>


<Paper ID = 87> <Table 1> <Abstractive Summary> =DistilRoBERTa 58.9 36.5
4.5 SensitivityAnalysis
Mate-KD 66.6 38.3
Our algorithm does not require the loss interpo-
lation weight of KD but instead relies on one ad-
Table 4: Model Performance on OOD evaluation sets
HANSandPAWSforMNLIandQQPrespectively ditional parameter, ρ, which is the probability of
masking a given token. </Abstractive Summary> <Extractive Summary> Single set tasks which include linguistic
Table 1 presents the results of MATE-KD on the
acceptability(CoLA)andsentimentanalysis(SST-
GLUEdevset. We present the effect of
We use the same model checkpoint as the one changingρinTable7onMNLIandRTEdevsetre-
presented in Table 1 and compare against Dis- sultsﬁxingallotherhyper-parameters.  </Extractive Summary>  </Table 1>  </Paper ID = 87>


<Paper ID = 87> <Table 2> <Abstractive Summary> =Moreover,wedemonstrate
Table 7: ρ value sensitivity analysis on two GLUE
theimportanceofmaskingforouralgorithm. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 87>


<Paper ID = 87> <Table 3> <Abstractive Summary> =RTE 16 7e-6 50
WNLI 8 7e-5 50
Raphael Tang, Yao Lu, Linqing Liu, Lili Mou, Olga
Table 8: Hyper-parameter values for the GLUE
Vechtomova, andJimmyLin.2019. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 87>


<Paper ID = 870> <Table 0> <Abstractive Summary> =jortypesoffactualerrorswhenproducingsum-
maries from customer feedback, which are
Table 1: Examples of the two major factual errors:
wrong entity detection (WED) and incorrect
WED(upper)andIPD(lower). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 870>


<Paper ID = 870> <Table 1> <Abstractive Summary> =whereL(s+,o)isthe cross entropylossbetween
s and o, L(s ,o) is the cross entropy loss be-
+ −
Table 2: Examples of corrupted summaries. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 870>


<Paper ID = 870> <Table 2> <Abstractive Summary> =160Model ROUGE-1 ROUGE-2 ROUGE-L
BART +0.30 +0.36 +0.49
+corruption,LDC
BART +0.54 +0.01 +0.59
+corruption,LCN
BART +0.83 +1.12 +0.68
+corruption,LCC
T5 +0.05 -0.19 +0.04
+corruption,LDC
T5 +0.20 +0.08 +0.25
+corruption,LCN
T5 +0.45 +0.71 +0.43
+corruption,LCC
Table 3: Impact of our approaches on ROUGE scores. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 870>


<Paper ID = 870> <Table 3> <Abstractive Summary> =CN CC
BART 1.2
4.3 Evaluationmetrics
T5 2.1
We employ the ROUGE-1, ROUGE-2, and
Table 5: Percentage of cases where the summaries
ROUGE-L scores (Lin, 2004) to ensure that our
fromtheordinarymodelsarefactualconsistentbutbe-
proposed methods do not degrade the ﬂuency
comeinconsistentafterourmethodsareapplied. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 870>


<Paper ID = 871> <Table 0> <Abstractive Summary> =Table 4: Performance of different guidance extrac-
#Train #Test #Categories
tion models. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 871>


<Paper ID = 871> <Table 1> <Abstractive Summary> =GetAccountSet- toaccessS3bucket
tings"" error and viaIAMuser
needed assistance
withthesame
Table 6: Examples of a few qualitative results produced by our model. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 871>


<Paper ID = 872> <Table 0> <Abstractive Summary> =lekinpricebahothighhai
an exponential growth in the number of
e-commerce users who are not proficient Table 1: Various noise present in product review
in English. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 872>


<Paper ID = 872> <Table 1> <Abstractive Summary> =(cid:1117)रयर कैमरा इमजे (cid:1340)ा(cid:1120)लट(cid:1200) बहुत अच्छ(cid:1201) ह।ै
(riyarkaimaraimejkvaaliteebahutachchheehai)
Table 3: Samples from the generated English-Hindi parallel corpus
ingtime(Vaibhavetal.,2019;Anastasopoulos 3.2 Pre-processing
et al., 2019). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 872>


<Paper ID = 872> <Table 2> <Abstractive Summary> =The hu-
Base+BT 48,000 37.79 41.35 man corrected parallel corpus is divided into
training, development and test set consisting
Table 4: BLEU and TER scores for English–to–
of 13000, 599 and 2,539 parallel sentences, re-
Hindi NMT system over review domain corpus
spectively. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 872>


<Paper ID = 872> <Table 3> <Abstractive Summary> =19https://github.com/awslabs/sockeye pl
180En–to–Hi(newstest2014) 20% 25% 30% 40% Adequacy Fluency
SubwordRegularization(SR) 14.37 13.68 10.31 9.81 Range: 0-4 Range: 0-4
Proposed 14.84 14.54 12.86 11.27 En–to–Hi(Proposed) 2.65 2.81
En–to–De(newstest2014) En–to–Hi(SR) 2.47 2.68
SubwordRegularization(SR) 27.24 26.18 24.83 23.48 En–to–Hi(BPE) 2.37 2.61
Proposed 28.53 27.34 26.08 25.22
En–to–Fr(IWSLT17) –
Table 8: Human evaluation for English–to–Hindi
SubwordRegularization(SR) 33.14 32.26 29.24 28.37
Proposed 34.45 33.29 31.07 30.35 translation
Table7: PerformanceevaluationintermsofBLEU
scores by increasing the % of noisy tokens
pre-processed; passed through an in-house ju-
dicial domain NMT system; and a part of this
dataset is post-edited by the language experts. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 872>


<Paper ID = 872> <Table 4> <Abstractive Summary> =Table 9: Output samples for English→Hindi and English→German translation
into Hindi. </Abstractive Summary> <Extractive Summary> Table 4 gives the statistics eration, andfinallynoisytokenreplacementat
about the dataset.  </Extractive Summary>  </Table 4>  </Paper ID = 872>


<Paper ID = 875> <Table 0> <Abstractive Summary> =Table 2: Word embeddings training hyper-parameter
2. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 875>


<Paper ID = 875> <Table 1> <Abstractive Summary> =Thethescaleofscore1to5isusedtoreﬂectpeo-
Table 5: Statistics of the gender bias scores from two
ple’sattitude,with1beingmorerelatedtofemale embeddings. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 875>


<Paper ID = 875> <Table 2> <Abstractive Summary> =Table 7: Pearson correlation coefﬁcient of the data Thiscouldbeexplainedbythedevelopmentoflan-
groupwithAGSSscores<3. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 875>


<Paper ID = 875> <Table 3> <Abstractive Summary> =However,thepublichasnotrealized
Table 8: Pearson correlation coefﬁcient of the data
suchdevelopmentalthoughtheymightstarttouse
groupwithAGSSscores>3. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 875>


<Paper ID = 876> <Table 0> <Abstractive Summary> =(2021) was trained on the IIT-Bombay
Hindi-English parallel data corpus (Kunchukut- Assume a fairness metric K is chosen from the
tan et al., 2018), which contains approximately setF,withaquerytemplates = (t,a),whereall
17Embedding WEAT RNSB RND ECT
NMT-English-(512D) 0.326529 0.018593 0.065842 0.540832
w2v-google-news-300 0.638202 0.01683 0.107376 0.743634
hi-300 0.273154 0.02065 0.168989 0.844888
NMT-Hindi-(512D) 0.182402 0.033457 0.031325 0.299023
Table 1: This table depicts the results for the various metrics that were used on the embeddings, and the ﬁnal
valuesbasedontheirrankingbytheWordEmbeddingFairnessEvaluationFramework. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 876>


<Paper ID = 877> <Table 0> <Abstractive Summary> =of Dates Personalpronouns Object
assistant source docs posted he/him she/her they/them pronounsit
amazon.com 5,000 2017-21 0.00 70.10 3.61 26.80
GooglePlay 12,537 2020-21 0.11 76.52 2.93 20.43
Alexa
r/alexa 5,022 2020-21 0.48 74.70 4.92 19.90
Total 22,559 – – – – –
GooglePlay 13,144 2018-21 6.20 36.78 3.31 55.37
Google
r/googleassistant 2,064 2020-21 3.55 11.24 4.73 80.47
Assistant
Total 15,208 – – – – –
Siri r/Siri(total) 1,356 2020-21 6.09 81.22 3.05 10.66
Table 3: Corpus statistics, and percentages of all pronouns used to refer to conversational assistants in user-
producedreviewsandforumposts. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 877>


<Paper ID = 877> <Table 1> <Abstractive Summary> =In the latter case, this is Siri 42.36 3.59 2.24
despitethefactthatSiricanbeusedwithamale-
Table 4: LIWC scores for Reddit posts discussing the
soundingvoice. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 877>


<Paper ID = 877> <Table 2> <Abstractive Summary> =Table 7: Cosine similarities between LIWC-derived
featurevectorsforsystemoutputsandgender-labelled
2. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 877>


<Paper ID = 879> <Table 0> <Abstractive Summary> =As no explanation is 
given in either paper for the choice of words within 
the word lists, we have no reason to assume that  Table 2:  Mean and standard dev. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 879>


<Paper ID = 879> <Table 1> <Abstractive Summary> =The word ‘office’ is the most male-skewed 
Table 1:  Garg gender terms. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 879>


<Paper ID = 879> <Table 2> <Abstractive Summary> ="#$%| |.&%"#$%| divorce, unmarried 
Caliskan’s manually clustered word sets produce 
an embedding bias against Garg’s female word list  Table 3:  Excerpt from the top twenty most 
of -0.03 in CAP. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 879>


<Paper ID = 879> <Table 3> <Abstractive Summary> =Similarly, all family terms came from the 
49
 
 Female  Female  Female  Male  Male  Male 
prostitution,  Children, heirs,  Incapable,  Shot, fired,  Price,  Engineer, 
illicit, abortion,  parents,  sick, weak,  killed,  amount,  foreman, 
lewd, carnal,  parent, spouse,  feeble,  drunk,  salary,  employer, 
unchaste,  wife, husband,  mentally,  shooting,  penalty,  employment, 
seduced, bastard  brother, sister,  physically,  fight  cost, fine,  contractor, 
daughter  mental  prices  master 
Table 5: K-Means clustered (automatic grouping) WLOR sample. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 879>


<Paper ID = 879> <Table 4> <Abstractive Summary> =For 
Table 4:  Excerpt of thematic grouping of 
example, in the manually-clustered WLOR output, 
highest-scoring WLOR results 
we  identified  areas  of  bias  by  thematically 
We then input our word l ists into WEAT in order to  grouping the output word list—but we still had an 
compute bias magnitude. </Abstractive Summary> <Extractive Summary> Although the words in 
standard  deviation  of  gender  slant  in  the  Table 4 are sorted thematically, it is interesting to 
embedding space (Table 2).  </Extractive Summary>  </Table 4>  </Paper ID = 879>


<Paper ID = 881> <Table 0> <Abstractive Summary> =However, adding the metadata
Table 4: Model performance of binary gender classiﬁ- aboutthepolarityofthereview(ifit’spositiveor
cation on dev and test for authors and critics. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 881>


<Paper ID = 882> <Table 0> <Abstractive Summary> =Inbothcases, thegroupsmarkedinredinTable4,andplottheir
79Women Men Generic
Sports USportswomen’ssoccer USportsmen’ssoccer USportssoccer
Lists Listofwomen’smagazines Listofmen’smagazines Listofmagazines
W|M|G
Social Humanfemalesexuality Humanmalesexuality Humansexuality
Sports Argentinawomen’snationalso- Argentina men’s national soft- –
ftballteam ballteam
W|M
Lists Listoffemaledetectivecharac- Listofmaledetectivecharacters –
ters
Social BollywoodMovieAward–Best BollywoodMovieAward–Best –
FemaleDebut MaleDebut
Sports Finlandwomen’snationalfoot- – Finlandnationalfootballteam
ballteam
W|G
Lists ListofAlbanianwomenwriters – ListofAlbanianwriters
Social WomeninIslam – Islam
Sports – TownChallengeCup(men) TownChallengeCup
Lists – List of Thai representatives at List of Thai representatives at
M|G
internationalmalebeautypage- internationalbeautypageants
ants
Social – Men’shealthinAustralia HealthinAustralia
Sports DanishLadiesMasters – –
Lists ListofDanishwomenphotogra- – –
W
phers
Social ViolenceagainstwomeninGu- – –
atemala
Names FourLadies(TVseries) – –
Sports – Ulster Senior League (men’s –
hockey)
M
Lists – Listofmalejazzsingers –
Social – MaleStudiesintheCaribbean –
Names – AndingMenstation –
Table 4: Examples of content-related tuples. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 882>


<Paper ID = 882> <Table 1> <Abstractive Summary> =Intermsofautomaticprocessing,the
Table 5: The titles and content properties of the Tur-
problemistwo-way. </Abstractive Summary> <Extractive Summary> universities,etc.,andOther,forarticlesthatdid
Table 1 lists word indicators used for the ﬁlte- notﬁtintoanyothermeta-category. canbebuiltfromthreearticles: Women,Men,and
Moreover,forGerman,Polish,andTurkishthelist
Generic(noticeinFigure1thatsomearticlesin
in Table 1 is extended with all inﬂected forms of
tuplesmightbemissing).  </Extractive Summary>  </Table 1>  </Paper ID = 882>


<Paper ID = 883> <Table 0> <Abstractive Summary> =Thisdifferenceisstatisti- with an average WER of 9.11% on books read
callysigniﬁcant(p-value=0.003)whenourtrain- by men and of and of 14.7% on books read by
89Model Gender test-clean
wper30 F 10.9%
M 8.3%
all 9.7%
wper50 F 11.0%
M 9.1%
all 10.2%
wper70 F 9.6%
M 8.3%
Figure 5: WER distributions on test-clean testing set
all 9.0%
bygenderforourtwomono-gendermodels.Blackdots
representthemeanvalueofeachdistributionregardless
Table 2: Mean WER by gender obtained on the Lib-
ofgendercategories. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 883>


<Paper ID = 884> <Table 0> <Abstractive Summary> =The unstructuredtest1 15892
sentencesmatchingthePOSsequencesmentioned
Table 1: Statistics of data used for building the NMT
intheAppendixwereextractedfromthisdataset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 884>


<Paper ID = 884> <Table 1> <Abstractive Summary> =4) N indíquemela indíquemela indíquemela indíquemela
disponibilidad disponibilidad emperbilidad evelbilidad
5) N indíquemesu indíquemesu indíquemesu indíquemesu
disponibilidad disponibilidad disponibilidad escorpibilidad
6) N unosmomentos unosmomentos unosmomentos unosmomentos
extraordinarios extraordinarios extraordinariasarios extraordinarios
7) N indíquenoscuánto indíquenoscuánto indíquenascuánto indíquenoscuánto
8) G estaeslaadecuada esteeseladecuado estaeslaadecuada estaesloadecuada
9) G estalahemosrecibido estelohemosrecibido estalahemosrecibido estalohemosrecibido
Table 4: Examples of incorrectly generated sentence variants for (a) structured sentences and (b) unstructured
sentences. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 884>


<Paper ID = 885> <Table 0> <Abstractive Summary> =TheGIPEextendsthis
108Table 3: Clustering: (reported as accuracy and v-measure (Rosenberg and Hirschberg, 2007)) is performed by
taking the n = 1500 most biased words in the original embedding space (excluding deﬁnitional gender words),
andperformingk-meansclustering(k =2)onthesamewordsinthedebiasedspace. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 885>


<Paper ID = 887> <Table 0> <Abstractive Summary> =With a
4FKGL Dress-Ls EncDecA Hybrid
Approach 0% 10% 50% 100% 0% 10% 50% 100% 0% 10% 50% 100%
random-period 4.5426 2.6223 1.4154 5.2902 3.4309 1.9016 4.2706 2.6543 1.3512
random-the 5.0006 4.9095 5.1919 6.1273 6.0509 5.9596 4.7434 4.6204 4.8678
replace-longest 4.8837 4.3242 3.6244 5.6408 5.1763 4.5984 4.6108 3.9492 3.1241
5.024 5.757 4.775
replace-rand-period 4.5510 2.6494 1.4359 5.2959 3.4474 1.9173 4.2884 2.7283 1.4524
replace-rand-the 4.9915 4.8636 4.7003 5.8014 5.8058 5.8001 4.7282 4.5449 4.3104
rand-period+
4.4098 1.9831 0.1643 5.1806 2.8913 0.8477 4.1234 1.9268 -0.0665
repl-longest
BLEU Dress-Ls EncDecA Hybrid
Approach 0% 10% 50% 100% 0% 10% 50% 100% 0% 10% 50% 100%
random-period 0.2330 0.2158 0.1953 0.2086 0.1954 0.1794 0.1069 0.1004 0.0898
random-the 0.2334 0.2174 0.1985 0.2088 0.1963 0.1814 0.1071 0.1015 0.0919
replace-longest 0.2343 0.2215 0.2052 0.2097 0.2008 0.1895 0.1069 0.1016 0.0948
0.237 0.212 0.108
replace-rand-period 0.2336 0.2176 0.1977 0.2088 0.1965 0.1808 0.1063 0.0984 0.0883
replace-rand-the 0.2337 0.2184 0.1991 0.2088 0.1965 0.1808 0.1063 0.0984 0.0879
rand-period+
0.2306 0.2036 0.1710 0.2067 0.1871 0.1621 0.1059 0.0957 0.0806
repl-longest
SARI Dress-Ls EncDecA Hybrid
Approach 0% 10% 50% 100% 0% 10% 50% 100% 0% 10% 50% 100%
random-period 0.3626 0.3618 0.3608 0.3598 0.3593 0.3586 0.3470 0.3468 0.3465
random-the 0.3627 0.3621 0.3616 0.3599 0.3596 0.3593 0.3471 0.3471 0.3473
replace-longest 0.3627 0.3622 0.3618 0.3600 0.3598 0.3597 0.3471 0.3472 0.3474
0.363 0.360 0.347
replace-rand-period 0.3626 0.3614 0.3601 0.3598 0.3590 0.3579 0.3470 0.3466 0.3462
replace-rand-the 0.3626 0.3617 0.3607 0.3599 0.3593 0.3586 0.3470 0.3469 0.3468
rand-period+
0.3625 0.3614 0.3604 0.3598 0.3591 0.3587 0.3470 0.3471 0.3471
repl-longest
Table 1: Experimental results (FKGL, BLEUand SARI scores) for10%, 50% and 100%of the sentences being
modiﬁedonthreesystems: Dress-Ls,EncDecAandHybrid. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 887>


<Paper ID = 887> <Table 1> <Abstractive Summary> =Table 3: Post-hoc statistics for original and reference
ForSARI,atthe1-gramlevel,theAddF1score datafromthetestcorpusandﬁvesystemoutputs. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 887>


<Paper ID = 887> <Table 2> <Abstractive Summary> =Dress-Ls
Approach/
10 20 30 40 50 60 70 80 90 100
%modiﬁed
FKGL
random-period 4.5426 4.0609 3.5802 3.1014 2.6223 2.5358 2.0595 1.9742 1.7763 1.4154
random-the 5.0006 4.9772 4.9543 4.9319 4.9095 4.8870 5.2557 5.2346 5.2130 5.1919
replace-longest 4.8837 4.7464 4.6050 4.4644 4.3242 4.1857 4.0442 3.9038 3.7647 3.6244
replace-rand-period 4.5510 4.0765 3.6007 3.1251 2.6494 2.5670 2.0910 2.0005 1.5256 1.4359
replace-rand-the 4.9915 4.9607 4.9259 4.8955 4.8636 4.8288 4.7985 4.7638 4.7324 4.7003
random-period
4.4098 3.8000 3.1911 2.5864 1.9831 1.7665 1.1681 0.9604 0.3671 0.1643
+replace-longest
SARI
random-period 0.3626 0.3624 0.3622 0.3619 0.3618 0.3616 0.3613 0.3612 0.3610 0.3608
random-the 0.3627 0.3626 0.3624 0.3623 0.3621 0.3620 0.3619 0.3618 0.3617 0.3616
replace-longest 0.3627 0.3626 0.3625 0.3623 0.3622 0.3622 0.3620 0.3620 0.3619 0.3618
replace-rand-period 0.3626 0.3623 0.3620 0.3617 0.3614 0.3612 0.3609 0.3606 0.3604 0.3601
replace-rand-the 0.3626 0.3624 0.3622 0.3619 0.3617 0.3615 0.3612 0.3611 0.3609 0.3607
random-period
0.3625 0.3622 0.3619 0.3617 0.3614 0.3612 0.3609 0.3608 0.3606 0.3604
+replace-longest
BLEU
random-period 0.2330 0.2287 0.2243 0.2200 0.2158 0.2119 0.2075 0.2033 0.1994 0.1953
random-the 0.2334 0.2293 0.2253 0.2216 0.2174 0.2136 0.2097 0.2059 0.2022 0.1985
replace-longest 0.2343 0.2312 0.2281 0.2247 0.2215 0.2184 0.2151 0.2120 0.2086 0.2052
replace-rand-period 0.2336 0.2297 0.2258 0.2218 0.2176 0.2138 0.2099 0.2057 0.2017 0.1977
replace-rand-the 0.2337 0.2300 0.2261 0.2224 0.2184 0.2148 0.2104 0.2068 0.2032 0.1991
random-period
0.2306 0.2237 0.2170 0.2104 0.2036 0.1972 0.1903 0.1843 0.1775 0.1710
+replace-longest
Table4: Metricscoresof10-100%modiﬁedoutputsofDress-LS
9EncDecA
Approach/
10 20 30 40 50 60 70 80 90 100
%modiﬁed
FKGL
random-period 5.2905 4.8237 4.3576 3.8938 3.4304 2.9668 2.8942 2.4334 2.3618 1.9012
random-the 6.1272 6.1077 6.0884 6.0696 6.0507 6.0319 6.0138 5.9956 5.9777 5.9600
replace-longest 5.6413 5.5258 5.4092 5.2943 5.1792 5.0623 4.9459 4.8306 4.7143 4.5984
replace-rand-period 5.2958 4.8351 4.3718 3.9104 3.4496 2.9878 2.9127 2.4525 2.3804 1.9200
replace-rand-the 5.8045 5.8418 5.7950 5.7942 5.8163 5.8146 5.8060 5.7801 5.7838 5.7498
random-period
5.1811 4.6057 4.0323 3.4621 2.8906 2.3232 2.1496 1.5827 1.4098 0.8463
+replace-longest
SARI
random-period 0.3598 0.3597 0.3595 0.3594 0.3592 0.3591 0.3590 0.3588 0.3587 0.3586
random-the 0.3599 0.3598 0.3597 0.3596 0.3596 0.3595 0.3595 0.3594 0.3593 0.3593
replace-longest 0.3600 0.3599 0.3599 0.3598 0.3598 0.3597 0.3598 0.3597 0.3597 0.3597
replace-rand-period 0.3598 0.3596 0.3593 0.3591 0.3590 0.3587 0.3585 0.3583 0.3582 0.3580
replace-rand-the 0.3599 0.3597 0.3596 0.3594 0.3593 0.3591 0.3589 0.3588 0.3587 0.3585
random-period
0.3598 0.3597 0.3595 0.3593 0.3592 0.3590 0.3590 0.3589 0.3588 0.3587
+replace-longest
BLEU
random-period 0.2085 0.2052 0.2019 0.1987 0.1954 0.1921 0.1891 0.1858 0.1827 0.1796
random-the 0.2087 0.2056 0.2024 0.1994 0.1964 0.1935 0.1905 0.1875 0.1844 0.1815
replace-longest 0.2098 0.2075 0.2053 0.2031 0.2007 0.1986 0.1964 0.1941 0.1918 0.1895
replace-rand-period 0.2088 0.2058 0.2025 0.1994 0.1966 0.1932 0.1903 0.1871 0.1841 0.1808
replace-rand-the 0.2089 0.2057 0.2027 0.1995 0.1965 0.1933 0.1900 0.1870 0.1837 0.1805
random-period
0.2068 0.2019 0.1967 0.1917 0.1869 0.1817 0.1768 0.1721 0.1670 0.1621
+replace-longest
Table5: Metricscoresof10-100%modiﬁedoutputsofEncDecA
Hybrid
Approach/
10 20 30 40 50 60 70 80 90 100
%modiﬁed
FKGL
random-period 4.2706 3.7659 3.2634 3.1522 2.6543 2.5450 2.0501 1.9458 1.4523 1.3512
random-the 4.7434 4.7118 4.6808 4.6503 4.6204 4.5907 4.9520 4.9236 4.8950 4.8678
replace-longest 4.6108 4.4474 4.2792 4.1167 3.9492 3.7866 3.6211 3.4546 3.2903 3.1241
replace-rand-period 4.2884 3.7986 3.3114 3.2161 2.7283 2.5598 2.1379 2.0364 1.5465 1.4524
replace-rand-the 4.7282 4.6833 4.6363 4.5903 4.5449 4.4997 4.4539 4.4070 4.3613 4.3104
random-period
4.1234 3.4704 2.8198 2.5699 1.9268 1.6807 1.0422 0.7992 0.1686 -0.0665
+replace-longest
SARI
random-period 0.3470 0.3469 0.3469 0.3468 0.3468 0.3467 0.3467 0.3466 0.3466 0.3465
random-the 0.3471 0.3471 0.3471 0.3471 0.3471 0.3472 0.3472 0.3472 0.3472 0.3473
replace-longest 0.3471 0.3471 0.3472 0.3472 0.3472 0.3473 0.3473 0.3473 0.3474 0.3474
replace-rand-period 0.3470 0.3469 0.3468 0.3467 0.3466 0.3466 0.3465 0.3464 0.3463 0.3462
replace-rand-the 0.3470 0.3470 0.3470 0.3470 0.3469 0.3469 0.3469 0.3469 0.3468 0.3468
random-period
0.3470 0.3470 0.3471 0.3471 0.3471 0.3471 0.3471 0.3471 0.3471 0.3471
+replace-longest
BLEU
random-period 0.1069 0.1054 0.1042 0.1026 0.1004 0.0981 0.0959 0.0939 0.0917 0.0898
random-the 0.1071 0.1059 0.1047 0.1033 0.1015 0.0994 0.0975 0.0956 0.0938 0.0919
replace-longest 0.1069 0.1055 0.1043 0.1028 0.1016 0.1002 0.0989 0.0975 0.0962 0.0948
replace-rand-period 0.1063 0.1043 0.1025 0.1006 0.0984 0.0965 0.0944 0.0926 0.0904 0.0883
replace-rand-the 0.1063 0.1042 0.1022 0.1004 0.0984 0.0962 0.0941 0.0921 0.0898 0.0879
random-period
0.1059 0.1036 0.1012 0.0986 0.0957 0.0924 0.0895 0.0866 0.0836 0.0806
+replace-longest
Table6: Metricscoresof10-100%modiﬁedoutputsofHybrid
10Dress
Approach/
10 20 30 40 50 60 70 80 90 100
%modiﬁed
FKGL
random-period 4.4416 3.9367 3.4778 2.9987 2.5223 2.4322 1.9566 1.8709 1.3976 1.3138
random-the 4.9011 4.8782 4.8557 4.8336 4.8115 4.7899 4.7686 5.1378 5.1166 5.0966
replace-longest 4.7838 4.6432 4.5021 4.3628 4.2182 4.0781 3.9378 3.7971 3.6582 3.5147
replace-rand-period 4.3679 3.7817 3.4981 3.0221 2.5450 2.4596 1.9872 1.8958 1.4210 1.3311
replace-rand-the 4.8922 4.8580 4.8276 4.7936 4.7614 4.7301 4.6980 4.6648 4.6344 4.5964
random-period
4.3096 3.3390 3.0860 2.4810 1.8723 1.6601 1.0603 0.8498 0.2588 0.0536
+replace-longest
SARI
random-period 0.3621 0.3618 0.3616 0.3614 0.3612 0.3610 0.3608 0.3607 0.3605 0.3603
random-the 0.3622 0.3620 0.3619 0.3617 0.3616 0.3615 0.3614 0.3613 0.3612 0.3611
replace-longest 0.3622 0.3621 0.3620 0.3620 0.3619 0.3618 0.3618 0.3617 0.3617 0.3617
replace-rand-period 0.3620 0.3617 0.3614 0.3612 0.3609 0.3607 0.3605 0.3601 0.3599 0.3597
replace-rand-the 0.3621 0.3619 0.3617 0.3615 0.3613 0.3612 0.3609 0.3608 0.3607 0.3605
random-period
0.3620 0.3618 0.3615 0.3613 0.3612 0.3609 0.3608 0.3606 0.3604 0.3603
+replace-longest
BLEU
random-period 0.2230 0.2187 0.2145 0.2104 0.2062 0.2021 0.1979 0.1941 0.1902 0.1864
random-the 0.2233 0.2193 0.2156 0.2116 0.2078 0.2041 0.2005 0.1969 0.1931 0.1895
replace-longest 0.2243 0.2214 0.2183 0.2156 0.2124 0.2095 0.2066 0.2034 0.2004 0.1974
replace-rand-period 0.2234 0.2196 0.2156 0.2121 0.2080 0.2041 0.2005 0.1964 0.1925 0.1889
replace-rand-the 0.2234 0.2198 0.2158 0.2120 0.2080 0.2043 0.2003 0.1964 0.1926 0.1886
random-period
0.2208 0.2142 0.2078 0.2015 0.1954 0.1887 0.1826 0.1761 0.1700 0.1638
+replace-longest
Table7: Metricscoresof10-100%modiﬁedoutputsofDress
PBMT-R
Approach/
10 20 30 40 50 60 70 80 90 100
%modiﬁed
FKGL
random-period 7.5360 7.0897 6.2541 5.8091 5.3639 4.9187 4.4746 4.4210 3.9773 3.5354
random-the 8.7462 8.7303 8.7147 8.6992 8.6838 8.6684 8.6535 8.6384 8.6233 8.6087
replace-longest 8.2773 8.1807 8.0855 7.9908 7.8946 7.7988 7.7028 7.6075 7.5115 7.4150
replace-rand-period 7.6177 7.0975 6.2632 5.8203 5.3775 4.9330 4.4944 4.3366 3.9970 3.5487
replace-rand-the 8.3526 8.3343 8.3227 8.3330 8.3251 8.2865 8.3119 8.3015 8.3143 8.3201
random-period
7.4441 6.9062 5.9773 5.4449 4.9073 4.3749 3.8442 3.7010 3.1695 2.6411
+replace-longest
SARI
random-period 0.3568 0.3566 0.3565 0.3563 0.3562 0.3560 0.3559 0.3557 0.3556 0.3555
random-the 0.3568 0.3568 0.3567 0.3566 0.3565 0.3565 0.3564 0.3564 0.3563 0.3562
replace-longest 0.3568 0.3566 0.3564 0.3563 0.3562 0.3560 0.3559 0.3558 0.3557 0.3556
replace-rand-period 0.3566 0.3564 0.3561 0.3559 0.3556 0.3554 0.3553 0.3550 0.3548 0.3546
replace-rand-the 0.3567 0.3565 0.3564 0.3561 0.3560 0.3558 0.3557 0.3555 0.3554 0.3553
random-period
0.3566 0.3564 0.3561 0.3558 0.3556 0.3554 0.3552 0.3549 0.3549 0.3546
+replace-longest
BLEU
random-period 0.1751 0.1730 0.1709 0.1689 0.1668 0.1647 0.1628 0.1608 0.1588 0.1567
random-the 0.1752 0.1732 0.1711 0.1692 0.1674 0.1655 0.1637 0.1617 0.1598 0.1580
replace-longest 0.1754 0.1736 0.1718 0.1700 0.1682 0.1664 0.1647 0.1628 0.1611 0.1592
replace-rand-period 0.1751 0.1732 0.1710 0.1691 0.1670 0.1650 0.1631 0.1610 0.1590 0.1571
replace-rand-the 0.1752 0.1732 0.1713 0.1691 0.1673 0.1651 0.1632 0.1611 0.1590 0.1571
random-period
0.1736 0.1701 0.1664 0.1628 0.1593 0.1559 0.1523 0.1487 0.1454 0.1418
+replace-longest
Table8: Metricscoresof10-100%modiﬁedoutputsofPBMT-R
11PercentModiﬁed 0 100
Approach random- random- replace- replace- replace- random-
period the longest rand- rand-the period
period +replace-
longest
Dress-Ls
1-gram 0.4590 0.4300 0.4394 0.4468 0.4340 0.4428 0.4186
2-gram 0.2638 0.2289 0.2301 0.2339 0.2289 0.2276 0.2026
3-gram 0.1896 0.1496 0.1509 0.1581 0.1511 0.1497 0.1249
4-gram 0.1384 0.0997 0.1003 0.1074 0.1016 0.1003 0.0763
EncDecA
1-gram 0.4156 0.4300 0.4394 0.4468 0.4340 0.4428 0.4186
2-gram 0.2373 0.2281 0.2300 0.2339 0.2291 0.2275 0.2037
3-gram 0.1686 0.1495 0.1518 0.1581 0.1516 0.1501 0.1265
4-gram 0.1212 0.0990 0.1014 0.1074 0.1019 0.1005 0.0787
Hybrid
1-gram 0.3708 0.4300 0.4394 0.4468 0.4339 0.4432 0.4186
2-gram 0.1328 0.2281 0.2298 0.2339 0.2286 0.2275 0.2038
3-gram 0.0710 0.1494 0.1517 0.1581 0.1509 0.1501 0.1268
4-gram 0.0442 0.0991 0.1015 0.1074 0.1012 0.1007 0.0794
Dress
1-gram 0.4517 0.4300 0.4394 0.4468 0.4336 0.4432 0.4186
2-gram 0.2537 0.2282 0.2299 0.2339 0.2286 0.2281 0.2038
3-gram 0.1800 0.1499 0.1516 0.1581 0.1507 0.1500 0.1266
4-gram 0.1292 0.0998 0.1016 0.1074 0.1010 0.1005 0.0790
PBMT-R
1-gram 0.3577 0.4300 0.4394 0.4468 0.4340 0.4428 0.4186
2-gram 0.2020 0.2280 0.2299 0.2339 0.2289 0.2274 0.2039
3-gram 0.1392 0.1492 0.1518 0.1581 0.1514 0.1500 0.1270
4-gram 0.0979 0.0990 0.1014 0.1074 0.1016 0.1008 0.0796
Table 9: BLEU score breakdown (1-, 2-, 3- and 4-gram scores) for all combination of systems and modiﬁcation
approaches
12PercentModiﬁed 0 100
Approach random- random- replace- replace- replace- random-
period the longest rand- rand- period
period the +replace-
longest
Dress-Ls
1-gram
AddF1 0.0382 0.0382 0.0518 0.0505 0.0371 0.0504 0.0505
KeepF1 0.1181 0.1181 0.1169 0.1181 0.1186 0.1174 0.1181
DeleteP 0.9740 0.9740 0.9741 0.9722 0.9718 0.9717 0.9722
2-gram
AddF1 0.0370 0.0345 0.0322 0.0319 0.0323 0.0311 0.0285
KeepF1 0.0742 0.0739 0.0740 0.0751 0.0736 0.0735 0.0746
DeleteP 0.9805 0.9798 0.9800 0.9794 0.9788 0.9787 0.9784
3-gram
AddF1 0.0263 0.0229 0.0215 0.0215 0.0221 0.0211 0.0173
KeepF1 0.0573 0.0570 0.0573 0.0588 0.0569 0.0569 0.0582
DeleteP 0.9850 0.9841 0.9844 0.9843 0.9837 0.9836 0.9832
4-gram
AddF1 0.0189 0.0155 0.0145 0.0150 0.0154 0.0143 0.0112
KeepF1 0.0450 0.0446 0.0450 0.0463 0.0448 0.0447 0.0455
DeleteP 0.9885 0.9876 0.9879 0.9878 0.9874 0.9874 0.9869
EncDecA
1-gram
AddF1 0.0382 0.0382 0.0518 0.0505 0.0372 0.0511 0.0505
KeepF1 0.1181 0.1181 0.1169 0.1181 0.1188 0.1174 0.1181
DeleteP 0.9740 0.9740 0.9741 0.9722 0.9719 0.9718 0.9722
2-gram
AddF1 0.0387 0.0343 0.0317 0.0319 0.0333 0.0316 0.0289
KeepF1 0.0744 0.0738 0.0739 0.0751 0.0736 0.0736 0.0748
DeleteP 0.9812 0.9798 0.9800 0.9794 0.9788 0.9788 0.9785
3-gram
AddF1 0.0293 0.0228 0.0217 0.0215 0.0223 0.0215 0.0174
KeepF1 0.0576 0.0570 0.0571 0.0588 0.0570 0.0568 0.0586
DeleteP 0.9859 0.9841 0.9843 0.9843 0.9837 0.9836 0.9833
4-gram
AddF1 0.0219 0.0154 0.0148 0.0150 0.0150 0.0147 0.0113
KeepF1 0.0454 0.0449 0.0450 0.0463 0.0448 0.0448 0.0459
DeleteP 0.9893 0.9877 0.9879 0.9878 0.9874 0.9874 0.9870
Hybrid
1-gram
AddF1 0.0382 0.0382 0.0518 0.0505 0.0365 0.0511 0.0505
KeepF1 0.1181 0.1181 0.1169 0.1181 0.1186 0.1174 0.1181
DeleteP 0.9740 0.9740 0.9741 0.9722 0.9718 0.9717 0.9722
2-gram
AddF1 0.0387 0.0339 0.0319 0.0319 0.0324 0.0312 0.0286
KeepF1 0.0744 0.0739 0.0740 0.0751 0.0732 0.0734 0.0744
DeleteP 0.9812 0.9798 0.9800 0.9794 0.9787 0.9787 0.9784
3-gram
AddF1 0.0293 0.0225 0.0215 0.0215 0.0215 0.0210 0.0177
KeepF1 0.0576 0.0571 0.0571 0.0588 0.0563 0.0567 0.0579
DeleteP 0.9859 0.9841 0.9843 0.9843 0.9835 0.9836 0.9832
4-gram
AddF1 0.0219 0.0153 0.0145 0.0150 0.0144 0.0142 0.0116
KeepF1 0.0454 0.0451 0.0449 0.0463 0.0440 0.0446 0.0452
DeleteP 0.9893 0.9877 0.9879 0.9878 0.9873 0.9874 0.9869
13PercentModiﬁed 0 100
Approach random- random- replace- replace- replace- random-
period the longest rand- rand- period
period the +replace-
longest
Dress
1-gram
AddF1 0.0382 0.0382 0.0518 0.0505 0.0369 0.0511 0.0505
KeepF1 0.1181 0.1181 0.1169 0.1181 0.1187 0.1174 0.1181
DeleteP 0.9740 0.9740 0.9741 0.9722 0.9718 0.9717 0.9722
2-gram
AddF1 0.0387 0.0340 0.0324 0.0319 0.0324 0.0317 0.0287
KeepF1 0.0744 0.0738 0.0739 0.0751 0.0735 0.0735 0.0745
DeleteP 0.9812 0.9797 0.9800 0.9794 0.9788 0.9787 0.9784
3-gram
AddF1 0.0293 0.0224 0.0215 0.0215 0.0218 0.0216 0.0173
KeepF1 0.0576 0.0568 0.0571 0.0588 0.0567 0.0568 0.0579
DeleteP 0.9859 0.9841 0.9843 0.9843 0.9836 0.9836 0.9832
4-gram
AddF1 0.0219 0.0151 0.0147 0.0150 0.0146 0.0147 0.0113
KeepF1 0.0454 0.0446 0.0450 0.0463 0.0445 0.0445 0.0452
DeleteP 0.9893 0.9876 0.9878 0.9878 0.9874 0.9873 0.9869
PBMT-R
1-gram
AddF1 0.0382 0.0382 0.0518 0.0505 0.0368 0.0509 0.0505
KeepF1 0.1181 0.1181 0.1169 0.1181 0.1187 0.1172 0.1181
DeleteP 0.9740 0.9740 0.9741 0.9722 0.9718 0.9716 0.9722
2-gram
AddF1 0.0387 0.0337 0.0320 0.0319 0.0327 0.0311 0.0288
KeepF1 0.0744 0.0739 0.0740 0.0751 0.0736 0.0731 0.0746
DeleteP 0.9812 0.9798 0.9800 0.9794 0.9788 0.9786 0.9784
3-gram
AddF1 0.0293 0.0223 0.0216 0.0215 0.0220 0.0207 0.0177
KeepF1 0.0576 0.0571 0.0572 0.0588 0.0568 0.0564 0.0581
DeleteP 0.9859 0.9842 0.9843 0.9843 0.9837 0.9835 0.9832
4-gram
AddF1 0.0219 0.0148 0.0145 0.0150 0.0151 0.0137 0.0116
KeepF1 0.0454 0.0447 0.0449 0.0463 0.0447 0.0442 0.0454
DeleteP 0.9893 0.9877 0.9878 0.9878 0.9874 0.9873 0.9869
Table10: SARIscorebreakdown(F1andprecisionscoresusedinthescorecalculationfor1-,2-,3-and4-gram)
forallcombinationofsystemsandmodiﬁcationapproaches(longtablespanningtwopages)
14 </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 887>


<Paper ID = 888> <Table 0> <Abstractive Summary> =Table 3: Scores for each system as evaluated by hu-
Thisphenomenonappearsexacerbatedwithlonger
mans and by the regressor, averaged over test set in-
texts, as the blue and red lines are more distant
stancesandthusoverallsentencelengths. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 888>


<Paper ID = 889> <Table 0> <Abstractive Summary> =26VocabSize VocabSize Type/Token AvgWord AvgSentence
Language
(Cased) (Uncased) Ratio Length Length
English 18,736 16,225 0.09 4.62 10.15
Turkish 29,461 26,649 0.19 6.20 8.26
Table 2: English and Turkish STSb dataset statistics. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 889>


<Paper ID = 889> <Table 1> <Abstractive Summary> =The
S-M-BERT+NLI+STS 75.74 75.41
modeloptimizesthecrossentropyloss: S-XLM-R+NLI+STS 77.26 77.32
Table 4: Experiment results for semantic textual sim-
o = softmax(W (u,v,|u−v|)),W (cid:15)R3n×k
t t ilarity. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 889>


<Paper ID = 889> <Table 2> <Abstractive Summary> =28Cross-Encoder Bi-Encoder ROUGE OtherMetrics
Model NLI+STS STS NLI+STS STS ROUGE-1 ROUGE-2 ROUGE-L BERTScore
Lead-1 52.11 55.71 59.18 61.67 26.56 17.31 25.31 73.72
Lead-3 60.78 61.86 69.72 71.01 30.04 18.90 28.83 74.15
mT5 59.00 61.03 66.43 68.29 33.22 22.44 31.90 75.90
Table 5: Results of the summarization models on MLSUM dataset. </Abstractive Summary> <Extractive Summary> Table 2 shows vocabulary size (cased and un-
cased),type/tokenratio,averagewordlengthand
C1: Birmasadaduraneskiyes¸ils¸is¸e.  </Extractive Summary>  </Table 2>  </Paper ID = 889>


<Paper ID = 89> <Table 0> <Abstractive Summary> =1091length, batch size, learning rate, and number of Table 3: Accuracy of representative shallow∗, deep,
and pre-trained models for complexity prediction. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 89>


<Paper ID = 89> <Table 1> <Abstractive Summary> =ACCESS 94.25% 93.66% Eventhoughthisexplainablepreliminarydoesnot
Biendata
DMLMTL 98.88% 98.73%
necessarilyreﬂecthowablack-boxsimpliﬁcation
model “thinks”, adding it to the model is able to
Table 7: Out-of-sample performance of simpliﬁcation
yieldbetterout-of-sampleperformance. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 89>


<Paper ID = 890> <Table 0> <Abstractive Summary> =63.0 71.1 75.0 76.2 62.4 65.5 74.4 89.9 83.2 90.2 87.0 60.1 95.9
Table 5: Comparison of Inform & Success. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 890>


<Paper ID = 892> <Table 0> <Abstractive Summary> =Direct rating refers to evaluations where Table 6: Number of papers using each rating type for
eachsystemoutputisassessedinisolationforthat thethreeevaluationdimensionsacrossyears. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 892>


<Paper ID = 892> <Table 1> <Abstractive Summary> =62
RatingScale (1) [-2,-1,0,1,2]
 ((((((314112)))))) [[[[[[-pppm03ooo,1o,lss-,irii22tette,ii]vv,f-oee1s,,rl,imnng0eeh,agglt1,laa,ymtt2iivvp,oeeo3r,,le]inrtieeenl,uafnotxrereamudl]t,araal,ln,nnseoliiytghehedtr]l]yrude,rude]
DIRECT (40)
(2) [1,2,3]
 Notavailable (1((((19212))))) [[[b011in,,,12a2,,r2,3y,3,34,,,445,,,565],]7,8,9,10]
(cid:26)
Bestselection (5)
RELATIVE (12)
Pairwise (7)
Table 7: Style results. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 892>


<Paper ID = 892> <Table 2> <Abstractive Summary> = RatingScale (1) [-2,-1,0,1,2]
 (2(((6115)))) [[[[0111,,,,1222,,,233,]],34,]4,5]
DIRECT (45)
(1) [0,1,2,3,4,5]
 Notavailable (((433))) [[11,,22,,33,,44,,55,,66],7,8,9,10]

Bestselection (3)

RELATIVE (9) Pairwise (3)
 Ranking (3)
Table 8: Meaning Preservation results. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 892>


<Paper ID = 893> <Table 0> <Abstractive Summary> =We also want a generation originality
testthatﬂagspotentialplagiarismoforiginalfrag- Table 1: Criterion per fragment type, where C is the
mentsinthegroundtruth,whichneitherBLEUnor number of times the fragment appears in the ground
PPLdoes. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 893>


<Paper ID = 896> <Table 0> <Abstractive Summary> =BART 0.57 0.12 0.41 7.1 10.7 583 2.7k 1.2k 10.5
CommonGen
T5 0.51 0.11 0.36 6.5 10.1 465 2.0k 1.0k 9.6
mT5-small 0.51 0.04 0.1 6.2 7.8 86 278 287 10.2
CzechRestaurant mT5-base 0.49 0.03 0.09 6.1 7.6 80 249 273 10.5
mT5-large 0.57 0.05 0.13 6.6 8.4 103 387 361 10.1
mT5-XL 0.6 0.06 0.19 6.8 9.0 146 614 438 9.5
TGen 0.57 0.03 0.11 6.4 8.0 58 239 245 9.1
TGen+ 0.61 0.04 0.12 6.5 8.1 84 290 305 9.2
TGen++ 0.56 0.04 0.11 6.5 8.1 85 280 297 9.5
BART 0.55 0.19 0.45 8.4 11.3 1.3k 3.6k 2.4k 12.0
DART
T5 0.51 0.19 0.42 8.0 10.7 1.2k 3.1k 2.1k 10.8
BART 0.32 0.005 0.02 5.7 7.2 16 104 149 22.0
LSTM 0.31 0.004 0.02 5.6 7.1 19 106 139 23.1
E2Eclean
T5 0.30 0.004 0.01 5.6 6.9 7 60 125 23.0
TGen 0.31 0.004 0.02 5.6 7.2 19 116 140 23.2
MLSum(de) mBART 0.78 0.11 0.52 10.6 16.3 27k 166k 46k 35.7
mT5-small 0.75 0.12 0.52 10.4 15.8 20.1k 113.8k 33.6k 24.7
mT5-base 0.76 0.12 0.53 10.4 15.8 20.2k 113.0k 33.3k 24.2
mT5-large 0.76 0.12 0.53 10.4 15.8 20.0k 114.0k 33.3k 24.4
mT5-XL 0.77 0.12 0.53 10.4 15.8 20.0k 114.6k 33.3k 24.5
MLSum(es) mBART 0.71 0.10 0.47 10.1 15.7 19k 120k 35k 32.3
mT5-small 0.69 0.12 0.48 10.0 15.1 14.0k 77.6k 25.5k 21.7
mT5-base 0.71 0.12 0.5 10.1 15.3 15.1k 85.2k 27.2k 23.0
mT5-large 0.71 0.12 0.5 10.1 15.3 14.9k 82.0k 26.6k 22.1
mT5-XL 0.72 0.12 0.5 10.1 15.3 14.8k 80.5k 26.1k 21.4
BART 0.56 0.02 0.06 7.0 9.2 1.8k 6.2k 3.9k 22.0
Schema-Guided
T5 0.67 0.03 0.10 7.9 10.6 1.6k 5.8k 3.8k 11.8
ToTTo T5 0.73 0.18 0.54 10.1 14.4 15k 60k 21k 15.3
XSum PEGASUS 0.73 0.20 0.64 9.3 13.1 3.0k 13k 5k 22.9
WebNLG(en) mBART 0.53 0.09 0.27 8.6 11.8 969 4.0k 3.2k 20.7
mT5-small 0.5 0.09 0.25 8.6 11.8 864 3.9k 3.2k 22.7
mT5-base 0.53 0.09 0.27 8.7 11.9 983 4.4k 3.3k 21.7
mT5-large 0.54 0.09 0.29 8.7 12.0 1.1k 4.8k 3.4k 21.7
mT5-XL 0.54 0.09 0.29 8.7 12.0 1.1k 4.8k 3.4k 21.6
WebNLG(ru) mBART 0.46 0.08 0.20 8.1 10.3 334 1.1k 1.2k 18.9
mT5-small 0.43 0.08 0.20 7.9 10.2 349 1.2k 1.2k 19.2
mT5-base 0.47 0.09 0.23 8.2 10.7 482 1.6k 1.4k 19.9
mT5-large 0.48 0.09 0.24 8.2 10.7 474 1.6k 1.4k 19.4
mT5-XL 0.46 0.09 0.22 8.2 10.5 418 1.4k 1.3k 19.5
BART 0.73 0.23 0.74 9.8 14.1 5.5k 23k 8.6k 18.4
Turk
T5 0.73 0.22 0.72 9.9 14.2 5.9k 25k 9.3k 20.1
BART 0.73 0.23 0.73 9.8 14.1 5.9k 24k 9.1k 20.1
ASSET
T5 0.73 0.22 0.72 9.9 14.2 5.9k 26k 9.4k 21.3
mBART 0.55 0.03 0.19 8.8 14.0 4.7k 63k 15k 29.4
WikiLingua(es→en)
mBART+ 0.58 0.03 0.21 9.1 14.5 5.9k 83k 18k 32.5
mT5-small 0.39 0.03 0.15 8.3 12.8 2.3k 20.9k 8.2k 31.8
mT5-base 0.52 0.04 0.23 8.7 13.7 3.5k 34.4k 10.3k 28.7
mT5-large 0.57 0.04 0.26 8.9 14.0 4.2k 44.4k 11.7k 30.8
mT5-XL 0.6 0.04 0.29 9.1 14.4 5.0k 57.7k 13.5k 34.7
mBART 0.54 0.04 0.20 8.5 13.3 2.8k 28k 8.7k 27.3
WikiLingua(ru→en)
mBART+ 0.55 0.04 0.23 8.8 13.7 3.5k 35k 10k 28.4
mT5-small 0.4 0.04 0.19 8.2 12.6 1.5k 11.6k 5.5k 31.8
mT5-base 0.55 0.06 0.3 8.6 13.4 2.5k 21.0k 7.1k 28.7
mT5-large 0.59 0.06 0.32 8.7 13.6 3.0k 26.1k 7.9k 31.1
mT5-XL 0.6 0.07 0.35 8.8 13.8 3.4k 29.0k 8.5k 31.4
mBART 0.45 0.08 0.28 7.7 11.2 743 4.1k 2.1k 34.2
WikiLingua(tr→en)
mBART+ 0.52 0.12 0.38 8.0 11.9 1.2k 6.1k 2.8k 30.7
mT5-small 0.55 0.14 0.46 8.1 11.6 935 4.4k 2.1k 40.2
mT5-base 0.59 0.16 0.51 8.2 11.9 1.0k 4.8k 2.2k 38.7
mT5-large 0.58 0.16 0.5 8.1 11.8 1.0k 4.7k 2.2k 38.0
mT5-XL 0.58 0.16 0.51 8.2 11.8 1.0k 4.7k 2.1k 36.8
mBART 0.54 0.07 0.28 8.2 12.3 1.5k 9.3k 4.0k 26.9
WikiLingua(vi→en)
mBART+ 0.54 0.08 0.33 8.6 12.9 2.1k 13k 5.3k 29.8
mT5-small 0.5 0.09 0.33 8.2 12.1 1.2k 6.4k 3.1k 32.9
mT5-base 0.58 0.12 0.43 8.4 12.6 1.6k 8.9k 3.7k 31.1
mT5-large 0.6 0.12 0.45 8.5 12.7 1.7k 9.3k 3.8k 30.7
mT5-XL 0.61 0.12 0.47 8.6 12.9 1.8k 10.2k 4.0k 31.5
Table 4: Results of the baseline results we release with GEM, focusing on diversity of the outputs and neutral
systemcharacterizations. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 896>


<Paper ID = 898> <Table 0> <Abstractive Summary> =Table 9: Examples illustrating model adaptation to the dialog context when using 5 previous turns of context
(Context 5) vs. just one previous turn (Prompt). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 898>


<Paper ID = 898> <Table 1> <Abstractive Summary> =Topromote
Context5 0.083 0.204 workalongtheselines,futureeditionsoftheGEM
sharedtaskcouldhavefew-shottrackswherethe
Table 12: Correlations between contextual BLEU-2
numberofsamplesforsupervisedtrainingisquite
scores (with no length penalty) for model using 5 pre-
limited. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 898>


<Paper ID = 899> <Table 0> <Abstractive Summary> =Thedataiscollectedfrom predicatemasking 46.73 37.36 59.79
multiple different sources including tables from entity+predicate 46.37 37.23 59.51
Wikipedia,questionsfromWikiSQLandmerged
Table 1: Results from automatic evaluation on the
with two existing data-to-text datasets, namely,
DART validation set with different masking strategies
WebNLG(en)(Gardentetal.,2017)andcleaned
on DBpedia abstracts for pre-training using the T5-
E2E(Dusˇeketal.,2019). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 899>


<Paper ID = 899> <Table 1> <Abstractive Summary> =DBpediatypes 50.75 40.33 60.45
Thetype<NUMERIC>isassignedtoentitieswhich spaCyNER 51.05 40.42 61.30
onlyconsistofnumericvaluesand<UNKNOWN>to
Table 2: Results from automatic evaluation on the
everythingelse. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 899>


<Paper ID = 899> <Table 2> <Abstractive Summary> =150BLEU METEOR ROUGE-L BLEU METEOR ROUGE-L
baseline 33.73 36.52 53.72 baseline 28.94 31.03 55.78
maskedpre-training maskedpre-training
MRmasking 34.09 36.62 53.64 conceptmasking 27.81 29.61 54.87
randommasking 34.21 36.50 53.85 randommasking 26.87 29.83 54.17
Table 3: Results from automatic evaluation on the Table4:ResultsfromautomaticevaluationontheCom-
E2Evalidationsetwithdifferentmaskingstrategieson monGen validation set with different masking strate-
monolingual data for pre-training using the T5-base giesonmonolingualdataforpre-trainingusingtheT5-
model. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 899>


<Paper ID = 899> <Table 3> <Abstractive Summary> =val 0.54 0.11 0.37 6.9 10.3 532 2.4k 1.2k 10.9
CommonGen
sample 0.55 0.16 0.46 6.8 10.0 455 1.6k 862 11.0
DART val 0.42 0.05 0.15 7.4 9.9 1.3k 5.0k 3.1k 22.7
val 0.26 0.001 0.004 5.6 7.0 11 68 144 23.4
test 0.27 0.001 0.005 5.7 7.1 5 33 136 22.4
E2Eclean
sample 0.44 0.01 0.027 5.6 7.0 6 43 117 23.7
scramble 0.47 0.01 0.034 5.7 7.1 7 56 117 22.4
val 0.54 0.10 0.30 8.5 11.9 1.1k 4.8k 3.2k 19.2
test 0.65 0.04 0.16 8.0 10.9 368 2.1k 1.5k 19.5
WebNLG(en) sample 0.57 0.20 0.50 8.3 11.3 942 3.0k 1.9k 19.2
scramble 0.50 0.11 0.32 7.9 10.6 362 1.5k 2.9k 19.8
numbers 0.65 0.12 0.32 7.9 10.6 426 1.6k 1.1k 19.6
Table 5: Results from automatic evaluation metrics measuring lexical similarity, semantic equivalence, diversity
andsystemcharacteristicsonthevalidationset,testsetandthethreechallengesets–sample,scrambleandnumbers
forDART,WebNLG(en),E2EandCommonGen. </Abstractive Summary> <Extractive Summary> Table 3 shows scores for the output set.  </Extractive Summary>  </Table 3>  </Paper ID = 899>


<Paper ID = 90> <Table 0> <Abstractive Summary> =confounders FEV AY2 T-REx zsRE NQ HoPo TQA WoW
BM25 74.72/46.96 83.78 69.18/53.54 77.23/41.70 61.51/28.80 44.21/38.42 61.95/24.56 39.70/24.07
BM25+adv 74.79/52.12 84.86 71.36/61.40 80.04/54.08 59.25/40.11 44.08/41.04 59.19/34.17 41.04/24.62
Table 8: Comparison of two confounder selection methods for the multi-task model: simple BM25, and BM25
augmentedwithadversarialconfounders(R-precisiononvalidationdataatpage/passagelevel). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 90>


<Paper ID = 901> <Table 0> <Abstractive Summary> =0.878 0.158 0.553
Table 4: Semantic similarity: BERTscore and Table6: Diversity: MSTTRandDistinct. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 901>


<Paper ID = 902> <Table 0> <Abstractive Summary> =inordertoinvestigatethefollowingphenomena:
Table 1: Example prompt and response excerpt from
1. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 902>


<Paper ID = 902> <Table 1> <Abstractive Summary> =Thismayexplainthelack
171SmallResponse MediumResponse LargeResponse
Model Decoding Dist-1 Dist-2 sent-BERT Dist-1 Dist-2 sent-BERT Dist-1 Dist-2 sent-BERT
p=0.7 0.018 0.149 0.830 0.011 0.112 0.741 0.003 0.034 0.694
GPT-2Small p=0.9 0.026 0.234 0.808 0.016 0.177 0.682 0.005 0.087 0.646
p=0.95 0.030 0.274 0.798 0.019 0.213 0.663 0.007 0.118 0.632
p=0.7 0.026 0.195 0.855 0.013 0.125 0.741 0.003 0.036 0.709
GPT-2Medium p=0.9 0.034 0.272 0.842 0.018 0.190 0.692 0.007 0.093 0.660
p=0.95 0.039 0.308 0.837 0.021 0.227 0.677 0.009 0.127 0.646
p=0.7 0.009 0.092 0.707 0.005 0.061 0.686 0.005 0.061 0.686
FusionModel p=0.9 0.014 0.174 0.667 0.008 0.130 0.637 0.008 0.130 0.637
p=0.95 0.017 0.213 0.655 0.009 0.155 0.624 0.008 0.149 0.624
Table 4: Automatic diversity evaluations across models and decoding methods for each response length. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 902>


<Paper ID = 902> <Table 2> <Abstractive Summary> =Daddypickup
yourchildandleavetheroom,youhavetogettowork”<newline><newline>Ipickedup
mydaughterandwewalkedoutintothekitchen.<newline><newline>Iheldhercloseand
whisperedintoherear“It’sokhoney,I’llbeok.”
Table 7: Medium-length stories generated using GPT-2 Medium with nucleus sampling (p = 0.7) and various
diversedecodingstrengthsλ. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 902>


<Paper ID = 902> <Table 3> <Abstractive Summary> =184Small Medium Large
Model Decoding Dist-1 Dist-2 sent-BERT Dist-1 Dist-2 sent-BERT Dist-1 Dist-2 sent-BERT
greedy 0.002 0.007 0.782 0.002 0.008 0.644 0.000 0.001 0.684
p=0.3 0.006 0.038 0.835 0.005 0.029 0.815 0.001 0.006 0.804
p=0.5 0.013 0.092 0.838 0.008 0.067 0.791 0.002 0.014 0.760
GPT-2Small
p=0.7 0.018 0.149 0.830 0.011 0.112 0.741 0.003 0.034 0.694
p=0.9 0.026 0.234 0.808 0.016 0.177 0.682 0.005 0.087 0.646
p=0.95 0.030 0.274 0.798 0.019 0.213 0.663 0.007 0.118 0.632
p=1.0 0.042 0.344 0.787 0.028 0.283 0.644 0.015 0.195 0.613
greedy 0.006 0.022 0.626 0.003 0.014 0.579 0.001 0.003 0.779
p=0.3 0.014 0.078 0.842 0.008 0.047 0.813 0.001 0.008 0.813
p=0.5 0.021 0.140 0.855 0.011 0.086 0.788 0.002 0.017 0.772
GPT-2Medium
p=0.7 0.026 0.195 0.855 0.013 0.125 0.741 0.003 0.036 0.709
p=0.9 0.034 0.272 0.842 0.018 0.190 0.692 0.007 0.093 0.660
p=0.95 0.039 0.308 0.837 0.021 0.227 0.677 0.009 0.127 0.646
p=1.0 0.051 0.374 0.831 0.030 0.291 0.658 0.017 0.210 0.628
greedy 0.006 0.068 0.690 0.005 0.055 0.666 0.005 0.055 0.666
p=0.3 0.003 0.017 0.783 0.001 0.009 0.779 0.001 0.009 0.779
p=0.5 0.005 0.046 0.758 0.003 0.027 0.750 0.003 0.027 0.750
FusionModel
p=0.7 0.009 0.092 0.707 0.005 0.061 0.686 0.005 0.061 0.686
p=0.9 0.014 0.174 0.667 0.008 0.130 0.637 0.008 0.130 0.637
p=0.95 0.017 0.213 0.655 0.009 0.155 0.624 0.008 0.149 0.624
p=1.0 0.025 0.277 0.633 0.016 0.229 0.603 0.016 0.229 0.603
Table 9: Automatic diversity evaluations across models and decoding methods for each response length. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 902>


<Paper ID = 904> <Table 0> <Abstractive Summary> =Explanatory Table 1: Examples of premises and hypotheses from
interactivemachinelearning. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 904>


<Paper ID = 905> <Table 0> <Abstractive Summary> =Weevaluatetheinteractionbetweenagent
Table 1: Relevant interaction data between each user
and user with the agent’s long-term memory, the
and the agent: Shortest and longest instruction, av-
transcript. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 905>


<Paper ID = 905> <Table 1> <Abstractive Summary> =Only cleaned instructions were Table 2: Instructions needed by each user until a task
usedforanalysis, asincorrectmodeloutputdoes wascompleted. </Abstractive Summary> <Extractive Summary> Table 1 (go to the tree) can be completed with one com-
showsrelevantstatisticsregardingtheinstructions mandsincetheagenthasitalreadyinitsknowledge
byeachuser. Table 1 shows that the
10SPACEbarwaspressedmoreoftenthantheM key, gives individualized linguistic feedback and one
meaningthattheGooglemodelwasaccessedmore whereitgivesaction-onlyfeedback.  </Extractive Summary>  </Table 1>  </Paper ID = 905>


<Paper ID = 906> <Table 0> <Abstractive Summary> =E(b)(n)returnsTrueiflengthofbsatisﬁesnandFalse
otherwise
6 BC→C B C(B) applicationofdenotationofCtodenotationofB
7 V→EN BC EN(BC) applicationofdenotationofEN todenotationofBC
8 EN→E N E(n) applicationofdenotationofEtodenotationofn
Inpututterance: ”onebluesquareoveraredtriangle”
LogicalForm: exist([1])(over(range(1,17))(blue(BF(square,all)))(red(BF(triangle,all))))
Denotation: Trueandthelistofguessedblocksconsistingofthebluesquareandtheredtriangle
Table 6: Illustration of the way in which the grammar works for the example ”[there is] one blue square over
a red triangle”. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 906>


<Paper ID = 907> <Table 0> <Abstractive Summary> =Table 1: Performance of two methods evaluated by
AlignmentROUGE-1andAlignmentROUGE-2. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 907>


<Paper ID = 909> <Table 0> <Abstractive Summary> =Table 2: ACL results for OntoNotes5 and CoNLL  Gui, Liangke, Tadas Baltrusaitis, and Louis-Philippe 
datasets. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 909>


<Paper ID = 91> <Table 0> <Abstractive Summary> =1123A Appendices
Task BatchSize LearningRate validationinterval MaxEpochs
BoolQ {2,4,8} {1e-6,5e-6,1e-5} 2400 10
CB {2,4,8} {1e-5,5e-5,1e-4} 60 40
COPA {16,32,64} {1e-6,5e-6,1e-5} 100 40
RTE {2,4,8} {5e-6,1e-5,5e-5} 1000 40
WiC {16,32,64} {1e-5,5e-5,1e-4} 1000 10
Table 1: Hyperparameter search ranges for the SuperGLUE tasks. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 91>


<Paper ID = 913> <Table 0> <Abstractive Summary> =𝑘  L*
Table 2: Link accuracies (LAcc), sentence accuracies 5.4.2 Trainingwithoutgroundtruth
(SAcc),coverage(Cov),andaveragenumberofparses
Training a model without ground-truth linkages
persentenceforthe𝔍 -trainedsystemsontheLCG-
NLL impairs system performance substantially, as ex-
banktestset.+TGreferstothemodelchangesofSec-
pected: the model has no signal guiding it to the
tion 3.2. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 913>


<Paper ID = 913> <Table 1> <Abstractive Summary> =Table 3: LCGbank test set coverage under various
ground-truth–free training conditions. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 913>


<Paper ID = 914> <Table 0> <Abstractive Summary> =thatrealizesthelemmatizationtaskpredictsediting
rules of the form s1@s2 where s1 is a sufﬁx of Table 2: Actions used in our RM architecture. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 914>


<Paper ID = 914> <Table 1> <Abstractive Summary> =Unfortunately,theresampling
Table 4: Features used in our RM architecture. </Abstractive Summary> <Extractive Summary> to w, labeled with function f. The graph built at Table 1 represents the tapes of a machine af-
the end of the parsing process is a tree.  </Extractive Summary>  </Table 1>  </Paper ID = 914>


<Paper ID = 915> <Table 0> <Abstractive Summary> =Relevant 83.06 76.82
Additionally, we collect two data sets in the Complex 55.80 37.98
noveldomains,novel-domain-ours-setandnovel-
Table 2: Human evaluation results between ours and
domain-oracle-set. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 915>


<Paper ID = 915> <Table 1> <Abstractive Summary> ==‘Murrayﬁeld’groupbyConcert.year
Table 5: Examples of Foreign-Key and Same-Name
Question: Howmanyconcertswereheld
conditions,withSQLqueriesintheﬁrstlineandpaired
inMurrayﬁeldeachyear? </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 915>


<Paper ID = 915> <Table 2> <Abstractive Summary> =Table 4: An example pair of SQL queries with simi-
lar structures in different domains, the corresponding C FeatureVectorforPersonalized
naturallanguagequestionsthatmaptothemhavevery
Examples
differentstructures. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 915>


<Paper ID = 915> <Table 3> <Abstractive Summary> =AVGincolumn 2.0
• ‘GROUP BY’ clauses always take effect Table 6: Feature vector values regarding the column
either by aggregating ‘SELECT’ columns, clauses,withweightsspeciﬁedtotherightofeachfea-
‘HAVING’ conditions or ‘ORDER BY’ ture. </Abstractive Summary> <Extractive Summary> We also tried applying the same ﬁne-tuning to The results in Table 3 are for the best ﬁne-
the IRNet and RAT-SQL parsers without BERT.  </Extractive Summary>  </Table 3>  </Paper ID = 915>


<Paper ID = 915> <Table 4> <Abstractive Summary> =Featureabout“FROM” Weight
• Columnspresentin‘SELECT’arelikelyalso
Numberoftablesin“FROM” 1.0
presentin‘ORDERBY’
Alltablesconnectedby“JOINON” 2.0
• Whentwoqueriesarelinkedtogetherviaan
Table 7: Feature vector values regarding the “FROM”
‘UNION’,‘EXCEPT’or‘INTERSECT’,itis
clauses,withweightsspeciﬁedtotherightofeachfea-
likelythatthetwoqueriessharesimilarstruc-
ture. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 4>  </Paper ID = 915>


<Paper ID = 915> <Table 5> <Abstractive Summary> =FeatureaboutSetOperations Weight
Involves“UNION”clause 4.0
Involves“EXCEPT”clause 4.0
Involves“INTERSECT”clause 4.0
Table 11: Feature vector values regarding the Set Op-
eration clauses, with weights speciﬁed to the right of
eachfeature. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 5>  </Paper ID = 915>


<Paper ID = 918> <Table 0> <Abstractive Summary> =S x|B V E SHIFT S|x B V E −
S|x B V E REDUCE S B V E −
S|x B V E NODEX S|x y|B V ∪{y} E|(y,x)X − x(cid:54)=root
S|x B V E NODE S|x y|B V ∪{y} E −
S|x B V E IMPLICITX S|x y|B V ∪{y} E|(x,y)#X −
S|y,x B V E LEFT-EDGEX S|y,x B V E|(x,y)X −
 x∈/w1:n,
S|x,y B V E RIGHT-EDGEX S|x,y B V E|(x,y)X − y(cid:54)= root,
 y∧Gx
S|y,x B V E LEFT-REMOTEX S|y,x B V E|(x,y)∗X −
S|x,y B V E RIGHT-REMOTEX S|x,y B V E|(x,y)∗X −
S|x,y B V E SWAP S|y x|B V E − i(x)<i(y)
[root] ∅ V E FINISH ∅ ∅ V E +
Table 3: The transition sets of two implicit transition systems. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 918>


<Paper ID = 918> <Table 1> <Abstractive Summary> =Equallyimportantly, modifytheparsertoreadnodeproperties, andto
thenewnodeisprohibitedtohaveanychildincon-
trasttotheprimarynodesthatthe NODEX action 3https://github.com/cfmrp/mtool
70Data #Sentences #Tokens #Nodes #Edges #Deictic #Generic #Genre-based #Type-i #Non-s #Iterated-s #Implicitsum
EWTTrain 2723 44751 59654 97561
EWTDev 554 5394 7534 11987
EWTEval 535 5381 7431 11907
Overall notreﬁned notreﬁned notreﬁned notreﬁned notreﬁned notreﬁned 153
IMPTrain 285 2671 3936 6146 87 59 103 3 18 4 274
IMPDev 59 540 781 1217 11 15 19 1 10 0 56
IMPEval 49 489 709 1106 9 12 25 2 8 5 61
Overall 107 86 147 6 36 9 391
Table 4: Statistics of train, dev and evaluation set in Original EWT and Revisited Implicit EWT. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 918>


<Paper ID = 918> <Table 2> <Abstractive Summary> =Primary Remote Implicit
LP LR LF LP LR LF LP LR LF UP UR UF
Baseline 0.495 0.467 0.480 0.538 0.304 0.389 1 0 0 1 0 0
IMPLICIT-EAGER 0.503 0.472 0.487 0.333 0.100 0.154 0.333 0.140 0.197 0.428 0.180 0.254
(7/21) (7/50) (9/21) (9/50)
IMPLICIT-STANDARD 0.474 0.431 0.451 0.438 0.280 0.341 0.409 0.180 0.250 0.500 0.220 0.306
(9/22) (9/50) (11/22) (11/50)
Table 5: Experiment results on Revisited Implicit EWT in percents. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 918>


<Paper ID = 918> <Table 3> <Abstractive Summary> =Generic 2 0 0 0 0 0 0 0 0 0 0 0 2
Generic&Genre-based 3 0 0 0 0 0 0 3 0 0 0 0 6
Genre-based 3 0 0 0 0 0 0 0 2 0 0 0 5
7 Discussion Genre-based&P 0 0 0 0 0 0 0 0 1 0 0 0 1
Table 7: Confusion matrix on the Revisited Implicit
AsisindicatedinTable5, IMPLICIT-EAGER and
EWT evaluation set: The column is the predicted la-
IMPLICIT-STANDARD successfully predicted re-
belswhiletherowistheactuallabels. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 918>


<Paper ID = 920> <Table 0> <Abstractive Summary> =87Language TreebankName #Tokens #Sentences
Bambara BambaraCRB 13.82k 1.03k
UD_English_EWT 254.83k 16.62k
English UD_English-GUM 80.18k 4.40k
UD_English-ParTUT 49.62k 2.09k
UD_French-FTB 556.06k 18.53k
UD_French-ParTUT 27.67k 1.02k
French
UD_French-Sequoia 68.64k 3.10k
UD_French-Spoken 34.98k 2.79k
Norwegian UD_Norwegian-Bokmaal 310.22k 20.04k
Wolof WolofWTB 42.83k 2.11k
Yoruba YorubaYTB 2.67k 0.10k
Table1:UDtreebanksusedintheexperiments
Figure1
88TOKEN VOCABSIZE Treebank UPOS FEATS LEM UAS LAS
Bambara 36.29 45.18 23.89 34.28 12.98
WordForm 178,214
Wolof 89.64 75.06 89.95 75.71 67.03
BERTWordpieces 119,547 Yoruba 60.73 60.43 93.59 48.99 31.43
UPOS 17
XPOS 206 Table 6: The full test results on Bambara, Wolof and
Yoruba when training UDify on the 9 UD treebanks
UFeats 1300
(the Bambara and Yoruba treebanks are only used for
Lemmas(tags) 3,834
testing). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 920>


<Paper ID = 920> <Table 1> <Abstractive Summary> =Deps 86
Treebank UPOS FEATS LEM UAS LAS
Table2:Vocabularysizesofwordsandtagsoverthe11
Bambara 35.05 44.32 23.84 33.83 12.94
UDv2.3treebanks Wolof 90.49 77.25 90.82 76.14 67.86
Yoruba 59.19 60.18 93.21 45.19 28.53
hyperparameter
Table 7: The full test results on Bambara, Wolof and
Dependencytagdimension 256
Yoruba when training UDify on the 8 UD treebanks,
Dependencyarcdimension 768
excludingtheEnglishtreebanks. </Abstractive Summary> <Extractive Summary> treebank was available for that language at that
Table 1 shows the selected treebank(s) used for time.  </Extractive Summary>  </Table 1>  </Paper ID = 920>


<Paper ID = 920> <Table 2> <Abstractive Summary> =Treebank UPOS FEATS LEM UAS LAS
Bambara 30.86 57.96 20.42 30.28 8.60 In the same way, we run a similar experiment
Yoruba 50.86 78.32 85.56 37.62 19.09 where we exclude only the French treebanks to
assesstheirimpactontheoveralresultsforthese-
Table 4: The full test results on Bambara and Yoruba
lectedlow-resourceAfricanlanguages.Theresults
when training UDify on the 124 UD treebanks (Kon-
dratyukandStraka,2019). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 920>


<Paper ID = 920> <Table 3> <Abstractive Summary> =Table 8: The full test results on Bambara, Wolof and
Thisprovidesagoodindicationthatatransferlearn-
Yoruba when training UDify on the 7 UD treebanks,
ingapproachinamultilingualdependencyparsing excludingtheFrenchtreebanks. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 920>


<Paper ID = 920> <Table 4> <Abstractive Summary> =As mentioned above, we used Norwegian as a
Toassesstheimpactofsomelanguagecombina- controllanguagetoverifyourassumptionwithre-
89Treebank UPOS FEATS LEM UAS LAS Treebank UPOS FEATS LEM UAS LAS
Bambara 36.02 45.08 23.87 33.94 11.94 Bambara 29.44 69.08 13.36 30.91 11.21
Wolof 90.76 83.55 90.91 75.35 67.25 Wolof 23.02 45.78 65.95 27.51 10.15
Yoruba 59.94 58.68 88.30 48.09 30.87 Yoruba 67.44 59.26 78.39 52.74 33.80
Table 9: The full test results on Bambara, Wolof and Table 10: The full test results on Bambara, Wolof and
Yoruba when training UDify on the 10 UD treebanks, Yoruba when training UDify on the 10 UD treebanks,
excludingtheNorwegiantreebank. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 4>  </Paper ID = 920>


<Paper ID = 921> <Table 0> <Abstractive Summary> =Treebank STL MTL weightedMTL wMTLweights
dev German GSD 84.63 83.76 84.74 0.90
tweeDe 74.69 79.01 79.99 0.10
Italian ISDT 91.31 T:90.59;P:90.31 T:91.54;P:91.45 0.95;0.90
TWITTIRO` 78.17 82.83 84.11 0.15
PoSTWITA 77.22 80.48 81.58 0.05
test German GSD 81.35 80.70 81.56 0.90
tweeDe 76.18 81.77 82.52 0.10
Italian ISDT 91.80 T:91.18;P:90.92 T:92.07;P:91.79 0.95;0.90
TWITTIRO` 78.07 81.64 82.28 0.15
PoSTWITA 75.46 78.57 79.24 0.05
Table 4: LAS Results Word+POS for STL, shared MTL, and weighted shared MTL using the full data sets. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 921>


<Paper ID = 923> <Table 0> <Abstractive Summary> =Epochs 200
Patience 10 LikemostSlaviclanguagesitdoesn’tmakeuseof
Trainingbatchsize 32 articles(Bielec,1998)butitdoeshaveacomplex
system of numeral and quantiﬁers that result in
Table 2: Hyperparameters for all models. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 923>


<Paper ID = 923> <Table 1> <Abstractive Summary> =Chinese 15K 408K 28.2 0.0 4.9 2K 51K 28.0 0.0 4.9 2K 49K 27.3 0.0 4.9
Hindi 13K 281K 22.1 2.6 11.4 2K 35K 22.2 2.4 11.5 2K 35K 22.2 2.4 11.3
Korean 23K 296K 13.9 4.5 8.2 2K 25K 13.2 4.7 8.6 2K 28K 13.4 4.0 8.3
Polish 18K 282K 16.9 1.4 5.4 2K 35K 16.7 1.5 5.4 2K 34K 16.2 1.4 5.4
Table 3: Treebank statistics: number of sentences (Sents. </Abstractive Summary> <Extractive Summary> codeisimplementedinDyNetwhichdoesn’tprop-
In Table 1 we report performance of modern erlysupportCUDA,andisadifferentframework
parsing systems for which speeds have been re- fromthatoftheotherparsersweoptedtochoose.  </Extractive Summary>  </Table 1>  </Paper ID = 923>


<Paper ID = 924> <Table 0> <Abstractive Summary> =Trankit XLM-R no yes
Withthisideainmind,weintroduceSTEPS(the
Stuttgart Transformer-based Extensible Parsing Table 1: Settings for a number of previously state-
System),amodulargraph-baseddependencyparser of-the-art graph-based dependency parsers. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 924>


<Paper ID = 924> <Table 1> <Abstractive Summary> =;Palmeretal.,2009)
Italian ItalianBERT-XXL(github.com/dbmdz/berts) ISDT
Japanese WikiBERT-Japanese(Pyysaloetal.,2020) GSD
Korean KR-BERT(Leeetal.,2020) Kaist(Chunetal.,2018)
Latvian WikiBERT-Latvian(Pyysaloetal.,2020) LVTB
Russian RuBERT(KuratovandArkhipov,2019) SynTagRus(Droganovaetal.,2018)
Multilingual mBERT(Devlinetal.,2019) –
Multilingual XLM-R(Conneauetal.,2020) –
Table 2: Language models and UD treebanks used in our experiments. </Abstractive Summary> <Extractive Summary> Table 1 shows
differentlanguagemodelsfordependencyparsing
theconﬁgurationsofthreeparsersthatwereamong
(e.g., Kanerva et al., 2018; Pyysalo et al., 2020;
the best-performing systems in the CoNLL 2017
Smith et al., 2018). As Table 1 shows,
language-speciﬁcmodelsfor56languages.  </Extractive Summary>  </Table 1>  </Paper ID = 924>


<Paper ID = 924> <Table 2> <Abstractive Summary> =In fact, the
Table 3: Hyperparameter values. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 924>


<Paper ID = 924> <Table 3> <Abstractive Summary> =ﬁ-TDT 89.24 89.97 91.53 91.51
WeevaluateintermsofELAS(EnhancedLAS, it-ISDT 91.54 91.49 92.35 92.39
lv-LVTB 84.94 87.64 89.04 88.95
i.e., F1 score over the set of enhanced dependen-
ru-STR 90.69 92.31 93.68 93.75
cies in the system output and the gold standard)
using the ofﬁcial evaluation script for the IWPT Table 6: Results (ELAS) for enhanced dependency
2020SharedTask6 andreportper-treebankresults parsing. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 924>


<Paper ID = 926> <Table 0> <Abstractive Summary> =PolishPDB PS GPSXRC
Thereare13treebanksof7languagesinUD2.7
PolishPUD PS GPSXRC
that contain all types of enhancements: Czech
RussianSynTagRus G GP XRC
(CAC, FicTree, PDT, and PUD), Dutch (Alpino
SlovakSNK GPSXRC GPSXRC
and LassySmall), English (EWT and PUD), Ital-
SwedishPUD GPSXRC GPSXRC
ian(ISDT),Lithuanian(ALKSNIS),Slovak(SNK),
SwedishTalbanken GPSXRC GPSXRC
andSwedish(TalbankenandPUD).Fortheremain-
TamilTTB PS PS RC
ing languages, we applied simple heuristics and
UkrainianIU GPSXR GPSXRC
addedatleastsomeenhancementsforthepurpose
ofthesharedtask,buttheseannotationsarenotyet Table 1: New annotation for the shared task. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 926>


<Paper ID = 926> <Table 1> <Abstractive Summary> =Tamil 64.23 65.58
Ukrainian 87.22 92.78
Team LAS EULAS ELAS
baseline 100.00 96.28 79.87 Table 4: Best ELAS per language for 2020 and 2021. </Abstractive Summary> <Extractive Summary> Table 1 gives an
overviewofenhancementsinindividualtreebanks.  </Extractive Summary>  </Table 1>  </Paper ID = 926>


<Paper ID = 926> <Table 2> <Abstractive Summary> =Table 3: Evaluation results on the test data, macro- Notethattheclassiﬁcationscriptassumesthatba-
averagedoverlanguages. </Abstractive Summary> <Extractive Summary> andPUD;nevertheless,thecorporausethesame Table 2 shows that the effect of enhancements
149nsubj dictallannotationlayers,andtheevaluationofthe
nsubj obj otherlayersisavailableonthesharedtaskwebsite.4
det acl xcomp det The task was open, in the sense that participants
wereallowedtouseanyadditionalresourcesthey
des pêcheurs venus nettoyer les rives
deemedﬁt(withtheexceptionofUD2.7testdata)
anglers come clean the banks
aslongasthiswasannouncedinadvanceandthe
“anglerswhocametocleanthebanks”
additional resource was freely available to every-
Figure 5: Participial adnominal clauses in French are body.  </Extractive Summary>  </Table 2>  </Paper ID = 926>


<Paper ID = 927> <Table 0> <Abstractive Summary> =It is important to Labelprojectionsize 128
notethatdesigningaheuristicthatidentiﬁesproper
positionsofelidedelementsremainsanopenissue, Table 2: COMBO training parameters (the upper en-
andappendingemptynodesattheendofasentence tries)andmodelparameters(thebottomentries). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 927>


<Paper ID = 928> <Table 0> <Abstractive Summary> =We use the same cycle check as Table 1: Graphs formed from splitting the gold an-
for the previous trees. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 928>


<Paper ID = 929> <Table 0> <Abstractive Summary> =180ar bg cs nl en et ﬁ fr it lv lt pl ru sk sv ta uk
nullsubject X X X X X X X X X X X
leftdeppropag X X
leftauxdeppropag X
leftcasedeppropag X X
leftcopdeppropag X X
leftmarkdeppropag X X
caseraising X X X X X X X X X X
subjcontrolraising X X X X X
speciﬁcextens X
partialenhancement X X X X X X
coordconjraising X X X X
rootpropagation X X X X X X
Table 1: The three kinds of adaptation of the system. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 929>


<Paper ID = 929> <Table 1> <Abstractive Summary> =Columns¬EUD
gives a detailed analysis of these enhancements
Table 2: Evalutation of the rule-based systems on
GoldUDdata: Dehouck(Dehoucketal.,2020), Hei- withthenumberbytype. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 929>


<Paper ID = 93> <Table 0> <Abstractive Summary> =(0QT(r(RiKsacwjhpliuearrtkkeaotrwaeslt.k,ai2le.0,t12a70l).1,82)019) 11730604,,,530617891 456,,,364471358 466,,,214991388 (cid:51)(cid:51) EEEMMM 596719...859 8466..8–5
S Quoref(Dasigietal.,2019) 19,399 1,209 1,209 (cid:51) EM 78.7 93.0
Table 1: Datasets grouped by their task format and ordered by release year. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 93>


<Paper ID = 931> <Table 0> <Abstractive Summary> =Table 2: Compared ELAS scores on development set
L = λL(label)+(1−λ)L(arc) ofﬁne-tuningsingleXLM-RembeddingandACE. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 931>


<Paper ID = 932> <Table 0> <Abstractive Summary> =Oursystemconsists
Median 83.64
of an unfactorized biafﬁne classiﬁer that op-
erates directly on ﬁne-tuned XLM-R embed-
dings and generates enhanced UD graphs by Table 1: Overview of IWPT 2021 results (avg. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 932>


<Paper ID = 932> <Table 1> <Abstractive Summary> =As we observed that
199XLM-Rembeddings Language Ensemblecomposition
Embeddingsdimension 1024
Czech 3xPDT,1xCAC,1xFictree
Tokenmaskprobability 0.15
Dutch 3xAlpino,2xLassySmall
Layerdropout 0.1
English 3xEWT,2xGUM
Hiddendropout 0.2
Estonian 4xEDT,1xEWT
Attentiondropout 0.2
Polish 5xPDB
Outputdropout 0.5
Biafﬁneclassiﬁer
Hiddensize 1024 Table 4: Ensemble compositions for languages with
Dropout 0.33 morethanonetrainingtreebank. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 932>


<Paper ID = 932> <Table 2> <Abstractive Summary> =200Otherteams RobertNLP
Language TGIF Shanghai Median single ensemble ensemble
heur hyb
Arabic 81.23 82.26 76.39 81.37 81.12 81.58
Bulgarian 93.63 92.52 90.84 92.94 92.91 93.16
Czech 92.24 91.78 89.08 89.99 89.51 90.21
Dutch 91.78 88.64 84.14 88.02 88.21 88.37
English 88.19 87.27 85.70 87.29 87.89 87.88
Estonian 88.38 86.66 84.02 86.10 86.52 86.55
Finnish 91.75 90.81 89.02 90.77 90.97 91.01
French 91.63 88.40 87.32 88.59 88.51 88.51
Italian 93.31 92.88 91.81 93.00 93.16 93.28
Latvian 90.23 89.17 84.57 88.68 88.80 88.82
Lithuanian 86.06 80.87 78.04 80.98 80.76 80.76
Polish 91.46 90.66 88.31 89.49 89.54 89.78
Russian 94.01 93.59 90.90 92.55 92.33 92.64
Slovak 94.96 90.25 87.04 89.60 89.29 89.66
Swedish 89.90 86.62 84.91 87.72 88.02 88.03
Tamil 65.58 58.94 52.27 58.24 59.00 59.33
Ukrainian 92.78 88.94 86.92 88.56 88.86 88.86
Average 89.24 87.07 83.64 86.70 86.78 86.97
Table 5: Parsing results (ELAS F1) on blind test data in the IWPT 2021 Shared Task. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 932>


<Paper ID = 933> <Table 0> <Abstractive Summary> =validate.py
207[1] [2] [3] [4] [5]
Language
Ofﬁcial [1]+Trankit [2]+XLM-R [3]+Concat [4]+MTL
Large
Arabic 71.01 78.05(+24.2%) 79.51(+6.6%) - 81.72(+10.8%)
Bulgarian 92.44 92.47(+0.4%) 93.26(+10.5%) - 93.59(+4.9%)
Czech 89.93 90.28(+3.5%) 91.06(+8.1%) 91.43(+4.1%) 91.30(-1.5%)
Dutch 81.89 86.51(+25.5%) 87.67(+8.6%) 88.60(+7.5%) 89.51(+7.9%)
English 85.70 85.97(+1.8%) 86.94(+6.9%) 87.46(+3.9%) 87.28(-1.4%)
Estonian 84.35 84.54(+1.2%) 85.92(+8.9%) 86.68(+5.4%) 86.76(+0.6%)
Finnish 89.02 89.34(+2.9%) 90.79(+13.6%) - 91.16(+4.1%)
French 86.68 86.80(+0.9%) 89.12(+17.6%) - 90.38(+11.6%)
Italian 92.41 92.44(+0.4%) 93.35(+12.1%) - 93.47(+1.8%)
Latvian 86.96 86.85(-0.8%) 88.81(+14.9%) - 89.18(+3.3%)
Lithuanian 78.04 78.44(+1.8%) 82.09(+16.9%) - 83.47(+7.7%)
Polish 89.17 89.30(+1.2%) 90.20(+8.4%) 91.15(+9.7%) 90.46(-7.8%)
Russian 92.83 93.06(+3.2%) 93.95(+12.8%) - 94.09(+2.3%)
Slovak 89.59 90.81(+11.7%) 92.33(+16.5%) - 92.73(+5.2%)
Swedish 85.20 85.98(+5.3%) 88.10(+15.1%) - 88.64(+4.5%)
Tamil 39.32 40.64(+2.2%) 48.85(+13.8%) 61.14(+24.0%) 62.06(+2.4%)
Ukrainian 86.09 86.30(+1.5%) 89.44(+22.91%) - 90.91(+13.9%)
Average 83.57 84.58(+6.2%) 86.55(+12.7%) 87.48(+6.9%) 88.04(+4.5%)
Table 2: Evaluation scores on the ofﬁcial test data on the language-speciﬁc test ﬁles. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 933>


<Paper ID = 934> <Table 0> <Abstractive Summary> =We ﬁrst train a language-
Average 89.51 89.61 89.57 90.20
genericmodelontheconcatenationofallavailable
training treebanks in the shared task data regard-
Table 1: Dev-set ELAS (%) results, comparing
graph parsers with connectivity-ﬁxing postprocessing lessoftheirsourcelanguages,andthenﬁnetuneon
against tree-graph integrated models (§2) and compar- eachindividuallanguageinasecondstep. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 934>


<Paper ID = 935> <Table 0> <Abstractive Summary> =Table 4: Results of all participants of IWPT 2021
SharedTask
BeginofTable
Language Models UPOS UFeats Lemma UAS LAS ELAS
Bulgarian combo 98.72 97.23 97.25 92.98 89.52 86.67
dcu-epﬂ 98.89 97.57 97.30 93.25 90.19 92.44
fastparse 99.15 97.95 97.97 87.85 83.39 78.73
grew 99.15 97.95 97.97 94.36 91.62 88.83
robertnlp 99.13 98.31 0.01 96.30 94.15 93.16
shanghaitech 0.00 35.92 0.01 5.80 1.54 92.52
tgif 0.00 35.98 0.01 10.58 1.13 93.63
unipi 98.81 97.57 97.40 95.29 92.71 90.84
nuig 98.81 35.97 97.40 93.37 90.03 78.45
English combo 95.74 93.54 95.26 89.61 87.22 84.09
dcu-epﬂ 94.96 93.53 95.66 86.45 83.64 85.70
fastparse 95.85 94.16 96.04 82.36 77.99 73.00
grew 95.85 94.16 96.04 89.22 86.83 85.49
robertnlp 96.24 94.44 0.00 90.79 88.48 87.88
shanghaitech 0.28 32.80 0.00 3.71 1.24 87.27
tgif 0.28 32.76 0.00 7.86 1.08 88.19
unipi 95.17 93.70 95.76 90.64 88.47 87.11
nuig 95.17 32.77 95.76 87.07 84.46 65.40
Estonian combo 97.42 96.57 86.09 90.00 87.53 84.02
dcu-epﬂ 96.46 95.30 95.58 85.31 82.35 84.35
fastparse 96.89 95.78 94.90 71.70 64.50 60.05
grew 96.89 95.78 94.90 86.62 83.85 78.19
robertnlp 97.09 96.46 0.00 90.02 87.59 86.55
shanghaitech 0.12 34.99 0.00 3.67 1.16 86.66
tgif 0.12 35.08 0.01 11.86 0.82 88.38
unipi 96.49 95.33 95.55 87.11 84.14 81.27
nuig 96.49 35.04 95.55 85.41 82.46 54.03
Latvian combo 97.35 94.97 96.53 92.91 90.25 84.57
dcu-epﬂ 95.95 93.59 95.34 88.47 85.10 86.96
fastparse 96.28 93.79 95.81 78.37 72.03 66.43
grew 96.28 93.79 95.81 88.32 85.27 77.45
robertnlp 97.61 95.18 0.03 93.62 91.25 88.82
shanghaitech 0.58 35.57 0.03 4.22 1.42 89.17
tgif 0.56 35.62 0.03 10.37 0.97 90.23
unipi 96.12 93.45 95.45 89.90 86.63 83.01
nuig 96.12 35.61 95.45 88.51 85.19 56.67
Lithuanian combo 97.26 95.05 93.76 88.03 84.75 79.75
dcu-epﬂ 93.47 87.74 92.71 78.36 73.25 78.04
fastparse 95.97 91.07 93.61 61.39 53.55 48.27
grew 95.97 91.07 93.61 82.54 78.65 74.62
robertnlp 97.42 93.20 0.00 90.49 83.27 80.76
231shanghaitech 1.51 30.12 0.00 5.12 1.77 80.87
tgif 1.51 30.20 0.00 10.89 1.24 86.06
unipi 93.40 87.14 92.66 82.75 78.31 71.31
nuig 93.40 30.09 92.66 78.25 73.52 59.13
Russian combo 98.94 98.04 98.16 95.37 94.29 90.73
dcu-epﬂ 98.19 87.67 97.39 92.61 90.97 92.83
fastparse 98.86 88.97 98.33 87.09 83.23 78.56
grew 98.86 88.97 98.33 94.22 92.97 90.56
robertnlp 99.06 89.51 0.00 95.65 94.64 92.64
shanghaitech 0.02 36.35 0.00 3.35 0.73 93.59
tgif 0.02 36.37 0.00 13.81 0.51 94.01
unipi 98.25 87.52 97.49 94.51 93.32 90.90
nuig 98.25 36.32 97.49 92.67 91.01 66.33
Slovak combo 97.88 95.03 95.61 93.19 91.72 87.04
dcu-epﬂ 96.55 91.15 94.72 89.27 86.60 89.59
fastparse 97.67 93.42 96.47 78.23 71.71 64.28
grew 97.67 93.42 96.47 92.27 90.45 86.92
robertnlp 98.28 95.54 0.00 96.16 93.88 89.66
shanghaitech 1.19 22.69 0.00 6.06 1.96 90.25
tgif 1.17 22.69 0.00 13.67 1.60 94.96
unipi 96.62 91.44 94.61 93.32 91.75 86.05
nuig 96.62 22.68 94.61 90.09 87.49 67.45
Swedish combo 97.67 89.19 92.45 90.31 87.82 83.20
dcu-epﬂ 96.12 87.92 92.47 85.83 82.30 85.20
fastparse 97.25 88.82 93.60 78.88 73.11 67.26
grew 97.25 88.82 93.60 89.26 86.59 81.54
robertnlp 98.30 89.87 0.00 92.15 89.92 88.03
shanghaitech 0.00 33.79 0.00 1.55 0.34 86.62
tgif 0.00 33.79 0.00 8.42 0.20 89.90
unipi 96.07 87.83 92.47 90.86 88.53 84.91
nuig 96.05 33.56 92.46 85.64 82.18 63.12
Language Models UPOS UFeats Lemmas UAS LAS ELAS
232 </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 935>


<Paper ID = 937> <Table 0> <Abstractive Summary> =For the purposes of
this task, ST data for three language pairs was
Table 3: Multilingual task language pairs. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 937>


<Paper ID = 937> <Table 1> <Abstractive Summary> =es fr it pt
FAIR ✓ ✓ 33.7 33.0 46.5 35.5
HWN ✓ ✓ 11.1 22.2 16.2 23.8 18.3
KIT ✓ ✓ 32.4 32.3 46.6 28.8
KIT ✓ ✓ 10.0 26.5 15.5 22.1 18.5
UEDIN ✓ ✓ ✓ 30.3 32.9 44.5 30.1
FAIR ✓ ✓ 11.2 18.7 19.6 27.4 19.2
HWN ✓ ✓ ✓ 27.0 30.8 43.2 26.9
ON-TRAC ✓ ✓ 8.2 11.1 25.6 14.9 UEDIN ✓ ✓ 12.0 23.4 18.7 25.9 20.0
Table 8: ASR: Results of primary submissions on ASR
Table7: MultilingualST:Resultsofprimarysubmis-
inWER↓(optional),sortedbyaverageWER
sionsonunofﬁciallanguagepairsinBLEU↑(optional)
28A.4. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 937>


<Paper ID = 938> <Table 0> <Abstractive Summary> =Table 8: Performance of ofﬂine speech translation on En→JATask ResultsofText-to-Textsimultane-
MuST-C(v2)tst-COMMONwithdifferentdatasets. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 938>


<Paper ID = 939> <Table 0> <Abstractive Summary> =Thepseudo-references translation/docs/enja-waitk.md
40System BLEU AL
18
ofﬂine 16.8 -
Baseline 16 20 26 283032
wwaaiitt--1200 1141..689 171.2.477 U14 k=10 12 14 16 1188 20 2222 2244 26283032
wait-30high 15.57 13.7 BLE12 k=10 12 14 16
Proposed 10
wait-10+CShuflow 13.77 7.29
8 wait-k
wait-10+SKD 13.5 7.28 wait-k+SKD
wait-20+SKDmedium 15.22 11.48 6
6 8 10 12 14 16
wait-30+SKD 15.21 13.71 Average Lagging
Figure1: Translationqualityagainstlatencyforwait-k
Table 1: In-house results of our systems on IWSLT
2021En-Jadevelopmentset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 939>


<Paper ID = 939> <Table 1> <Abstractive Summary> =Theencoderanddecoderwerecom- Table 2: Target-side chunk shufﬂing result in pr =
posed of 6 layers. </Abstractive Summary> <Extractive Summary> In
r
Table 1 shows the excerpt of system results for contrast, pr = 0.01 and pr = 0.03 increased the
thefull-sentencetopline(ofﬂine),wait-kbaselines outputlength.  </Extractive Summary>  </Table 1>  </Paper ID = 939>


<Paper ID = 94> <Table 0> <Abstractive Summary> =Participantswere
Table 1: Summary of models investigated with lan- given sentence fragments and asked to complete
guage and approximate number of tokens in train- thesentenceandcircletheirintendedreferent. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 94>


<Paper ID = 94> <Table 1> <Abstractive Summary> =sila¨, Christopher D. Manning, Sebastian Schuster,
1169Siva Reddy, Dima Taji, Nizar Habash, Herman Le- SG PL NA
ung, Marie-Catherine de Marneffe, Manuela San- 1 519 417 -
guinetti, Maria Simi, Hiroshi Kanayama, Valeria 2 99 7 -
dePaiva,KiraDroganova,He´ctorMart´ınezAlonso,
3 3574 944 -
C¸ag˘rı C¸o¨ltekin, Umut Sulubacak, Hans Uszkor-
eit, Vivien Macketanz, Aljoscha Burchardt, Kim
Table 4: Breakdown of pronouns added for Spanish
Harris, Katrin Marheinecke, Georg Rehm, Tolga
ﬁne-tuningdata. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 94>


<Paper ID = 940> <Table 0> <Abstractive Summary> =High 20 14.73 33.09 lm
High 21 14.94 33.2 mask
Validation Test
High 20 14.8 33.3 lm+mask
TED2014,15 TED2018 MuST-C.v2
Medium 6 5.98 30.58 lm
Baseline 30.8 27.5 32.7
Medium 6 5.72 30.92 mask
Fine-tuned 31.9 29.4 33.6
Medium 5 5.49 31.55 lm+mask
Decodersettings:Beamsize=12;Normalization=1.0
Low 2 2.38 25.16 lm
Low 2 2.32 26.77 mask
Table 2: BLEU scores on full sentence translation,
computedwithSacreBLEU.a Low 1 2.48 27.57 lm+mask
aBLEU+case.mixed+numrefs.1+smooth.exp+tok.13a+version.1.5.1
Table 3: AL vs BLEU scores for three regimes (Low,
Medium,High)onMuST-C.v2testsetusingbeamsize
Forevaluatingthesimultaneoustranslation,we
12andnormalization1.0. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 940>


<Paper ID = 941> <Table 0> <Abstractive Summary> =250 11.7 11.1 12.4
500 10.7 10.3 10.8
4.5.2 Latency/QualityTrade-OffParameters
1000 10.4 9.7 10.4
AsdescribedinSection4.2,wecanvarythebound-
ary prediction threshold probability t to set dif- Table 3: WER [%] of streaming hybrid ASR on
b
MuST-CtestsetsforvariouswindowsizesW
ferentlatency/qualitytrade-offsatinferencetime. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 941>


<Paper ID = 941> <Table 1> <Abstractive Summary> =Wenotethatourend-
Table 5: AppTek IWSLT 2021 ofﬁcial simultaneous
to-enddirectprimaryandcontrastivesystemshave speechtranslationresultsontheblindtextandspeech
theidenticalmodelparameterswithanensemble inputtestsets. </Abstractive Summary> <Extractive Summary> The training deals with a more complex
model in line 3 and the Transformer-based ASR errorpropagation,causingasub-optimalsolution
model from Table 1 make up the cascade system for the entire optimization problem.  </Extractive Summary>  </Table 1>  </Paper ID = 941>


<Paper ID = 941> <Table 2> <Abstractive Summary> =Byusingfuturecontextofvariablelength
we are able to do reliable sentence segmentation
Table 4: AppTek IWSLT 2021 submission for ofﬂine
ofASRoutputdesignedtointroduceminimaladdi-
speechtranslationmeasuredby BLEU [%]. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 941>


<Paper ID = 941> <Table 3> <Abstractive Summary> =62A Appendix
trade-offid D t ∆t α
b b
1’ 1 0.3 0.006 0.3
2’ 1 0.4 0.008 0.6 31
3’ 1 0.5 0.012 0.8
30
4’ 1 0.6 0.012 1.0
29
1 2 0.3 0.006 0.3
2 2 0.4 0.008 0.4 U 28
3 2 0.5 0.012 0.6 E
L
4 2 0.6 0.012 0.8 B 27
5 2 0.6 0.008 0.8 26
6 2 0.7 0.012 1.0
25
7 2 0.9 0.032 1.0 D=1
(low-latencyﬁne-tuning)
8 2 0.9 0.027 1.0 24 D=2
9 2 0.9 0.023 1.0
1 2 3 4 5 6 7 8 9 10 11 12
10 2 0.9 0.017 1.0
AverageLagging(AL)
11 2 0.9 0.012 1.0
12 2 0.9 0.008 1.0
Figure3: ResultsforEnglish→Germantext-to-textsi-
Table 6: Trade-off parameters for submitted text in- multaneoustranslationonMuST-Cdev
putsimultaneousMTsystems,sortedfromlowtohigh
latency. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 941>


<Paper ID = 941> <Table 4> <Abstractive Summary> =trade-offid D W (ms) t ∆t α
ASR b b
1’ 1 250 0.3 0.006 0.3
2’ 1 250 0.4 0.008 0.6
3’ 1 250 0.5 0.012 0.8
1 2 250 0.3 0.006 0.3
25
2 2 250 0.4 0.008 0.6
3 2 250 0.5 0.012 0.8 24
4 2 250 0.6 0.012 1.0 23
5 2 500 0.4 0.008 0.6
22
6 2 500 0.5 0.012 0.8 U
7 2 500 0.6 0.012 1.0 E 21
L
8 2 500 0.6 0.008 1.0 B 20
9 2 500 0.9 0.032 1.0
19
10 2 500 0.9 0.027 1.0
11 2 500 0.9 0.023 1.0 18 D=1
(low-latencyﬁne-tuning)
12 2 500 0.9 0.017 1.0 17 D=2
13 2 500 0.9 0.012 1.0
2,000 3,000 4,000 5,000
14 2 1000 0.9 0.017 1.0
AverageLagging(AL)inms
15 2 1000 0.9 0.012 1.0
16 2 1000 0.9 0.008 1.0
Figure4: ResultsforEnglish→Germanspeech-to-text
Table 7: Trade-off parameters for submitted speech simultaneoustranslationonMuST-Cdev
input simultaneous MT systems, sorted from low to
high latency. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 4>  </Paper ID = 941>


<Paper ID = 942> <Table 0> <Abstractive Summary> =MuST-C 250,942 450
LibriSpeech 281,241 961
Transformer Transformer
CommonVoice 562,517 899
Decoder Decoder
iwslt-corpus 157,909 231
TED-LIUM3 111,600 165
Transformer Transformer
Table 1: The statistics of audio datasets to train the Encoder Encoder
ASR model. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 942>


<Paper ID = 942> <Table 1> <Abstractive Summary> =DataCombinationandSamplingStrategy We Indetail,wedistillfromfourMTmodels: MT#1,
train transformer models with different combina-
Europarlv10,NewsCommentaryv15,andParaCrawlv5.1
6http://www.statmt.org/wmt20/ 7https://opus.nlpl.eu/
translation-task.html, including Common Crawl, OpenSubtitles2018.php
66MT#2
Dataset Size MT#1 MT#3 MT#4 MT#5
pretrain ﬁne-tune
WMT2020 13.7M P P / P / P
OpenSubtitles2018 10.7M P P / P P /
MuST-C 0.25M P P/BT/SR P/BT/SR P/SR/KD P/BT/SR P/BT/SR
iwslt-corpus 0.16M / P/BT/SR P/BT/SR P/SR/KD P/SR P/BT/SR
TED-LIUM3(EN) 0.11M / / / KD / /
CommonVoice(EN) 0.56M / / / KD / /
extramonolingual(EN/DE) 6.77M / / BT KD BT BT
Table 2: The statistics of MT datasets after data ﬁltering and the detailed combination modes of datasets for
difference MT models (MT#1-5). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 942>


<Paper ID = 942> <Table 2> <Abstractive Summary> =Thoughitmayresultinaslight
Table 5: The model setups. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 942>


<Paper ID = 942> <Table 3> <Abstractive Summary> =The
look-aheadbeamsearchachievesconsistentperfor-
10https://github.com/jniehues-kit/
manceimprovementwhenk issmallwhileits sacrebleu
eval
69# System dev tst-COM dev(v1) tst-COM(v1) Trainingdatacomposition
PureMT
1 MT(w/opunc.&lc) 32.0 34.1 32.2 34.0
2 MT(w/punc.&tc) 33.8 36.2 33.7 35.9
MT(seeTable2)
3 ensembleMT(w/opunc.&lc) 33.8 35.2 33.8 35.3
4 ensembleMT(w/punc.&tc) 34.7 36.7 34.6 36.2
CascadedASR→MT
5 AppTek/RWTH (Baharetal.,2020) - - - 29.7 /
6 ASR→MT 29.9 32.1 28.4 31.3 ASR+MT
7 ASR→ensembleMT 31.7 33.3 30.1 32.3 /
End-to-EndST
8 directSTbaseline 23.9 23.9 - - MuST-CONLY
9 directST 28.9 29.9 27.9 29.5 ST+STAugm.byMT#1&2
10 directST++ 29.6 30.4 28.3 29.7 STAll
11 directST++* 30.0 30.2 28.2 29.6 STAll
12 XSTNet-768(Yeetal.,2021) 30.4 31.1 - 30.3 ASR+MT+STAll
13 directST+fbank2vec-512 28.7 29.1 26.7 27.6 STAll
14 PMTL-ST+fbank2vec-768 29.6 29.6 26.9 28.1 ASR+MT+STAll
15 PMTL-ST+fbank2vec-768++ 30.8 31.1 28.8 30.1 ASR+MT+STAll+speedpertub
16 PMTL-ST+fbank2vec-768++* 30.9 31.1 28.8 30.1 ASR+MT+STAll+speedpertub
17 ensemble(9,10,11) 30.4 31.2 29.0 30.6 /
18 ensemble(15,16) 31.0 31.1 28.8 30.1 /
19 ensemble(14,15,16) 31.4 31.5 29.3 30.6 /
20 ensemble(13,14,15,16) 31.6 31.8 29.5 30.8 /
Table 6: The overall results of the ofﬂine speech translation. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 942>


<Paper ID = 942> <Table 4> <Abstractive Summary> =dev(v1) 10.6
tst-COMMON(v1) 7.4 Theresultsofourend-to-endsolutionsarepre-
sented in line 8-20, where line 8 is a benchmark
Table 7: The WER of the ASR system for the ofﬂine
model (Zhao et al., 2020) trained on the MuST-
ST.
C dataset only. </Abstractive Summary> <Extractive Summary> Thenumberofchannelskeepsthesameas
settings are presented in Table 4 and Table 5 re-
thedimensionoffbank2vecoutput.  </Extractive Summary>  </Table 4>  </Paper ID = 942>


<Paper ID = 942> <Table 5> <Abstractive Summary> =Low Medium High tst2021
#-System tst2020
ref2 ref1 both
Ensemble 25.86 31.73 33.21
EN→DE
+seg 28.75 32.87 32.97 7-Cascade(ensemble) 22.2 21.8 17.1 29.5
6-Cascade(single) 21.0 20.3 16.4 27.7
Ensemble 14.81 15.85 15.85
EN→JA
+seg 15.79 15.79 15.79 20-Direct(ensemble) 24.3 21.7 18.7 31.3
16-Direct(single) 23.5 21.6 18.2 30.6
17-Direct(ensemble) 22.4 21.1 17.5 29.2
Table 8: Performance of our ﬁnal submissions mod-
10-Direct(single) 21.6 20.4 17.0 28.1
elsonMuST-Ctst-COMMONforEnglish-Germanand
IWSLT21devsetforEnglish-Japanese. </Abstractive Summary> <Extractive Summary> Thenumberofchannelskeepsthesameas
settings are presented in Table 4 and Table 5 re-
thedimensionoffbank2vecoutput.  </Extractive Summary>  </Table 5>  </Paper ID = 942>


<Paper ID = 945> <Table 0> <Abstractive Summary> =Table 1: Data statistics of the ASR, MT, and ST cor- 3.2 Conformer
pora. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 945>


<Paper ID = 945> <Table 1> <Abstractive Summary> =3http://i13pc106.ira.uka.de/˜mmueller/iwslt-corpus.zip 4https://github.com/NiuTrans/MTBook
93Model tst-COMMON Data Corpora Size Time
Baseline 23.98 LibriSpeech 281241 960h
+Conformer 24.43 CommonVoice 1000000 1387h
+RPE 24.69 Synthetic MuST-C 249462 435h
+SATE 25.35 STTED 170133 254h
Total 1700836 3036h
Table 2: Effects of the architecture improvements. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 945>


<Paper ID = 945> <Table 2> <Abstractive Summary> =Usingthegivenseg-
Table 6: Final results with ensemble decoding. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 945>


<Paper ID = 946> <Table 0> <Abstractive Summary> =Speciﬁcally,wefoundthat ﬁrst observed the baseline Conformer model
104BLEU(↑)
Model
Must-C Must-Cv2 Must-C
tst2010 tst2015 tst2018 tst2019
dev tst-COMMON tst-COMMON Train
Base(Must-Conly) – 30.02 29.86 27.28 24.92 21.13 20.37
Base(WMT5M) 31.31 34.13 33.85 31.61 32.44 28.30 28.28 45.68
+Big 27.32 29.11 28.85 27.61 28.44 24.42 23.92 –
Base(WMT10M) 33.28 35.09 34.80 33.58 33.26 29.24 28.87 38.31
+In-domainﬁnetune 30.67 35.50 35.30 30.79 31.43 25.35 26.10 –
Base(WMT20M) 33.15 35.06 34.87 33.26 33.56 29.94 29.08 33.60
Table6: BLEUscoresoftext-basedMTsystems
BLEU(↑)
ID Model
Must-C Must-Cv2
tst2010 tst2015 tst2018 tst2019
dev tst-COMMON tst-HE tst-COMMON
BidirSeqKD(E2E)(Inagumaetal.,2021b) 25.67 27.01 25.36 – – – – –
Multi-Decoder(E2E)(Dalmiaetal.,2021) – 26.4 – – – – – –
RWTH(Cascade)(Baharetal.,2021) – 26.50 26.80 – – 28.4 – –
-
KIT(E2E)(Phametal.,2020) – 30.60 – – 24.27 21.82 – –
KIT(Cascade)(Phametal.,2020) – – – – 26.68 24.95 – –
SRPOL(E2E)(PotapczykandPrzybysz,2020) – – – – 29.44 24.6 – 23.96
A1 Baseline(X) 25.14 35.63 22.63 36.07 21.40 18.18 16.69 17.39
A2 +SeqKD(Y) 26.31 29.29 26.33 29.50 23.34 21.24 21.09 22.25
A3 +2refSeqKD(X+Y) 26.50 30.59 26.21 30.92 23.00 22.18 20.38 21.59
A4 +3refSeqKD(X+Y+Z) 27.66 30.90 27.44 31.07 24.97 22.66 22.20 23.41
B1 MD+2refSeqKD – 30.78 – – – – – 23.78
C1 ConformerASR→BaseMT(WMT10M) 27.01 29.42 26.13 29.75 25.04 23.17 23.05 23.19
Table 7: BLEU scores of ST systems. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 946>


<Paper ID = 946> <Table 1> <Abstractive Summary> =On the other hand, unlike our E4 B1,A4,A1,A3,A2 23.61
observationsin(Inagumaetal.,2021a,b),SeqKD
(A2-4) degraded the performance on the Must- Table 8: BLEU (↑) scores of ensembled E2E-ST sys-
C tst-COMMON set. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 946>


<Paper ID = 949> <Table 0> <Abstractive Summary> =Table 1: Summary of the English data-sets used for
speechrecognition
1 Introduction
Corpus Utterances Speechdata[h]
Asinpreviousyears,thecascadesystem’spipeline
A:TrainingData
is constituted by an ASR module, a text segmen-
MozillaCommonVoice 1225k 1667
tation module and a machine translation module. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 949>


<Paper ID = 949> <Table 1> <Abstractive Summary> =3.5.1 CascadeOfﬂineSpeechTranslation
Table 5: ST: Translation performance in BLEU↑ on
Speech Recognition. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 949>


<Paper ID = 95> <Table 0> <Abstractive Summary> =keyvectorsized =1, 2, and4, Weﬁndtheiden-
s k
The zero dimensional (left) null space of T con- tiﬁableTransformer’sperformanceiscomparable
1179Sizeofkeyvector(d )
Dataset Version k
1 2 4 8 16 32 64 128 256
Con 0.884 0.888 0.886 0.888 0.846 0.824 0.803 0.788 0.755
IMDB
Add 0.888 0.885 0.887 0.884 0.886 0.882 0.877 0.832 0.825
Con 0.836 0.836 0.840 0.822 0.823 0.764 0.786 0.706 0.737
TREC
Add 0.841 0.842 0.835 0.842 0.841 0.836 0.809 0.809 0.771
Con 0.643 0.625 0.627 0.609 0.603 0.582 0.574 0.573 0.554
SST
Add 0.599 0.618 0.628 0.633 0.628 0.629 0.592 0.581 0.586
Con 0.675 0.674 0.673 0.672 0.662 0.659 0.659 0.655 0.648
SNLI
Add 0.683 0.677 0.674 0.676 0.673 0.669 0.663 0.664 0.655
Con 0.913 0.911 0.907 0.898 0.879 0.862 0.857 0.849 0.837
Yelp
Add 0.914 0.915 0.916 0.914 0.915 0.916 0.910 0.909 0.891
Con 0.979 0.977 0.977 0.971 0.966 0.961 0.957 0.951 0.949
DBPedia
Add 0.979 0.978 0.979 0.977 0.978 0.973 0.970 0.969 0.964
Con 0.915 0.907 0.898 0.900 0.893 0.888 0.868 0.858 0.838
Sogou
Add 0.915 0.908 0.906 0.904 0.913 0.914 0.910 0.906 0.899
Con 0.906 0.903 0.904 0.904 0.886 0.877 0.870 0.870 0.869
AGNews
Add 0.902 0.908 0.907 0.906 0.897 0.899 0.901 0.897 0.893
Con 0.695 0.690 0.684 0.664 0.644 0.627 0.616 0.597 0.574
Yahoo
Add 0.697 0.695 0.696 0.693 0.693 0.694 0.688 0.649 0.683
Con 0.924 0.925 0.923 0.922 0.900 0.892 0.887 0.882 0.873
Amazon
Add 0.925 0.923 0.925 0.924 0.924 0.920 0.907 0.896 0.889
Table 1: The test accuracy on varied text classiﬁcation tasks spread over ten datasets. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 95>


<Paper ID = 950> <Table 0> <Abstractive Summary> =→en →es
Encoder Ave.
es fr pt it fr pt it
M4 XLSR-SPM 32.3 36.6 33.8 28.4 38.3 35.9 35.7 34.4
M6 VP100K-SPM 30.5 35.6 33.7 28.5 36.9 36.9 36.2 34.0
Table 6: Ablation studies of different encoders. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 950>


<Paper ID = 951> <Table 0> <Abstractive Summary> =Table 2: ASR performance in WER↓ (%) (lower-
The model is jointly trained on all four lan- cased,nopunctuation)ofthemultilingualASRsystem
guages. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 951>


<Paper ID = 951> <Table 1> <Abstractive Summary> =Cascaded C3 34.5 21.9 24.3 24.3 29.3 21.7 26.8 26.1
End-to-end E5 33.9 25.4 27.6 25.7 33.7 22.8 29.4 28.4
Table 6: Speech translation performance in BLEU↑ on the blind test set. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 951>


<Paper ID = 954> <Table 0> <Abstractive Summary> =Aftermultilingualtexttranslationhasbeen fr 30K 20K 116K - -
it - - - 50K -
established,therecentfocusisnaturallyshiftedto
pt - 30K - - 90K
multilingual speech translation especially with a
seriesofpublicspeechcorporawithmultipletrans-
Table 1: Data statistics for speech recogni-
lationbeingreleased(Iranzo-Sa´nchezetal.,2020;
tion/translationinthenumberofutterances. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 954>


<Paper ID = 954> <Table 1> <Abstractive Summary> =However,thecompetition Table 2: Data statistics for machine translation in the
betweentwomodelingschemessuggeststhateach numberofsentencepairs. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 954>


<Paper ID = 954> <Table 2> <Abstractive Summary> =GELU (Hendrycks and Gimpel, 2016) and
SiLU (Elfwing et al., 2018) are combined with Table 3: Comparison on Multilingual TEDx dataset
(WER↓). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 954>


<Paper ID = 954> <Table 3> <Abstractive Summary> =oftrainingdataforSLTsigniﬁcantly,especiallyfor
156Pair/Model TF +Rel +MCR +16L +ESB +DSF +ESB +DSF2
es-en 33.48 33.98 34.94 34.93 35.16 35.88 36.14 35.83
en-es 30.87 31.34 31.88 31.72 32.76 33.42 33.97 33.56
es-fr 40.65 41.40 41.19 41.26 42.06 42.87 43.57 43.12
fr-es 38.48 38.59 38.98 38.85 39.87 40.82 41.09 40.88
es-it 28.82 29.07 30.24 31.29 31.27 32.50 33.80 32.93
it-es 34.74 35.27 35.25 35.31 36.58 38.41 39.01 38.50
es-pt 43.04 43.40 43.65 43.53 44.30 44.96 45.40 45.03
pt-es 46.95 47.01 46.63 46.59 47.70 48.74 48.95 48.41
fr-en 38.29 38.62 39.64 39.53 40.32 41.09 41.65 40.93
en-fr 39.88 40.47 40.85 41.18 41.51 42.40 43.17 42.14
fr-pt 40.61 41.31 41.71 42.52 42.50 43.94 44.25 43.52
pt-fr 46.14 46.42 46.57 47.02 47.76 48.90 49.66 48.76
fr-pt 37.67 38.49 38.73 39.81 39.57 40.23 40.55 39.52
pt-fr 34.60 34.53 35.07 35.43 35.58 36.59 37.05 36.51
avg 38.16 38.56 38.95 39.21 39.78 40.76 41.3 40.68
+0.4 +0.29 +0.26 +0.57 +0.98 +0.54 -0.62
Table 4: IWSLT 2021 machine translation progressive results. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 954>


<Paper ID = 954> <Table 4> <Abstractive Summary> =Table 5: End-to-end speech translation results on pro-
gressivetestsets. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 4>  </Paper ID = 954>


<Paper ID = 955> <Table 0> <Abstractive Summary> =The ﬁnal acoustic input is 360-
It -/50K -/50K -/50K -/50K 50K/-
dimensional,aconcatenationofthefeaturescorre-
Table 1: Statistics for ST training data used for the spondingtothreeconsecutiveandnon-overlapping
IWSLT2021multilingualSTtask.“-”:denotesnodataavail- frames. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 955>


<Paper ID = 956> <Table 0> <Abstractive Summary> =MFCChires 19.90 29.57
wav2vec2.0 18.34 27.29 et al., 2021), in which there are four source lan-
guages(Spanish(es),French(fr),Portuguese(pt),
andItalian(it))andﬁvetargetlanguages(theafore-
Table 1: ASR performance (WER,%) for the develop-
mentioned source languages plus English (en)). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 956>


<Paper ID = 956> <Table 1> <Abstractive Summary> =Table 2: Ofﬁcial ASR performance (WER,%) for the 3.2 Modelarchitecture
testdatasetsofthelow-resourcetask. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 956>


<Paper ID = 957> <Table 0> <Abstractive Summary> =#11,average7checkpoints 17.8 19.6 18.7
Table 3: Datasets used to train the MT systems and
15. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 957>


<Paper ID = 957> <Table 1> <Abstractive Summary> =#13,externalLMweight0.7 13.8 19.9 16.9
For the text-to-text neural machine translation
Table 2: ASR results (WER, %) on the shared task (NMT) system we use a Transformer big model
validation data. </Abstractive Summary> <Extractive Summary> 2.1 Data
OurSpeech-to-Texttranslationsystemsaimtocon-
Table 1 summarizes the datasets used to develop
tributetothisglobaleffort.  </Extractive Summary>  </Table 1>  </Paper ID = 957>


<Paper ID = 958> <Table 0> <Abstractive Summary> =Table 2: Example of the effectiveness of post-
processinginhandlinginconsistentnumbertranslation. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 958>


<Paper ID = 958> <Table 1> <Abstractive Summary> =Totallycollectedcorpus PreparingforSelf-Training
commoncrawlEnglish 30,513,498 1 parallelEnglish 2.4M
2 parallelSwahili 2.4M
Cleanedcorpuswithcriteriain§2.6
3 monolingualEnglish 4.4M
indomainEnglish 10,000,000
4 monolingualSwahili 0.4M
Self-TrainingRound1
Table 5: Statistics of monolingual data for Tagged
5 syntheticparallel 9.6M
Back-Translation. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 958>


<Paper ID = 958> <Table 2> <Abstractive Summary> =In
Table 6: Data statistics for bidirectional self-training. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 958>


<Paper ID = 958> <Table 3> <Abstractive Summary> =WeempiricallyshowthatTransductiveFineTune
Table 8: Explanation of why Bidirectional Self- (§2.8)indeedimprovestheofﬁcialvalidationper-
Trainingworks. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 958>


<Paper ID = 959> <Table 0> <Abstractive Summary> =The model is a 5-layer Transformer
Table 2: BLEU scores of IWSLT De↔En, Es↔En,
withembeddingdimensionandfeed-forwardnet-
FLORESEn↔Ne,En↔Si,andWMTEn→De. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 959>


<Paper ID = 959> <Table 1> <Abstractive Summary> =Swap+mixSeq 34.73 28.98
3.3 Analysis
Mask 35.78 29.49
Mask+mixSeq 36.63 30.00 In this section, we conduct ablation study on the
usage of <sep> and the effect of concatenating
Table 3: Comparison and combination with data aug- morethantwosequences. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 959>


<Paper ID = 959> <Table 2> <Abstractive Summary> =ctxMixSeq 29.65 35.96
ctxMixSeq+2in 29.50 35.79 Dataset En→Ne Ne→En En→Si Si→En
ctxPS 29.26 35.48
D 4.28 7.68 1.21 6.68
ctxPS+2in 29.29 35.78 D∪Dˆ 5.26 8.38 1.49 7.71
ctxMixSeq+mixSeq 29.74 36.09 D∪Dˆ 5.39 8.88 2.08 7.50
3
D∪Dˆ∪Dˆ 5.43 8.25 2.21 7.47
3
Table 4: Results of context-aware versions of
mixSeqonIWSLT’14En↔De. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 959>


<Paper ID = 959> <Table 3> <Abstractive Summary> =Table 6: Results of concatenating various numbers of
sequences. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 959>


<Paper ID = 96> <Table 0> <Abstractive Summary> =Avg.#TestNoveltytri-gram(%) 68.20 84.44
Avg.#TestNoveltyfour-gram(%) 82.70 92.75 5.3 Systems
Avg.#Keywords(K) 0.20 0.12
Avg.#RetrievedUtterances(K) 854.8 731.3 We apply our data augmentation approach
Avg.#AugmentedPairs(K) 34.0 25.6 AUGNLGtotwobaselinesystems,
Avg.#Delex.MRsinAug.Pairs(K) 2.12 0.57
• FT-GPTGPT-2isdirectlyﬁne-tunedonthe
Table 1: Comparison of FEWSHOTWOZ and FEW-
SHOTSGD.Thebottomsectionshowsthestatisticsfor in-domainground-truthMR-to-Textdata. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 96>


<Paper ID = 96> <Table 1> <Abstractive Summary> =Table 5: Augmented data evaluation of MR Cov. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 96>


<Paper ID = 96> <Table 2> <Abstractive Summary> =Althoughwedonotseethesamepattern
MRCov↑ .59 .58 .74 .67 .81 .77 .88 .55
SLCov↑ .75 .67 .80 .75 .80 .78 .93 .71 on FEWSHOTWOZ, it could be attributed to the
largevarianceinthenumberofdelexicalizedMRs
Table 6: Augmented data evaluation of MR Cov. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 96>


<Paper ID = 960> <Table 0> <Abstractive Summary> =Themodel
5.1 Dataset istrainedusingAdamwithaninitiallearningrate
We conducted experiments for English to Italian 1https://github.com/mjpost/sacreBLEU
andSpanishtoEnglishNMT.ForEnglish-Italian, 2https://github.com/pytorch/fairseq
200STType System ASR-basedinput Cleaninput
ST+ASR-PT(DiGangietal.,2019b)1 16.8
ST+ASR-PT(ESPnet)2 21.5
End-to-end
ST 17.0
ST+ASR-PT 21.4
MT (DiGangietal.,2019b)1 18.9 -
clean
MT 22.4 29.7
clean
MT 22.1 27.2
asr
MT +FT 23.2 29.8
asr
Cascade
MT +KD 22.5 28.2
asr
MT +FT+KD 23.4 29.9
asr
MT +KD → FT 23.1 29.3
asr
MT +FT → KD 23.5 30.2
asr
Table 1: ST systems on MuST-C English-Italian. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 960>


<Paper ID = 961> <Table 0> <Abstractive Summary> =Table 1: Examples from WMT17 Chinese⇒English with distant recovery degrees measured by sentence-level
BLEUscore. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 961>


<Paper ID = 961> <Table 1> <Abstractive Summary> =23
Subset Range Average
21.75
D 17.72-100.00 35.62
1
D2 9.18-17.72 12.77 BLEU 20.5
D 5.16-9.18 6.97
3
D4 0.00-5.16 3.35 19.25
Baseline
SGCL Dynamic
Table 3: Range and average of recovery degree 18
0 20 40 60 80 100 120 140 160 180 200 220 240 260 280 300
(sentence-levelBLEU)insubsets{D ,D ,D ,D } Steps
1 2 3 4
(b)Baselinevs.SGCLDynamic
Figure4: Learningcurvesw.r.tBLEUscores. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 961>


<Paper ID = 962> <Table 0> <Abstractive Summary> =Table 2: Percentage of subtitle blocks containing the
Themeanabsoluteerrorbetweenthemanually samenumberoflinesforFrenchandGermanoutputs. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 962>


<Paper ID = 963> <Table 0> <Abstractive Summary> =128 254.5 304.5
4.1 Data
Table 3: Recorded hours of our SI corpus. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 963>


<Paper ID = 963> <Table 1> <Abstractive Summary> =F1
S-rank 2.95 2.48 S-rank 0.6544 0.6396 0.6465
A-rank 3.57 3.89 A-rank 0.5374 0.5221 0.5292
B-rank 3.46 2.79 B-rank 0.6238 0.6115 0.6171
Table 5: Comparison of EVS (seconds) among inter- Table 6: Comparison of BERTScores among inter-
preters with different amounts of experience. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 963>


<Paper ID = 963> <Table 2> <Abstractive Summary> =ofthehumanevaluatorsremarkedthatkeywords
On the other hand, as shown in the next exam- such as proper nouns were well translated or ap-
231Talk Interpreter BSPS
Ale S-rank 0.5671
0
(easy) A-rank 0.4316 4 S
B-rank 0.5871 ● ● ● A
((mdiefLNﬁdaiciucuumlt)) AABSS-----rrrrraaaaannnnnkkkkk 00000.....44333414767311110158 Bunsetsu length 0102030 ●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●● B
B-rank 0.3207
0 5000 15000
EVS (start)
Table 7: Comparison of BSPS among three talks and
interpreter’srank
Figure5: RelationshipbetweenEVS andthenum-
start
berofbunsetsusinSIs
propriately rephrased to corresponding Japanese
words. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 963>


<Paper ID = 963> <Table 3> <Abstractive Summary> =Onepossiblereasonis
Table 9: Correlation between human evaluations and
that the translators were strict about the sentence
qualitymetrics
structureinthesourcelanguage,asinthisexample:
(En) People are motivated by different
valuesperhaps. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 963>


<Paper ID = 964> <Table 0> <Abstractive Summary> =Thisapproachovercomes
Table 6: Results on 88 English videos from YouTube
translatedintoGerman.Nonewmodelsweretrainedin thetrain-testmismatchpresentinpreviousattempts
theseexperiments: themodelstrainedinTable5were totrainonlong-formASRoutputbyexposingMT
directlyevaluatedonthesevideos. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 964>


<Paper ID = 966> <Table 0> <Abstractive Summary> ={ner,upos}-multi
257Table 1: BLEU scores on word-tokenized sentences Table2: BLEUscoresforwordmodelswithPOStags. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 966>


<Paper ID = 966> <Table 1> <Abstractive Summary> =Adding
3baseline
4enhancedbaseline/ablationstudy inonlysource-sidetagembeddingscouldbecon-
5ablationstudy sidered an enhanced baseline, since this kind of
258Table3: BLEUscoresonsubword-tokenizedsentences Table 4: BLEU scores for subword models with or
withorwithoutnamedentities,formodelswithorwith- withoutPOStags. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 966>


<Paper ID = 967> <Table 0> <Abstractive Summary> =bewer@@t@@ungsin@@stru@@mente
2 Relatedwork
Table 1: Examples of unsatisfactory BPE splitting of
Germanwords. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 967>


<Paper ID = 967> <Table 1> <Abstractive Summary> =267Word BPE S-BPE
ungluecks unglu@@ecks unglueck@@s
anstehenden anstehenden an@@stehenden
vorlaeuﬁge vorlaeuﬁ@@ge vor@@laeuﬁge
gefangengenommen gefan@@gen@@genommen gefangen@@genommen
ﬁnanzdienstleistungen ﬁnanzdienstleistungen ﬁnanz@@dienstleistungen
Table 3: Segmentation examples of German words: S-BPE produces consistent segmentations of single and
compoundwords,whileBPEbreaksinsomecasesthemorphologicalstructureofwords. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 967>


<Paper ID = 967> <Table 2> <Abstractive Summary> =Table 5: Translation examples showing the impact of morphologically wrong segmentation by BPE and how
statisticalBPEavoidssucherrors. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 967>


<Paper ID = 968> <Table 0> <Abstractive Summary> =All experiments use
the decoder states interface for NAT-based integrated
Table 3: French→German dev set results using differ-
training. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 968>


<Paper ID = 969> <Table 0> <Abstractive Summary> =gl→en sk→en en→vi en→he average
dev test dev test dev test dev test dev ∆ test ∆
baseline 22.9 20.7 29.2 30.3 29.0 32.7 30.3 28.1 27.8 28.0
CONSEC 24.9 22.9† 30.3 31.5† 29.2 33.5† 30.6 28.6† 28.8 +1.0 29.1 +1.1
RAND 25.3 23.1† 30.3 31.6† 29.2 33.0 30.8 28.5† 28.9 +1.1 29.0 +1.0
Table 2: Consecutive (CONSEC) and random(RAND) concatenation givethe same BLEU improvementacross our
four low-resource language pairs. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 969>


<Paper ID = 969> <Table 1> <Abstractive Summary> =devBLEU
gl→en sk→en en→vi en→he avg
CONSEC 23.5 29.6 29.7 31.1 28.5
RAND 24.0 29.2 29.4 31.3 28.5
Table 3: Even when we concatenate consecutive sentence-pairs during translation, CONSEC does not outperform
RAND.AllBLEUscoresinthistablearecomputedonconcatenatedversionsofthedevsets,andsoarenotcompa-
rablewiththescoresinothertables. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 969>


<Paper ID = 969> <Table 2> <Abstractive Summary> =Row gl→en sk→en en→vi en→he avg ∆
1 baseline 22.9 29.2 29.0 30.3 27.8
2 baseline+sim-shift 22.7 29.8 29.0 30.4 28.0 +0.2
3 baseline+uniform-shift 23.8 29.8 29.3 30.5 28.4 +0.6
4 RAND 25.3 30.3 29.2 30.8 28.9 +1.1
5 RAND+uniform-shift 25.5 30.7 29.14 30.7 29.0 +1.2
Table 4: Position shifting improves accuracy somewhat, but the version of position shifting that mimics that of
concatenation(sim-shift)giveslessofanimprovementthanshiftingbydistancesuniformlysampledfrom[0,100]
(uniform-shift). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 969>


<Paper ID = 971> <Table 0> <Abstractive Summary> =0.82 0.49 0.59
Table 2: Statistics of the dataset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 971>


<Paper ID = 972> <Table 0> <Abstractive Summary> =RuShiftEval-3 0.597 0.632 1015 2
Thedatasetispubliclyavailable,includingthe
rawscoresassignedbyannotators.4
Table 1: RuShiftEval statistics. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 972>


<Paper ID = 973> <Table 0> <Abstractive Summary> =Theforegroundredplotshowsthecorrespond-
Table 2: OP-SGNS Parameters for the creation of the
wordembeddings. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 973>


<Paper ID = 975> <Table 0> <Abstractive Summary> =knowntochangeovertime,andcanoftenbeshort-
3http://lipad.ca
lived (Burridge, 2012), and as such we might ex-
4https://data.stanford.edu/congress t
pect the usage of a given euphemism to change ext
30Reddit NYT CanadianParliament USCongress
timespan 2006–2020 1987–2007 1951–2018 1951–2010
meanentriesperyear 8,138,844 88,365 40,756 138,105
initial%entriesbywomen 28% 9% 0.4% 0.6%
ﬁnal%entriesbywomen 39% 21% 24% 41%
Table 1: A summary of basic statistics for each corpus used in this study. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 975>


<Paper ID = 976> <Table 0> <Abstractive Summary> =The former two projects are also 
Table 1:  Text types of the GLAUx corpus. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 976>


<Paper ID = 976> <Table 1> <Abstractive Summary> =whether the lemma occurs 
in a list of pre-defined lemmas: for this I used the 
Table 2:  Tagging accuracy by genre. </Abstractive Summary> <Extractive Summary> Table 1 gives an overview of the 
efforts to add linguistic annotation.  </Extractive Summary>  </Table 1>  </Paper ID = 976>


<Paper ID = 976> <Table 2> <Abstractive Summary> =These results are higher than the state-of-
the-art reported in Vatri and McGillivray (2020),7 
Case  0.959 (136,764) 
but  the  high  accuracy  is  not  completely 
Gender  0.958 (136,764) 
unexpected, since in most cases only one option is 
Table 3:  Tagging accuracy by morphological  possible due to the morphological complexity of 
attribute. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 976>


<Paper ID = 976> <Table 3> <Abstractive Summary> =However, this role set was expanded and 
Polyhistory  0.969 (8,095) 
revised  to  be  compatible  with  a  number  of 
Lyric Poetry  0.967 (928) 
frameworks used for other languages as well (the 
Comedy  0.965 (4,650)  description  of  arguments  in  particular  remains 
rather underdeveloped in the Pedalion grammar), 
Table 4:  Lemmatization accuracy by genre. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 976>


<Paper ID = 977> <Table 0> <Abstractive Summary> =Therearethreedata ing on a language circle brings up the scrollable
ﬁles in JSON format, for reference metadata (in bibliographyforthatlanguage,witheachentryin
52Topic Count
overview(descriptivegrammars) 494
syntax 141
phonetics/phonology 125
historical 111
morphology 100
sociolinguistics 91
lexicography 83
corpora 51
dialectology 48
comparative 44
Total 1104
Figure 3: Map of all locations extracted from the
Table 1: Count of sources labelled under the top 10
sourcesintheBha¯s.a¯citradatabase. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 977>


<Paper ID = 979> <Table 0> <Abstractive Summary> =To test this hypothesis, we used the IT 3.59 4.10 5.04e-07
PT 3.45 3.92 3.72e-05
manuallabelsfortheEnglishcognatewordsasold
RO 2.33 2.93 1.36e-03
orrecentborrowingsandusedaMann-WhitneyU
Test on the two sets, to check whether the means Table 3: Average (log-)frequencies for old and recent
of the two groups are actually different, shown in Englishborrowingsandtheircognates. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 979>


<Paper ID = 979> <Table 1> <Abstractive Summary> =fork is illustrative for the
IT 2.07 3.35 7.49e-08
semantic divergence that affected the relationship
PT 3.16 4.00 0.02
betweenanearlyloanwordinCeltictakendirectly
Table 4: Average polysemy scores for old and recent fromLatinanditsRomancevirtualcognates. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 979>


<Paper ID = 98> <Table 0> <Abstractive Summary> =We then build models for other degenerativebehaviorsareobservedinothertext
1213Monolingual MT Multilingual
ROUGE DIST1 DIST2 ROUGE DIST1 DIST2 ROUGE DIST1 DIST2
EN .0543 .0341 .161 - - - .0412 .0352 .175
ES .0397 .0214 .182 .0270 .0261 .190 .0366 .0209 .175
DE .0469 .0332 .228 .0288 .0244 .142 .0454 .0321 .220
PT .0566 .0209 .194 .0276 .0221 .161 .0564 .0207 .190
FR .0446 .0207 .174 .0271 .0165 .109 .0428 .0211 .175
JA .0139 .1931 .245 .0042 .2812 .216 .0114 .0954 .179
IT .0493 .0322 .243 .0316 .0393 .240 .0295 .0312 .222
SV .0387 .0376 .236 .0369 .0359 .203 .0241 .0380 .227
NL .0377 .0337 .230 .0320 .0284 .162 .0233 .0334 .219
RU .0286 .0825 .349 .0238 .0310 .094 .0165 .0607 .224
Table 4: Results for generation model. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 98>


<Paper ID = 98> <Table 1> <Abstractive Summary> =1219A Resultsfor XLM-R
Monolingual Zero-Shot MT Multilingual
ROUGE Dist-1 Dist-2 ROUGE Dist-1 Dist-2 ROUGE Dist-1 Dist-2 ROUGE Dist-1 Dist-2
EN .0354 .0177 .0454 .0354 .0177 .0454 - - - .0319 .0152 .0398
ES .0158 .0069 .0172 .0140 .0065 .0160 .0122 .0079 .0181 .0155 .0076 .0182
DE .0179 .0098 .0261 .0141 .0064 .0162 .0132 .0071 .0170 .0171 .0069 .0170
PT .0345 .0088 .0239 .0126 .0076 .0209 .0120 .0071 .0178 .0332 .0086 .0230
FR .0161 .0062 .0168 .0143 .0066 .0177 .0135 .0073 .0184 .0161 .0069 .0185
JA .0271 .0132 .0364 .0181 .0097 .0277 .0157 .0106 .0293 .0166 .0123 .0328
IT .0157 .0123 .0291 .0144 .0123 .0306 .0155 .0156 .0375 .0143 .0136 .0337
SV .0172 .0129 .0333 .0165 .0133 .0333 .0153 .0140 .0341 .0168 .0125 .0321
NL .0171 .0142 .0390 .0161 .0134 .0371 .0155 .0134 .0353 .0162 .0135 .0370
RU .0128 .0259 .0541 .0123 .0223 .0467 .0111 .0248 .0506 .0130 .0244 .0510
Table 5: Results for retrieval model initialized with XLM-R (Conneau et al., 2020), The settings are in Sec-
tion3.2. </Abstractive Summary> <Extractive Summary> About one percent of examples are
Table 1 shows some dataset statistics.  </Extractive Summary>  </Table 1>  </Paper ID = 98>


<Paper ID = 982> <Table 0> <Abstractive Summary> =(2020) 74.42 75.07 71.83 66.05 61.51 69.45 49.76 55.39 61.20 71.82 71.11 70.19 67.95 62.20 66.28
Aux.language el el el el el el el el el el ur ur ur ur
Fine-tuningbaseline 75.42 75.77 72.57 67.22 61.08 70.23 51.70 51.03 64.26 71.61 72.52 69.97 69.16 55.40 66.28
Meta-Optimizer 75.78 75.87 73.15 67.34 62.00 70.47 51.22 50.54 63.96 72.06 72.32 70.20 69.34 55.88 66.44
Aux.language:el+ur
Fine-tuningbaseline 74.87 75.78 72.27 66.96 62.73 70.16 50.21 48.20 63.86 71.61 71.97 70.24 69.64 56.04 66.04
Meta-Optimizer 75.53 75.93 72.68 67.04 63.33 70.88 51.51 49.89 64.33 72.06 72.36 70.32 70.38 56.29 66.61
Table 1: Accuracy of our approach compared with baselines on the XNLI dataset (averaged over ﬁve runs). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 982>


<Paper ID = 983> <Table 0> <Abstractive Summary> =InconventionalZSCL,the
pairsaresplitintotwodisjointsetswith1200 Table 1: Conventional and Generalized Data Split for
MIT-StatesandZapposDatasets. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 983>


<Paper ID = 983> <Table 1> <Abstractive Summary> =3) walkametal.,2019),wemeasuretheperformance
AttOperator(NagarajanandGrauman,2018)mod- 3https://github.com/Tushar-N/attributes-as-operators
elscompositionbytreatingattributesasmatrixop- 4https://github.com/ucbdrive/tafe-net.git
24Mit-States UT-Zappos
ValAUC TestAUC ValAUC TestAUC
ModelTopk−→ 1 2 3 1 2 3 1 2 3 1 2 3
AttOperator 2.5 6.2 10.1 1.6 4.7 7.6 21.5 44.2 61.6 25.9 51.3 67.6
RedWine 2.9 7.3 11.8 2.4 5.7 9.3 30.4 52.2 63.5 27.1 54.6 68.8
LabelEmbed+ 3.0 7.6 12.2 2.0 5.6 9.4 26.4 49.0 66.1 25.7 52.1 67.8
TMN 3.5 8.1 12.4 2.9 7.1 11.5 36.8 57.1 69.2 29.3 55.3 69.8
SymNet 4.3 9.8 14.8 3.0 7.6 12.3 \ \ \ \ \ \
InductiveEpiCA 7.73 12.19 22.93 6.55 13.07 20.01 25.13 50.19 61.97 25.59 50.06 63.08
TransductiveEpiCA 9.01 17.63 24.01 7.18 14.02 21.31 53.18 68.71 77.89 35.04 54.83 70.02
Table 3: AUC in percentage (multiplied by 100) on MIT-States and UT-Zappos. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 983>


<Paper ID = 983> <Table 2> <Abstractive Summary> =The ex- -w/oGPandCA 14.13 48.76
perimentalresultsinTab.2andTab.3showtheim-
Table 4: Ablation study of EpiCA components. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 983>


<Paper ID = 984> <Table 0> <Abstractive Summary> =Table 1: Evaluations of multiple text style transfer
models on testing set of the listed data. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 984>


<Paper ID = 985> <Table 0> <Abstractive Summary> =encoder en es de zh ja pt fr hi tr
targetonly mBERT 98.54 97.31 98.43 97.09 97.20 97.54 98.88 90.93 83.36
mBERT+PNN(5w1s) 97.46 95.14 97.18 96.35 95.53 96.80 97.11 84.95 85.17
mBERT+PNN(5w10s) 98.77 96.97 98.54 97.0 96.64 97.42 97.98 91.33 89.33
multilingual mBERT 98.42 97.98 98.59 97.65 97.45 98.3 98.46 95.33 93.93
mBERT+PNN(5w1s) 95.33 93.71 95.93 95.89 94.42 94.00 94.78 91.4 90.91
mBERT+PNN(5w10s) 99.87 98.54 98.60 98.67 98.54 98.32 98.66 95.49 92.61
multilingual(zeroshot) mBERT 96.42 97.98 97.54 96.71 97.45 97.42 97.87 94.37 91.61
mBERT+PNN(5w1s) 93.73 92.02 93.27 95.62 91.73 93.51 93.28 90.51 89.92
mBERT+PNN(5w10s) 96.47 97.87 96.86 97.65 96.64 98.10 97.45 93.17 90.67
Table 2: Averaged intent accuracies obtained with PNNs on 5-way k-shot classiﬁcation k ∈ [1, 10] (best scores
aremarkedinbold)andbaselineresults. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 985>


<Paper ID = 986> <Table 0> <Abstractive Summary> =Algorithm Decoder MicroF1 Best#meta-epochs Best#epochs Trainingtime
SoftMax 61.04±5.23 N/A 10 01:33:44
Baseline
CRF 59.49±3.12 N/A 9 01:43:42
SoftMax 70.48±3.83 5 10 11:19:57
ProtoNet
CRF 73.65±2.92 8 5 14:53:58
SoftMax 71.88±2.19 8 3 13:57:09
Reptile
CRF 70.64±2.30 4 2 16:56:16
SoftMax 70.89±2.98 10 5 10:57:57
Proto-Reptile
CRF 76.18±4.22 6 8 24:18:03
Table 8: Best validation run found using Bayesian optimization. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 986>


<Paper ID = 988> <Table 0> <Abstractive Summary> =lar pre-trained model (e.g., BERT (Devlin et al.,
68N=5,K=5 N=5,K=10
Meta-Test Meta-Test Meta-Test Meta-Test
Dataset
Accuracy Std Accuracy Std
1.unseenexamples(banking) 0.935 0.044 0.940 0.042
2.unseenexamples 0.914 0.056 0.948 0.040
3.unseenclasses 0.883 0.060 0.917 0.049
4.unseendomains 0.870 0.066 0.908 0.055
Table 1: Meta test accuracy and standard deviations for ProtoNet on CLINC150 few shot intent classiﬁcation
dataset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 988>


<Paper ID = 988> <Table 1> <Abstractive Summary> =Table 3: Meta test accuracy changes with the number
ofavailablelabeleddataperclass Afterrunningfor800episodes,thetestaccuracyis
showninTable5. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 988>


<Paper ID = 988> <Table 2> <Abstractive Summary> =Approach Threshold OOSF1 OOSRecall OOSPrecision In-domainAccuracy
ProtoNet+BERT
0.4 0.471 0.772 0.339 0.723
(nometatraining)
ProtoNet+BERT 0.9 0.494 0.703 0.381 0.796
ProtoNet+BERT
0.9 0.601 0.787 0.487 0.856
+SMLMT
ProtoNet+RoBERTa
0.3 0.286 1.000 0.167 0.200
(nometatraining)
ProtoNet+RoBERTa 0.9 0.632 0.562 0.722 0.958
ProtoNet+RoBERTa
0.9 0.766 0.771 0.761 0.959
+SMLMT
Table 6: Evaluation statistics on OOS examples with N=5, K=10 respectively for protoNet with BERT and
RoBERTa
Figure1:Metatestaccuracyofapplyingfourdifferentmeta-learningapproacheswithK=5andK=10respectively. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 988>


<Paper ID = 989> <Table 0> <Abstractive Summary> =In our exper-
Table 1: Tag set mapping to the 6 basic emotions of
iments, we use various encoders to represent a
EmoTagSet3. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 989>


<Paper ID = 989> <Table 1> <Abstractive Summary> =Table 4: Average euclidean (l2) distance from queries
Wewantheretoinvestigatewhetherthedifﬁculty
topredictedemotionsusingourbestmodel(Tr.+Proto),
ofthismeta-learningtaskcomesfromvaryingtag
onGoEmotions(go)andDialyDialog(dd). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 989>


<Paper ID = 989> <Table 2> <Abstractive Summary> =Proto 66.24±18.2 66.09±18.0 60.43±21.9
References
Table 6: Meta learning trained on Empathetic Dia- Maruan Al-Shedivat, Liam Li, Eric Xing, and Ameet
logues (ED) before applying the model on DailyDia- Talwalkar. </Abstractive Summary> <Extractive Summary> 5 Results
SupervisedLearningtrainedonGoEmotions
testedonGoEmotions(valset–6ﬁlteredclasses)
Table 2 shows two main different result sets: the
Enc Clf Acc ± F1 ± MCC ±
onesobtainedusingsupervisedlearning,andthose
obtainedusingmeta-learning. Proto 61.7720.8 58.5524.1 58.8222.4
tom section of Table 2 shows two sets of results:
themeta-trainingphaseonGoEmotions(Demszky Fine-tuningmeta-learnedmodels
onGoEmotionstestset(1epochof10episodes)
et al., 2020a) using splits by emotion labels (the
EvalonDailyDialog’stestset(1,000episodes)
EmoTagSetsfromTable1)andevaluationofthese
Enc.  </Extractive Summary>  </Table 2>  </Paper ID = 989>


<Paper ID = 989> <Table 3> <Abstractive Summary> =token count token count
lol 576 reservation 267
f**k 248 madam 143
op 204 doesn 142
reddit 147 taxi 127
omg 145 courses 102
lmao 143 shipment 79
’’ 133 noon 50
congrats 115 aren 49
* 110 aisle 47
meme 106 exhibition 45
Table 8: Top 10 frequent nouns (SpaCy) exclusive Table 9: Top 10 frequent nouns (SpaCy) exclusive
toGoEmotions toDailyDialog
Figure3: GoEmotionsPOSdistribution(POStaggedus-Figure4: DailyDialogPOSdistribution(POStaggedus-
ingSpaCy) ingSpacy)
89 </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 3>  </Paper ID = 989>


<Paper ID = 99> <Table 0> <Abstractive Summary> =At the end of each Table 3: Inter-annotator agreement statistics for each
smallroundofwriting,thesubmittedexamplesare datatset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 99>


<Paper ID = 99> <Table 1> <Abstractive Summary> =Wealso EXPERT 81.3 56.8 52.4
tellthemwhatpercentageoftheirquestion-answer
pairs were labeled as having distracting answer Table 4: Zero-shot model accuracy on our datasets,
whentrainingonthedatasetsnamedinthecolumns. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 99>


<Paper ID = 99> <Table 2> <Abstractive Summary> =BASE JUST CROWD EXP Cross-val
BASE - 88.2 87.4 87.8 87.9(2.0)
JUST 84.9 - 85.3 84.9 85.6(2.4)
C Inter-AnnotatorAgreement CROWD 81.6 83.2 - 81.7 82.5(1.9)
EXPERT 80.6 81.2 81.7 - 82.8(1.4)
Table3showstheinter-annotatoragreementduring Table 5: Cross-protocol evaluation where the row and
datavalidationtaskforeachdataset. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 2>  </Paper ID = 99>


<Paper ID = 993> <Table 0> <Abstractive Summary> =noidiom 247 1135 1382 Moreover,whenidiomaticuseconstitutestheover-
whelmingly dominant use, such as ‘kenne meine
total 775 1367 Pappenheimer’(literal: ‘knowmyPappenheimers’,
roughly: ‘know the weak people (in my team)’),
Table 6: Confusion Matrix for prediction on idioms neitherCOnorSY_Wfeaturescancontribute. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 993>


<Paper ID = 994> <Table 0> <Abstractive Summary> =Thecross-
29SourceLanguage Targetlanguage Sourcedataset Targetdataset Model %Accuracy
MFC 54.3
EN-DEV RUSSIAN
mBERT 75.7±3.0
English Russian
MFC 54.3
EN-TEST RUSSIAN
mBERT 72.4±5.7
MFC 60.9
RUSSIAN EN-DEV CForm 73.6
mBERT 75.2±2.0
Russian English
MFC 63.3
RUSSIAN EN-TEST CForm 70.0
mBERT 80.1±1.3
Table 5: % accuracy and standard deviation for cross-lingual experiments from English to Russian (top panel)
andRussiantoEnglish(bottompanel)usingmBERT,amost-frequentclass(MFC)baseline,andforEnglish,the
unsupervisedCFormbaseline. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 994>


<Paper ID = 995> <Table 0> <Abstractive Summary> =Considering that automatic evaluation cannot The beneﬁt of the copy mechanism by explicitly
fullyanalyzetheresults,weusehumanevaluation retainingthecontextsasrequiredbyourtasks,is
39BLEU SARI GRUEN
Model
s2i i2s s2i i2s s2i i2s
Seq2Seq 25.16 42.96 24.13 33.89 32.25 33.45
Seq2Seqwithcopy 38.02 47.58 43.02 49.69 27.79 32.84
Transformer 45.58 46.65 36.67 38.62 44.05 44.06
Transformerwithcopy 59.56 57.91 39.93 45.10 59.27 52.25
PretrainedBART 79.32 78.53 62.30 61.82 77.49 78.03
Pipeline 65.56 70.03 67.64 62.45 67.27 74.16
Table 5: Automatic evaluation results for the task of idiomatic sentence generation (s2i) and idiomatic sentence
paraphrasing(i2s). </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 995>


<Paper ID = 995> <Table 1> <Abstractive Summary> =Table 11: Samples of generated idiomatic sentences. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 1>  </Paper ID = 995>


<Paper ID = 998> <Table 0> <Abstractive Summary> =LVCs of this Table 4: Preferences in the choice of causative light
typeexemplify(atleast)twodifferentsystematic verbs. </Abstractive Summary> <Extractive Summary>  </Extractive Summary>  </Table 0>  </Paper ID = 998>


